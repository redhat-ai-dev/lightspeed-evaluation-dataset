data:
- context:
  - '# Configuring dynamic plugins # Installing Ansible plug-ins for Red Hat Developer
    Hub Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific portal
    experience with curated learning paths, push-button content creation, integrated
    development tools, and other opinionated resources. Installing Ansible plug ins
    for Red Hat Developer Hub #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:14:24.202748'
    uuid: 07144e84-f3d8-4568-8bf3-de0c4ccc420e
  response: Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific
    portal experience with curated learning paths, push-button content creation, integrated
    development tools, and other opinionated resources.
  user_input: i am trying to install plugins for the Red Hat Developer Hub and i see
    this ansible stuff, what is the point of installing the ansible plug ins what
    do they do for the portal experience?
- context:
  - '# Configuring dynamic plugins # Installing Ansible plug-ins for Red Hat Developer
    Hub Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific portal
    experience with curated learning paths, push-button content creation, integrated
    development tools, and other opinionated resources. Installing Ansible plug ins
    for Red Hat Developer Hub #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:14:32.441457'
    uuid: 34db822d-0263-447a-97fa-7aa76f51a79e
  response: Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific
    portal experience that includes curated learning paths, push-button content creation,
    integrated development tools, and other opinionated resources.
  user_input: From a platform engineering perspective focused on streamlining developer
    workflows, what specific portal experience and resources are delivered by the
    Ansible plug-ins for Red Hat Developer Hub to enhance our unified platform?
- context:
  - '# Configuring dynamic plugins # Installing Ansible plug-ins for Red Hat Developer
    Hub Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific portal
    experience with curated learning paths, push-button content creation, integrated
    development tools, and other opinionated resources. Installing Ansible plug ins
    for Red Hat Developer Hub #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:14:39.883490'
    uuid: fa2e6520-44b0-4e6b-ad7f-b1dbe58493ce
  response: Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific
    portal experience that includes curated learning paths, push-button content creation,
    integrated development tools, and other opinionated resources.
  user_input: As a Platform Engineer responsible for our organization's Red Hat Developer
    Hub, what specific features and resources can I expect the Ansible plug-ins to
    deliver to create a specialized portal experience for our development teams?
- context:
  - "Installing and configuring Argo CD You can use the Argo CD plugin to visualize\
    \ the Continuous Delivery (CD) workflows in OpenShift GitOps. ## Enabling the\
    \ Argo CD plugin The Argo CD plugin provides a visual overview of the application\u2019\
    s status, deployment details, commit message, author of the commit, container\
    \ image promoted to environment and deployment history. Add Argo CD instance information\
    \ to your app config.yaml configmap as shown in the following example: ```yaml\
    \ argocd: appLocatorMethods: type: 'config' instances: name: argoInstance1 url:\
    \ https://argoInstance1.com username: ${ARGOCD_USERNAME} password: ${ARGOCD_PASSWORD}\
    \ name: argoInstance2 url: https://argoInstance2.com username: ${ARGOCD_USERNAME}\
    \ password: ${ARGOCD_PASSWORD} ``` [NOTE] ---- Avoid using a trailing slash in\
    \ the url, as it might cause unexpected behavior. ---- * Add the following annotation\
    \ to the entity\u2019s catalog-info.yaml file to identify the Argo CD applications.\
    \ ```yaml annotations: ... # The label that Argo CD uses to fetch all the applications.\
    \ The format to be used is label.key=label.value. For example, rht-gitops.com/janus-argocd=quarkus-app.\
    \ argocd/app selector: '${ARGOCD_LABEL_SELECTOR}' ``` (Optional) Add the following\
    \ annotation to the entity\u2019s catalog info.yaml file to switch between Argo\
    \ CD instances as shown in the following example: ```yaml annotations: ... # The\
    \ Argo CD instance name used in `app-config.yaml`. argocd/instance name: '${ARGOCD_INSTANCE}'\
    \ ``` [NOTE] ---- If you do not set this annotation, the Argo CD plugin defaults\
    \ to the first Argo CD instance configured in app-config.yaml. ---- Add the following\
    \ to your dynamic plugins ConfigMap to enable the Argo CD plugin. ```yaml global:\
    \ dynamic: includes: dynamic plugins.default.yaml plugins: package: ./dynamic\
    \ plugins/dist/roadiehq backstage plugin argo cd backend dynamic disabled: false\
    \ package: ./dynamic plugins/dist/backstage community plugin redhat argocd disabled:\
    \ false ``` ## Enabling Argo CD Rollouts The optional Argo CD Rollouts feature\
    \ enhances Kubernetes by providing advanced deployment strategies, such as blue-green\
    \ and canary deployments, for your applications. When integrated into the backstage\
    \ Kubernetes plugin, it allows developers and operations teams to visualize and\
    \ manage Argo CD Rollouts seamlessly within the Backstage interface. The Backstage\
    \ Kubernetes plugin (@backstage/plugin kubernetes) is installed and configured.\
    \ To install and configure Kubernetes plugin in Backstage, see Installaltion and\
    \ Configuration guide. You have access to the Kubernetes cluster with the necessary\
    \ permissions to create and manage custom resources and ClusterRoles. The Kubernetes\
    \ cluster has the argoproj.io group resources (for example, Rollouts and AnalysisRuns)\
    \ installed. 1. In the app-config.yaml file in your Backstage instance, add the\
    \ following customResources component under the kubernetes configuration to enable\
    \ Argo Rollouts and AnalysisRuns: ```yaml kubernetes: ... customResources: group:\
    \ 'argoproj.io' apiVersion: 'v1alpha1' plural: 'Rollouts' group: 'argoproj.io'\
    \ apiVersion: 'v1alpha1' plural: 'analysisruns' ``` 2. Grant ClusterRole permissions\
    \ for custom resources. [NOTE] ---- * If the Backstage Kubernetes plugin is already\
    \ configured, the ClusterRole permissions for Rollouts and AnalysisRuns might\
    \ already be granted. * Use the prepared manifest to provide read-only ClusterRole\
    \ access to both the Kubernetes and ArgoCD plugins. ---- 1. If the ClusterRole\
    \ permission is not granted, use the following YAML manifest to create the ClusterRole:\
    \ ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:\
    \ name: backstage read only rules: apiGroups: argoproj.io resources: rollouts\
    \ analysisruns verbs: get list ``` 1. Apply the manifest to the cluster using\
    \ kubectl: ```bash kubectl apply f <your clusterrole file>.yaml ``` 2. Ensure\
    \ the ServiceAccount accessing the cluster has this ClusterRole assigned. 3. Add\
    \ annotations to catalog-info.yaml to identify Kubernetes resources for Backstage.\
    \ 1. For identifying resources by entity ID: ```yaml annotations: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. (Optional) For identifying resources by namespace:\
    \ ```yaml annotations: ... backstage.io/kubernetes namespace: <RESOURCE_NAMESPACE>\
    \ ``` 3. For using custom label selectors, which override resource identification\
    \ by entity ID or namespace: ```yaml annotations: ... backstage.io/kubernetes\
    \ label selector: 'app=my app,component=front end' ``` [NOTE] ---- Ensure you\
    \ specify the labels declared in backstage.io/kubernetes-label-selector on your\
    \ Kubernetes resources. This annotation overrides entity-based or namespace-based\
    \ identification annotations, such as backstage.io/kubernetes-id and backstage.io/kubernetes-namespace.\
    \ ---- 4. Add label to Kubernetes resources to enable Backstage to find the appropriate\
    \ Kubernetes resources. 1. Backstage Kubernetes plugin label: Add this label to\
    \ map resources to specific Backstage entities. ```yaml labels: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. GitOps application mapping: Add this label\
    \ to map Argo CD Rollouts to a specific GitOps application ```yaml labels: ...\
    \ app.kubernetes.io/instance: <GITOPS_APPLICATION_NAME> ``` [NOTE] ---- If using\
    \ the label selector annotation (backstage.io/kubernetes-label-selector), ensure\
    \ the specified labels are present on the resources. The label selector will override\
    \ other annotations like kubernetes-id or kubernetes-namespace. ---- 1. Push the\
    \ updated configuration to your GitOps repository to trigger a rollout. 2. Open\
    \ Red Hat Developer Hub interface and navigate to the entity you configured. 3.\
    \ Select the CD tab and then select the GitOps application. The side panel opens.\
    \ 4. In the Resources table of the side panel, verify that the following resources\
    \ are displayed: * Rollouts * AnalysisRuns (optional) 5. Expand a rollout resource\
    \ and review the following details: * The Revisions row displays traffic distribution\
    \ details for different rollout versions. * The Analysis Runs row displays the\
    \ status of analysis tasks that evaluate rollout success. Installing and viewing\
    \ plugins in Red Hat Developer Hub #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:14:52.073653'
    uuid: 8dcc2fd4-8907-452b-993a-b8180f657e5f
  response: "To enable the Argo CD plugin, you must first add your Argo CD instance\
    \ information to your `app-config.yaml` configmap. Next, add the `argocd/app-selector`\
    \ annotation to the entity\u2019s `catalog-info.yaml` file to identify the Argo\
    \ CD applications. An optional annotation, `argocd/instance-name`, can be added\
    \ to switch between Argo CD instances; if this is not set, the plugin defaults\
    \ to the first instance configured in `app-config.yaml`. Finally, you must add\
    \ the package information for `roadiehq-backstage-plugin-argo-cd-backend-dynamic`\
    \ and `backstage-community-plugin-redhat-argocd` to your dynamic plugins ConfigMap\
    \ to enable the plugin."
  user_input: how to enable the Argo CD plugin for OpenShift GitOps
- context:
  - "Installing and configuring Argo CD You can use the Argo CD plugin to visualize\
    \ the Continuous Delivery (CD) workflows in OpenShift GitOps. ## Enabling the\
    \ Argo CD plugin The Argo CD plugin provides a visual overview of the application\u2019\
    s status, deployment details, commit message, author of the commit, container\
    \ image promoted to environment and deployment history. Add Argo CD instance information\
    \ to your app config.yaml configmap as shown in the following example: ```yaml\
    \ argocd: appLocatorMethods: type: 'config' instances: name: argoInstance1 url:\
    \ https://argoInstance1.com username: ${ARGOCD_USERNAME} password: ${ARGOCD_PASSWORD}\
    \ name: argoInstance2 url: https://argoInstance2.com username: ${ARGOCD_USERNAME}\
    \ password: ${ARGOCD_PASSWORD} ``` [NOTE] ---- Avoid using a trailing slash in\
    \ the url, as it might cause unexpected behavior. ---- * Add the following annotation\
    \ to the entity\u2019s catalog-info.yaml file to identify the Argo CD applications.\
    \ ```yaml annotations: ... # The label that Argo CD uses to fetch all the applications.\
    \ The format to be used is label.key=label.value. For example, rht-gitops.com/janus-argocd=quarkus-app.\
    \ argocd/app selector: '${ARGOCD_LABEL_SELECTOR}' ``` (Optional) Add the following\
    \ annotation to the entity\u2019s catalog info.yaml file to switch between Argo\
    \ CD instances as shown in the following example: ```yaml annotations: ... # The\
    \ Argo CD instance name used in `app-config.yaml`. argocd/instance name: '${ARGOCD_INSTANCE}'\
    \ ``` [NOTE] ---- If you do not set this annotation, the Argo CD plugin defaults\
    \ to the first Argo CD instance configured in app-config.yaml. ---- Add the following\
    \ to your dynamic plugins ConfigMap to enable the Argo CD plugin. ```yaml global:\
    \ dynamic: includes: dynamic plugins.default.yaml plugins: package: ./dynamic\
    \ plugins/dist/roadiehq backstage plugin argo cd backend dynamic disabled: false\
    \ package: ./dynamic plugins/dist/backstage community plugin redhat argocd disabled:\
    \ false ``` ## Enabling Argo CD Rollouts The optional Argo CD Rollouts feature\
    \ enhances Kubernetes by providing advanced deployment strategies, such as blue-green\
    \ and canary deployments, for your applications. When integrated into the backstage\
    \ Kubernetes plugin, it allows developers and operations teams to visualize and\
    \ manage Argo CD Rollouts seamlessly within the Backstage interface. The Backstage\
    \ Kubernetes plugin (@backstage/plugin kubernetes) is installed and configured.\
    \ To install and configure Kubernetes plugin in Backstage, see Installaltion and\
    \ Configuration guide. You have access to the Kubernetes cluster with the necessary\
    \ permissions to create and manage custom resources and ClusterRoles. The Kubernetes\
    \ cluster has the argoproj.io group resources (for example, Rollouts and AnalysisRuns)\
    \ installed. 1. In the app-config.yaml file in your Backstage instance, add the\
    \ following customResources component under the kubernetes configuration to enable\
    \ Argo Rollouts and AnalysisRuns: ```yaml kubernetes: ... customResources: group:\
    \ 'argoproj.io' apiVersion: 'v1alpha1' plural: 'Rollouts' group: 'argoproj.io'\
    \ apiVersion: 'v1alpha1' plural: 'analysisruns' ``` 2. Grant ClusterRole permissions\
    \ for custom resources. [NOTE] ---- * If the Backstage Kubernetes plugin is already\
    \ configured, the ClusterRole permissions for Rollouts and AnalysisRuns might\
    \ already be granted. * Use the prepared manifest to provide read-only ClusterRole\
    \ access to both the Kubernetes and ArgoCD plugins. ---- 1. If the ClusterRole\
    \ permission is not granted, use the following YAML manifest to create the ClusterRole:\
    \ ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:\
    \ name: backstage read only rules: apiGroups: argoproj.io resources: rollouts\
    \ analysisruns verbs: get list ``` 1. Apply the manifest to the cluster using\
    \ kubectl: ```bash kubectl apply f <your clusterrole file>.yaml ``` 2. Ensure\
    \ the ServiceAccount accessing the cluster has this ClusterRole assigned. 3. Add\
    \ annotations to catalog-info.yaml to identify Kubernetes resources for Backstage.\
    \ 1. For identifying resources by entity ID: ```yaml annotations: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. (Optional) For identifying resources by namespace:\
    \ ```yaml annotations: ... backstage.io/kubernetes namespace: <RESOURCE_NAMESPACE>\
    \ ``` 3. For using custom label selectors, which override resource identification\
    \ by entity ID or namespace: ```yaml annotations: ... backstage.io/kubernetes\
    \ label selector: 'app=my app,component=front end' ``` [NOTE] ---- Ensure you\
    \ specify the labels declared in backstage.io/kubernetes-label-selector on your\
    \ Kubernetes resources. This annotation overrides entity-based or namespace-based\
    \ identification annotations, such as backstage.io/kubernetes-id and backstage.io/kubernetes-namespace.\
    \ ---- 4. Add label to Kubernetes resources to enable Backstage to find the appropriate\
    \ Kubernetes resources. 1. Backstage Kubernetes plugin label: Add this label to\
    \ map resources to specific Backstage entities. ```yaml labels: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. GitOps application mapping: Add this label\
    \ to map Argo CD Rollouts to a specific GitOps application ```yaml labels: ...\
    \ app.kubernetes.io/instance: <GITOPS_APPLICATION_NAME> ``` [NOTE] ---- If using\
    \ the label selector annotation (backstage.io/kubernetes-label-selector), ensure\
    \ the specified labels are present on the resources. The label selector will override\
    \ other annotations like kubernetes-id or kubernetes-namespace. ---- 1. Push the\
    \ updated configuration to your GitOps repository to trigger a rollout. 2. Open\
    \ Red Hat Developer Hub interface and navigate to the entity you configured. 3.\
    \ Select the CD tab and then select the GitOps application. The side panel opens.\
    \ 4. In the Resources table of the side panel, verify that the following resources\
    \ are displayed: * Rollouts * AnalysisRuns (optional) 5. Expand a rollout resource\
    \ and review the following details: * The Revisions row displays traffic distribution\
    \ details for different rollout versions. * The Analysis Runs row displays the\
    \ status of analysis tasks that evaluate rollout success. Installing and viewing\
    \ plugins in Red Hat Developer Hub #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:00.654253'
    uuid: 1ec614a4-bf36-44c0-8cf7-1955be1f5faf
  response: "To enable the Argo CD plugin, you must add Argo CD instance information\
    \ to your `app-config.yaml` configmap. You also need to add an annotation to the\
    \ entity\u2019s `catalog-info.yaml` file, specifically `argocd/app-selector`,\
    \ to identify the Argo CD applications. An optional annotation, `argocd/instance-name`,\
    \ can be added to switch between Argo CD instances. Finally, you must add the\
    \ plugin configuration to your dynamic plugins ConfigMap, ensuring the packages\
    \ for the Argo CD plugin are not disabled."
  user_input: how i enable argo cd plugin for Backstage?
- context:
  - "Installing and configuring Argo CD You can use the Argo CD plugin to visualize\
    \ the Continuous Delivery (CD) workflows in OpenShift GitOps. ## Enabling the\
    \ Argo CD plugin The Argo CD plugin provides a visual overview of the application\u2019\
    s status, deployment details, commit message, author of the commit, container\
    \ image promoted to environment and deployment history. Add Argo CD instance information\
    \ to your app config.yaml configmap as shown in the following example: ```yaml\
    \ argocd: appLocatorMethods: type: 'config' instances: name: argoInstance1 url:\
    \ https://argoInstance1.com username: ${ARGOCD_USERNAME} password: ${ARGOCD_PASSWORD}\
    \ name: argoInstance2 url: https://argoInstance2.com username: ${ARGOCD_USERNAME}\
    \ password: ${ARGOCD_PASSWORD} ``` [NOTE] ---- Avoid using a trailing slash in\
    \ the url, as it might cause unexpected behavior. ---- * Add the following annotation\
    \ to the entity\u2019s catalog-info.yaml file to identify the Argo CD applications.\
    \ ```yaml annotations: ... # The label that Argo CD uses to fetch all the applications.\
    \ The format to be used is label.key=label.value. For example, rht-gitops.com/janus-argocd=quarkus-app.\
    \ argocd/app selector: '${ARGOCD_LABEL_SELECTOR}' ``` (Optional) Add the following\
    \ annotation to the entity\u2019s catalog info.yaml file to switch between Argo\
    \ CD instances as shown in the following example: ```yaml annotations: ... # The\
    \ Argo CD instance name used in `app-config.yaml`. argocd/instance name: '${ARGOCD_INSTANCE}'\
    \ ``` [NOTE] ---- If you do not set this annotation, the Argo CD plugin defaults\
    \ to the first Argo CD instance configured in app-config.yaml. ---- Add the following\
    \ to your dynamic plugins ConfigMap to enable the Argo CD plugin. ```yaml global:\
    \ dynamic: includes: dynamic plugins.default.yaml plugins: package: ./dynamic\
    \ plugins/dist/roadiehq backstage plugin argo cd backend dynamic disabled: false\
    \ package: ./dynamic plugins/dist/backstage community plugin redhat argocd disabled:\
    \ false ``` ## Enabling Argo CD Rollouts The optional Argo CD Rollouts feature\
    \ enhances Kubernetes by providing advanced deployment strategies, such as blue-green\
    \ and canary deployments, for your applications. When integrated into the backstage\
    \ Kubernetes plugin, it allows developers and operations teams to visualize and\
    \ manage Argo CD Rollouts seamlessly within the Backstage interface. The Backstage\
    \ Kubernetes plugin (@backstage/plugin kubernetes) is installed and configured.\
    \ To install and configure Kubernetes plugin in Backstage, see Installaltion and\
    \ Configuration guide. You have access to the Kubernetes cluster with the necessary\
    \ permissions to create and manage custom resources and ClusterRoles. The Kubernetes\
    \ cluster has the argoproj.io group resources (for example, Rollouts and AnalysisRuns)\
    \ installed. 1. In the app-config.yaml file in your Backstage instance, add the\
    \ following customResources component under the kubernetes configuration to enable\
    \ Argo Rollouts and AnalysisRuns: ```yaml kubernetes: ... customResources: group:\
    \ 'argoproj.io' apiVersion: 'v1alpha1' plural: 'Rollouts' group: 'argoproj.io'\
    \ apiVersion: 'v1alpha1' plural: 'analysisruns' ``` 2. Grant ClusterRole permissions\
    \ for custom resources. [NOTE] ---- * If the Backstage Kubernetes plugin is already\
    \ configured, the ClusterRole permissions for Rollouts and AnalysisRuns might\
    \ already be granted. * Use the prepared manifest to provide read-only ClusterRole\
    \ access to both the Kubernetes and ArgoCD plugins. ---- 1. If the ClusterRole\
    \ permission is not granted, use the following YAML manifest to create the ClusterRole:\
    \ ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:\
    \ name: backstage read only rules: apiGroups: argoproj.io resources: rollouts\
    \ analysisruns verbs: get list ``` 1. Apply the manifest to the cluster using\
    \ kubectl: ```bash kubectl apply f <your clusterrole file>.yaml ``` 2. Ensure\
    \ the ServiceAccount accessing the cluster has this ClusterRole assigned. 3. Add\
    \ annotations to catalog-info.yaml to identify Kubernetes resources for Backstage.\
    \ 1. For identifying resources by entity ID: ```yaml annotations: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. (Optional) For identifying resources by namespace:\
    \ ```yaml annotations: ... backstage.io/kubernetes namespace: <RESOURCE_NAMESPACE>\
    \ ``` 3. For using custom label selectors, which override resource identification\
    \ by entity ID or namespace: ```yaml annotations: ... backstage.io/kubernetes\
    \ label selector: 'app=my app,component=front end' ``` [NOTE] ---- Ensure you\
    \ specify the labels declared in backstage.io/kubernetes-label-selector on your\
    \ Kubernetes resources. This annotation overrides entity-based or namespace-based\
    \ identification annotations, such as backstage.io/kubernetes-id and backstage.io/kubernetes-namespace.\
    \ ---- 4. Add label to Kubernetes resources to enable Backstage to find the appropriate\
    \ Kubernetes resources. 1. Backstage Kubernetes plugin label: Add this label to\
    \ map resources to specific Backstage entities. ```yaml labels: ... backstage.io/kubernetes\
    \ id: <BACKSTAGE_ENTITY_NAME> ``` 2. GitOps application mapping: Add this label\
    \ to map Argo CD Rollouts to a specific GitOps application ```yaml labels: ...\
    \ app.kubernetes.io/instance: <GITOPS_APPLICATION_NAME> ``` [NOTE] ---- If using\
    \ the label selector annotation (backstage.io/kubernetes-label-selector), ensure\
    \ the specified labels are present on the resources. The label selector will override\
    \ other annotations like kubernetes-id or kubernetes-namespace. ---- 1. Push the\
    \ updated configuration to your GitOps repository to trigger a rollout. 2. Open\
    \ Red Hat Developer Hub interface and navigate to the entity you configured. 3.\
    \ Select the CD tab and then select the GitOps application. The side panel opens.\
    \ 4. In the Resources table of the side panel, verify that the following resources\
    \ are displayed: * Rollouts * AnalysisRuns (optional) 5. Expand a rollout resource\
    \ and review the following details: * The Revisions row displays traffic distribution\
    \ details for different rollout versions. * The Analysis Runs row displays the\
    \ status of analysis tasks that evaluate rollout success. Installing and viewing\
    \ plugins in Red Hat Developer Hub #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:10.477857'
    uuid: 5499543d-325d-41be-9bd6-581cb0706de0
  response: "To enable the Argo CD plugin for GitOps, you must add your Argo CD instance\
    \ information to your app-config.yaml configmap. You also need to add an annotation\
    \ to the entity\u2019s catalog-info.yaml file to identify the Argo CD applications\
    \ using `argocd/app-selector: '${ARGOCD_LABEL_SELECTOR}'`. The format for the\
    \ label is `label.key=label.value`. Finally, add the following to your dynamic\
    \ plugins ConfigMap to enable the plugin: `package: ./dynamic-plugins/dist/roadiehq-backstage-plugin-argo-cd-backend-dynamic`\
    \ with `disabled: false`, and `package: ./dynamic-plugins/dist/backstage-community-plugin-redhat-argocd`\
    \ with `disabled: false`."
  user_input: how to enable the argocd gitops plugn?
- context:
  - 'Enabling and configuring the Keycloak plugin The Keycloak backend plugin, which
    integrates Keycloak into Developer Hub, has the following capabilities: Synchronization
    of Keycloak users in a realm. Synchronization of Keycloak groups and their users
    in a realm. [NOTE] ---- The supported Red Hat Build of Keycloak (RHBK) version
    is 26.0. ---- ## Enabling the Keycloak plugin To enable the Keycloak plugin, you
    must set the following environment variables: KEYCLOAK_BASE_URL KEYCLOAK_LOGIN_REALM
    KEYCLOAK_REALM KEYCLOAK_CLIENT_ID KEYCLOAK_CLIENT_SECRET 1. The Keycloak plugin
    is pre-loaded in Developer Hub with basic configuration properties. To enable
    it, set the disabled property to false as follows: ```yaml global: dynamic: includes:
    dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin catalog backend module keycloak dynamic disabled: false ``` ##
    Configuring the Keycloak plugin 1. To configure the Keycloak plugin, add the following
    in your app-config.yaml file: schedule:: Configure the schedule frequency, timeout,
    and initial delay. The fields support cron, ISO duration, "human duration" as
    used in code. ```yaml catalog: providers: keycloakOrg: default: schedule: frequency:
    { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds: 15 } ``` userQuerySize
    and groupQuerySize:: Optionally, configure the Keycloak query parameters to define
    the number of users and groups to query at a time. Default values are 100 for
    both fields. ```yaml catalog: providers: keycloakOrg: default: userQuerySize:
    100 groupQuerySize: 100 ``` Authentication:: Communication between Developer Hub
    and Keycloak is enabled by using the Keycloak API. Username and password, or client
    credentials are supported authentication methods. The following table describes
    the parameters that you can configure to enable the plugin under catalog.providers.keycloakOrg.<ENVIRONMENT_NAME>
    object in the app-config.yaml file: 2. When using client credentials 1. Set the
    access type to confidential. 2. Enable service accounts. 3. Add the following
    roles from the realm-management client role: * query-groups * query-users * view-users
    3. Optionally, if you have self-signed or corporate certificate issues, you can
    set the following environment variable before starting Developer Hub: ``` NODE_TLS_REJECT_UNAUTHORIZED=0
    ``` [WARNING] ---- Setting the environment variable is not recommended. ---- ##
    Keycloack plugin metrics The Keycloak backend plugin supports OpenTelemetry metrics
    that you can use to monitor fetch operations and diagnose potential issues. ###
    Available Counters ### Labels All counters include the taskInstanceId label, which
    uniquely identifies each scheduled fetch task. You can use this label to trace
    failures back to individual task executions. Users can enter queries in the Prometheus
    UI or Grafana to explore and manipulate metric data. In the following examples,
    a Prometheus Query Language (PromQL) expression returns the number of backend
    failures. ``` backend_keycloak_fetch_data_batch_failure_count_total{taskInstanceId="df040f82
    2e80 44bd 83b0 06a984ca05ba"} 1 ``` ``` sum(backend_keycloak_fetch_data_batch_failure_count_total)
    sum(backend_keycloak_fetch_data_batch_failure_count_total offset 1h) ``` [NOTE]
    ---- PromQL supports arithmetic operations, comparison operators, logical/set
    operations, aggregation, and various functions. Users can combine these features
    to analyze time-series data effectively. Additionally, the results can be visualized
    using Grafana. ---- ### Exporting Metrics You can export metrics using any OpenTelemetry-compatible
    backend, such as Prometheus. OpenTelemetry Backstage OpenTelemetry setup guide
    # Enabling and configuring the Nexus Repository Manager plugin The Nexus Repository
    Manager plugin displays the information about your build artifacts in your Developer
    Hub application. The build artifacts are available in the Nexus Repository Manager.
    [IMPORTANT] ---- The Nexus Repository Manager plugin is a Technology Preview feature
    only. Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- ## Enabling the Nexus Repository
    Manager plugin The Nexus Repository Manager plugin is pre-loaded in Developer
    Hub with basic configuration properties. To enable it, set the disabled property
    to false as follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage community plugin nexus repository
    manager disabled: false ``` ## Configuring the Nexus Repository Manager plugin
    1. Set the proxy to the desired Nexus Repository Manager server in the app-config.yaml
    file as follows: ```yaml proxy: ''/nexus-repository-manager'': target: ''https://<NEXUS_REPOSITORY_MANAGER_URL>''
    headers: X-Requested-With: ''XMLHttpRequest'' # Uncomment the following line to
    access a private Nexus Repository Manager using a token # Authorization: ''Bearer
    <YOUR TOKEN>'' changeOrigin: true # Change to "false" in case of using self hosted
    Nexus Repository Manager instance with a self-signed certificate secure: true
    ``` 2. Optional: Change the base URL of Nexus Repository Manager proxy as follows:
    ```yaml nexusRepositoryManager: # default path is `/nexus-repository-manager`
    proxyPath: /custom-path ``` 3. Optional: Enable the following experimental annotations:
    ```yaml nexusRepositoryManager: experimentalAnnotations: true ``` 4. Annotate
    your entity using the following annotations: ```yaml metadata: annotations: #
    insert the chosen annotations here # example nexus-repository-manager/docker.image-name:
    `<ORGANIZATION>/<REPOSITORY>`, ``` # Enabling the Tekton plugin You can use the
    Tekton plugin to visualize the results of CI/CD pipeline runs on your Kubernetes
    or OpenShift clusters. The plugin allows users to visually see high level status
    of all associated tasks in the pipeline for their applications. You have installed
    and configured the @backstage/plugin kubernetes and @backstage/plugin kubernetes
    backend dynamic plugins. You have configured the Kubernetes plugin to connect
    to the cluster using a ServiceAccount. The ClusterRole must be granted for custom
    resources (PipelineRuns and TaskRuns) to the ServiceAccount accessing the cluster.
    [NOTE] ---- If you have the RHDH Kubernetes plugin configured, then the ClusterRole
    is already granted. ---- * To view the pod logs, you have granted permissions
    for pods/log. * You can use the following code to grant the ClusterRole for custom
    resources and pod logs: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion:
    ''v1'' ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:
    name: backstage read only rules: apiGroups: "" resources: pods/log verbs: get
    list watch ... apiGroups: tekton.dev resources: pipelineruns taskruns verbs: get
    list ``` You can use the prepared manifest for a read-only ClusterRole, which
    provides access for both Kubernetes plugin and Tekton plugin. * Add'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:18.119544'
    uuid: 490b4e7a-2ee0-445b-9bcc-91ab106e415f
  response: The Nexus Repository Manager plugin is a Technology Preview feature. Technology
    Preview features are not supported with Red Hat production service level agreements
    (SLAs), might not be functionally complete, and Red Hat does not recommend using
    them for production. The purpose of these features is to provide early access
    to upcoming product features, which enables customers to test functionality and
    provide feedback during the development process.
  user_input: What is the official Red Hat support policy for Technology Preview features,
    such as the Nexus Repository Manager plugin?
- context:
  - 'Enabling and configuring the Keycloak plugin The Keycloak backend plugin, which
    integrates Keycloak into Developer Hub, has the following capabilities: Synchronization
    of Keycloak users in a realm. Synchronization of Keycloak groups and their users
    in a realm. [NOTE] ---- The supported Red Hat Build of Keycloak (RHBK) version
    is 26.0. ---- ## Enabling the Keycloak plugin To enable the Keycloak plugin, you
    must set the following environment variables: KEYCLOAK_BASE_URL KEYCLOAK_LOGIN_REALM
    KEYCLOAK_REALM KEYCLOAK_CLIENT_ID KEYCLOAK_CLIENT_SECRET 1. The Keycloak plugin
    is pre-loaded in Developer Hub with basic configuration properties. To enable
    it, set the disabled property to false as follows: ```yaml global: dynamic: includes:
    dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin catalog backend module keycloak dynamic disabled: false ``` ##
    Configuring the Keycloak plugin 1. To configure the Keycloak plugin, add the following
    in your app-config.yaml file: schedule:: Configure the schedule frequency, timeout,
    and initial delay. The fields support cron, ISO duration, "human duration" as
    used in code. ```yaml catalog: providers: keycloakOrg: default: schedule: frequency:
    { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds: 15 } ``` userQuerySize
    and groupQuerySize:: Optionally, configure the Keycloak query parameters to define
    the number of users and groups to query at a time. Default values are 100 for
    both fields. ```yaml catalog: providers: keycloakOrg: default: userQuerySize:
    100 groupQuerySize: 100 ``` Authentication:: Communication between Developer Hub
    and Keycloak is enabled by using the Keycloak API. Username and password, or client
    credentials are supported authentication methods. The following table describes
    the parameters that you can configure to enable the plugin under catalog.providers.keycloakOrg.<ENVIRONMENT_NAME>
    object in the app-config.yaml file: 2. When using client credentials 1. Set the
    access type to confidential. 2. Enable service accounts. 3. Add the following
    roles from the realm-management client role: * query-groups * query-users * view-users
    3. Optionally, if you have self-signed or corporate certificate issues, you can
    set the following environment variable before starting Developer Hub: ``` NODE_TLS_REJECT_UNAUTHORIZED=0
    ``` [WARNING] ---- Setting the environment variable is not recommended. ---- ##
    Keycloack plugin metrics The Keycloak backend plugin supports OpenTelemetry metrics
    that you can use to monitor fetch operations and diagnose potential issues. ###
    Available Counters ### Labels All counters include the taskInstanceId label, which
    uniquely identifies each scheduled fetch task. You can use this label to trace
    failures back to individual task executions. Users can enter queries in the Prometheus
    UI or Grafana to explore and manipulate metric data. In the following examples,
    a Prometheus Query Language (PromQL) expression returns the number of backend
    failures. ``` backend_keycloak_fetch_data_batch_failure_count_total{taskInstanceId="df040f82
    2e80 44bd 83b0 06a984ca05ba"} 1 ``` ``` sum(backend_keycloak_fetch_data_batch_failure_count_total)
    sum(backend_keycloak_fetch_data_batch_failure_count_total offset 1h) ``` [NOTE]
    ---- PromQL supports arithmetic operations, comparison operators, logical/set
    operations, aggregation, and various functions. Users can combine these features
    to analyze time-series data effectively. Additionally, the results can be visualized
    using Grafana. ---- ### Exporting Metrics You can export metrics using any OpenTelemetry-compatible
    backend, such as Prometheus. OpenTelemetry Backstage OpenTelemetry setup guide
    # Enabling and configuring the Nexus Repository Manager plugin The Nexus Repository
    Manager plugin displays the information about your build artifacts in your Developer
    Hub application. The build artifacts are available in the Nexus Repository Manager.
    [IMPORTANT] ---- The Nexus Repository Manager plugin is a Technology Preview feature
    only. Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- ## Enabling the Nexus Repository
    Manager plugin The Nexus Repository Manager plugin is pre-loaded in Developer
    Hub with basic configuration properties. To enable it, set the disabled property
    to false as follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage community plugin nexus repository
    manager disabled: false ``` ## Configuring the Nexus Repository Manager plugin
    1. Set the proxy to the desired Nexus Repository Manager server in the app-config.yaml
    file as follows: ```yaml proxy: ''/nexus-repository-manager'': target: ''https://<NEXUS_REPOSITORY_MANAGER_URL>''
    headers: X-Requested-With: ''XMLHttpRequest'' # Uncomment the following line to
    access a private Nexus Repository Manager using a token # Authorization: ''Bearer
    <YOUR TOKEN>'' changeOrigin: true # Change to "false" in case of using self hosted
    Nexus Repository Manager instance with a self-signed certificate secure: true
    ``` 2. Optional: Change the base URL of Nexus Repository Manager proxy as follows:
    ```yaml nexusRepositoryManager: # default path is `/nexus-repository-manager`
    proxyPath: /custom-path ``` 3. Optional: Enable the following experimental annotations:
    ```yaml nexusRepositoryManager: experimentalAnnotations: true ``` 4. Annotate
    your entity using the following annotations: ```yaml metadata: annotations: #
    insert the chosen annotations here # example nexus-repository-manager/docker.image-name:
    `<ORGANIZATION>/<REPOSITORY>`, ``` # Enabling the Tekton plugin You can use the
    Tekton plugin to visualize the results of CI/CD pipeline runs on your Kubernetes
    or OpenShift clusters. The plugin allows users to visually see high level status
    of all associated tasks in the pipeline for their applications. You have installed
    and configured the @backstage/plugin kubernetes and @backstage/plugin kubernetes
    backend dynamic plugins. You have configured the Kubernetes plugin to connect
    to the cluster using a ServiceAccount. The ClusterRole must be granted for custom
    resources (PipelineRuns and TaskRuns) to the ServiceAccount accessing the cluster.
    [NOTE] ---- If you have the RHDH Kubernetes plugin configured, then the ClusterRole
    is already granted. ---- * To view the pod logs, you have granted permissions
    for pods/log. * You can use the following code to grant the ClusterRole for custom
    resources and pod logs: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion:
    ''v1'' ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:
    name: backstage read only rules: apiGroups: "" resources: pods/log verbs: get
    list watch ... apiGroups: tekton.dev resources: pipelineruns taskruns verbs: get
    list ``` You can use the prepared manifest for a read-only ClusterRole, which
    provides access for both Kubernetes plugin and Tekton plugin. * Add'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:27.207738'
    uuid: 24b12a74-5e2b-4460-a34d-77ccd14ed59a
  response: The Nexus Repository Manager plugin is a Technology Preview feature only.
    Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process.
  user_input: What is the support status of the Nexus Repository Manager plugin?
- context:
  - 'Enabling and configuring the Keycloak plugin The Keycloak backend plugin, which
    integrates Keycloak into Developer Hub, has the following capabilities: Synchronization
    of Keycloak users in a realm. Synchronization of Keycloak groups and their users
    in a realm. [NOTE] ---- The supported Red Hat Build of Keycloak (RHBK) version
    is 26.0. ---- ## Enabling the Keycloak plugin To enable the Keycloak plugin, you
    must set the following environment variables: KEYCLOAK_BASE_URL KEYCLOAK_LOGIN_REALM
    KEYCLOAK_REALM KEYCLOAK_CLIENT_ID KEYCLOAK_CLIENT_SECRET 1. The Keycloak plugin
    is pre-loaded in Developer Hub with basic configuration properties. To enable
    it, set the disabled property to false as follows: ```yaml global: dynamic: includes:
    dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin catalog backend module keycloak dynamic disabled: false ``` ##
    Configuring the Keycloak plugin 1. To configure the Keycloak plugin, add the following
    in your app-config.yaml file: schedule:: Configure the schedule frequency, timeout,
    and initial delay. The fields support cron, ISO duration, "human duration" as
    used in code. ```yaml catalog: providers: keycloakOrg: default: schedule: frequency:
    { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds: 15 } ``` userQuerySize
    and groupQuerySize:: Optionally, configure the Keycloak query parameters to define
    the number of users and groups to query at a time. Default values are 100 for
    both fields. ```yaml catalog: providers: keycloakOrg: default: userQuerySize:
    100 groupQuerySize: 100 ``` Authentication:: Communication between Developer Hub
    and Keycloak is enabled by using the Keycloak API. Username and password, or client
    credentials are supported authentication methods. The following table describes
    the parameters that you can configure to enable the plugin under catalog.providers.keycloakOrg.<ENVIRONMENT_NAME>
    object in the app-config.yaml file: 2. When using client credentials 1. Set the
    access type to confidential. 2. Enable service accounts. 3. Add the following
    roles from the realm-management client role: * query-groups * query-users * view-users
    3. Optionally, if you have self-signed or corporate certificate issues, you can
    set the following environment variable before starting Developer Hub: ``` NODE_TLS_REJECT_UNAUTHORIZED=0
    ``` [WARNING] ---- Setting the environment variable is not recommended. ---- ##
    Keycloack plugin metrics The Keycloak backend plugin supports OpenTelemetry metrics
    that you can use to monitor fetch operations and diagnose potential issues. ###
    Available Counters ### Labels All counters include the taskInstanceId label, which
    uniquely identifies each scheduled fetch task. You can use this label to trace
    failures back to individual task executions. Users can enter queries in the Prometheus
    UI or Grafana to explore and manipulate metric data. In the following examples,
    a Prometheus Query Language (PromQL) expression returns the number of backend
    failures. ``` backend_keycloak_fetch_data_batch_failure_count_total{taskInstanceId="df040f82
    2e80 44bd 83b0 06a984ca05ba"} 1 ``` ``` sum(backend_keycloak_fetch_data_batch_failure_count_total)
    sum(backend_keycloak_fetch_data_batch_failure_count_total offset 1h) ``` [NOTE]
    ---- PromQL supports arithmetic operations, comparison operators, logical/set
    operations, aggregation, and various functions. Users can combine these features
    to analyze time-series data effectively. Additionally, the results can be visualized
    using Grafana. ---- ### Exporting Metrics You can export metrics using any OpenTelemetry-compatible
    backend, such as Prometheus. OpenTelemetry Backstage OpenTelemetry setup guide
    # Enabling and configuring the Nexus Repository Manager plugin The Nexus Repository
    Manager plugin displays the information about your build artifacts in your Developer
    Hub application. The build artifacts are available in the Nexus Repository Manager.
    [IMPORTANT] ---- The Nexus Repository Manager plugin is a Technology Preview feature
    only. Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- ## Enabling the Nexus Repository
    Manager plugin The Nexus Repository Manager plugin is pre-loaded in Developer
    Hub with basic configuration properties. To enable it, set the disabled property
    to false as follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage community plugin nexus repository
    manager disabled: false ``` ## Configuring the Nexus Repository Manager plugin
    1. Set the proxy to the desired Nexus Repository Manager server in the app-config.yaml
    file as follows: ```yaml proxy: ''/nexus-repository-manager'': target: ''https://<NEXUS_REPOSITORY_MANAGER_URL>''
    headers: X-Requested-With: ''XMLHttpRequest'' # Uncomment the following line to
    access a private Nexus Repository Manager using a token # Authorization: ''Bearer
    <YOUR TOKEN>'' changeOrigin: true # Change to "false" in case of using self hosted
    Nexus Repository Manager instance with a self-signed certificate secure: true
    ``` 2. Optional: Change the base URL of Nexus Repository Manager proxy as follows:
    ```yaml nexusRepositoryManager: # default path is `/nexus-repository-manager`
    proxyPath: /custom-path ``` 3. Optional: Enable the following experimental annotations:
    ```yaml nexusRepositoryManager: experimentalAnnotations: true ``` 4. Annotate
    your entity using the following annotations: ```yaml metadata: annotations: #
    insert the chosen annotations here # example nexus-repository-manager/docker.image-name:
    `<ORGANIZATION>/<REPOSITORY>`, ``` # Enabling the Tekton plugin You can use the
    Tekton plugin to visualize the results of CI/CD pipeline runs on your Kubernetes
    or OpenShift clusters. The plugin allows users to visually see high level status
    of all associated tasks in the pipeline for their applications. You have installed
    and configured the @backstage/plugin kubernetes and @backstage/plugin kubernetes
    backend dynamic plugins. You have configured the Kubernetes plugin to connect
    to the cluster using a ServiceAccount. The ClusterRole must be granted for custom
    resources (PipelineRuns and TaskRuns) to the ServiceAccount accessing the cluster.
    [NOTE] ---- If you have the RHDH Kubernetes plugin configured, then the ClusterRole
    is already granted. ---- * To view the pod logs, you have granted permissions
    for pods/log. * You can use the following code to grant the ClusterRole for custom
    resources and pod logs: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion:
    ''v1'' ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata:
    name: backstage read only rules: apiGroups: "" resources: pods/log verbs: get
    list watch ... apiGroups: tekton.dev resources: pipelineruns taskruns verbs: get
    list ``` You can use the prepared manifest for a read-only ClusterRole, which
    provides access for both Kubernetes plugin and Tekton plugin. * Add'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:38.642910'
    uuid: 774d6f1f-7a9c-4fee-99d2-808866dd9981
  response: To use the Tekton plugin with Kubernetes, you must have the @backstage/plugin
    kubernetes and @backstage/plugin kubernetes backend dynamic plugins installed
    and configured. The Kubernetes plugin must be configured to connect to the cluster
    using a ServiceAccount, and a ClusterRole must be granted to that ServiceAccount
    for custom resources like PipelineRuns and TaskRuns. To view pod logs, you also
    need to have granted permissions for pods/log.
  user_input: what i need for tekton plugin with kubernetes?
- context:
  - 'the following annotation to the entity''s catalog-info.yaml file to identify
    whether an entity contains the Kubernetes resources: ```yaml annotations: ...
    backstage.io/kubernetes-id: <BACKSTAGE_ENTITY_NAME> ``` * You can also add the
    backstage.io/kubernetes-namespace annotation to identify the Kubernetes resources
    using the defined namespace. ```yaml annotations: ... backstage.io/kubernetes-namespace:
    <RESOURCE_NS> ``` * Add the following annotation to the catalog-info.yaml file
    of the entity to enable the Tekton related features in RHDH. The value of the
    annotation identifies the name of the RHDH entity: ```yaml annotations: ... janus-idp.io/tekton
    : <BACKSTAGE_ENTITY_NAME> ``` * Add a custom label selector, which RHDH uses to
    find the Kubernetes resources. The label selector takes precedence over the ID
    annotations. ```yaml annotations: ... backstage.io/kubernetes-label-selector:
    ''app=my-app,component=front-end'' ``` * Add the following label to the resources
    so that the Kubernetes plugin gets the Kubernetes resources from the requested
    entity: ```yaml labels: ... backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>
    ``` [NOTE] ---- When you use the label selector, the mentioned labels must be
    present on the resource. ---- The Tekton plugin is pre loaded in RHDH with basic
    configuration properties. To enable it, set the disabled property to false as
    follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage community plugin tekton disabled: false
    ``` # Installing the Topology plugin ### Installing the Topology plugin The Topology
    plugin enables you to visualize the workloads such as Deployment, Job, Daemonset,
    Statefulset, CronJob, Pods and Virtual Machines powering any service on your Kubernetes
    cluster. You have installed and configured the @backstage/plugin kubernetes backend
    dynamic plugins. You have configured the Kubernetes plugin to connect to the cluster
    using a ServiceAccount. The ClusterRole must be granted to ServiceAccount accessing
    the cluster. [NOTE] ---- If you have the Developer Hub Kubernetes plugin configured,
    then the ClusterRole is already granted. ---- The Topology plugin is pre loaded
    in Developer Hub with basic configuration properties. To enable it, set the disabled
    property to false as follows: app config.yaml fragment ```yaml auth: global: dynamic:
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin topology disabled: false ``` ## Configuring the Topology plugin
    ### Viewing OpenShift routes 1. To view OpenShift routes, grant read access to
    the routes resource in the Cluster Role: ```yaml apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: route.openshift.io
    resources: routes verbs: get list ``` 2. Also add the following in kubernetes.customResources
    property in your app-config.yaml file: ```yaml kubernetes: ... customResources:
    group: ''route.openshift.io'' apiVersion: ''v1'' plural: ''routes'' ``` ### Viewing
    pod logs To view pod logs, you must grant the following permission to the ClusterRole:
    ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name:
    backstage read only rules: ... apiGroups: '''' resources: pods pods/log verbs:
    get list watch ``` ### Viewing Tekton PipelineRuns 1. To view the Tekton PipelineRuns,
    grant read access to the pipelines, pipelinesruns, and taskruns resources in the
    ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: ... apiGroups: tekton.dev resources:
    pipelines pipelineruns taskruns verbs: get list ``` 2. To view the Tekton PipelineRuns
    list in the side panel and the latest PipelineRuns status in the Topology node
    decorator, add the following code to the kubernetes.customResources property in
    your app-config.yaml file: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelines'' group: ''tekton.dev'' apiVersion: ''v1''
    plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion: ''v1'' plural: ''taskruns''
    ``` ### Viewing virtual machines 1. The OpenShift Virtualization operator is installed
    and configured on a Kubernetes cluster. .Procedure 2. Grant read access to the
    VirtualMachines resource in the ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: kubevirt.io
    resources: virtualmachines virtualmachineinstances verbs: get list ``` 3. To view
    the virtual machine nodes on the topology plugin, add the following code to the
    kubernetes.customResources property in the app-config.yaml file: ```yaml kubernetes:
    ... customResources: group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachines''
    group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachineinstances''
    ``` ### Enabling the source code editor To enable the source code editor, you
    must grant read access to the CheClusters resource in the ClusterRole as shown
    in the following example code: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: org.eclipse.che
    resources: checlusters verbs: get list ``` To use the source code editor, you
    must add the following configuration to the kubernetes.customResources property
    in your app-config.yaml file: ```yaml kubernetes: ... customResources: group:
    ''org.eclipse.che'' apiVersion: ''v2'' plural: ''checlusters'' ``` ## Managing
    labels and annotations for Topology plugins ### Linking to the source code editor
    or the source Add the following annotations to workload resources, such as Deployments
    to navigate to the Git repository of the associated application using the source
    code editor: ```yaml annotations: app.openshift.io/vcs uri: <GIT_REPO_URL> ```
    Add the following annotation to navigate to a specific branch: ```yaml annotations:
    app.openshift.io/vcs ref: <GIT_REPO_BRANCH> ``` [NOTE] ---- If Red Hat OpenShift
    Dev Spaces is installed and configured and Git URL annotations are also added
    to the workload YAML file, then clicking on the edit code decorator redirects
    you to the Red Hat OpenShift Dev Spaces instance. ---- [NOTE] ---- When you deploy
    your application using the OCP Git import flows, then you do not need to add the
    labels as import flows do that. Otherwise, you need to add the labels manually
    to the workload YAML file. ---- You can also add the app.openshift.io/edit-link
    annotation with the edit URL that you want to access using the decorator. ###
    Entity annotation/label For RHDH to detect that an entity has Kubernetes components,
    add the following annotation to the catalog-info.yaml file of the entity: ```yaml
    annotations: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME> ``` Add the following
    label to the resources so that the Kubernetes plugin gets the Kubernetes resources
    from the requested entity: ```yaml labels: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>`
    ``` [NOTE] ---- When using the label selector, the mentioned labels must be present
    on the resource. ---- ### Namespace annotation To identify the Kubernetes resources
    using the defined namespace, add the backstage.io/kubernetes namespace annotation:
    ```yaml annotations: backstage.io/kubernetes namespace: <RESOURCE_NS> ``` The
    Red Hat OpenShift Dev Spaces instance is not accessible using the source code
    editor if the backstage.io/kubernetes-namespace annotation is added'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:15:47.758657'
    uuid: 359ce97d-311f-428c-9efb-ddbb5db6c194
  response: The Topology plugin enables you to visualize the workloads such as Deployment,
    Job, Daemonset, Statefulset, CronJob, Pods and Virtual Machines powering any service
    on your Kubernetes cluster.
  user_input: What kind of workloads can the Topolgy plugn vizualize on our Kubernetes
    cluster once its enabled?
- context:
  - 'the following annotation to the entity''s catalog-info.yaml file to identify
    whether an entity contains the Kubernetes resources: ```yaml annotations: ...
    backstage.io/kubernetes-id: <BACKSTAGE_ENTITY_NAME> ``` * You can also add the
    backstage.io/kubernetes-namespace annotation to identify the Kubernetes resources
    using the defined namespace. ```yaml annotations: ... backstage.io/kubernetes-namespace:
    <RESOURCE_NS> ``` * Add the following annotation to the catalog-info.yaml file
    of the entity to enable the Tekton related features in RHDH. The value of the
    annotation identifies the name of the RHDH entity: ```yaml annotations: ... janus-idp.io/tekton
    : <BACKSTAGE_ENTITY_NAME> ``` * Add a custom label selector, which RHDH uses to
    find the Kubernetes resources. The label selector takes precedence over the ID
    annotations. ```yaml annotations: ... backstage.io/kubernetes-label-selector:
    ''app=my-app,component=front-end'' ``` * Add the following label to the resources
    so that the Kubernetes plugin gets the Kubernetes resources from the requested
    entity: ```yaml labels: ... backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>
    ``` [NOTE] ---- When you use the label selector, the mentioned labels must be
    present on the resource. ---- The Tekton plugin is pre loaded in RHDH with basic
    configuration properties. To enable it, set the disabled property to false as
    follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage community plugin tekton disabled: false
    ``` # Installing the Topology plugin ### Installing the Topology plugin The Topology
    plugin enables you to visualize the workloads such as Deployment, Job, Daemonset,
    Statefulset, CronJob, Pods and Virtual Machines powering any service on your Kubernetes
    cluster. You have installed and configured the @backstage/plugin kubernetes backend
    dynamic plugins. You have configured the Kubernetes plugin to connect to the cluster
    using a ServiceAccount. The ClusterRole must be granted to ServiceAccount accessing
    the cluster. [NOTE] ---- If you have the Developer Hub Kubernetes plugin configured,
    then the ClusterRole is already granted. ---- The Topology plugin is pre loaded
    in Developer Hub with basic configuration properties. To enable it, set the disabled
    property to false as follows: app config.yaml fragment ```yaml auth: global: dynamic:
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin topology disabled: false ``` ## Configuring the Topology plugin
    ### Viewing OpenShift routes 1. To view OpenShift routes, grant read access to
    the routes resource in the Cluster Role: ```yaml apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: route.openshift.io
    resources: routes verbs: get list ``` 2. Also add the following in kubernetes.customResources
    property in your app-config.yaml file: ```yaml kubernetes: ... customResources:
    group: ''route.openshift.io'' apiVersion: ''v1'' plural: ''routes'' ``` ### Viewing
    pod logs To view pod logs, you must grant the following permission to the ClusterRole:
    ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name:
    backstage read only rules: ... apiGroups: '''' resources: pods pods/log verbs:
    get list watch ``` ### Viewing Tekton PipelineRuns 1. To view the Tekton PipelineRuns,
    grant read access to the pipelines, pipelinesruns, and taskruns resources in the
    ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: ... apiGroups: tekton.dev resources:
    pipelines pipelineruns taskruns verbs: get list ``` 2. To view the Tekton PipelineRuns
    list in the side panel and the latest PipelineRuns status in the Topology node
    decorator, add the following code to the kubernetes.customResources property in
    your app-config.yaml file: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelines'' group: ''tekton.dev'' apiVersion: ''v1''
    plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion: ''v1'' plural: ''taskruns''
    ``` ### Viewing virtual machines 1. The OpenShift Virtualization operator is installed
    and configured on a Kubernetes cluster. .Procedure 2. Grant read access to the
    VirtualMachines resource in the ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: kubevirt.io
    resources: virtualmachines virtualmachineinstances verbs: get list ``` 3. To view
    the virtual machine nodes on the topology plugin, add the following code to the
    kubernetes.customResources property in the app-config.yaml file: ```yaml kubernetes:
    ... customResources: group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachines''
    group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachineinstances''
    ``` ### Enabling the source code editor To enable the source code editor, you
    must grant read access to the CheClusters resource in the ClusterRole as shown
    in the following example code: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: org.eclipse.che
    resources: checlusters verbs: get list ``` To use the source code editor, you
    must add the following configuration to the kubernetes.customResources property
    in your app-config.yaml file: ```yaml kubernetes: ... customResources: group:
    ''org.eclipse.che'' apiVersion: ''v2'' plural: ''checlusters'' ``` ## Managing
    labels and annotations for Topology plugins ### Linking to the source code editor
    or the source Add the following annotations to workload resources, such as Deployments
    to navigate to the Git repository of the associated application using the source
    code editor: ```yaml annotations: app.openshift.io/vcs uri: <GIT_REPO_URL> ```
    Add the following annotation to navigate to a specific branch: ```yaml annotations:
    app.openshift.io/vcs ref: <GIT_REPO_BRANCH> ``` [NOTE] ---- If Red Hat OpenShift
    Dev Spaces is installed and configured and Git URL annotations are also added
    to the workload YAML file, then clicking on the edit code decorator redirects
    you to the Red Hat OpenShift Dev Spaces instance. ---- [NOTE] ---- When you deploy
    your application using the OCP Git import flows, then you do not need to add the
    labels as import flows do that. Otherwise, you need to add the labels manually
    to the workload YAML file. ---- You can also add the app.openshift.io/edit-link
    annotation with the edit URL that you want to access using the decorator. ###
    Entity annotation/label For RHDH to detect that an entity has Kubernetes components,
    add the following annotation to the catalog-info.yaml file of the entity: ```yaml
    annotations: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME> ``` Add the following
    label to the resources so that the Kubernetes plugin gets the Kubernetes resources
    from the requested entity: ```yaml labels: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>`
    ``` [NOTE] ---- When using the label selector, the mentioned labels must be present
    on the resource. ---- ### Namespace annotation To identify the Kubernetes resources
    using the defined namespace, add the backstage.io/kubernetes namespace annotation:
    ```yaml annotations: backstage.io/kubernetes namespace: <RESOURCE_NS> ``` The
    Red Hat OpenShift Dev Spaces instance is not accessible using the source code
    editor if the backstage.io/kubernetes-namespace annotation is added'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:16:00.232389'
    uuid: d31ca06b-9960-4aa1-ae24-3d19c7f2f2df
  response: 'To identify whether an entity contains Kubernetes resources, you add
    the `backstage.io/kubernetes-id: <BACKSTAGE_ENTITY_NAME>` annotation to the entity''s
    catalog-info.yaml file. You can also use the `backstage.io/kubernetes-namespace:
    <RESOURCE_NS>` annotation to identify resources by a defined namespace. Another
    method is to add a custom label selector with the `backstage.io/kubernetes-label-selector:
    ''app=my-app,component=front-end''` annotation, which takes precedence over ID
    annotations. Correspondingly, the Kubernetes resources must have the label `backstage.io/kubernetes
    id: <BACKSTAGE_ENTITY_NAME>` so that the Kubernetes plugin can retrieve them.'
  user_input: What are the various annotations and labels required to identify and
    link an entity's Kubernetes resources within Red Hat Developer Hub?
- context:
  - 'the following annotation to the entity''s catalog-info.yaml file to identify
    whether an entity contains the Kubernetes resources: ```yaml annotations: ...
    backstage.io/kubernetes-id: <BACKSTAGE_ENTITY_NAME> ``` * You can also add the
    backstage.io/kubernetes-namespace annotation to identify the Kubernetes resources
    using the defined namespace. ```yaml annotations: ... backstage.io/kubernetes-namespace:
    <RESOURCE_NS> ``` * Add the following annotation to the catalog-info.yaml file
    of the entity to enable the Tekton related features in RHDH. The value of the
    annotation identifies the name of the RHDH entity: ```yaml annotations: ... janus-idp.io/tekton
    : <BACKSTAGE_ENTITY_NAME> ``` * Add a custom label selector, which RHDH uses to
    find the Kubernetes resources. The label selector takes precedence over the ID
    annotations. ```yaml annotations: ... backstage.io/kubernetes-label-selector:
    ''app=my-app,component=front-end'' ``` * Add the following label to the resources
    so that the Kubernetes plugin gets the Kubernetes resources from the requested
    entity: ```yaml labels: ... backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>
    ``` [NOTE] ---- When you use the label selector, the mentioned labels must be
    present on the resource. ---- The Tekton plugin is pre loaded in RHDH with basic
    configuration properties. To enable it, set the disabled property to false as
    follows: ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage community plugin tekton disabled: false
    ``` # Installing the Topology plugin ### Installing the Topology plugin The Topology
    plugin enables you to visualize the workloads such as Deployment, Job, Daemonset,
    Statefulset, CronJob, Pods and Virtual Machines powering any service on your Kubernetes
    cluster. You have installed and configured the @backstage/plugin kubernetes backend
    dynamic plugins. You have configured the Kubernetes plugin to connect to the cluster
    using a ServiceAccount. The ClusterRole must be granted to ServiceAccount accessing
    the cluster. [NOTE] ---- If you have the Developer Hub Kubernetes plugin configured,
    then the ClusterRole is already granted. ---- The Topology plugin is pre loaded
    in Developer Hub with basic configuration properties. To enable it, set the disabled
    property to false as follows: app config.yaml fragment ```yaml auth: global: dynamic:
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    community plugin topology disabled: false ``` ## Configuring the Topology plugin
    ### Viewing OpenShift routes 1. To view OpenShift routes, grant read access to
    the routes resource in the Cluster Role: ```yaml apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: route.openshift.io
    resources: routes verbs: get list ``` 2. Also add the following in kubernetes.customResources
    property in your app-config.yaml file: ```yaml kubernetes: ... customResources:
    group: ''route.openshift.io'' apiVersion: ''v1'' plural: ''routes'' ``` ### Viewing
    pod logs To view pod logs, you must grant the following permission to the ClusterRole:
    ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name:
    backstage read only rules: ... apiGroups: '''' resources: pods pods/log verbs:
    get list watch ``` ### Viewing Tekton PipelineRuns 1. To view the Tekton PipelineRuns,
    grant read access to the pipelines, pipelinesruns, and taskruns resources in the
    ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: ... apiGroups: tekton.dev resources:
    pipelines pipelineruns taskruns verbs: get list ``` 2. To view the Tekton PipelineRuns
    list in the side panel and the latest PipelineRuns status in the Topology node
    decorator, add the following code to the kubernetes.customResources property in
    your app-config.yaml file: ```yaml kubernetes: ... customResources: group: ''tekton.dev''
    apiVersion: ''v1'' plural: ''pipelines'' group: ''tekton.dev'' apiVersion: ''v1''
    plural: ''pipelineruns'' group: ''tekton.dev'' apiVersion: ''v1'' plural: ''taskruns''
    ``` ### Viewing virtual machines 1. The OpenShift Virtualization operator is installed
    and configured on a Kubernetes cluster. .Procedure 2. Grant read access to the
    VirtualMachines resource in the ClusterRole: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: kubevirt.io
    resources: virtualmachines virtualmachineinstances verbs: get list ``` 3. To view
    the virtual machine nodes on the topology plugin, add the following code to the
    kubernetes.customResources property in the app-config.yaml file: ```yaml kubernetes:
    ... customResources: group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachines''
    group: ''kubevirt.io'' apiVersion: ''v1'' plural: ''virtualmachineinstances''
    ``` ### Enabling the source code editor To enable the source code editor, you
    must grant read access to the CheClusters resource in the ClusterRole as shown
    in the following example code: ```yaml ... apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole metadata: name: backstage read only rules: ... apiGroups: org.eclipse.che
    resources: checlusters verbs: get list ``` To use the source code editor, you
    must add the following configuration to the kubernetes.customResources property
    in your app-config.yaml file: ```yaml kubernetes: ... customResources: group:
    ''org.eclipse.che'' apiVersion: ''v2'' plural: ''checlusters'' ``` ## Managing
    labels and annotations for Topology plugins ### Linking to the source code editor
    or the source Add the following annotations to workload resources, such as Deployments
    to navigate to the Git repository of the associated application using the source
    code editor: ```yaml annotations: app.openshift.io/vcs uri: <GIT_REPO_URL> ```
    Add the following annotation to navigate to a specific branch: ```yaml annotations:
    app.openshift.io/vcs ref: <GIT_REPO_BRANCH> ``` [NOTE] ---- If Red Hat OpenShift
    Dev Spaces is installed and configured and Git URL annotations are also added
    to the workload YAML file, then clicking on the edit code decorator redirects
    you to the Red Hat OpenShift Dev Spaces instance. ---- [NOTE] ---- When you deploy
    your application using the OCP Git import flows, then you do not need to add the
    labels as import flows do that. Otherwise, you need to add the labels manually
    to the workload YAML file. ---- You can also add the app.openshift.io/edit-link
    annotation with the edit URL that you want to access using the decorator. ###
    Entity annotation/label For RHDH to detect that an entity has Kubernetes components,
    add the following annotation to the catalog-info.yaml file of the entity: ```yaml
    annotations: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME> ``` Add the following
    label to the resources so that the Kubernetes plugin gets the Kubernetes resources
    from the requested entity: ```yaml labels: backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>`
    ``` [NOTE] ---- When using the label selector, the mentioned labels must be present
    on the resource. ---- ### Namespace annotation To identify the Kubernetes resources
    using the defined namespace, add the backstage.io/kubernetes namespace annotation:
    ```yaml annotations: backstage.io/kubernetes namespace: <RESOURCE_NS> ``` The
    Red Hat OpenShift Dev Spaces instance is not accessible using the source code
    editor if the backstage.io/kubernetes-namespace annotation is added'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:16:09.159968'
    uuid: 9a16294b-ae95-493e-97c5-3f137ef79cd1
  response: 'To have RHDH detect that an entity has Kubernetes components, you can
    add the `backstage.io/kubernetes-id: <BACKSTAGE_ENTITY_NAME>` annotation to the
    entity''s catalog-info.yaml file. You can also use the `backstage.io/kubernetes-namespace`
    annotation to identify resources by a defined namespace. Another method is to
    add a custom label selector, such as `backstage.io/kubernetes-label-selector:
    ''app=my-app,component=front-end''`, which takes precedence over ID annotations.
    Additionally, you can add the `backstage.io/kubernetes id: <BACKSTAGE_ENTITY_NAME>`
    label to the resources themselves so the Kubernetes plugin can get the resources
    from the requested entity.'
  user_input: Backstage how to identify kubernetes resources
- context:
  - 'to the catalog-info.yaml file. To retrieve the instance URL, you require the
    CheCluster custom resource (CR). As the CheCluster CR is created in the openshift-devspaces
    namespace, the instance URL is not retrieved if the namespace annotation value
    is not openshift-devspaces. ### Label selector query annotation You can write
    your own custom label, which RHDH uses to find the Kubernetes resources. The label
    selector takes precedence over the ID annotations: ```yaml annotations: backstage.io/kubernetes
    label selector: ''app=my app,component=front end'' ``` If you have multiple entities
    while Red Hat Dev Spaces is configured and want multiple entities to support the
    edit code decorator that redirects to the Red Hat Dev Spaces instance, you can
    add the backstage.io/kubernetes-label-selector annotation to the catalog-info.yaml
    file for each entity. ```yaml annotations: backstage.io/kubernetes label selector:
    ''component in (<BACKSTAGE_ENTITY_NAME>,che)'' ``` If you are using the previous
    label selector, you must add the following labels to your resources so that the
    Kubernetes plugin gets the Kubernetes resources from the requested entity: ```yaml
    labels: component: che # add this label to your che cluster instance labels: component:
    <BACKSTAGE_ENTITY_NAME> # add this label to the other resources associated with
    your entity ``` You can also write your own custom query for the label selector
    with unique labels to differentiate your entities. However, you need to ensure
    that you add those labels to the resources associated with your entities including
    your CheCluster instance. ### Displaying icon in the node To display a runtime
    icon in the topology nodes, add the following label to workload resources, such
    as Deployments: ```yaml labels: app.openshift.io/runtime: <RUNTIME_NAME> ``` Alternatively,
    you can include the following label to display the runtime icon: ```yaml labels:
    app.kubernetes.io/name: <RUNTIME_NAME> ``` Supported values of <RUNTIME_NAME>
    include: django dotnet drupal go gopher golang grails jboss jruby js nginx nodejs
    openjdk perl phalcon php python quarkus rails redis rh spring boot rust java rh
    openjdk ruby spring spring boot [NOTE] ---- Other values result in icons not being
    rendered for the node. ---- ### App grouping To display workload resources such
    as deployments or pods in a visual group, add the following label: ```yaml labels:
    app.kubernetes.io/part of: <GROUP_NAME> ``` ### Node connector To display the
    workload resources such as deployments or pods with a visual connector, add the
    following annotation: ```yaml annotations: app.openshift.io/connects-to: ''[{"apiVersion":
    <RESOURCE_APIVERSION>,"kind": <RESOURCE_KIND>,"name": <RESOURCE_NAME>}]'' ```
    For more information about the labels and annotations, see Guidelines for labels
    and annotations for OpenShift applications. # Bulk importing in Red Hat Developer
    Hub [IMPORTANT] ---- These features are for Technology Preview only. Technology
    Preview features are not supported with Red Hat production service level agreements
    (SLAs), might not be functionally complete, and Red Hat does not recommend using
    them for production. These features provide early access to upcoming product features,
    enabling customers to test functionality and provide feedback during the development
    process. For more information on Red Hat Technology Preview features, see Technology
    Preview Features Scope. ---- Red Hat Developer Hub can automate the onboarding
    of GitHub repositories and GitLab projects, and track their import status. ##
    Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:16:19.934365'
    uuid: 620ce97e-de89-4f20-8f88-3714cffa2807
  response: Red Hat Developer Hub can automate the onboarding of GitLab projects and
    track their import status. This is accomplished through the Bulk Import feature,
    which is available for both GitLab projects and GitHub repositories. The Bulk
    Import page shows a list of added GitLab projects.
  user_input: What capability does Red Hat Developer Hub offer for automating the
    onboarding of GitLab projects to streamline our development workflows?
- context:
  - 'to the catalog-info.yaml file. To retrieve the instance URL, you require the
    CheCluster custom resource (CR). As the CheCluster CR is created in the openshift-devspaces
    namespace, the instance URL is not retrieved if the namespace annotation value
    is not openshift-devspaces. ### Label selector query annotation You can write
    your own custom label, which RHDH uses to find the Kubernetes resources. The label
    selector takes precedence over the ID annotations: ```yaml annotations: backstage.io/kubernetes
    label selector: ''app=my app,component=front end'' ``` If you have multiple entities
    while Red Hat Dev Spaces is configured and want multiple entities to support the
    edit code decorator that redirects to the Red Hat Dev Spaces instance, you can
    add the backstage.io/kubernetes-label-selector annotation to the catalog-info.yaml
    file for each entity. ```yaml annotations: backstage.io/kubernetes label selector:
    ''component in (<BACKSTAGE_ENTITY_NAME>,che)'' ``` If you are using the previous
    label selector, you must add the following labels to your resources so that the
    Kubernetes plugin gets the Kubernetes resources from the requested entity: ```yaml
    labels: component: che # add this label to your che cluster instance labels: component:
    <BACKSTAGE_ENTITY_NAME> # add this label to the other resources associated with
    your entity ``` You can also write your own custom query for the label selector
    with unique labels to differentiate your entities. However, you need to ensure
    that you add those labels to the resources associated with your entities including
    your CheCluster instance. ### Displaying icon in the node To display a runtime
    icon in the topology nodes, add the following label to workload resources, such
    as Deployments: ```yaml labels: app.openshift.io/runtime: <RUNTIME_NAME> ``` Alternatively,
    you can include the following label to display the runtime icon: ```yaml labels:
    app.kubernetes.io/name: <RUNTIME_NAME> ``` Supported values of <RUNTIME_NAME>
    include: django dotnet drupal go gopher golang grails jboss jruby js nginx nodejs
    openjdk perl phalcon php python quarkus rails redis rh spring boot rust java rh
    openjdk ruby spring spring boot [NOTE] ---- Other values result in icons not being
    rendered for the node. ---- ### App grouping To display workload resources such
    as deployments or pods in a visual group, add the following label: ```yaml labels:
    app.kubernetes.io/part of: <GROUP_NAME> ``` ### Node connector To display the
    workload resources such as deployments or pods with a visual connector, add the
    following annotation: ```yaml annotations: app.openshift.io/connects-to: ''[{"apiVersion":
    <RESOURCE_APIVERSION>,"kind": <RESOURCE_KIND>,"name": <RESOURCE_NAME>}]'' ```
    For more information about the labels and annotations, see Guidelines for labels
    and annotations for OpenShift applications. # Bulk importing in Red Hat Developer
    Hub [IMPORTANT] ---- These features are for Technology Preview only. Technology
    Preview features are not supported with Red Hat production service level agreements
    (SLAs), might not be functionally complete, and Red Hat does not recommend using
    them for production. These features provide early access to upcoming product features,
    enabling customers to test functionality and provide feedback during the development
    process. For more information on Red Hat Technology Preview features, see Technology
    Preview Features Scope. ---- Red Hat Developer Hub can automate the onboarding
    of GitHub repositories and GitLab projects, and track their import status. ##
    Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:16:27.055098'
    uuid: ce1fca91-7867-4f3f-a4e3-8196b48fc4da
  response: In Red Hat Developer Hub, you can select your GitHub repositories to automate
    their onboarding. First, click Bulk Import in the left sidebar. Then, click the
    Add button in the top-right corner to see a list of accessible repositories. From
    the Repositories view, you can select any repository, or from the Organizations
    view, you can select an organization to choose repositories from. After making
    selections, you can click Preview file to view or edit the pull request details
    for each repository, including the catalog-info.yaml file content. An optional
    step is to select the "Use CODEOWNERS file as Entity Owner" checkbox if the repository
    has a .github/CODEOWNERS file. Finally, click Create pull requests, which will
    run a set of dry-run checks before creating the pull requests.
  user_input: how do i bulk inport repos into Red Hat Develper Hub?
- context:
  - 'to the catalog-info.yaml file. To retrieve the instance URL, you require the
    CheCluster custom resource (CR). As the CheCluster CR is created in the openshift-devspaces
    namespace, the instance URL is not retrieved if the namespace annotation value
    is not openshift-devspaces. ### Label selector query annotation You can write
    your own custom label, which RHDH uses to find the Kubernetes resources. The label
    selector takes precedence over the ID annotations: ```yaml annotations: backstage.io/kubernetes
    label selector: ''app=my app,component=front end'' ``` If you have multiple entities
    while Red Hat Dev Spaces is configured and want multiple entities to support the
    edit code decorator that redirects to the Red Hat Dev Spaces instance, you can
    add the backstage.io/kubernetes-label-selector annotation to the catalog-info.yaml
    file for each entity. ```yaml annotations: backstage.io/kubernetes label selector:
    ''component in (<BACKSTAGE_ENTITY_NAME>,che)'' ``` If you are using the previous
    label selector, you must add the following labels to your resources so that the
    Kubernetes plugin gets the Kubernetes resources from the requested entity: ```yaml
    labels: component: che # add this label to your che cluster instance labels: component:
    <BACKSTAGE_ENTITY_NAME> # add this label to the other resources associated with
    your entity ``` You can also write your own custom query for the label selector
    with unique labels to differentiate your entities. However, you need to ensure
    that you add those labels to the resources associated with your entities including
    your CheCluster instance. ### Displaying icon in the node To display a runtime
    icon in the topology nodes, add the following label to workload resources, such
    as Deployments: ```yaml labels: app.openshift.io/runtime: <RUNTIME_NAME> ``` Alternatively,
    you can include the following label to display the runtime icon: ```yaml labels:
    app.kubernetes.io/name: <RUNTIME_NAME> ``` Supported values of <RUNTIME_NAME>
    include: django dotnet drupal go gopher golang grails jboss jruby js nginx nodejs
    openjdk perl phalcon php python quarkus rails redis rh spring boot rust java rh
    openjdk ruby spring spring boot [NOTE] ---- Other values result in icons not being
    rendered for the node. ---- ### App grouping To display workload resources such
    as deployments or pods in a visual group, add the following label: ```yaml labels:
    app.kubernetes.io/part of: <GROUP_NAME> ``` ### Node connector To display the
    workload resources such as deployments or pods with a visual connector, add the
    following annotation: ```yaml annotations: app.openshift.io/connects-to: ''[{"apiVersion":
    <RESOURCE_APIVERSION>,"kind": <RESOURCE_KIND>,"name": <RESOURCE_NAME>}]'' ```
    For more information about the labels and annotations, see Guidelines for labels
    and annotations for OpenShift applications. # Bulk importing in Red Hat Developer
    Hub [IMPORTANT] ---- These features are for Technology Preview only. Technology
    Preview features are not supported with Red Hat production service level agreements
    (SLAs), might not be functionally complete, and Red Hat does not recommend using
    them for production. These features provide early access to upcoming product features,
    enabling customers to test functionality and provide feedback during the development
    process. For more information on Red Hat Technology Preview features, see Technology
    Preview Features Scope. ---- Red Hat Developer Hub can automate the onboarding
    of GitHub repositories and GitLab projects, and track their import status. ##
    Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:16:35.483710'
    uuid: d4eb9034-0afc-426e-bd9c-8e0bae233faf
  response: To import multiple GitHub repositories, you must first click "Bulk Import"
    in the left sidebar. Then, click the "Add" button in the top-right corner, which
    will show a list of all repositories accessible from your configured GitHub integrations.
    You can select repositories directly from the "Repositories" view or go to the
    "Organizations" view to select an organization and then choose repositories from
    it. For each repository selected, a catalog-info.yaml is generated. You can then
    click "Preview file" to view or edit the pull request details. In this view, you
    can review the pull request description and the catalog-info.yaml content, and
    optionally select the "Use CODEOWNERS file as Entity Owner" checkbox if the repository
    has a .github/CODEOWNERS file. After clicking "Save", you can click "Create pull
    requests", which will run a set of dry-run checks before creating the pull requests.
  user_input: So for the developer hub we are building, how we can do the bulk import
    for all our GitHub repos, like what are the steps i need to do to get all the
    repositories from github into the catalog automatically?
- context:
  - 'created, and you are redirected to the list of added repositories. 5. Review
    and merge each pull request that creates a catalog-info.yml file. The Added entities
    list displays the repositories you imported, each with an appropriate status:
    either Waiting for approval or Added. For each Waiting for approval import job
    listed, there is a corresponding pull request adding the catalog info.yaml file
    in the corresponding repository. ## Importing multiple GitLab repositories In
    Red Hat Developer Hub, you can select your GitLab projects and automate their
    onboarding to the Developer Hub catalog. This feature is a Technology preview.
    [IMPORTANT] ---- Technology Preview features provide early access to upcoming
    product innovations, enabling you to test functionality and provide feedback during
    the development process. However, these features are not fully supported under
    Red Hat Subscription Level Agreements, may not be functionally complete, and are
    not intended for production use. As Red Hat considers making future iterations
    of Technology Preview features generally available, we will attempt to resolve
    any issues that customers experience when using these features. See: Technology
    Preview support scope. ---- You have include::modules/streamline software development
    and management/proc enabling and authorizing bulk import capabilities.adoc[enabled
    the Bulk Import feature and given access to it]. You have set up a GitLab personal
    access token (PAT). 1. In RHDH, click Bulk Import 2. Click Import. 3. Select GitLab
    as your Approval tool option. 4. Use the Project and Group views to see the list
    of all available GitLab projects and groups: * Use the Project view to select
    GitLab projects for importing. * Use the Group view to select GitLab groups and
    their associated projects for importing. 5. In GitLab, review the automatically
    created "Ad catalog-info.yaml file" merge request for each project you selected
    for Bulk Import. 6. Merge the merge request. 1. In RHDH, click Bulk Import 2.
    In the Imported entities list, each imported GitLab project has the appropriate
    status: either Waiting for approval or Added. * For each Waiting for approval
    import job listed, there is a corresponding merge request adding the catalog-info.yaml
    file in the corresponding project. ## Monitoring Bulk Import actions using audit
    logs The Bulk Import backend plugin adds the following events to the Developer
    Hub audit logs. See Audit logs in Red Hat Developer Hub for more information on
    how to configure and view audit logs. Bulk Import Events: BulkImportUnknownEndpoint::
    Tracks requests to unknown endpoints. BulkImportPing:: Tracks GET requests to
    the /ping endpoint, which allows us to make sure the bulk import backend is up
    and running. BulkImportFindAllOrganizations:: Tracks GET requests to the /organizations
    endpoint, which returns the list of organizations accessible from all configured
    GitHub Integrations. BulkImportFindRepositoriesByOrganization:: Tracks GET requests
    to the /organizations/:orgName/repositories endpoint, which returns the list of
    repositories for the specified organization (accessible from any of the configured
    GitHub Integrations). BulkImportFindAllRepositories:: Tracks GET requests to the
    /repositories endpoint, which returns the list of repositories accessible from
    all configured GitHub Integrations. BulkImportFindAllImports:: Tracks GET requests
    to the /imports endpoint, which returns the list of existing import jobs along
    with their statuses. BulkImportCreateImportJobs:: Tracks POST requests to the
    /imports endpoint, which allows to submit requests to bulk-import one or many
    repositories into the Developer Hub catalog, by eventually creating import pull
    requests in the target repositories. BulkImportFindImportStatusByRepo:: Tracks
    GET requests to the /import/by-repo endpoint, which fetches details about the
    import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:16:43.965535'
    uuid: fbd61a31-7bc0-4549-b73c-0bb0f0d6397f
  response: The feature in Red Hat Developer Hub to select GitLab projects and automate
    their onboarding to the Developer Hub catalog is a Technology Preview. Technology
    Preview features are not fully supported under Red Hat Subscription Level Agreements,
    may not be functionally complete, and are not intended for production use. They
    provide early access to upcoming product innovations to enable testing and feedback
    during the development process.
  user_input: What is the support status for the Red Hat Developer Hub feature that
    automates onboarding multiple GitLab repositories?
- context:
  - 'created, and you are redirected to the list of added repositories. 5. Review
    and merge each pull request that creates a catalog-info.yml file. The Added entities
    list displays the repositories you imported, each with an appropriate status:
    either Waiting for approval or Added. For each Waiting for approval import job
    listed, there is a corresponding pull request adding the catalog info.yaml file
    in the corresponding repository. ## Importing multiple GitLab repositories In
    Red Hat Developer Hub, you can select your GitLab projects and automate their
    onboarding to the Developer Hub catalog. This feature is a Technology preview.
    [IMPORTANT] ---- Technology Preview features provide early access to upcoming
    product innovations, enabling you to test functionality and provide feedback during
    the development process. However, these features are not fully supported under
    Red Hat Subscription Level Agreements, may not be functionally complete, and are
    not intended for production use. As Red Hat considers making future iterations
    of Technology Preview features generally available, we will attempt to resolve
    any issues that customers experience when using these features. See: Technology
    Preview support scope. ---- You have include::modules/streamline software development
    and management/proc enabling and authorizing bulk import capabilities.adoc[enabled
    the Bulk Import feature and given access to it]. You have set up a GitLab personal
    access token (PAT). 1. In RHDH, click Bulk Import 2. Click Import. 3. Select GitLab
    as your Approval tool option. 4. Use the Project and Group views to see the list
    of all available GitLab projects and groups: * Use the Project view to select
    GitLab projects for importing. * Use the Group view to select GitLab groups and
    their associated projects for importing. 5. In GitLab, review the automatically
    created "Ad catalog-info.yaml file" merge request for each project you selected
    for Bulk Import. 6. Merge the merge request. 1. In RHDH, click Bulk Import 2.
    In the Imported entities list, each imported GitLab project has the appropriate
    status: either Waiting for approval or Added. * For each Waiting for approval
    import job listed, there is a corresponding merge request adding the catalog-info.yaml
    file in the corresponding project. ## Monitoring Bulk Import actions using audit
    logs The Bulk Import backend plugin adds the following events to the Developer
    Hub audit logs. See Audit logs in Red Hat Developer Hub for more information on
    how to configure and view audit logs. Bulk Import Events: BulkImportUnknownEndpoint::
    Tracks requests to unknown endpoints. BulkImportPing:: Tracks GET requests to
    the /ping endpoint, which allows us to make sure the bulk import backend is up
    and running. BulkImportFindAllOrganizations:: Tracks GET requests to the /organizations
    endpoint, which returns the list of organizations accessible from all configured
    GitHub Integrations. BulkImportFindRepositoriesByOrganization:: Tracks GET requests
    to the /organizations/:orgName/repositories endpoint, which returns the list of
    repositories for the specified organization (accessible from any of the configured
    GitHub Integrations). BulkImportFindAllRepositories:: Tracks GET requests to the
    /repositories endpoint, which returns the list of repositories accessible from
    all configured GitHub Integrations. BulkImportFindAllImports:: Tracks GET requests
    to the /imports endpoint, which returns the list of existing import jobs along
    with their statuses. BulkImportCreateImportJobs:: Tracks POST requests to the
    /imports endpoint, which allows to submit requests to bulk-import one or many
    repositories into the Developer Hub catalog, by eventually creating import pull
    requests in the target repositories. BulkImportFindImportStatusByRepo:: Tracks
    GET requests to the /import/by-repo endpoint, which fetches details about the
    import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:16:52.616286'
    uuid: 7b8526db-0e65-4a76-b82d-3ef2ff4b70ca
  response: The feature in Red Hat Developer Hub to select your GitLab projects and
    automate their onboarding to the Developer Hub catalog is a Technology Preview.
    Technology Preview features are not fully supported under Red Hat Subscription
    Level Agreements, may not be functionally complete, and are not intended for production
    use. They provide early access to upcoming product innovations, allowing you to
    test functionality and provide feedback. Red Hat will attempt to resolve any issues
    that customers experience when using these features as they consider making future
    iterations generally available.
  user_input: What is the support level under Red Hat Subscription Level Agreements
    for the Technology Preview feature that allows bulk importing of multiple GitLab
    repositories in Red Hat Developer Hub?
- context:
  - 'created, and you are redirected to the list of added repositories. 5. Review
    and merge each pull request that creates a catalog-info.yml file. The Added entities
    list displays the repositories you imported, each with an appropriate status:
    either Waiting for approval or Added. For each Waiting for approval import job
    listed, there is a corresponding pull request adding the catalog info.yaml file
    in the corresponding repository. ## Importing multiple GitLab repositories In
    Red Hat Developer Hub, you can select your GitLab projects and automate their
    onboarding to the Developer Hub catalog. This feature is a Technology preview.
    [IMPORTANT] ---- Technology Preview features provide early access to upcoming
    product innovations, enabling you to test functionality and provide feedback during
    the development process. However, these features are not fully supported under
    Red Hat Subscription Level Agreements, may not be functionally complete, and are
    not intended for production use. As Red Hat considers making future iterations
    of Technology Preview features generally available, we will attempt to resolve
    any issues that customers experience when using these features. See: Technology
    Preview support scope. ---- You have include::modules/streamline software development
    and management/proc enabling and authorizing bulk import capabilities.adoc[enabled
    the Bulk Import feature and given access to it]. You have set up a GitLab personal
    access token (PAT). 1. In RHDH, click Bulk Import 2. Click Import. 3. Select GitLab
    as your Approval tool option. 4. Use the Project and Group views to see the list
    of all available GitLab projects and groups: * Use the Project view to select
    GitLab projects for importing. * Use the Group view to select GitLab groups and
    their associated projects for importing. 5. In GitLab, review the automatically
    created "Ad catalog-info.yaml file" merge request for each project you selected
    for Bulk Import. 6. Merge the merge request. 1. In RHDH, click Bulk Import 2.
    In the Imported entities list, each imported GitLab project has the appropriate
    status: either Waiting for approval or Added. * For each Waiting for approval
    import job listed, there is a corresponding merge request adding the catalog-info.yaml
    file in the corresponding project. ## Monitoring Bulk Import actions using audit
    logs The Bulk Import backend plugin adds the following events to the Developer
    Hub audit logs. See Audit logs in Red Hat Developer Hub for more information on
    how to configure and view audit logs. Bulk Import Events: BulkImportUnknownEndpoint::
    Tracks requests to unknown endpoints. BulkImportPing:: Tracks GET requests to
    the /ping endpoint, which allows us to make sure the bulk import backend is up
    and running. BulkImportFindAllOrganizations:: Tracks GET requests to the /organizations
    endpoint, which returns the list of organizations accessible from all configured
    GitHub Integrations. BulkImportFindRepositoriesByOrganization:: Tracks GET requests
    to the /organizations/:orgName/repositories endpoint, which returns the list of
    repositories for the specified organization (accessible from any of the configured
    GitHub Integrations). BulkImportFindAllRepositories:: Tracks GET requests to the
    /repositories endpoint, which returns the list of repositories accessible from
    all configured GitHub Integrations. BulkImportFindAllImports:: Tracks GET requests
    to the /imports endpoint, which returns the list of existing import jobs along
    with their statuses. BulkImportCreateImportJobs:: Tracks POST requests to the
    /imports endpoint, which allows to submit requests to bulk-import one or many
    repositories into the Developer Hub catalog, by eventually creating import pull
    requests in the target repositories. BulkImportFindImportStatusByRepo:: Tracks
    GET requests to the /import/by-repo endpoint, which fetches details about the
    import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:17:00.741052'
    uuid: eb48a976-a178-4ecf-993f-a2df92b76d9c
  response: 'The Bulk Import backend plugin adds the following events to the Developer
    Hub audit logs: BulkImportUnknownEndpoint, which tracks requests to unknown endpoints;
    BulkImportPing, which tracks GET requests to the /ping endpoint; BulkImportFindAllOrganizations,
    which tracks GET requests to the /organizations endpoint; BulkImportFindRepositoriesByOrganization,
    which tracks GET requests to the /organizations/:orgName/repositories endpoint;
    BulkImportFindAllRepositories, which tracks GET requests to the /repositories
    endpoint; BulkImportFindAllImports, which tracks GET requests to the /imports
    endpoint; BulkImportCreateImportJobs, which tracks POST requests to the /imports
    endpoint; BulkImportFindImportStatusByRepo, which tracks GET requests to the /import/by-repo
    endpoint; and BulkImportDeleteImportByRepo, which tracks DELETE requests to the
    /import/by-repo endpoint.'
  user_input: What audit events does Backstage generat for bulk import?
- context:
  - 'following example: ```yaml bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog. # ServiceNow
    Custom actions in Red Hat Developer Hub [IMPORTANT] ---- These features are for
    Technology Preview only. Technology Preview features are not supported with Red
    Hat production service level agreements (SLAs), might not be functionally complete,
    and Red Hat does not recommend using them for production. These features provide
    early access to upcoming product features, enabling customers to test functionality
    and provide feedback during the development process. For more information on Red
    Hat Technology Preview features, see Technology Preview Features Scope. ---- In
    Red Hat Developer Hub, you can access ServiceNow custom actions (custom actions)
    for fetching and registering resources in the catalog. The custom actions in Developer
    Hub enable you to facilitate and automate the management of records. Using the
    custom actions, you can perform the following actions: Create, update, or delete
    a record Retrieve information about a single record or multiple records ## Enabling
    ServiceNow custom actions plugin in Red Hat Developer Hub In Red Hat Developer
    Hub, the ServiceNow custom actions are provided as a pre-loaded plugin, which
    is disabled by default. You can enable the custom actions plugin using the following
    procedure. Red Hat Developer Hub is installed and running. You have created a
    project in the Developer Hub. 1. To activate the custom actions plugin, add a
    package with plugin name and update the disabled field in your Helm chart as follows:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module servicenow
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however, you can use
    a pluginConfig entry to override the default configuration. ---- 2. Set the following
    variables in the Helm chart to access the custom actions: ```yaml servicenow:
    # The base url of the ServiceNow instance. baseUrl: ${SERVICENOW_BASE_URL} # The
    username to use for authentication. username: ${SERVICENOW_USERNAME} # The password
    to use for authentication. password: ${SERVICENOW_PASSWORD} ``` ## Supported ServiceNow
    custom actions in Red Hat Developer Hub The ServiceNow custom actions enable you
    to manage records in the Red Hat Developer Hub. The custom actions support the
    following HTTP methods for API requests: GET: Retrieves specified information
    from a specified resource endpoint POST: Creates or updates a resource PUT: Modify
    a resource PATCH: Updates a resource DELETE: Deletes a resource [GET] servicenow:now:table:retrieveRecord::
    Retrieves information of a specified record from a table in the Developer Hub.
    [GET] servicenow:now:table:retrieveRecords:: Retrieves information about multiple
    records from a table in the Developer Hub. [POST] servicenow:now:table:createRecord::
    Creates a record in a table in the Developer Hub. [PUT] servicenow:now:table:modifyRecord::
    Modifies a record in a table in the Developer Hub. [PATCH] servicenow:now:table:updateRecord::
    Updates a record in a table in the Developer Hub. [DELETE] servicenow:now:table:deleteRecord::
    Deletes a record from a table in the Developer Hub. # Kubernetes custom actions
    in Red Hat Developer Hub With Kubernetes custom actions, you can create and manage
    Kubernetes resources. The Kubernetes custom actions plugin is preinstalled and
    disabled on a Developer Hub instance by default. You can disable or enable the
    Kubernetes custom actions plugin, and change other parameters, by configuring
    the Red Hat Developer Hub Helm chart. [NOTE] ---- Kubernetes scaffolder actions
    and Kubernetes custom actions refer to the same concept throughout this documentation.
    ---- ## Enabling Kubernetes custom actions plugin in Red Hat Developer Hub In
    Red Hat Developer Hub, the Kubernetes custom actions are provided as a preinstalled
    plugin, which is disabled by default. You can enable the Kubernetes custom actions
    plugin by updating the disabled key value in your Helm chart. You have installed
    Red Hat Developer Hub with the Helm chart. To enable the Kubernetes custom actions
    plugin, complete the following step: In your Helm chart, add a package with the
    Kubernetes custom action plugin name and update the disabled field. For example:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module kubernetes
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however,'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:17:09.869649'
    uuid: b7ced70f-e82a-4983-8c27-7a3730c83d68
  response: "The ServiceNow custom actions are a Technology Preview feature, are not\
    \ supported with Red Hat production service level agreements (SLAs), and are not\
    \ recommended for production use. In Red Hat Developer Hub, the ServiceNow custom\
    \ actions are provided as a pre-loaded plugin, which is disabled by default. To\
    \ activate the plugin, add a package with the plugin name and update the disabled\
    \ field in your Helm chart as follows: ```yaml\nglobal:\n  dynamic:\n    includes:\
    \ dynamic plugins.default.yaml\nplugins:\n  package: ./dynamic plugins/dist/backstage\
    \ community plugin scaffolder backend module servicenow\n  dynamic\n    disabled:\
    \ false\n```. Next, you must set the following variables in the Helm chart to\
    \ access the custom actions: ```yaml\nservicenow:\n  # The base url of the ServiceNow\
    \ instance.\n  baseUrl: ${SERVICENOW_BASE_URL}\n  # The username to use for authentication.\n\
    \  username: ${SERVICENOW_USERNAME}\n  # The password to use for authentication.\n\
    \  password: ${SERVICENOW_PASSWORD}\n```"
  user_input: how i enable servicenow custom actions plugin in Red Hat Developer Hub?
    it say it disabled.
- context:
  - 'following example: ```yaml bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog. # ServiceNow
    Custom actions in Red Hat Developer Hub [IMPORTANT] ---- These features are for
    Technology Preview only. Technology Preview features are not supported with Red
    Hat production service level agreements (SLAs), might not be functionally complete,
    and Red Hat does not recommend using them for production. These features provide
    early access to upcoming product features, enabling customers to test functionality
    and provide feedback during the development process. For more information on Red
    Hat Technology Preview features, see Technology Preview Features Scope. ---- In
    Red Hat Developer Hub, you can access ServiceNow custom actions (custom actions)
    for fetching and registering resources in the catalog. The custom actions in Developer
    Hub enable you to facilitate and automate the management of records. Using the
    custom actions, you can perform the following actions: Create, update, or delete
    a record Retrieve information about a single record or multiple records ## Enabling
    ServiceNow custom actions plugin in Red Hat Developer Hub In Red Hat Developer
    Hub, the ServiceNow custom actions are provided as a pre-loaded plugin, which
    is disabled by default. You can enable the custom actions plugin using the following
    procedure. Red Hat Developer Hub is installed and running. You have created a
    project in the Developer Hub. 1. To activate the custom actions plugin, add a
    package with plugin name and update the disabled field in your Helm chart as follows:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module servicenow
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however, you can use
    a pluginConfig entry to override the default configuration. ---- 2. Set the following
    variables in the Helm chart to access the custom actions: ```yaml servicenow:
    # The base url of the ServiceNow instance. baseUrl: ${SERVICENOW_BASE_URL} # The
    username to use for authentication. username: ${SERVICENOW_USERNAME} # The password
    to use for authentication. password: ${SERVICENOW_PASSWORD} ``` ## Supported ServiceNow
    custom actions in Red Hat Developer Hub The ServiceNow custom actions enable you
    to manage records in the Red Hat Developer Hub. The custom actions support the
    following HTTP methods for API requests: GET: Retrieves specified information
    from a specified resource endpoint POST: Creates or updates a resource PUT: Modify
    a resource PATCH: Updates a resource DELETE: Deletes a resource [GET] servicenow:now:table:retrieveRecord::
    Retrieves information of a specified record from a table in the Developer Hub.
    [GET] servicenow:now:table:retrieveRecords:: Retrieves information about multiple
    records from a table in the Developer Hub. [POST] servicenow:now:table:createRecord::
    Creates a record in a table in the Developer Hub. [PUT] servicenow:now:table:modifyRecord::
    Modifies a record in a table in the Developer Hub. [PATCH] servicenow:now:table:updateRecord::
    Updates a record in a table in the Developer Hub. [DELETE] servicenow:now:table:deleteRecord::
    Deletes a record from a table in the Developer Hub. # Kubernetes custom actions
    in Red Hat Developer Hub With Kubernetes custom actions, you can create and manage
    Kubernetes resources. The Kubernetes custom actions plugin is preinstalled and
    disabled on a Developer Hub instance by default. You can disable or enable the
    Kubernetes custom actions plugin, and change other parameters, by configuring
    the Red Hat Developer Hub Helm chart. [NOTE] ---- Kubernetes scaffolder actions
    and Kubernetes custom actions refer to the same concept throughout this documentation.
    ---- ## Enabling Kubernetes custom actions plugin in Red Hat Developer Hub In
    Red Hat Developer Hub, the Kubernetes custom actions are provided as a preinstalled
    plugin, which is disabled by default. You can enable the Kubernetes custom actions
    plugin by updating the disabled key value in your Helm chart. You have installed
    Red Hat Developer Hub with the Helm chart. To enable the Kubernetes custom actions
    plugin, complete the following step: In your Helm chart, add a package with the
    Kubernetes custom action plugin name and update the disabled field. For example:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module kubernetes
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however,'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:17:20.943949'
    uuid: 9fcb1344-d991-472d-8a42-c99a7bd87eac
  response: You can direct the Bulk Import plugin to hand off the entire list of selected
    repositories to a custom Orchestrator workflow. The Orchestrator iterates through
    the repository list, launching the template once for each repository and passes
    only the data for that single repository to the template run.
  user_input: How dose the custom Orchestrater workflow handle the list of repositeries
    during a bulk import?
- context:
  - 'following example: ```yaml bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog. # ServiceNow
    Custom actions in Red Hat Developer Hub [IMPORTANT] ---- These features are for
    Technology Preview only. Technology Preview features are not supported with Red
    Hat production service level agreements (SLAs), might not be functionally complete,
    and Red Hat does not recommend using them for production. These features provide
    early access to upcoming product features, enabling customers to test functionality
    and provide feedback during the development process. For more information on Red
    Hat Technology Preview features, see Technology Preview Features Scope. ---- In
    Red Hat Developer Hub, you can access ServiceNow custom actions (custom actions)
    for fetching and registering resources in the catalog. The custom actions in Developer
    Hub enable you to facilitate and automate the management of records. Using the
    custom actions, you can perform the following actions: Create, update, or delete
    a record Retrieve information about a single record or multiple records ## Enabling
    ServiceNow custom actions plugin in Red Hat Developer Hub In Red Hat Developer
    Hub, the ServiceNow custom actions are provided as a pre-loaded plugin, which
    is disabled by default. You can enable the custom actions plugin using the following
    procedure. Red Hat Developer Hub is installed and running. You have created a
    project in the Developer Hub. 1. To activate the custom actions plugin, add a
    package with plugin name and update the disabled field in your Helm chart as follows:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module servicenow
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however, you can use
    a pluginConfig entry to override the default configuration. ---- 2. Set the following
    variables in the Helm chart to access the custom actions: ```yaml servicenow:
    # The base url of the ServiceNow instance. baseUrl: ${SERVICENOW_BASE_URL} # The
    username to use for authentication. username: ${SERVICENOW_USERNAME} # The password
    to use for authentication. password: ${SERVICENOW_PASSWORD} ``` ## Supported ServiceNow
    custom actions in Red Hat Developer Hub The ServiceNow custom actions enable you
    to manage records in the Red Hat Developer Hub. The custom actions support the
    following HTTP methods for API requests: GET: Retrieves specified information
    from a specified resource endpoint POST: Creates or updates a resource PUT: Modify
    a resource PATCH: Updates a resource DELETE: Deletes a resource [GET] servicenow:now:table:retrieveRecord::
    Retrieves information of a specified record from a table in the Developer Hub.
    [GET] servicenow:now:table:retrieveRecords:: Retrieves information about multiple
    records from a table in the Developer Hub. [POST] servicenow:now:table:createRecord::
    Creates a record in a table in the Developer Hub. [PUT] servicenow:now:table:modifyRecord::
    Modifies a record in a table in the Developer Hub. [PATCH] servicenow:now:table:updateRecord::
    Updates a record in a table in the Developer Hub. [DELETE] servicenow:now:table:deleteRecord::
    Deletes a record from a table in the Developer Hub. # Kubernetes custom actions
    in Red Hat Developer Hub With Kubernetes custom actions, you can create and manage
    Kubernetes resources. The Kubernetes custom actions plugin is preinstalled and
    disabled on a Developer Hub instance by default. You can disable or enable the
    Kubernetes custom actions plugin, and change other parameters, by configuring
    the Red Hat Developer Hub Helm chart. [NOTE] ---- Kubernetes scaffolder actions
    and Kubernetes custom actions refer to the same concept throughout this documentation.
    ---- ## Enabling Kubernetes custom actions plugin in Red Hat Developer Hub In
    Red Hat Developer Hub, the Kubernetes custom actions are provided as a preinstalled
    plugin, which is disabled by default. You can enable the Kubernetes custom actions
    plugin by updating the disabled key value in your Helm chart. You have installed
    Red Hat Developer Hub with the Helm chart. To enable the Kubernetes custom actions
    plugin, complete the following step: In your Helm chart, add a package with the
    Kubernetes custom action plugin name and update the disabled field. For example:
    ```yaml global: dynamic: includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin scaffolder backend module kubernetes
    dynamic disabled: false ``` [NOTE] ---- The default configuration for a plugin
    is extracted from the dynamic-plugins.default.yaml file, however,'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:17:31.387804'
    uuid: ec327ce7-008b-49c2-9381-11cff1e1db5a
  response: 'In Red Hat Developer Hub, the ServiceNow custom actions are provided
    as a pre-loaded plugin, which is disabled by default. To activate the custom actions
    plugin, you must add a package with the plugin name and update the `disabled`
    field in your Helm chart to `false`. After activating the plugin, you need to
    set the following variables in the Helm chart to access the custom actions: `baseUrl`,
    which is the base url of the ServiceNow instance; `username`, which is the username
    to use for authentication; and `password`, which is the password to use for authentication.'
  user_input: i am trying to enable the ServiceNow custom actions in my Red Hat Developer
    Hub for my teams, but i dont know how, what is the procedure to activate this
    plugin because it is disabled by default and what variables i need to set in the
    helm chart for it to work?
- context:
  - 'you can use a pluginConfig entry to override the default configuration. ----
    ## Using Kubernetes custom actions plugin in Red Hat Developer Hub In Red Hat
    Developer Hub, the Kubernetes custom actions enable you to run template actions
    for Kubernetes. To use a Kubernetes custom action in your custom template, add
    the following Kubernetes actions to your template: ```yaml action: kubernetes:create
    namespace id: create kubernetes namespace name: Create kubernetes namespace input:
    namespace: my rhdh project clusterRef: bar token: TOKEN skipTLSVerify: false caData:
    Zm9v labels: app.io/type=ns; app.io/managed by=org; ``` Configuring templates
    ## Creating a template using Kubernetes custom actions in Red Hat Developer Hub
    To create a template, define a Template object as a YAML file. The Template object
    describes the template and its metadata. It also contains required input variables
    and a list of actions that are executed by the scaffolding service. ```yaml apiVersion:
    scaffolder.backstage.io/v1beta3 kind: Template metadata: name: create-kubernetes-namespace
    title: Create a kubernetes namespace description: Create a kubernetes namespace
    spec: type: service parameters: - title: Information required: [namespace, token]
    properties: namespace: title: Namespace name type: string description: Name of
    the namespace to be created clusterRef: title: Cluster reference type: string
    description: Cluster resource entity reference from the catalog ui:field: EntityPicker
    ui:options: catalogFilter: kind: Resource url: title: Url type: string description:
    Url of the kubernetes API, will be used if clusterRef is not provided token: title:
    Token type: string ui:field: Secret description: Bearer token to authenticate
    with skipTLSVerify: title: Skip TLS verification type: boolean description: Skip
    TLS certificate verification, not recommended to use in production environment,
    default to false caData: title: CA data type: string ui:field: Secret description:
    Certificate Authority base64 encoded certificate labels: title: Labels type: string
    description: Labels to be applied to the namespace ui:widget: textarea ui:options:
    rows: 3 ui:help: ''Hint: Separate multiple labels with a semicolon!'' ui:placeholder:
    ''kubernetes.io/type=namespace; app.io/managed-by=org'' steps: - id: create-kubernetes-namespace
    name: Create kubernetes namespace action: kubernetes:create-namespace input: namespace:
    ${{ parameters.namespace }} clusterRef: ${{ parameters.clusterRef }} url: ${{
    parameters.url }} token: ${{ secrets.token }} skipTLSVerify: ${{ parameters.skipTLSVerify
    }} caData: ${{ secrets.caData }} labels: ${{ parameters.labels }} ``` ## Supported
    Kubernetes custom actions in Red Hat Developer Hub In Red Hat Developer Hub, you
    can use custom Kubernetes actions in scaffolder templates. Action: kubernetes:create-namespace::
    Creates a namespace for the Kubernetes cluster in the Developer Hub. # Configuring
    Red Hat Developer Hub Events Module Use the Events Module together with scheduled
    updates to make sure your GitHub user or catalog entities are updated whenever
    changes occur in the external system. This is a Developer Preview feature. [IMPORTANT]
    ---- Developer Preview features are not supported by Red Hat in any way and are
    not functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    ## Configuring Events Module for GitHub Learn how to configure Events Module for
    use with the RHDH GitHub Discovery feature and GitHub organization data. This
    is a Developer Preview feature. [IMPORTANT] ---- Developer Preview features are
    not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- You have added your GitHub integration credentials
    in the app config.yaml file. You have defined the schedule.frequency in the app
    config.yaml file as longer time period, such as 24 hours. For GitHub Discovery
    only: You have enabled GitHub Discovery. For GitHub Organizational Data only:
    You have enabled Github Authentication with user ingestion. 1. Add the GitHub
    Events Module to your dynamic-plugins.yaml configuration file as follows: ```yaml
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: oci://ghcr.io/redhat developer/rhdh plugin export overlays/backstage
    plugin events backend module github:bs_1.42.5__0.4.3!backstage plugin events backend
    module github disabled: false ``` 2. To create HTTP endpoints to receive events
    for the github, add the following to your app-config.yaml file: ```yaml events:
    http: topics: github modules: github: webhookSecret: ${GITHUB_WEBHOOK_SECRET}
    ``` [IMPORTANT] ---- Secure your workflow by adding a webhook secret token to
    validate webhook deliveries. ---- 3. Create a GitHub webhook with the following
    specifications: * For Github Discovery Events: push, repository * For Github Organizational
    Data Events: organization, team and membership * Content Type: application/json
    * Payload URL: https://<my_developer_hub_domain>/api/events/http/github [NOTE]
    ---- Payload URL is the URL exposed after configuring the HTTP endpoint. ----
    Check the log for an entry that confirms that http endpoint was set up successfully
    to receive events from the GitHub webhook. Example of a log of successfully set
    up http endpoint:: ```code {"level":"\u001b[32minfo\u001b[39m","message":"Registered
    /api/events/http/github to receive events","plugin":"events","service":"backstage","timestamp":"2025-11-03
    02:19:12"} ``` For GitHub Discovery only: Trigger a GitHub push event by adding,
    modifying or deleting the catalog info.yaml file in the repository where you set
    up your webhook. A record of this event should appear in the pod logs of your
    RHDH instance. Example of a log with changes to catalog info.yaml file:: ```code
    {"level":"\u001b[32minfo\u001b[39m","message":"Processed Github push event: added
    0 - removed 0 - modified 1","plugin":"catalog","service":"backstage","span_id":"47534b96c4afc654","target":"github-provider:providerId","timestamp":"2025-06-15
    21:33:14","trace_flags":"01","trace_id":"ecc782deb86aed2027da0ae6b1999e5c"} ```
    For GitHub Organizational Data only: Newly added users and teams appear in the'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:17:41.493070'
    uuid: c34cdaaa-34b9-4dc1-99da-2f5d8d8d2d50
  response: 'To configure the Events Module for GitHub, you must first have your GitHub
    integration credentials in the app-config.yaml file, a defined schedule.frequency
    in the app-config.yaml file, and have enabled either GitHub Discovery or Github
    Authentication with user ingestion. The steps are as follows: 1. Add the GitHub
    Events Module to your dynamic-plugins.yaml configuration file with the package
    `oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/backstage-plugin-events-backend-module-github:bs_1.42.5__0.4.3!backstage-plugin-events-backend-module-github`.
    2. Create HTTP endpoints in your app-config.yaml file by adding `events: http:
    topics: github modules: github: webhookSecret: ${GITHUB_WEBHOOK_SECRET}`. 3. Create
    a GitHub webhook with the Content Type set to `application/json` and the Payload
    URL as `https://<my_developer_hub_domain>/api/events/http/github`. For Github
    Discovery Events, the specifications are `push` and `repository`. For Github Organizational
    Data Events, the specifications are `organization`, `team`, and `membership`.'
  user_input: how i can configure the Events Module for GitHub in Red Hat Developer
    Hub, what is the steps?
- context:
  - 'you can use a pluginConfig entry to override the default configuration. ----
    ## Using Kubernetes custom actions plugin in Red Hat Developer Hub In Red Hat
    Developer Hub, the Kubernetes custom actions enable you to run template actions
    for Kubernetes. To use a Kubernetes custom action in your custom template, add
    the following Kubernetes actions to your template: ```yaml action: kubernetes:create
    namespace id: create kubernetes namespace name: Create kubernetes namespace input:
    namespace: my rhdh project clusterRef: bar token: TOKEN skipTLSVerify: false caData:
    Zm9v labels: app.io/type=ns; app.io/managed by=org; ``` Configuring templates
    ## Creating a template using Kubernetes custom actions in Red Hat Developer Hub
    To create a template, define a Template object as a YAML file. The Template object
    describes the template and its metadata. It also contains required input variables
    and a list of actions that are executed by the scaffolding service. ```yaml apiVersion:
    scaffolder.backstage.io/v1beta3 kind: Template metadata: name: create-kubernetes-namespace
    title: Create a kubernetes namespace description: Create a kubernetes namespace
    spec: type: service parameters: - title: Information required: [namespace, token]
    properties: namespace: title: Namespace name type: string description: Name of
    the namespace to be created clusterRef: title: Cluster reference type: string
    description: Cluster resource entity reference from the catalog ui:field: EntityPicker
    ui:options: catalogFilter: kind: Resource url: title: Url type: string description:
    Url of the kubernetes API, will be used if clusterRef is not provided token: title:
    Token type: string ui:field: Secret description: Bearer token to authenticate
    with skipTLSVerify: title: Skip TLS verification type: boolean description: Skip
    TLS certificate verification, not recommended to use in production environment,
    default to false caData: title: CA data type: string ui:field: Secret description:
    Certificate Authority base64 encoded certificate labels: title: Labels type: string
    description: Labels to be applied to the namespace ui:widget: textarea ui:options:
    rows: 3 ui:help: ''Hint: Separate multiple labels with a semicolon!'' ui:placeholder:
    ''kubernetes.io/type=namespace; app.io/managed-by=org'' steps: - id: create-kubernetes-namespace
    name: Create kubernetes namespace action: kubernetes:create-namespace input: namespace:
    ${{ parameters.namespace }} clusterRef: ${{ parameters.clusterRef }} url: ${{
    parameters.url }} token: ${{ secrets.token }} skipTLSVerify: ${{ parameters.skipTLSVerify
    }} caData: ${{ secrets.caData }} labels: ${{ parameters.labels }} ``` ## Supported
    Kubernetes custom actions in Red Hat Developer Hub In Red Hat Developer Hub, you
    can use custom Kubernetes actions in scaffolder templates. Action: kubernetes:create-namespace::
    Creates a namespace for the Kubernetes cluster in the Developer Hub. # Configuring
    Red Hat Developer Hub Events Module Use the Events Module together with scheduled
    updates to make sure your GitHub user or catalog entities are updated whenever
    changes occur in the external system. This is a Developer Preview feature. [IMPORTANT]
    ---- Developer Preview features are not supported by Red Hat in any way and are
    not functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    ## Configuring Events Module for GitHub Learn how to configure Events Module for
    use with the RHDH GitHub Discovery feature and GitHub organization data. This
    is a Developer Preview feature. [IMPORTANT] ---- Developer Preview features are
    not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- You have added your GitHub integration credentials
    in the app config.yaml file. You have defined the schedule.frequency in the app
    config.yaml file as longer time period, such as 24 hours. For GitHub Discovery
    only: You have enabled GitHub Discovery. For GitHub Organizational Data only:
    You have enabled Github Authentication with user ingestion. 1. Add the GitHub
    Events Module to your dynamic-plugins.yaml configuration file as follows: ```yaml
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: oci://ghcr.io/redhat developer/rhdh plugin export overlays/backstage
    plugin events backend module github:bs_1.42.5__0.4.3!backstage plugin events backend
    module github disabled: false ``` 2. To create HTTP endpoints to receive events
    for the github, add the following to your app-config.yaml file: ```yaml events:
    http: topics: github modules: github: webhookSecret: ${GITHUB_WEBHOOK_SECRET}
    ``` [IMPORTANT] ---- Secure your workflow by adding a webhook secret token to
    validate webhook deliveries. ---- 3. Create a GitHub webhook with the following
    specifications: * For Github Discovery Events: push, repository * For Github Organizational
    Data Events: organization, team and membership * Content Type: application/json
    * Payload URL: https://<my_developer_hub_domain>/api/events/http/github [NOTE]
    ---- Payload URL is the URL exposed after configuring the HTTP endpoint. ----
    Check the log for an entry that confirms that http endpoint was set up successfully
    to receive events from the GitHub webhook. Example of a log of successfully set
    up http endpoint:: ```code {"level":"\u001b[32minfo\u001b[39m","message":"Registered
    /api/events/http/github to receive events","plugin":"events","service":"backstage","timestamp":"2025-11-03
    02:19:12"} ``` For GitHub Discovery only: Trigger a GitHub push event by adding,
    modifying or deleting the catalog info.yaml file in the repository where you set
    up your webhook. A record of this event should appear in the pod logs of your
    RHDH instance. Example of a log with changes to catalog info.yaml file:: ```code
    {"level":"\u001b[32minfo\u001b[39m","message":"Processed Github push event: added
    0 - removed 0 - modified 1","plugin":"catalog","service":"backstage","span_id":"47534b96c4afc654","target":"github-provider:providerId","timestamp":"2025-06-15
    21:33:14","trace_flags":"01","trace_id":"ecc782deb86aed2027da0ae6b1999e5c"} ```
    For GitHub Organizational Data only: Newly added users and teams appear in the'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:17:51.664746'
    uuid: c090c40d-61f4-42d2-aef4-0a63c0a3c97f
  response: To configure the Events Module for GitHub Organizational Data, you must
    have added your GitHub integration credentials in the app-config.yaml file, defined
    the schedule.frequency in the app-config.yaml file for a longer time period like
    24 hours, and enabled Github Authentication with user ingestion. For the GitHub
    webhook, the specifications for Github Organizational Data Events are 'organization',
    'team' and 'membership'. The Content Type must be 'application/json' and the Payload
    URL is 'https://<my_developer_hub_domain>/api/events/http/github'. You should
    also add a webhook secret token to validate webhook deliveries.
  user_input: What are the prerequisites and webhook specifications for configuring
    the Events Module for GitHub Organizational Data in Red Hat Developer Hub?
- context:
  - 'you can use a pluginConfig entry to override the default configuration. ----
    ## Using Kubernetes custom actions plugin in Red Hat Developer Hub In Red Hat
    Developer Hub, the Kubernetes custom actions enable you to run template actions
    for Kubernetes. To use a Kubernetes custom action in your custom template, add
    the following Kubernetes actions to your template: ```yaml action: kubernetes:create
    namespace id: create kubernetes namespace name: Create kubernetes namespace input:
    namespace: my rhdh project clusterRef: bar token: TOKEN skipTLSVerify: false caData:
    Zm9v labels: app.io/type=ns; app.io/managed by=org; ``` Configuring templates
    ## Creating a template using Kubernetes custom actions in Red Hat Developer Hub
    To create a template, define a Template object as a YAML file. The Template object
    describes the template and its metadata. It also contains required input variables
    and a list of actions that are executed by the scaffolding service. ```yaml apiVersion:
    scaffolder.backstage.io/v1beta3 kind: Template metadata: name: create-kubernetes-namespace
    title: Create a kubernetes namespace description: Create a kubernetes namespace
    spec: type: service parameters: - title: Information required: [namespace, token]
    properties: namespace: title: Namespace name type: string description: Name of
    the namespace to be created clusterRef: title: Cluster reference type: string
    description: Cluster resource entity reference from the catalog ui:field: EntityPicker
    ui:options: catalogFilter: kind: Resource url: title: Url type: string description:
    Url of the kubernetes API, will be used if clusterRef is not provided token: title:
    Token type: string ui:field: Secret description: Bearer token to authenticate
    with skipTLSVerify: title: Skip TLS verification type: boolean description: Skip
    TLS certificate verification, not recommended to use in production environment,
    default to false caData: title: CA data type: string ui:field: Secret description:
    Certificate Authority base64 encoded certificate labels: title: Labels type: string
    description: Labels to be applied to the namespace ui:widget: textarea ui:options:
    rows: 3 ui:help: ''Hint: Separate multiple labels with a semicolon!'' ui:placeholder:
    ''kubernetes.io/type=namespace; app.io/managed-by=org'' steps: - id: create-kubernetes-namespace
    name: Create kubernetes namespace action: kubernetes:create-namespace input: namespace:
    ${{ parameters.namespace }} clusterRef: ${{ parameters.clusterRef }} url: ${{
    parameters.url }} token: ${{ secrets.token }} skipTLSVerify: ${{ parameters.skipTLSVerify
    }} caData: ${{ secrets.caData }} labels: ${{ parameters.labels }} ``` ## Supported
    Kubernetes custom actions in Red Hat Developer Hub In Red Hat Developer Hub, you
    can use custom Kubernetes actions in scaffolder templates. Action: kubernetes:create-namespace::
    Creates a namespace for the Kubernetes cluster in the Developer Hub. # Configuring
    Red Hat Developer Hub Events Module Use the Events Module together with scheduled
    updates to make sure your GitHub user or catalog entities are updated whenever
    changes occur in the external system. This is a Developer Preview feature. [IMPORTANT]
    ---- Developer Preview features are not supported by Red Hat in any way and are
    not functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    ## Configuring Events Module for GitHub Learn how to configure Events Module for
    use with the RHDH GitHub Discovery feature and GitHub organization data. This
    is a Developer Preview feature. [IMPORTANT] ---- Developer Preview features are
    not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- You have added your GitHub integration credentials
    in the app config.yaml file. You have defined the schedule.frequency in the app
    config.yaml file as longer time period, such as 24 hours. For GitHub Discovery
    only: You have enabled GitHub Discovery. For GitHub Organizational Data only:
    You have enabled Github Authentication with user ingestion. 1. Add the GitHub
    Events Module to your dynamic-plugins.yaml configuration file as follows: ```yaml
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: oci://ghcr.io/redhat developer/rhdh plugin export overlays/backstage
    plugin events backend module github:bs_1.42.5__0.4.3!backstage plugin events backend
    module github disabled: false ``` 2. To create HTTP endpoints to receive events
    for the github, add the following to your app-config.yaml file: ```yaml events:
    http: topics: github modules: github: webhookSecret: ${GITHUB_WEBHOOK_SECRET}
    ``` [IMPORTANT] ---- Secure your workflow by adding a webhook secret token to
    validate webhook deliveries. ---- 3. Create a GitHub webhook with the following
    specifications: * For Github Discovery Events: push, repository * For Github Organizational
    Data Events: organization, team and membership * Content Type: application/json
    * Payload URL: https://<my_developer_hub_domain>/api/events/http/github [NOTE]
    ---- Payload URL is the URL exposed after configuring the HTTP endpoint. ----
    Check the log for an entry that confirms that http endpoint was set up successfully
    to receive events from the GitHub webhook. Example of a log of successfully set
    up http endpoint:: ```code {"level":"\u001b[32minfo\u001b[39m","message":"Registered
    /api/events/http/github to receive events","plugin":"events","service":"backstage","timestamp":"2025-11-03
    02:19:12"} ``` For GitHub Discovery only: Trigger a GitHub push event by adding,
    modifying or deleting the catalog info.yaml file in the repository where you set
    up your webhook. A record of this event should appear in the pod logs of your
    RHDH instance. Example of a log with changes to catalog info.yaml file:: ```code
    {"level":"\u001b[32minfo\u001b[39m","message":"Processed Github push event: added
    0 - removed 0 - modified 1","plugin":"catalog","service":"backstage","span_id":"47534b96c4afc654","target":"github-provider:providerId","timestamp":"2025-06-15
    21:33:14","trace_flags":"01","trace_id":"ecc782deb86aed2027da0ae6b1999e5c"} ```
    For GitHub Organizational Data only: Newly added users and teams appear in the'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:18:11.018400'
    uuid: 8c31c005-570b-4a77-bb6c-11d4eab6ea40
  response: Developer Preview features are not supported by Red Hat in any way and
    are not functionally complete or production-ready. They should not be used for
    production or business-critical workloads. These features provide early access
    to functionality for testing and feedback, might not have any documentation, are
    subject to change or removal at any time, and have received limited testing. Red
    Hat might provide ways to submit feedback on these features without an associated
    SLA.
  user_input: Red Hat Developer Preview support scope
- context:
  - "Enabling and configuring the JFrog plugin JFrog Artifactory is a front-end plugin\
    \ that displays the information about your container images stored in the JFrog\
    \ Artifactory repository. The JFrog Artifactory plugin is preinstalled with Developer\
    \ Hub and disabled by default. To use it, you need to enable and configure it\
    \ first. [IMPORTANT] ---- The JFrog Artifactory plugin is a Technology Preview\
    \ feature only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ Additional detail on how Red Hat provides support for bundled community dynamic\
    \ plugins is available on the Red Hat Developer Support Policy page. ---- ## Enabling\
    \ the JFrog Artifactory plugin 1. The JFrog Artifactory plugin is preinstalled\
    \ in Developer Hub with basic configuration properties. To enable it, set the\
    \ disabled property to false as follows: ```yaml global: dynamic: includes: dynamic\
    \ plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin jfrog artifactory disabled: false ``` ## Configuring the JFrog Artifactory\
    \ plugin 1. Set the proxy to the desired JFrog Artifactory server in the app-config.yaml\
    \ file as follows: ```yaml proxy: endpoints: \u2018/jfrog-artifactory/api\u2019\
    : target: http://<hostname>:8082 # or https://<customer>.jfrog.io headers: # Authorization:\
    \ 'Bearer <YOUR TOKEN>' # Change to \"false\" in case of using a self-hosted Artifactory\
    \ instance with a self-signed certificate secure: true ``` 2. Add the following\
    \ annotation to the entity\u2019s catalog-info.yaml file to enable the JFrog Artifactory\
    \ plugin features in RHDH components: ```yaml metadata: annotations: 'jfrog artifactory/image\
    \ name': '<IMAGE NAME>' ``` # RHDH catalog. # Overriding Core Backend Service\
    \ Configuration The Red Hat Developer Hub (RHDH) backend platform consists of\
    \ a number of core services that are well encapsulated. The RHDH backend installs\
    \ these default core services statically during initialization. Customize a core\
    \ service by installing it as a BackendFeature by using the dynamic plugin functionality.\
    \ 1. Configure Developer Hub to allow a core service override, by setting the\
    \ corresponding core service ID environment variable to true in the Developer\
    \ Hub app-config.yaml configuration file. Environment variables and core service\
    \ IDs 2. Install your custom core service as a BackendFeature as shown in the\
    \ following example: ```javascript // Create the BackendFeature export const customRootHttpServerFactory:\
    \ BackendFeature = rootHttpRouterServiceFactory({ configure: ({ app, routes, middleware,\
    \ logger }) => { logger.info( 'Using custom root HttpRouterServiceFactory configure\
    \ function', ); app.use(middleware.helmet()); app.use(middleware.cors()); app.use(middleware.compression());\
    \ app.use(middleware.logging()); // Add a the custom middleware function before\
    \ all // of the route handlers app.use(addTestHeaderMiddleware({ logger })); app.use(routes);\
    \ app.use(middleware.notFound()); app.use(middleware.error()); }, }); // Export\
    \ the BackendFeature as the default entrypoint export default customRootHttpServerFactory;\
    \ ``` + In the previous example, as the BackendFeature overrides the default implementation\
    \ of the HTTP router service, you must set the ENABLE_CORE_ROOTHTTPROUTER_OVERRIDE\
    \ environment variable to true so that the Developer Hub does not install the\
    \ default implementation automatically."
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:18:18.977077'
    uuid: a506f3c2-1779-49b3-aac6-47f3e71335bc
  response: 'To customize a Core Backend Service in the Red Hat Developer Hub (RHDH)
    backend, you must install it as a BackendFeature using the dynamic plugin functionality.
    The process involves two steps: 1. Configure Developer Hub to allow a core service
    override by setting the corresponding core service ID environment variable to
    true in the app-config.yaml configuration file. For example, to override the default
    HTTP router service, the ENABLE_CORE_ROOTHTTPROUTER_OVERRIDE environment variable
    must be set to true. 2. Install your custom core service as a BackendFeature.'
  user_input: What is the detailed process for overriding a default Core Backend Service
    in the Red Hat Developer Hub backend platform using the dynamic plugin functionality?
- context:
  - "Enabling and configuring the JFrog plugin JFrog Artifactory is a front-end plugin\
    \ that displays the information about your container images stored in the JFrog\
    \ Artifactory repository. The JFrog Artifactory plugin is preinstalled with Developer\
    \ Hub and disabled by default. To use it, you need to enable and configure it\
    \ first. [IMPORTANT] ---- The JFrog Artifactory plugin is a Technology Preview\
    \ feature only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ Additional detail on how Red Hat provides support for bundled community dynamic\
    \ plugins is available on the Red Hat Developer Support Policy page. ---- ## Enabling\
    \ the JFrog Artifactory plugin 1. The JFrog Artifactory plugin is preinstalled\
    \ in Developer Hub with basic configuration properties. To enable it, set the\
    \ disabled property to false as follows: ```yaml global: dynamic: includes: dynamic\
    \ plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin jfrog artifactory disabled: false ``` ## Configuring the JFrog Artifactory\
    \ plugin 1. Set the proxy to the desired JFrog Artifactory server in the app-config.yaml\
    \ file as follows: ```yaml proxy: endpoints: \u2018/jfrog-artifactory/api\u2019\
    : target: http://<hostname>:8082 # or https://<customer>.jfrog.io headers: # Authorization:\
    \ 'Bearer <YOUR TOKEN>' # Change to \"false\" in case of using a self-hosted Artifactory\
    \ instance with a self-signed certificate secure: true ``` 2. Add the following\
    \ annotation to the entity\u2019s catalog-info.yaml file to enable the JFrog Artifactory\
    \ plugin features in RHDH components: ```yaml metadata: annotations: 'jfrog artifactory/image\
    \ name': '<IMAGE NAME>' ``` # RHDH catalog. # Overriding Core Backend Service\
    \ Configuration The Red Hat Developer Hub (RHDH) backend platform consists of\
    \ a number of core services that are well encapsulated. The RHDH backend installs\
    \ these default core services statically during initialization. Customize a core\
    \ service by installing it as a BackendFeature by using the dynamic plugin functionality.\
    \ 1. Configure Developer Hub to allow a core service override, by setting the\
    \ corresponding core service ID environment variable to true in the Developer\
    \ Hub app-config.yaml configuration file. Environment variables and core service\
    \ IDs 2. Install your custom core service as a BackendFeature as shown in the\
    \ following example: ```javascript // Create the BackendFeature export const customRootHttpServerFactory:\
    \ BackendFeature = rootHttpRouterServiceFactory({ configure: ({ app, routes, middleware,\
    \ logger }) => { logger.info( 'Using custom root HttpRouterServiceFactory configure\
    \ function', ); app.use(middleware.helmet()); app.use(middleware.cors()); app.use(middleware.compression());\
    \ app.use(middleware.logging()); // Add a the custom middleware function before\
    \ all // of the route handlers app.use(addTestHeaderMiddleware({ logger })); app.use(routes);\
    \ app.use(middleware.notFound()); app.use(middleware.error()); }, }); // Export\
    \ the BackendFeature as the default entrypoint export default customRootHttpServerFactory;\
    \ ``` + In the previous example, as the BackendFeature overrides the default implementation\
    \ of the HTTP router service, you must set the ENABLE_CORE_ROOTHTTPROUTER_OVERRIDE\
    \ environment variable to true so that the Developer Hub does not install the\
    \ default implementation automatically."
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:18:27.932063'
    uuid: 5b04489e-5bce-4c1f-8bee-854cda64bdaf
  response: "The JFrog Artifactory plugin is a preinstalled front-end plugin for displaying\
    \ container image information, but it is disabled by default and is considered\
    \ a Technology Preview feature not recommended for production. To enable it, you\
    \ must set the `disabled` property to `false` for the `backstage-community-plugin-jfrog-artifactory`\
    \ package. To configure it, first set the proxy to your JFrog Artifactory server\
    \ in the `app-config.yaml` file by defining an endpoint for `/jfrog-artifactory/api`\
    \ with the server's URL as the target. Second, to enable the plugin's features\
    \ in RHDH components, you must add the annotation `'jfrog-artifactory/image-name':\
    \ '<IMAGE NAME>'` to the entity\u2019s `catalog-info.yaml` file."
  user_input: I'm trying to get the JFrog plugin working in our Red Hat Developer
    Hub instalation, can you tell me all the steps I need to take to enable it and
    then configure it? I need to know what files to edit and what to put in them for
    both the proxy and the anntations for the RHDH components.
- context:
  - "Enabling and configuring the JFrog plugin JFrog Artifactory is a front-end plugin\
    \ that displays the information about your container images stored in the JFrog\
    \ Artifactory repository. The JFrog Artifactory plugin is preinstalled with Developer\
    \ Hub and disabled by default. To use it, you need to enable and configure it\
    \ first. [IMPORTANT] ---- The JFrog Artifactory plugin is a Technology Preview\
    \ feature only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ Additional detail on how Red Hat provides support for bundled community dynamic\
    \ plugins is available on the Red Hat Developer Support Policy page. ---- ## Enabling\
    \ the JFrog Artifactory plugin 1. The JFrog Artifactory plugin is preinstalled\
    \ in Developer Hub with basic configuration properties. To enable it, set the\
    \ disabled property to false as follows: ```yaml global: dynamic: includes: dynamic\
    \ plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin jfrog artifactory disabled: false ``` ## Configuring the JFrog Artifactory\
    \ plugin 1. Set the proxy to the desired JFrog Artifactory server in the app-config.yaml\
    \ file as follows: ```yaml proxy: endpoints: \u2018/jfrog-artifactory/api\u2019\
    : target: http://<hostname>:8082 # or https://<customer>.jfrog.io headers: # Authorization:\
    \ 'Bearer <YOUR TOKEN>' # Change to \"false\" in case of using a self-hosted Artifactory\
    \ instance with a self-signed certificate secure: true ``` 2. Add the following\
    \ annotation to the entity\u2019s catalog-info.yaml file to enable the JFrog Artifactory\
    \ plugin features in RHDH components: ```yaml metadata: annotations: 'jfrog artifactory/image\
    \ name': '<IMAGE NAME>' ``` # RHDH catalog. # Overriding Core Backend Service\
    \ Configuration The Red Hat Developer Hub (RHDH) backend platform consists of\
    \ a number of core services that are well encapsulated. The RHDH backend installs\
    \ these default core services statically during initialization. Customize a core\
    \ service by installing it as a BackendFeature by using the dynamic plugin functionality.\
    \ 1. Configure Developer Hub to allow a core service override, by setting the\
    \ corresponding core service ID environment variable to true in the Developer\
    \ Hub app-config.yaml configuration file. Environment variables and core service\
    \ IDs 2. Install your custom core service as a BackendFeature as shown in the\
    \ following example: ```javascript // Create the BackendFeature export const customRootHttpServerFactory:\
    \ BackendFeature = rootHttpRouterServiceFactory({ configure: ({ app, routes, middleware,\
    \ logger }) => { logger.info( 'Using custom root HttpRouterServiceFactory configure\
    \ function', ); app.use(middleware.helmet()); app.use(middleware.cors()); app.use(middleware.compression());\
    \ app.use(middleware.logging()); // Add a the custom middleware function before\
    \ all // of the route handlers app.use(addTestHeaderMiddleware({ logger })); app.use(routes);\
    \ app.use(middleware.notFound()); app.use(middleware.error()); }, }); // Export\
    \ the BackendFeature as the default entrypoint export default customRootHttpServerFactory;\
    \ ``` + In the previous example, as the BackendFeature overrides the default implementation\
    \ of the HTTP router service, you must set the ENABLE_CORE_ROOTHTTPROUTER_OVERRIDE\
    \ environment variable to true so that the Developer Hub does not install the\
    \ default implementation automatically."
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:18:38.869874'
    uuid: 2e566c5b-81e2-45d8-a548-b4d56e528afe
  response: To override a core service in Red Hat Developer Hub (RHDH), you must first
    configure Developer Hub to allow the override by setting the corresponding core
    service ID environment variable to true in the app-config.yaml configuration file.
    For example, to override the default HTTP router service, you must set the ENABLE_CORE_ROOTHTTPROUTER_OVERRIDE
    environment variable to true. This prevents the Developer Hub from installing
    the default implementation automatically. After that, you can install your custom
    core service as a BackendFeature using the dynamic plugin functionality.
  user_input: How do I override a core backend service in Red Hat Developer Hub by
    setting an environment variable and installing a custom BackendFeature?
- context:
  - 'New features This section highlights new features in Red Hat Developer Hub 1.8.
    ## Built-in monitoring for Red Hat Developer Hub operator This update introduces
    built-in monitoring for the Red Hat Developer Hub Operator. By enabling spec.monitoring.enabled:
    true in your Backstage custom resource, the Red Hat Developer Hub Operator will
    automatically manage service monitor resources for Prometheus metrics collection
    on the /metrics endpoint. This simplifies the monitoring process, eliminating
    the need for manual service monitor setup, and enhances the user experience on
    OpenShift and Kubernetes clusters with Prometheus Operator installed. For more
    information, see Enabling metrics monitoring in a Red Hat Developer Hub Operator
    installation on an OpenShift Container Platform cluster. ## Introducing localization
    support in core plugins, and French localization This update introduces localization
    support and French localization to these core plugins: Adoption insights AI Integrations
    Bulk Import Extensions (Marketplace) Lightspeed Orchestrator QuickStart RBAC ScoreCard
    Topology Global header Homepage Tekton ArgoCD This enhancement allows Red Hat
    Developer Hub to display content in French, improving accessibility for users
    who speak French. AI/Cursor automation ensures a seamless translation process,
    enhancing the user experience by providing content in their preferred language,
    preparing Red Hat Developer Hub for use in multilingual environments and fostering
    a more inclusive developer community. For more information, see Selecting the
    language for your Developer Hub instance. ## Localization support for strings
    defined in Red Hat Developer Hub configuration files With this update, localization
    support is introduced for strings defined in Red Hat Developer Hub configuration
    files such as app-config.yaml and dynamic-plugins.default.yaml. This enables users
    to customize the interface in their preferred language, providing a consistent
    multilingual interface across these components: Entity Tabs Configuration Global
    Header QuickStart Sidebar Menu Items Floating Action Button (FAB) labels and tooltips
    This localization support ensures a more inclusive and user-friendly experience
    for a diverse user base, improving user experience and supporting global users.
    For more information, see Enabling Quickstart localization in RHDH. ## Plugins
    localization support With this update, Red Hat Developer Hub integrates the Backstage
    localization framework, enabling users to load translations provided by their
    plugins. The selected language will persist according to the user settings persistence
    configuration. Additionally, users can load translations from an external JSON
    file, allowing them to override existing translations or add translations for
    existing translation keys. For more information, see Localization support for
    plugins. ## Enhanced Bulk Import with Scaffolder Templates With this update, users
    can enhance the Bulk Import plugin by importing repositories using scaffolder
    templates. This automates and optimizes the process by integrating with existing
    Backstage templates and Orchestrator workflows. Users can select their preferred
    pre-ingestion workflow and incorporate various scaffolder actions into their bulk
    import process, resulting in a more efficient and flexible Bulk Import experience.
    For more information, see Input parameters for Bulk Import Scaffolder template.
    ## Enabling Software Template version update notifications With this update, you
    can enable notification alerts whenever a Software Template is updated with a
    new version. For more information, see Enabling Software Template version update
    notifications in Red Hat Developer Hub. ## Software Template provenance and dependency
    tracking With this update, Red Hat Developer Hub supports Software Template provenance
    and a dedicated dependency view to improve component traceability and lifecycle
    management across your organization. For more information, see Tracking component
    origin and Software Template version. ## Users can customize their homepage With
    this update, Red Hat Developer Hub users can customize their homepage, empowering
    personalization and productivity. Users can now move, resize, remove, and add
    existing cards, fostering a more flexible and adaptable user experience. The customization
    options are based on the existing settings, and users can reset their configuration
    to the default. The feature aims to improve the resize and reorder mechanism,
    and update existing cards to work better on different card sizes. For more information,
    see Customizing the Home page. ## Developer Hub community plugins updated to Backstage
    1.42 The Developer Hub community plugins have been updated to Backstage version
    1.42. ## Quick Start experience for developers logging into Red Hat Developer
    Hub for the first time With this update, Red Hat Developer Hub includes a guided
    Quick Start experience tailored for the developer persona. This new feature appears
    automatically upon a developer&#39;s first login to help them get started quickly
    and accelerate adoption of the platform. The developer Quick Start provides guided
    next steps for key features, including: Bulk import Software Catalog Self service
    templates Learning paths This feature is integrated with RBAC, allowing platform
    engineers to configure the Quick Start content and conditionally display it to
    specific developer groups for personalized onboarding. For more information, see
    {setting-up-and-configuring-your-first-rhdh-instance-link}[{setting-up-and-configuring-your-first-rhdh-instance-title}].
    ## Transparent plugin support indicators With this update, the plugin support
    model is now transparently aligned with Red Hat&#39;s standard release classifications.
    The Verified badge is removed, a clearer tiered support system is implemented,
    and plugin metadata are enhanced, providing a more informative and user-friendly
    experience in the Extensions Catalog. This change improves visibility into plugin
    maturity, enhances customer trust, and ensures internal consistency across the
    catalog. Release Status:: Indicates the support status: * Generally Available
    (GA) * Technology Preview (TP) * Developer Preview (DP). Supported By:: Indicates
    the support provider: * Red Hat * Partner Name * Customer Name * Backstage Community
    Backstage Version Supported:: Replaces the previous Version field. Author:: Indicates
    the plugin author. Tags:: Indicates the plugin tags. Category:: Indicates the
    plugin category. Badges:: GA (Green):: For plugins that have the Generally Available
    Release Status, and a non empty Supported By value. Certified (Purple):: For Red
    Hat partner plugins (unchanged). Custom (Yellow):: For customer-developed plugins
    (unchanged). ``` The Verified badge is removed. ``` For more information, see
    Utilizing plugin indicators and support types in Red Hat Developer Hub. ## Enhanced
    package management in the Extensions page With this update, Red Hat Developer
    Hub includes a reorganized Extensions navigation, enabling the user to manage
    installed packages more easily. The former Installed Plugins tab is renamed to
    Installed Packages and includes new row actions that allow you to edit, enable,
    and disable packages directly from the'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:18:49.824619'
    uuid: b237c4a1-1293-4774-96d2-941c6cb23ad6
  response: 'The Red Hat Developer Hub 1.8 update introduces built-in monitoring for
    the Red Hat Developer Hub Operator. By enabling `spec.monitoring.enabled: true`
    in your Backstage custom resource, the Operator will automatically manage service
    monitor resources for Prometheus metrics collection on the /metrics endpoint.
    This simplifies the monitoring process and enhances the user experience on Kubernetes
    clusters with Prometheus Operator installed by eliminating the need for manual
    service monitor setup.'
  user_input: How does the new Red Hat Developer Hub Operator update simplify the
    process for setting up Prometheus metrics monitoring on our Kubernetes clusters?
- context:
  - 'New features This section highlights new features in Red Hat Developer Hub 1.8.
    ## Built-in monitoring for Red Hat Developer Hub operator This update introduces
    built-in monitoring for the Red Hat Developer Hub Operator. By enabling spec.monitoring.enabled:
    true in your Backstage custom resource, the Red Hat Developer Hub Operator will
    automatically manage service monitor resources for Prometheus metrics collection
    on the /metrics endpoint. This simplifies the monitoring process, eliminating
    the need for manual service monitor setup, and enhances the user experience on
    OpenShift and Kubernetes clusters with Prometheus Operator installed. For more
    information, see Enabling metrics monitoring in a Red Hat Developer Hub Operator
    installation on an OpenShift Container Platform cluster. ## Introducing localization
    support in core plugins, and French localization This update introduces localization
    support and French localization to these core plugins: Adoption insights AI Integrations
    Bulk Import Extensions (Marketplace) Lightspeed Orchestrator QuickStart RBAC ScoreCard
    Topology Global header Homepage Tekton ArgoCD This enhancement allows Red Hat
    Developer Hub to display content in French, improving accessibility for users
    who speak French. AI/Cursor automation ensures a seamless translation process,
    enhancing the user experience by providing content in their preferred language,
    preparing Red Hat Developer Hub for use in multilingual environments and fostering
    a more inclusive developer community. For more information, see Selecting the
    language for your Developer Hub instance. ## Localization support for strings
    defined in Red Hat Developer Hub configuration files With this update, localization
    support is introduced for strings defined in Red Hat Developer Hub configuration
    files such as app-config.yaml and dynamic-plugins.default.yaml. This enables users
    to customize the interface in their preferred language, providing a consistent
    multilingual interface across these components: Entity Tabs Configuration Global
    Header QuickStart Sidebar Menu Items Floating Action Button (FAB) labels and tooltips
    This localization support ensures a more inclusive and user-friendly experience
    for a diverse user base, improving user experience and supporting global users.
    For more information, see Enabling Quickstart localization in RHDH. ## Plugins
    localization support With this update, Red Hat Developer Hub integrates the Backstage
    localization framework, enabling users to load translations provided by their
    plugins. The selected language will persist according to the user settings persistence
    configuration. Additionally, users can load translations from an external JSON
    file, allowing them to override existing translations or add translations for
    existing translation keys. For more information, see Localization support for
    plugins. ## Enhanced Bulk Import with Scaffolder Templates With this update, users
    can enhance the Bulk Import plugin by importing repositories using scaffolder
    templates. This automates and optimizes the process by integrating with existing
    Backstage templates and Orchestrator workflows. Users can select their preferred
    pre-ingestion workflow and incorporate various scaffolder actions into their bulk
    import process, resulting in a more efficient and flexible Bulk Import experience.
    For more information, see Input parameters for Bulk Import Scaffolder template.
    ## Enabling Software Template version update notifications With this update, you
    can enable notification alerts whenever a Software Template is updated with a
    new version. For more information, see Enabling Software Template version update
    notifications in Red Hat Developer Hub. ## Software Template provenance and dependency
    tracking With this update, Red Hat Developer Hub supports Software Template provenance
    and a dedicated dependency view to improve component traceability and lifecycle
    management across your organization. For more information, see Tracking component
    origin and Software Template version. ## Users can customize their homepage With
    this update, Red Hat Developer Hub users can customize their homepage, empowering
    personalization and productivity. Users can now move, resize, remove, and add
    existing cards, fostering a more flexible and adaptable user experience. The customization
    options are based on the existing settings, and users can reset their configuration
    to the default. The feature aims to improve the resize and reorder mechanism,
    and update existing cards to work better on different card sizes. For more information,
    see Customizing the Home page. ## Developer Hub community plugins updated to Backstage
    1.42 The Developer Hub community plugins have been updated to Backstage version
    1.42. ## Quick Start experience for developers logging into Red Hat Developer
    Hub for the first time With this update, Red Hat Developer Hub includes a guided
    Quick Start experience tailored for the developer persona. This new feature appears
    automatically upon a developer&#39;s first login to help them get started quickly
    and accelerate adoption of the platform. The developer Quick Start provides guided
    next steps for key features, including: Bulk import Software Catalog Self service
    templates Learning paths This feature is integrated with RBAC, allowing platform
    engineers to configure the Quick Start content and conditionally display it to
    specific developer groups for personalized onboarding. For more information, see
    {setting-up-and-configuring-your-first-rhdh-instance-link}[{setting-up-and-configuring-your-first-rhdh-instance-title}].
    ## Transparent plugin support indicators With this update, the plugin support
    model is now transparently aligned with Red Hat&#39;s standard release classifications.
    The Verified badge is removed, a clearer tiered support system is implemented,
    and plugin metadata are enhanced, providing a more informative and user-friendly
    experience in the Extensions Catalog. This change improves visibility into plugin
    maturity, enhances customer trust, and ensures internal consistency across the
    catalog. Release Status:: Indicates the support status: * Generally Available
    (GA) * Technology Preview (TP) * Developer Preview (DP). Supported By:: Indicates
    the support provider: * Red Hat * Partner Name * Customer Name * Backstage Community
    Backstage Version Supported:: Replaces the previous Version field. Author:: Indicates
    the plugin author. Tags:: Indicates the plugin tags. Category:: Indicates the
    plugin category. Badges:: GA (Green):: For plugins that have the Generally Available
    Release Status, and a non empty Supported By value. Certified (Purple):: For Red
    Hat partner plugins (unchanged). Custom (Yellow):: For customer-developed plugins
    (unchanged). ``` The Verified badge is removed. ``` For more information, see
    Utilizing plugin indicators and support types in Red Hat Developer Hub. ## Enhanced
    package management in the Extensions page With this update, Red Hat Developer
    Hub includes a reorganized Extensions navigation, enabling the user to manage
    installed packages more easily. The former Installed Plugins tab is renamed to
    Installed Packages and includes new row actions that allow you to edit, enable,
    and disable packages directly from the'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:19:01.518715'
    uuid: 9a2be8e8-da17-4a3b-8f0b-4a8ba21877a2
  response: 'The built-in monitoring for the Red Hat Developer Hub Operator enhances
    the user experience on Kubernetes clusters with Prometheus Operator installed
    by automatically managing service monitor resources for Prometheus metrics collection
    on the /metrics endpoint. This update simplifies the monitoring process by eliminating
    the need for manual service monitor setup, which can be enabled by setting spec.monitoring.enabled:
    true in your Backstage custom resource.'
  user_input: How does the new built-in monitoring feature for the Red Hat Developer
    Hub Operator enhance the user experience on Kubernetes clusters?
- context:
  - 'New features This section highlights new features in Red Hat Developer Hub 1.8.
    ## Built-in monitoring for Red Hat Developer Hub operator This update introduces
    built-in monitoring for the Red Hat Developer Hub Operator. By enabling spec.monitoring.enabled:
    true in your Backstage custom resource, the Red Hat Developer Hub Operator will
    automatically manage service monitor resources for Prometheus metrics collection
    on the /metrics endpoint. This simplifies the monitoring process, eliminating
    the need for manual service monitor setup, and enhances the user experience on
    OpenShift and Kubernetes clusters with Prometheus Operator installed. For more
    information, see Enabling metrics monitoring in a Red Hat Developer Hub Operator
    installation on an OpenShift Container Platform cluster. ## Introducing localization
    support in core plugins, and French localization This update introduces localization
    support and French localization to these core plugins: Adoption insights AI Integrations
    Bulk Import Extensions (Marketplace) Lightspeed Orchestrator QuickStart RBAC ScoreCard
    Topology Global header Homepage Tekton ArgoCD This enhancement allows Red Hat
    Developer Hub to display content in French, improving accessibility for users
    who speak French. AI/Cursor automation ensures a seamless translation process,
    enhancing the user experience by providing content in their preferred language,
    preparing Red Hat Developer Hub for use in multilingual environments and fostering
    a more inclusive developer community. For more information, see Selecting the
    language for your Developer Hub instance. ## Localization support for strings
    defined in Red Hat Developer Hub configuration files With this update, localization
    support is introduced for strings defined in Red Hat Developer Hub configuration
    files such as app-config.yaml and dynamic-plugins.default.yaml. This enables users
    to customize the interface in their preferred language, providing a consistent
    multilingual interface across these components: Entity Tabs Configuration Global
    Header QuickStart Sidebar Menu Items Floating Action Button (FAB) labels and tooltips
    This localization support ensures a more inclusive and user-friendly experience
    for a diverse user base, improving user experience and supporting global users.
    For more information, see Enabling Quickstart localization in RHDH. ## Plugins
    localization support With this update, Red Hat Developer Hub integrates the Backstage
    localization framework, enabling users to load translations provided by their
    plugins. The selected language will persist according to the user settings persistence
    configuration. Additionally, users can load translations from an external JSON
    file, allowing them to override existing translations or add translations for
    existing translation keys. For more information, see Localization support for
    plugins. ## Enhanced Bulk Import with Scaffolder Templates With this update, users
    can enhance the Bulk Import plugin by importing repositories using scaffolder
    templates. This automates and optimizes the process by integrating with existing
    Backstage templates and Orchestrator workflows. Users can select their preferred
    pre-ingestion workflow and incorporate various scaffolder actions into their bulk
    import process, resulting in a more efficient and flexible Bulk Import experience.
    For more information, see Input parameters for Bulk Import Scaffolder template.
    ## Enabling Software Template version update notifications With this update, you
    can enable notification alerts whenever a Software Template is updated with a
    new version. For more information, see Enabling Software Template version update
    notifications in Red Hat Developer Hub. ## Software Template provenance and dependency
    tracking With this update, Red Hat Developer Hub supports Software Template provenance
    and a dedicated dependency view to improve component traceability and lifecycle
    management across your organization. For more information, see Tracking component
    origin and Software Template version. ## Users can customize their homepage With
    this update, Red Hat Developer Hub users can customize their homepage, empowering
    personalization and productivity. Users can now move, resize, remove, and add
    existing cards, fostering a more flexible and adaptable user experience. The customization
    options are based on the existing settings, and users can reset their configuration
    to the default. The feature aims to improve the resize and reorder mechanism,
    and update existing cards to work better on different card sizes. For more information,
    see Customizing the Home page. ## Developer Hub community plugins updated to Backstage
    1.42 The Developer Hub community plugins have been updated to Backstage version
    1.42. ## Quick Start experience for developers logging into Red Hat Developer
    Hub for the first time With this update, Red Hat Developer Hub includes a guided
    Quick Start experience tailored for the developer persona. This new feature appears
    automatically upon a developer&#39;s first login to help them get started quickly
    and accelerate adoption of the platform. The developer Quick Start provides guided
    next steps for key features, including: Bulk import Software Catalog Self service
    templates Learning paths This feature is integrated with RBAC, allowing platform
    engineers to configure the Quick Start content and conditionally display it to
    specific developer groups for personalized onboarding. For more information, see
    {setting-up-and-configuring-your-first-rhdh-instance-link}[{setting-up-and-configuring-your-first-rhdh-instance-title}].
    ## Transparent plugin support indicators With this update, the plugin support
    model is now transparently aligned with Red Hat&#39;s standard release classifications.
    The Verified badge is removed, a clearer tiered support system is implemented,
    and plugin metadata are enhanced, providing a more informative and user-friendly
    experience in the Extensions Catalog. This change improves visibility into plugin
    maturity, enhances customer trust, and ensures internal consistency across the
    catalog. Release Status:: Indicates the support status: * Generally Available
    (GA) * Technology Preview (TP) * Developer Preview (DP). Supported By:: Indicates
    the support provider: * Red Hat * Partner Name * Customer Name * Backstage Community
    Backstage Version Supported:: Replaces the previous Version field. Author:: Indicates
    the plugin author. Tags:: Indicates the plugin tags. Category:: Indicates the
    plugin category. Badges:: GA (Green):: For plugins that have the Generally Available
    Release Status, and a non empty Supported By value. Certified (Purple):: For Red
    Hat partner plugins (unchanged). Custom (Yellow):: For customer-developed plugins
    (unchanged). ``` The Verified badge is removed. ``` For more information, see
    Utilizing plugin indicators and support types in Red Hat Developer Hub. ## Enhanced
    package management in the Extensions page With this update, Red Hat Developer
    Hub includes a reorganized Extensions navigation, enabling the user to manage
    installed packages more easily. The former Installed Plugins tab is renamed to
    Installed Packages and includes new row actions that allow you to edit, enable,
    and disable packages directly from the'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:19:11.231093'
    uuid: 237359b3-363b-4c70-8081-05d57b0e1a9b
  response: 'Red Hat Developer Hub 1.8 introduces built-in monitoring for the Red
    Hat Developer Hub Operator. By enabling "spec.monitoring.enabled: true" in your
    Backstage custom resource, the Operator will automatically manage service monitor
    resources for Prometheus metrics collection on the /metrics endpoint. This simplifies
    the monitoring process, eliminating the need for manual service monitor setup
    and enhancing the user experience on OpenShift and Kubernetes clusters where the
    Prometheus Operator is installed.'
  user_input: How does Red Hat Developer Hub 1.8 simplify monitoring on OpenShift
    clusters?
- context:
  - 'Deprecated functionalities This section lists deprecated functionalities in Red
    Hat Developer Hub 1.8. ## Backstage CR versions v1alpha1 and v1alpha2 Backstage
    CR versions v1alpha1 and v1alpha2 were deprecated in 1.7 and will be removed in
    1.9. RHIDP 6917 ## Deprecation of Bundled Plugin Wrappers To enhance performance,
    decrease image size, and reduce maintenance, the method of including &#34;wrapped&#34;
    dynamic plugins within the main Red Hat Developer Hub container image was deprecated
    in RHDH 1.7.0. We are transitioning to a model where all dynamic plugins will
    be distributed as independent OCI artifacts. This is a deprecation notice only;
    there are no breaking changes in 1.8.0 related to plugins, wrappers, or support
    for OCI artifacts. All previously bundled plugins will continue to be bundled
    in this release. However, we encourage customers to prepare for the removal of
    wrappers in a future release by beginning to use the new OCI artifacts in 1.9.0.
    Documentation will be updated to guide this migration. For more information, see
    Loading a plugin packaged as an OCI image. RHIDP 8525 ## Deprecation of OCM Plugins
    The Open Cluster Management (OCM) plugins integrates your Red Hat Developer Hub
    instance with the MultiClusterHub and MultiCluster engines of OCM. The OCM plugins
    are deprecated as of RHDH 1.8, and will be removed in a future release. RHIDP
    9180 # Technology Preview This section lists Technology Preview features in Red
    Hat Developer Hub 1.8. [IMPORTANT] ---- Technology Preview features provide early
    access to upcoming product innovations, enabling you to test functionality and
    provide feedback during the development process. However, these features are not
    fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- ## Bulk import GitLab projects With
    this update, users can bulk import entities from GitLab into Red Hat Developer
    Hub, enhancing onboarding efficiency. For more information, see Importing multiple
    GitLab repositories. # Developer Preview This section lists Developer Preview
    features in Red Hat Developer Hub 1.8. [IMPORTANT] ---- Developer Preview features
    are not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- ## Interacting with Model Context Protocol
    tools for Red Hat Developer Hub You can enhance your Red Hat Developer Hub integration
    by leveraging the Model Context Protocol (MCP) server. This integration enables
    seamless communication with various Artificial Intelligence (AI) clients, facilitating
    efficient data exchange and expanding the functionality of the platform. RHDHPAI
    1087 Interacting with Model Context Protocol tools for Red Hat Developer Hub Blogpost
    on MCP in Red Hat Developer Hub ## OpenShift AI Connector for Red Hat Developer
    Hub You can use OpenShift AI Connector for RHDH to enable users to use Red Hat
    Developer Hub (RHDH) to surface AI Models and Model Servers from Red Hat OpenShift
    AI (RHOAI) directly into the RHDH/Backstage Catalog. RHDHPAI 1089 OpenShift AI
    Connector for Red Hat Developer Hub Blogpost on OpenShift AI Connector for RHDH
    ## Built-in TechDocs for RHDH Local With this update, RHDH Local includes essential
    Getting Started and How-To documentation about RHDH Local which is embedded as
    TechDocs. In RHDH Local, you can access this built-in documentation directly within
    the application. Additional information about configuring RHDH for its supported
    platforms can be found at https://docs.redhat.com/en/documentation/red_hat_developer_hub/.
    ## Red Hat Developer Lightspeed for Red Hat Developer Hub now uses Lightspeed
    Core (LCORE) The Developer Lightspeed for RHDH plugin has completed its migration
    from the Road-Core Service to Lightspeed Core (LCORE). This architectural change
    provides enhanced stability and prepares the plugin for future feature development
    during the Developer Preview. RHDHPAI 1091 What is Llama Stack Lightspeed Core
    Red Hat Developer Lightspeed for Red Hat Developer Hub ## Tech Radar and Quay
    plugins in RHDH Local With this update, RHDH Local integrates the Tech Radar and
    Quay plugins, for a better out of the box experience for users. The Tech Radar
    plugin provides a visually engaging element on the homepage or via navigation,
    and showcases the dynamic plugins loading mechanism for simple Developer Hub extension.
    The Quay plugin demonstrates integration with external services and provides a
    practical example of extending the Developer Hub software catalog. RHIDP 8296
    ## RHDH Local default homepage enhancements With this update, RHDH Local default
    homepage integrates a floating action button with quick links for easy access
    to documentation and information. RHIDP 8297 ## Enhanced customization and collaboration
    with pre-loaded templates in RHDH Local With this update, RHDH Local integrates
    pre-loaded essential templates, enabling users to create their own custom plugins
    and add TechDocs or software components to existing projects within Red Hat Developer
    Hub. This enhancement demonstrates Developer Hub extensibility, empowers users
    to extend the platform, and enhances the overall user experience by promoting
    collaboration and customization. RHIDP 8298 ## Configurable Key Performance Indicators
    (KPIs) by using the Scorecard plugin With this release, Red Hat Developer Hub
    integrates the Scorecard plugin, enabling users to visualize software quality
    and health metrics directly in Developer Hub. Developers can visualize scorecards
    with the metrics available to the their role in a tab on component detail pages,
    allowing them to quickly check the quality of their code and ensure it meets team
    standards. Platform engineers can configure Key Performance Indicators (KPIs)
    from various data sources, with initial support'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:19:23.934936'
    uuid: 065b0d25-2b22-42d6-ac86-92e5f1c03c8e
  response: You can use the OpenShift AI Connector for RHDH to enable users to use
    Red Hat Developer Hub (RHDH) to surface AI Models and Model Servers from Red Hat
    OpenShift AI (RHOAI) directly into the RHDH/Backstage Catalog. The OpenShift AI
    Connector is a Developer Preview feature, which means it is not supported by Red
    Hat in any way, is not functionally complete or production-ready, and should not
    be used for production or business-critical workloads.
  user_input: What is the functionality of the OpenShift AI Connector for Red Hat
    Developer Hub and what is its official support status in RHDH 1.8 for production
    environments?
- context:
  - 'Deprecated functionalities This section lists deprecated functionalities in Red
    Hat Developer Hub 1.8. ## Backstage CR versions v1alpha1 and v1alpha2 Backstage
    CR versions v1alpha1 and v1alpha2 were deprecated in 1.7 and will be removed in
    1.9. RHIDP 6917 ## Deprecation of Bundled Plugin Wrappers To enhance performance,
    decrease image size, and reduce maintenance, the method of including &#34;wrapped&#34;
    dynamic plugins within the main Red Hat Developer Hub container image was deprecated
    in RHDH 1.7.0. We are transitioning to a model where all dynamic plugins will
    be distributed as independent OCI artifacts. This is a deprecation notice only;
    there are no breaking changes in 1.8.0 related to plugins, wrappers, or support
    for OCI artifacts. All previously bundled plugins will continue to be bundled
    in this release. However, we encourage customers to prepare for the removal of
    wrappers in a future release by beginning to use the new OCI artifacts in 1.9.0.
    Documentation will be updated to guide this migration. For more information, see
    Loading a plugin packaged as an OCI image. RHIDP 8525 ## Deprecation of OCM Plugins
    The Open Cluster Management (OCM) plugins integrates your Red Hat Developer Hub
    instance with the MultiClusterHub and MultiCluster engines of OCM. The OCM plugins
    are deprecated as of RHDH 1.8, and will be removed in a future release. RHIDP
    9180 # Technology Preview This section lists Technology Preview features in Red
    Hat Developer Hub 1.8. [IMPORTANT] ---- Technology Preview features provide early
    access to upcoming product innovations, enabling you to test functionality and
    provide feedback during the development process. However, these features are not
    fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- ## Bulk import GitLab projects With
    this update, users can bulk import entities from GitLab into Red Hat Developer
    Hub, enhancing onboarding efficiency. For more information, see Importing multiple
    GitLab repositories. # Developer Preview This section lists Developer Preview
    features in Red Hat Developer Hub 1.8. [IMPORTANT] ---- Developer Preview features
    are not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- ## Interacting with Model Context Protocol
    tools for Red Hat Developer Hub You can enhance your Red Hat Developer Hub integration
    by leveraging the Model Context Protocol (MCP) server. This integration enables
    seamless communication with various Artificial Intelligence (AI) clients, facilitating
    efficient data exchange and expanding the functionality of the platform. RHDHPAI
    1087 Interacting with Model Context Protocol tools for Red Hat Developer Hub Blogpost
    on MCP in Red Hat Developer Hub ## OpenShift AI Connector for Red Hat Developer
    Hub You can use OpenShift AI Connector for RHDH to enable users to use Red Hat
    Developer Hub (RHDH) to surface AI Models and Model Servers from Red Hat OpenShift
    AI (RHOAI) directly into the RHDH/Backstage Catalog. RHDHPAI 1089 OpenShift AI
    Connector for Red Hat Developer Hub Blogpost on OpenShift AI Connector for RHDH
    ## Built-in TechDocs for RHDH Local With this update, RHDH Local includes essential
    Getting Started and How-To documentation about RHDH Local which is embedded as
    TechDocs. In RHDH Local, you can access this built-in documentation directly within
    the application. Additional information about configuring RHDH for its supported
    platforms can be found at https://docs.redhat.com/en/documentation/red_hat_developer_hub/.
    ## Red Hat Developer Lightspeed for Red Hat Developer Hub now uses Lightspeed
    Core (LCORE) The Developer Lightspeed for RHDH plugin has completed its migration
    from the Road-Core Service to Lightspeed Core (LCORE). This architectural change
    provides enhanced stability and prepares the plugin for future feature development
    during the Developer Preview. RHDHPAI 1091 What is Llama Stack Lightspeed Core
    Red Hat Developer Lightspeed for Red Hat Developer Hub ## Tech Radar and Quay
    plugins in RHDH Local With this update, RHDH Local integrates the Tech Radar and
    Quay plugins, for a better out of the box experience for users. The Tech Radar
    plugin provides a visually engaging element on the homepage or via navigation,
    and showcases the dynamic plugins loading mechanism for simple Developer Hub extension.
    The Quay plugin demonstrates integration with external services and provides a
    practical example of extending the Developer Hub software catalog. RHIDP 8296
    ## RHDH Local default homepage enhancements With this update, RHDH Local default
    homepage integrates a floating action button with quick links for easy access
    to documentation and information. RHIDP 8297 ## Enhanced customization and collaboration
    with pre-loaded templates in RHDH Local With this update, RHDH Local integrates
    pre-loaded essential templates, enabling users to create their own custom plugins
    and add TechDocs or software components to existing projects within Red Hat Developer
    Hub. This enhancement demonstrates Developer Hub extensibility, empowers users
    to extend the platform, and enhances the overall user experience by promoting
    collaboration and customization. RHIDP 8298 ## Configurable Key Performance Indicators
    (KPIs) by using the Scorecard plugin With this release, Red Hat Developer Hub
    integrates the Scorecard plugin, enabling users to visualize software quality
    and health metrics directly in Developer Hub. Developers can visualize scorecards
    with the metrics available to the their role in a tab on component detail pages,
    allowing them to quickly check the quality of their code and ensure it meets team
    standards. Platform engineers can configure Key Performance Indicators (KPIs)
    from various data sources, with initial support'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:19:33.039750'
    uuid: 27797e44-c224-4ceb-99b7-7b35f4ad1caf
  response: The Backstage CR versions v1alpha1 and v1alpha2 were deprecated in Red
    Hat Developer Hub 1.7 and are planned to be removed in version 1.9.
  user_input: As a Platform Engineering Lead, I need to understand the lifecycle of
    our core components; what is the deprecation status of the v1alpha1 and v1alpha2
    Backstage CR versions?
- context:
  - 'Deprecated functionalities This section lists deprecated functionalities in Red
    Hat Developer Hub 1.8. ## Backstage CR versions v1alpha1 and v1alpha2 Backstage
    CR versions v1alpha1 and v1alpha2 were deprecated in 1.7 and will be removed in
    1.9. RHIDP 6917 ## Deprecation of Bundled Plugin Wrappers To enhance performance,
    decrease image size, and reduce maintenance, the method of including &#34;wrapped&#34;
    dynamic plugins within the main Red Hat Developer Hub container image was deprecated
    in RHDH 1.7.0. We are transitioning to a model where all dynamic plugins will
    be distributed as independent OCI artifacts. This is a deprecation notice only;
    there are no breaking changes in 1.8.0 related to plugins, wrappers, or support
    for OCI artifacts. All previously bundled plugins will continue to be bundled
    in this release. However, we encourage customers to prepare for the removal of
    wrappers in a future release by beginning to use the new OCI artifacts in 1.9.0.
    Documentation will be updated to guide this migration. For more information, see
    Loading a plugin packaged as an OCI image. RHIDP 8525 ## Deprecation of OCM Plugins
    The Open Cluster Management (OCM) plugins integrates your Red Hat Developer Hub
    instance with the MultiClusterHub and MultiCluster engines of OCM. The OCM plugins
    are deprecated as of RHDH 1.8, and will be removed in a future release. RHIDP
    9180 # Technology Preview This section lists Technology Preview features in Red
    Hat Developer Hub 1.8. [IMPORTANT] ---- Technology Preview features provide early
    access to upcoming product innovations, enabling you to test functionality and
    provide feedback during the development process. However, these features are not
    fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- ## Bulk import GitLab projects With
    this update, users can bulk import entities from GitLab into Red Hat Developer
    Hub, enhancing onboarding efficiency. For more information, see Importing multiple
    GitLab repositories. # Developer Preview This section lists Developer Preview
    features in Red Hat Developer Hub 1.8. [IMPORTANT] ---- Developer Preview features
    are not supported by Red Hat in any way and are not functionally complete or production-ready.
    Do not use Developer Preview features for production or business-critical workloads.
    Developer Preview features provide early access to functionality in advance of
    possible inclusion in a Red Hat product offering. Customers can use these features
    to test functionality and provide feedback during the development process. Developer
    Preview features might not have any documentation, are subject to change or removal
    at any time, and have received limited testing. Red Hat might provide ways to
    submit feedback on Developer Preview features without an associated SLA. For more
    information about the support scope of Red Hat Developer Preview features, see
    Developer Preview Support Scope. ---- ## Interacting with Model Context Protocol
    tools for Red Hat Developer Hub You can enhance your Red Hat Developer Hub integration
    by leveraging the Model Context Protocol (MCP) server. This integration enables
    seamless communication with various Artificial Intelligence (AI) clients, facilitating
    efficient data exchange and expanding the functionality of the platform. RHDHPAI
    1087 Interacting with Model Context Protocol tools for Red Hat Developer Hub Blogpost
    on MCP in Red Hat Developer Hub ## OpenShift AI Connector for Red Hat Developer
    Hub You can use OpenShift AI Connector for RHDH to enable users to use Red Hat
    Developer Hub (RHDH) to surface AI Models and Model Servers from Red Hat OpenShift
    AI (RHOAI) directly into the RHDH/Backstage Catalog. RHDHPAI 1089 OpenShift AI
    Connector for Red Hat Developer Hub Blogpost on OpenShift AI Connector for RHDH
    ## Built-in TechDocs for RHDH Local With this update, RHDH Local includes essential
    Getting Started and How-To documentation about RHDH Local which is embedded as
    TechDocs. In RHDH Local, you can access this built-in documentation directly within
    the application. Additional information about configuring RHDH for its supported
    platforms can be found at https://docs.redhat.com/en/documentation/red_hat_developer_hub/.
    ## Red Hat Developer Lightspeed for Red Hat Developer Hub now uses Lightspeed
    Core (LCORE) The Developer Lightspeed for RHDH plugin has completed its migration
    from the Road-Core Service to Lightspeed Core (LCORE). This architectural change
    provides enhanced stability and prepares the plugin for future feature development
    during the Developer Preview. RHDHPAI 1091 What is Llama Stack Lightspeed Core
    Red Hat Developer Lightspeed for Red Hat Developer Hub ## Tech Radar and Quay
    plugins in RHDH Local With this update, RHDH Local integrates the Tech Radar and
    Quay plugins, for a better out of the box experience for users. The Tech Radar
    plugin provides a visually engaging element on the homepage or via navigation,
    and showcases the dynamic plugins loading mechanism for simple Developer Hub extension.
    The Quay plugin demonstrates integration with external services and provides a
    practical example of extending the Developer Hub software catalog. RHIDP 8296
    ## RHDH Local default homepage enhancements With this update, RHDH Local default
    homepage integrates a floating action button with quick links for easy access
    to documentation and information. RHIDP 8297 ## Enhanced customization and collaboration
    with pre-loaded templates in RHDH Local With this update, RHDH Local integrates
    pre-loaded essential templates, enabling users to create their own custom plugins
    and add TechDocs or software components to existing projects within Red Hat Developer
    Hub. This enhancement demonstrates Developer Hub extensibility, empowers users
    to extend the platform, and enhances the overall user experience by promoting
    collaboration and customization. RHIDP 8298 ## Configurable Key Performance Indicators
    (KPIs) by using the Scorecard plugin With this release, Red Hat Developer Hub
    integrates the Scorecard plugin, enabling users to visualize software quality
    and health metrics directly in Developer Hub. Developers can visualize scorecards
    with the metrics available to the their role in a tab on component detail pages,
    allowing them to quickly check the quality of their code and ensure it meets team
    standards. Platform engineers can configure Key Performance Indicators (KPIs)
    from various data sources, with initial support'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:19:43.586817'
    uuid: ffd83937-f11a-4dcd-badf-02edc3c16e5f
  response: 'The Developer Preview features in Red Hat Developer Hub 1.8 include:
    interacting with Model Context Protocol (MCP) tools to communicate with AI clients;
    the OpenShift AI Connector to surface AI Models and Model Servers from Red Hat
    OpenShift AI into the catalog; built-in TechDocs for RHDH Local; the migration
    of Red Hat Developer Lightspeed to Lightspeed Core (LCORE) for enhanced stability;
    the integration of Tech Radar and Quay plugins in RHDH Local; homepage enhancements
    for RHDH Local, such as a floating action button with quick links; pre-loaded
    templates in RHDH Local for creating custom plugins and adding components; and
    configurable Key Performance Indicators (KPIs) using the Scorecard plugin. The
    deprecated functionalities are: Backstage CR versions v1alpha1 and v1alpha2, which
    will be removed in 1.9; the method of including "wrapped" dynamic plugins, with
    a transition to independent OCI artifacts (though there are no breaking changes
    in 1.8.0); and the Open Cluster Management (OCM) plugins, which are deprecated
    as of RHDH 1.8 and will be removed in a future release.'
  user_input: so i am looking at the new Red Hat Developer Hub and i see a lot of
    things is changing, what are all the new developer preview features that is coming
    out and also what things are getting deprecated that i need to worry about for
    my team's platform?
- context:
  - '# Red Hat Developer Hub release notes Red Hat Developer Hub (Developer Hub) 1.8
    is now generally available. Developer Hub is a fully supported, enterprise-grade
    productized version of upstream Backstage, compatible with version 1.42.5. Plugins
    might be compatible with a newer Backstage version. You can access and download
    the Red Hat Developer Hub application from the Red Hat Customer Portal or from
    the Ecosystem Catalog. # list. ## Support for high availability in Google Kubernetes
    Engine Red Hat Developer Hub now supports high availability setups in Google Kubernetes
    Engine (GKE). This enhancement allows the deployment to scale beyond a single
    replica, ensuring the application remains operational and accessible even in the
    event of failures or disruptions. For more information, see Configuring high availability
    in Red Hat Developer Hub. ## Customizable container deployment in Red Hat Developer
    Hub pods Previously, injecting necessary files (extraFiles) and environment variables
    (extraEnvs) was restricted to the default backstage-backend container. With this
    update, you can configure resource injection for any container in the Red Hat
    Developer Hub pod, including sidecars and system containers. This allows you to
    complete the job of deploying custom components, such as security agents, log
    collectors, or configuration managers, that require specific volumes or runtime
    variables to operate successfully. For more information, see Injecting extra files
    and environment variables into Backstage containers. # Breaking changes This section
    lists breaking changes in Red Hat Developer Hub 1.8. ## Argo CD, Tekton, and Topology
    plugins require the Kubernetes Frontend and Kubernetes Backend plugins With this
    update, the Argo CD, Tekton, and Topology plugins requires the Kubernetes Frontend
    and Kubernetes Backend plugins. Before this update, these plugins depended only
    on the Kubernetes Backend plugin, and the feature provided by the Kubernetes Frontend
    plugin where provided by the removed @janus-idp/shared-react package. 1. Enable
    the Kubernetes Frontend and Kubernetes Backend plugins. ```yaml global: dynamic:
    plugins: package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic
    disabled: false ``` 2. The Kubernetes Frontend plugin shows automatically a Kubernetes
    tab for Software Catalog entities with the annotation backstage.io/kubernetes-id
    or backstage.io/kubernetes-namespace. Optionally, to hide the Kubernetes tab in
    the Software Catalog, disable the feature with this dynamic plugin configuration:
    ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin
    kubernetes disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    kubernetes: mountPoints: [] package: ./dynamic plugins/dist/backstage plugin kubernetes
    backend dynamic disabled: false ``` RHIDP 5309 # for GitHub open pull requests
    and Jira open issues. Custom metric providers will allow for the addition of more
    data sources. This simplifies the monitoring of applications by offering a single,
    clear report on health, security, and compliance. RHIDP 8709 Understand and visualize
    Red Hat Developer Hub project health using Scorecards ## Dynamic Plugin Factory
    to convert plugins into dynamic plugins You can automate the conversion and packaging
    of standard Backstage plugins into RHDH dynamic plugins by using the RHDH Dynamic
    Plugin Factory tool. The core function of the Dynamic Plugin Factory tool is to
    streamline the dynamic plugin build process, offering the following capabilities:
    Source Code Handling:: Manages cloning, checking out, and applying custom patches
    to the plugin source. Dependency Management:: Handles yarn installation and TypeScript
    compilation. Packaging:: Uses the RHDH CLI to build, export, and package the final
    dynamic plugin. Deployment:: Offers an option to push the resulting container
    image to registries like Quay or OpenShift. The Dynamic Plugin Factory tool provides
    a simplified, reproducible method for developers and platform engineers to create
    and test dynamic plugins using a pre-configured dynamic plugin factory container
    and documentation, significantly easing migration and testing. For more information,
    see RHDH Dynamic Plugin Factory. ## Events Module available With this release,
    you can use the Events Module together with scheduled updates to make sure your
    GitHub user or catalog entities are updated whenever changes occur in the external
    system. See Configuring Events module. RHIDP 8196 #'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:19:53.004362'
    uuid: 5ede5963-e505-4014-8021-30febd592c93
  response: The Scorecards feature can utilize data from Jira open issues. Custom
    metric providers will allow for the addition of more data sources, which simplifies
    the monitoring of applications by offering a single, clear report on health, security,
    and compliance.
  user_input: i was looking at the new release notes and saw something about scorecards,
    how does that feature use Jira, like can we see the open issues from Jira to understand
    if our projects is healthy or not for my team?
- context:
  - '# Red Hat Developer Hub release notes Red Hat Developer Hub (Developer Hub) 1.8
    is now generally available. Developer Hub is a fully supported, enterprise-grade
    productized version of upstream Backstage, compatible with version 1.42.5. Plugins
    might be compatible with a newer Backstage version. You can access and download
    the Red Hat Developer Hub application from the Red Hat Customer Portal or from
    the Ecosystem Catalog. # list. ## Support for high availability in Google Kubernetes
    Engine Red Hat Developer Hub now supports high availability setups in Google Kubernetes
    Engine (GKE). This enhancement allows the deployment to scale beyond a single
    replica, ensuring the application remains operational and accessible even in the
    event of failures or disruptions. For more information, see Configuring high availability
    in Red Hat Developer Hub. ## Customizable container deployment in Red Hat Developer
    Hub pods Previously, injecting necessary files (extraFiles) and environment variables
    (extraEnvs) was restricted to the default backstage-backend container. With this
    update, you can configure resource injection for any container in the Red Hat
    Developer Hub pod, including sidecars and system containers. This allows you to
    complete the job of deploying custom components, such as security agents, log
    collectors, or configuration managers, that require specific volumes or runtime
    variables to operate successfully. For more information, see Injecting extra files
    and environment variables into Backstage containers. # Breaking changes This section
    lists breaking changes in Red Hat Developer Hub 1.8. ## Argo CD, Tekton, and Topology
    plugins require the Kubernetes Frontend and Kubernetes Backend plugins With this
    update, the Argo CD, Tekton, and Topology plugins requires the Kubernetes Frontend
    and Kubernetes Backend plugins. Before this update, these plugins depended only
    on the Kubernetes Backend plugin, and the feature provided by the Kubernetes Frontend
    plugin where provided by the removed @janus-idp/shared-react package. 1. Enable
    the Kubernetes Frontend and Kubernetes Backend plugins. ```yaml global: dynamic:
    plugins: package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic
    disabled: false ``` 2. The Kubernetes Frontend plugin shows automatically a Kubernetes
    tab for Software Catalog entities with the annotation backstage.io/kubernetes-id
    or backstage.io/kubernetes-namespace. Optionally, to hide the Kubernetes tab in
    the Software Catalog, disable the feature with this dynamic plugin configuration:
    ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin
    kubernetes disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    kubernetes: mountPoints: [] package: ./dynamic plugins/dist/backstage plugin kubernetes
    backend dynamic disabled: false ``` RHIDP 5309 # for GitHub open pull requests
    and Jira open issues. Custom metric providers will allow for the addition of more
    data sources. This simplifies the monitoring of applications by offering a single,
    clear report on health, security, and compliance. RHIDP 8709 Understand and visualize
    Red Hat Developer Hub project health using Scorecards ## Dynamic Plugin Factory
    to convert plugins into dynamic plugins You can automate the conversion and packaging
    of standard Backstage plugins into RHDH dynamic plugins by using the RHDH Dynamic
    Plugin Factory tool. The core function of the Dynamic Plugin Factory tool is to
    streamline the dynamic plugin build process, offering the following capabilities:
    Source Code Handling:: Manages cloning, checking out, and applying custom patches
    to the plugin source. Dependency Management:: Handles yarn installation and TypeScript
    compilation. Packaging:: Uses the RHDH CLI to build, export, and package the final
    dynamic plugin. Deployment:: Offers an option to push the resulting container
    image to registries like Quay or OpenShift. The Dynamic Plugin Factory tool provides
    a simplified, reproducible method for developers and platform engineers to create
    and test dynamic plugins using a pre-configured dynamic plugin factory container
    and documentation, significantly easing migration and testing. For more information,
    see RHDH Dynamic Plugin Factory. ## Events Module available With this release,
    you can use the Events Module together with scheduled updates to make sure your
    GitHub user or catalog entities are updated whenever changes occur in the external
    system. See Configuring Events module. RHIDP 8196 #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:20:03.453019'
    uuid: 32a4dae5-c227-4727-91f9-3e5771dd291d
  response: For Jira open issues, custom metric providers will allow for the addition
    of more data sources, which simplifies the monitoring of applications by offering
    a single, clear report on health, security, and compliance.
  user_input: what the jira thing do?
- context:
  - '# Red Hat Developer Hub release notes Red Hat Developer Hub (Developer Hub) 1.8
    is now generally available. Developer Hub is a fully supported, enterprise-grade
    productized version of upstream Backstage, compatible with version 1.42.5. Plugins
    might be compatible with a newer Backstage version. You can access and download
    the Red Hat Developer Hub application from the Red Hat Customer Portal or from
    the Ecosystem Catalog. # list. ## Support for high availability in Google Kubernetes
    Engine Red Hat Developer Hub now supports high availability setups in Google Kubernetes
    Engine (GKE). This enhancement allows the deployment to scale beyond a single
    replica, ensuring the application remains operational and accessible even in the
    event of failures or disruptions. For more information, see Configuring high availability
    in Red Hat Developer Hub. ## Customizable container deployment in Red Hat Developer
    Hub pods Previously, injecting necessary files (extraFiles) and environment variables
    (extraEnvs) was restricted to the default backstage-backend container. With this
    update, you can configure resource injection for any container in the Red Hat
    Developer Hub pod, including sidecars and system containers. This allows you to
    complete the job of deploying custom components, such as security agents, log
    collectors, or configuration managers, that require specific volumes or runtime
    variables to operate successfully. For more information, see Injecting extra files
    and environment variables into Backstage containers. # Breaking changes This section
    lists breaking changes in Red Hat Developer Hub 1.8. ## Argo CD, Tekton, and Topology
    plugins require the Kubernetes Frontend and Kubernetes Backend plugins With this
    update, the Argo CD, Tekton, and Topology plugins requires the Kubernetes Frontend
    and Kubernetes Backend plugins. Before this update, these plugins depended only
    on the Kubernetes Backend plugin, and the feature provided by the Kubernetes Frontend
    plugin where provided by the removed @janus-idp/shared-react package. 1. Enable
    the Kubernetes Frontend and Kubernetes Backend plugins. ```yaml global: dynamic:
    plugins: package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic
    disabled: false ``` 2. The Kubernetes Frontend plugin shows automatically a Kubernetes
    tab for Software Catalog entities with the annotation backstage.io/kubernetes-id
    or backstage.io/kubernetes-namespace. Optionally, to hide the Kubernetes tab in
    the Software Catalog, disable the feature with this dynamic plugin configuration:
    ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin
    kubernetes disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    kubernetes: mountPoints: [] package: ./dynamic plugins/dist/backstage plugin kubernetes
    backend dynamic disabled: false ``` RHIDP 5309 # for GitHub open pull requests
    and Jira open issues. Custom metric providers will allow for the addition of more
    data sources. This simplifies the monitoring of applications by offering a single,
    clear report on health, security, and compliance. RHIDP 8709 Understand and visualize
    Red Hat Developer Hub project health using Scorecards ## Dynamic Plugin Factory
    to convert plugins into dynamic plugins You can automate the conversion and packaging
    of standard Backstage plugins into RHDH dynamic plugins by using the RHDH Dynamic
    Plugin Factory tool. The core function of the Dynamic Plugin Factory tool is to
    streamline the dynamic plugin build process, offering the following capabilities:
    Source Code Handling:: Manages cloning, checking out, and applying custom patches
    to the plugin source. Dependency Management:: Handles yarn installation and TypeScript
    compilation. Packaging:: Uses the RHDH CLI to build, export, and package the final
    dynamic plugin. Deployment:: Offers an option to push the resulting container
    image to registries like Quay or OpenShift. The Dynamic Plugin Factory tool provides
    a simplified, reproducible method for developers and platform engineers to create
    and test dynamic plugins using a pre-configured dynamic plugin factory container
    and documentation, significantly easing migration and testing. For more information,
    see RHDH Dynamic Plugin Factory. ## Events Module available With this release,
    you can use the Events Module together with scheduled updates to make sure your
    GitHub user or catalog entities are updated whenever changes occur in the external
    system. See Configuring Events module. RHIDP 8196 #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:20:12.156809'
    uuid: 7043afb5-8600-478b-a307-ea5b403812dc
  response: The RHDH Dynamic Plugin Factory tool is used to automate the conversion
    and packaging of standard Backstage plugins into RHDH dynamic plugins. Its core
    function is to streamline the dynamic plugin build process by offering capabilities
    for source code handling, dependency management, packaging, and deployment. The
    tool provides a simplified, reproducible method for developers and platform engineers
    to create and test dynamic plugins, which significantly eases migration and testing.
  user_input: What is the core function of the RHDH Dynamic Plugin Factory?
- context:
  - 'Fixed issues This section lists issues fixed in Red Hat Developer Hub 1.8. ##
    Fixed issues in 1.8.0 ### Improved startup speed with updated init container image
    pull policy for Developer Hub Helm Chart With this update, the pull policy for
    the init container image of the Developer Hub Helm Chart was changed from Always
    to IfNotPresent. This change reduces the repeated download time during startup
    of the container image, which is approximately 2.5 GB, thereby significantly improving
    startup speed for users. RHDHBUGS 1000 ### Improved Authentication for Self-Hosted
    Enterprise SCM Providers Previously, actions requiring access to a self-hosted
    enterprise SCM provider failed, returning an error that no authentication provider
    was available for the specified host. With this update, the SCM integration correctly
    identifies and uses the configured authentication provider for the corresponding
    enterprise host. RHDHBUGS 1028 ### Customizable image names for job and data index
    services in Developer Hub Helm Chart Previously, when deploying the Developer
    Hub Helm Chart with the Orchestrator enabled, it was not possible to customize
    the image names of the job and data index services, for example in disconnected
    environments. Setting the orchestrator.sonataflowPlatform.jobServiceImage and
    orchestrator.sonataflowPlatform.dataIndexImage would return a schema validation
    error from Helm. This update fixes this issue. RHDHBUGS 2003 ### Network policy
    installation fix for Developer Hub RHDH Helm Chart with Orchestrator flavor Before
    this update, the Developer Hub RHDH Helm Chart would not install Network Policies
    when the Orchestrator flavor was deployed with serverlessLogicOperator disabled,
    preventing the Developer Hub Pods from being completely available. This update
    fixes this situation by installing network policies unconditionally when the orchestrator
    is enabled. RHDHBUGS 2020 ### Resolved SonataFlow Pod Crash Issue In the new release,
    a timing problem during the RHDH 1.7 installation with Orchestrator plugins, affecting
    SonataFlow database provisioning, has been addressed. This issue caused SonataFlow
    pods to repeatedly enter the CrashLoopBackOff state, leading to delays and potential
    confusion for users. With this update, SonataFlow pods no longer encounter the
    CrashLoopBackOff state due to the database provisioning delay. This improvement
    enhances the user experience, as SonataFlow pods now start promptly, eliminating
    unnecessary wait times. RHDHBUGS 2036 ### Fixed SCM integration failures for self-hosted
    enterprise SCM providers Previously, SCM integration failed for self-hosted enterprise
    SCM providers because the system could not identify the configured host. This
    resulted in a No auth provider available error. With this release, the SCM integration
    now correctly uses the configured authentication provider for the corresponding
    enterprise host. As a result, end users can now successfully perform actions requiring
    enterprise SCM access. RHDHBUGS 2249 ### Fixed incorrect version detection for
    local plugin updates Before this update, local plugins within the image were incorrectly
    detected for updates due to version misidentification. This led to users being
    unable to update local plugins from wrappers, resulting in outdated functionality.
    With this release, local plugin updates are now automatically detected, eliminating
    the need for manual adjustments and ensuring seamless plugin version updates for
    end users. RHDHBUGS 2250 # Fixed security issues You can view the security issues
    fixed in Red Hat Developer Hub 1.8 at Red Hat Security Updates. For 1.8.0, see
    Red Hat Security Advisory RHSA-2025:20047. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:20:21.229923'
    uuid: e5705dd6-61db-4d1b-9b47-a546697934c1
  response: In the new release, a timing problem during the RHDH 1.7 installation
    with Orchestrator plugins, which affected SonataFlow database provisioning, has
    been addressed. This issue was the cause of SonataFlow pods repeatedly entering
    the CrashLoopBackOff state, leading to delays and potential confusion for users.
    With this update, SonataFlow pods no longer encounter the CrashLoopBackOff state
    due to the database provisioning delay. This improvement enhances the user experience,
    as SonataFlow pods now start promptly, eliminating unnecessary wait times.
  user_input: so i was having this big problem with my rhdh 1.7 install where the
    sonataflow pods they just kept crashing over and over again in a crashloopbackoff
    what was the deal with that and what did you guys do to fix it in the new release
    because it was a real headache for my teams?
- context:
  - 'Fixed issues This section lists issues fixed in Red Hat Developer Hub 1.8. ##
    Fixed issues in 1.8.0 ### Improved startup speed with updated init container image
    pull policy for Developer Hub Helm Chart With this update, the pull policy for
    the init container image of the Developer Hub Helm Chart was changed from Always
    to IfNotPresent. This change reduces the repeated download time during startup
    of the container image, which is approximately 2.5 GB, thereby significantly improving
    startup speed for users. RHDHBUGS 1000 ### Improved Authentication for Self-Hosted
    Enterprise SCM Providers Previously, actions requiring access to a self-hosted
    enterprise SCM provider failed, returning an error that no authentication provider
    was available for the specified host. With this update, the SCM integration correctly
    identifies and uses the configured authentication provider for the corresponding
    enterprise host. RHDHBUGS 1028 ### Customizable image names for job and data index
    services in Developer Hub Helm Chart Previously, when deploying the Developer
    Hub Helm Chart with the Orchestrator enabled, it was not possible to customize
    the image names of the job and data index services, for example in disconnected
    environments. Setting the orchestrator.sonataflowPlatform.jobServiceImage and
    orchestrator.sonataflowPlatform.dataIndexImage would return a schema validation
    error from Helm. This update fixes this issue. RHDHBUGS 2003 ### Network policy
    installation fix for Developer Hub RHDH Helm Chart with Orchestrator flavor Before
    this update, the Developer Hub RHDH Helm Chart would not install Network Policies
    when the Orchestrator flavor was deployed with serverlessLogicOperator disabled,
    preventing the Developer Hub Pods from being completely available. This update
    fixes this situation by installing network policies unconditionally when the orchestrator
    is enabled. RHDHBUGS 2020 ### Resolved SonataFlow Pod Crash Issue In the new release,
    a timing problem during the RHDH 1.7 installation with Orchestrator plugins, affecting
    SonataFlow database provisioning, has been addressed. This issue caused SonataFlow
    pods to repeatedly enter the CrashLoopBackOff state, leading to delays and potential
    confusion for users. With this update, SonataFlow pods no longer encounter the
    CrashLoopBackOff state due to the database provisioning delay. This improvement
    enhances the user experience, as SonataFlow pods now start promptly, eliminating
    unnecessary wait times. RHDHBUGS 2036 ### Fixed SCM integration failures for self-hosted
    enterprise SCM providers Previously, SCM integration failed for self-hosted enterprise
    SCM providers because the system could not identify the configured host. This
    resulted in a No auth provider available error. With this release, the SCM integration
    now correctly uses the configured authentication provider for the corresponding
    enterprise host. As a result, end users can now successfully perform actions requiring
    enterprise SCM access. RHDHBUGS 2249 ### Fixed incorrect version detection for
    local plugin updates Before this update, local plugins within the image were incorrectly
    detected for updates due to version misidentification. This led to users being
    unable to update local plugins from wrappers, resulting in outdated functionality.
    With this release, local plugin updates are now automatically detected, eliminating
    the need for manual adjustments and ensuring seamless plugin version updates for
    end users. RHDHBUGS 2250 # Fixed security issues You can view the security issues
    fixed in Red Hat Developer Hub 1.8 at Red Hat Security Updates. For 1.8.0, see
    Red Hat Security Advisory RHSA-2025:20047. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:20:35.645966'
    uuid: 4b010343-c08e-4fa1-a4a3-339945a8e189
  response: Red Hat Developer Hub 1.8 fixed several issues, including improved startup
    speed by changing the init container image pull policy to IfNotPresent, and improved
    authentication for self-hosted enterprise SCM providers. The update also allows
    for customizable image names for job and data index services in the Developer
    Hub Helm Chart, fixes a network policy installation issue with the Orchestrator
    flavor, and resolves a SonataFlow Pod crash issue related to database provisioning.
    Additionally, it fixes SCM integration failures for self-hosted providers and
    corrects version detection for local plugin updates. Security issues were also
    fixed in this release.
  user_input: what issues did red hat dev hub fixx?
- context:
  - 'Fixed issues This section lists issues fixed in Red Hat Developer Hub 1.8. ##
    Fixed issues in 1.8.0 ### Improved startup speed with updated init container image
    pull policy for Developer Hub Helm Chart With this update, the pull policy for
    the init container image of the Developer Hub Helm Chart was changed from Always
    to IfNotPresent. This change reduces the repeated download time during startup
    of the container image, which is approximately 2.5 GB, thereby significantly improving
    startup speed for users. RHDHBUGS 1000 ### Improved Authentication for Self-Hosted
    Enterprise SCM Providers Previously, actions requiring access to a self-hosted
    enterprise SCM provider failed, returning an error that no authentication provider
    was available for the specified host. With this update, the SCM integration correctly
    identifies and uses the configured authentication provider for the corresponding
    enterprise host. RHDHBUGS 1028 ### Customizable image names for job and data index
    services in Developer Hub Helm Chart Previously, when deploying the Developer
    Hub Helm Chart with the Orchestrator enabled, it was not possible to customize
    the image names of the job and data index services, for example in disconnected
    environments. Setting the orchestrator.sonataflowPlatform.jobServiceImage and
    orchestrator.sonataflowPlatform.dataIndexImage would return a schema validation
    error from Helm. This update fixes this issue. RHDHBUGS 2003 ### Network policy
    installation fix for Developer Hub RHDH Helm Chart with Orchestrator flavor Before
    this update, the Developer Hub RHDH Helm Chart would not install Network Policies
    when the Orchestrator flavor was deployed with serverlessLogicOperator disabled,
    preventing the Developer Hub Pods from being completely available. This update
    fixes this situation by installing network policies unconditionally when the orchestrator
    is enabled. RHDHBUGS 2020 ### Resolved SonataFlow Pod Crash Issue In the new release,
    a timing problem during the RHDH 1.7 installation with Orchestrator plugins, affecting
    SonataFlow database provisioning, has been addressed. This issue caused SonataFlow
    pods to repeatedly enter the CrashLoopBackOff state, leading to delays and potential
    confusion for users. With this update, SonataFlow pods no longer encounter the
    CrashLoopBackOff state due to the database provisioning delay. This improvement
    enhances the user experience, as SonataFlow pods now start promptly, eliminating
    unnecessary wait times. RHDHBUGS 2036 ### Fixed SCM integration failures for self-hosted
    enterprise SCM providers Previously, SCM integration failed for self-hosted enterprise
    SCM providers because the system could not identify the configured host. This
    resulted in a No auth provider available error. With this release, the SCM integration
    now correctly uses the configured authentication provider for the corresponding
    enterprise host. As a result, end users can now successfully perform actions requiring
    enterprise SCM access. RHDHBUGS 2249 ### Fixed incorrect version detection for
    local plugin updates Before this update, local plugins within the image were incorrectly
    detected for updates due to version misidentification. This led to users being
    unable to update local plugins from wrappers, resulting in outdated functionality.
    With this release, local plugin updates are now automatically detected, eliminating
    the need for manual adjustments and ensuring seamless plugin version updates for
    end users. RHDHBUGS 2250 # Fixed security issues You can view the security issues
    fixed in Red Hat Developer Hub 1.8 at Red Hat Security Updates. For 1.8.0, see
    Red Hat Security Advisory RHSA-2025:20047. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:20:46.750974'
    uuid: d5f9c59b-73ff-440b-a003-c32d889bff02
  response: Several issues with the Orchestrator have been fixed. When deploying the
    Developer Hub Helm Chart with the Orchestrator enabled, it is now possible to
    customize the image names of the job and data index services without a schema
    validation error. The Helm Chart will also now install Network Policies unconditionally
    when the orchestrator is enabled, which fixes an issue that prevented Developer
    Hub Pods from being completely available. Finally, a timing problem during installation
    with Orchestrator plugins that caused SonataFlow pods to enter a CrashLoopBackOff
    state has been addressed, allowing the pods to start promptly.
  user_input: My team was having a bunch of deployment problems with the Red Hat Developer
    Hub, espesially with the Orchestrator flavor. We couldn't customize image names
    for our disconnected env, network policys weren't installing correctly, and the
    SonataFlow pods kept crashing. What specific fixes were made to adress these Orchestrator
    instalation issues?
- context:
  - "Known issues This section lists known issues in Red Hat Developer Hub 1.8. ##\
    \ Existing Operator users with Orchestator 1.7 require a manual update in their\
    \ dynamic-plugins ConfigMap If you have an existing Operator-backed instance of\
    \ Developer Hub with the Orchestrator, you must update your dynamic-plugins ConfigMap\
    \ to set the version of the Orchestrator plugins to 1.8.2 once the Developer Hub\
    \ Operator is upgraded to 1.8. Otherwise, the Developer Hub instance will not\
    \ be upgraded at all. ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic\
    \ plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml\
    \ plugins: package: &#34;@redhat/backstage plugin orchestrator@1.8.2&#34; disabled:\
    \ false package: &#34;@redhat/backstage plugin orchestrator backend dynamic@1.8.2&#34;\
    \ disabled: false dependencies: ref: sonataflow package: &#34;@redhat/backstage\
    \ plugin scaffolder backend module orchestrator dynamic@1.8.2&#34; disabled: false\
    \ package: &#34;@redhat/backstage plugin orchestrator form widgets@1.8.2&#34;\
    \ disabled: false ``` RHDHBUGS 2240 ## Deployment update error with dynamic plugin\
    \ configuration Updating the deployment configuration using the values.yaml to\
    \ include specific dynamic plugin configurations might cause an error during the\
    \ deployment process. When configuring the dynamicRoutes for the red-hat-developer-hub.backstage-plugin-dynamic-home-page\
    \ plugin, the use of the placeholder {{firstName}} in a configuration property,\
    \ for example title, can result in the following fatal deployment error: \"function\
    \ firstName not defined\". This error prevents the cluster from spinning up correctly.\
    \ ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:\
    \ dynamicRoutes: - path: / importName: DynamicHomePage config: props: title: 'Howdy\
    \ {{firstName}} or {{displayName}}' ``` RHDHBUGS 2227 ## Starting time is not\
    \ displayed correctly in Results pane when workflows are started There is an known\
    \ issue with the displayed starting time in the Orchestrator 1.8.2 plugins when\
    \ starting a workflow. When a workflow starts executing, the starting time is\
    \ not displayed correctly in the Results window of the workflow instance. It remains\
    \ this way until the workflow changes state. This will be fixed in a future release.\
    \ RHDHBUGS 2220 ## Clicking on the dedicated RHDH local guide link in the UI sidebar\
    \ also highlights the Catalog item In this update, the RHDH Local default configuration\
    \ includes built-in TechDocs. However, when selecting the new \"RHDH Local Guide\"\
    \ link in the RHDH Local UI sidebar, the Catalog link is also highlighted. There\
    \ is currently no known workaround. RHDHBUGS 2132 ## Handle installation disabled\
    \ scenario in the installed packages page When installation is disabled, the actions\
    \ on the Installed Packages page are still shown. Similarly, if the YAML file\
    \ is misconfigured, the actions appear, but the API call fails with an error.\
    \ This doesn&#8217;t break the UI, the API failure is handled gracefully, and\
    \ the correct reason for the failure is displayed in the UI. RHDHBUGS 2126 ##\
    \ Changes to the Operator default configuration do not persist across operator\
    \ upgrades Changes to the Developer Hub Operator default configuration do not\
    \ persist across operator upgrades. There is no known workaround. RHDHBUGS 2102\
    \ ## Error message when manually accessing plugins without associated entity YAML\
    \ This error occurs when a user tries to access a package or plugin that does\
    \ not have an associated entity YAML. Users will not encounter this error under\
    \ normal usage; it only appears if they manually modify the plugin or package\
    \ name in the URL. This ticket will handle this scenario more gracefully by indicating\
    \ why access to a particular plugin is not allowed. RHDHBUGS 2059 ## Hide package\
    \ for entities missing dynamicArtifact value in code editor For packages with\
    \ missing spec.dynamicArtifact value in their catalog entity, we currently show\
    \ - package: ./dynamic-plugins/dis/&#8230;&#8203; RHDHBUGS 2058 ## Quay and Argo\
    \ CD require their respective backend plugins to correctly display permissions\
    \ in the UI. ```yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin quay disabled: false package: oci://ghcr.io/redhat developer/rhdh plugin\
    \ export overlays/backstage community plugin quay backend:bs_1.42.5__1.6.0!backstage\
    \ community plugin quay backend disabled: false pluginConfig: quay: apiUrl: ${QUAY_API_URL}\
    \ apiKey: ${QUAY_API_KEY} ``` ```yaml plugins: package: ./dynamic plugins/dist/roadiehq\
    \ scaffolder backend argocd dynamic disabled: true package: ./dynamic plugins/dist/backstage\
    \ community plugin redhat argocd disabled: false package: oci://ghcr.io/redhat\
    \ developer/rhdh plugin export overlays/backstage community plugin redhat argocd\
    \ backend:bs_1.42.5__0.10.0!backstage community plugin redhat argocd backend disabled:\
    \ false pluginConfig: argocd: username: \"${ARGOCD_USERNAME}\" password: \"${ARGOCD_PASSWORD}\"\
    \ appLocatorMethods: type: 'config' instances: name: argoInstance1 url: \"${ARGOCD_INSTANCE1_URL}\"\
    \ ``` For ArgoCD, you will need to update your app-config.yaml to add its id to\
    \ permission.rbac.pluginsWithPermission: ```yaml permission: enabled: true rbac:\
    \ pluginsWithPermission: argocd ``` RHDHBUGS 2038 ## MUI v5 components might render\
    \ with broken styles in non-bundled plugins Plugins that are not bundled with\
    \ Red Hat Developer Hub, meaning not part of the Red Hat Developer Hub wrappers,\
    \ might experience styling issues or broken visuals when using Material UI v5\
    \ components. 1. Workaround * Add the following code to the plugin\u2019s entry\
    \ file, such as workspaces/<pluginId>/plugins/<pluginId>/src/index.ts: ```javascript\
    \ import { unstable_ClassNameGenerator as ClassNameGenerator } from &#39;@mui/material/className&#39;;\
    \ ClassNameGenerator.configure(componentName =&gt; { return componentName.startsWith(&#39;v5\
    \ &#39;) ? componentName : `v5 ${componentName}`; }); ``` RHDHBUGS 986 ## Out-Of-Memory\
    \ errors in the Red Hat Developer Hub Operator To resolve Out-Of-Memory errors\
    \ in the Red Hat Developer Hub Operator, adjust memory settings manually: 1. Edit\
    \ the deployment: ``` kubectl edit deployment rhdh operator n &lt;namespace&gt;\
    \ ``` 2. In the editor, set the memory request to 1 GiB and the limit to 2 GiB:\
    \ ```yaml spec: containers: name: rhdh operator resources: requests: memory: &#34;1G&#34;\
    \ limits: memory: &#34;2G&#34; ``` 3. Reapply this change whenever the Operator\
    \ is actively reconciled. The pod should become healthy, using about 1.07 GiB\
    \ of memory. RHDHBUGS 664"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T15:20:59.569479'
    uuid: a2e8b6d5-ca35-4636-a1b0-05e767387af7
  response: "Argo CD requires its respective backend plugins to correctly display\
    \ permissions in the UI. For ArgoCD, you will need to update your app-config.yaml\
    \ to add its id to permission.rbac.pluginsWithPermission: ```yaml\npermission:\n\
    \  enabled: true\n  rbac:\n    pluginsWithPermission:\n      argocd\n```"
  user_input: how come my Argo CD permissions dont show up right in the UI what do
    i need to do to fix it
- context:
  - "Known issues This section lists known issues in Red Hat Developer Hub 1.8. ##\
    \ Existing Operator users with Orchestator 1.7 require a manual update in their\
    \ dynamic-plugins ConfigMap If you have an existing Operator-backed instance of\
    \ Developer Hub with the Orchestrator, you must update your dynamic-plugins ConfigMap\
    \ to set the version of the Orchestrator plugins to 1.8.2 once the Developer Hub\
    \ Operator is upgraded to 1.8. Otherwise, the Developer Hub instance will not\
    \ be upgraded at all. ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic\
    \ plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml\
    \ plugins: package: &#34;@redhat/backstage plugin orchestrator@1.8.2&#34; disabled:\
    \ false package: &#34;@redhat/backstage plugin orchestrator backend dynamic@1.8.2&#34;\
    \ disabled: false dependencies: ref: sonataflow package: &#34;@redhat/backstage\
    \ plugin scaffolder backend module orchestrator dynamic@1.8.2&#34; disabled: false\
    \ package: &#34;@redhat/backstage plugin orchestrator form widgets@1.8.2&#34;\
    \ disabled: false ``` RHDHBUGS 2240 ## Deployment update error with dynamic plugin\
    \ configuration Updating the deployment configuration using the values.yaml to\
    \ include specific dynamic plugin configurations might cause an error during the\
    \ deployment process. When configuring the dynamicRoutes for the red-hat-developer-hub.backstage-plugin-dynamic-home-page\
    \ plugin, the use of the placeholder {{firstName}} in a configuration property,\
    \ for example title, can result in the following fatal deployment error: \"function\
    \ firstName not defined\". This error prevents the cluster from spinning up correctly.\
    \ ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:\
    \ dynamicRoutes: - path: / importName: DynamicHomePage config: props: title: 'Howdy\
    \ {{firstName}} or {{displayName}}' ``` RHDHBUGS 2227 ## Starting time is not\
    \ displayed correctly in Results pane when workflows are started There is an known\
    \ issue with the displayed starting time in the Orchestrator 1.8.2 plugins when\
    \ starting a workflow. When a workflow starts executing, the starting time is\
    \ not displayed correctly in the Results window of the workflow instance. It remains\
    \ this way until the workflow changes state. This will be fixed in a future release.\
    \ RHDHBUGS 2220 ## Clicking on the dedicated RHDH local guide link in the UI sidebar\
    \ also highlights the Catalog item In this update, the RHDH Local default configuration\
    \ includes built-in TechDocs. However, when selecting the new \"RHDH Local Guide\"\
    \ link in the RHDH Local UI sidebar, the Catalog link is also highlighted. There\
    \ is currently no known workaround. RHDHBUGS 2132 ## Handle installation disabled\
    \ scenario in the installed packages page When installation is disabled, the actions\
    \ on the Installed Packages page are still shown. Similarly, if the YAML file\
    \ is misconfigured, the actions appear, but the API call fails with an error.\
    \ This doesn&#8217;t break the UI, the API failure is handled gracefully, and\
    \ the correct reason for the failure is displayed in the UI. RHDHBUGS 2126 ##\
    \ Changes to the Operator default configuration do not persist across operator\
    \ upgrades Changes to the Developer Hub Operator default configuration do not\
    \ persist across operator upgrades. There is no known workaround. RHDHBUGS 2102\
    \ ## Error message when manually accessing plugins without associated entity YAML\
    \ This error occurs when a user tries to access a package or plugin that does\
    \ not have an associated entity YAML. Users will not encounter this error under\
    \ normal usage; it only appears if they manually modify the plugin or package\
    \ name in the URL. This ticket will handle this scenario more gracefully by indicating\
    \ why access to a particular plugin is not allowed. RHDHBUGS 2059 ## Hide package\
    \ for entities missing dynamicArtifact value in code editor For packages with\
    \ missing spec.dynamicArtifact value in their catalog entity, we currently show\
    \ - package: ./dynamic-plugins/dis/&#8230;&#8203; RHDHBUGS 2058 ## Quay and Argo\
    \ CD require their respective backend plugins to correctly display permissions\
    \ in the UI. ```yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin quay disabled: false package: oci://ghcr.io/redhat developer/rhdh plugin\
    \ export overlays/backstage community plugin quay backend:bs_1.42.5__1.6.0!backstage\
    \ community plugin quay backend disabled: false pluginConfig: quay: apiUrl: ${QUAY_API_URL}\
    \ apiKey: ${QUAY_API_KEY} ``` ```yaml plugins: package: ./dynamic plugins/dist/roadiehq\
    \ scaffolder backend argocd dynamic disabled: true package: ./dynamic plugins/dist/backstage\
    \ community plugin redhat argocd disabled: false package: oci://ghcr.io/redhat\
    \ developer/rhdh plugin export overlays/backstage community plugin redhat argocd\
    \ backend:bs_1.42.5__0.10.0!backstage community plugin redhat argocd backend disabled:\
    \ false pluginConfig: argocd: username: \"${ARGOCD_USERNAME}\" password: \"${ARGOCD_PASSWORD}\"\
    \ appLocatorMethods: type: 'config' instances: name: argoInstance1 url: \"${ARGOCD_INSTANCE1_URL}\"\
    \ ``` For ArgoCD, you will need to update your app-config.yaml to add its id to\
    \ permission.rbac.pluginsWithPermission: ```yaml permission: enabled: true rbac:\
    \ pluginsWithPermission: argocd ``` RHDHBUGS 2038 ## MUI v5 components might render\
    \ with broken styles in non-bundled plugins Plugins that are not bundled with\
    \ Red Hat Developer Hub, meaning not part of the Red Hat Developer Hub wrappers,\
    \ might experience styling issues or broken visuals when using Material UI v5\
    \ components. 1. Workaround * Add the following code to the plugin\u2019s entry\
    \ file, such as workspaces/<pluginId>/plugins/<pluginId>/src/index.ts: ```javascript\
    \ import { unstable_ClassNameGenerator as ClassNameGenerator } from &#39;@mui/material/className&#39;;\
    \ ClassNameGenerator.configure(componentName =&gt; { return componentName.startsWith(&#39;v5\
    \ &#39;) ? componentName : `v5 ${componentName}`; }); ``` RHDHBUGS 986 ## Out-Of-Memory\
    \ errors in the Red Hat Developer Hub Operator To resolve Out-Of-Memory errors\
    \ in the Red Hat Developer Hub Operator, adjust memory settings manually: 1. Edit\
    \ the deployment: ``` kubectl edit deployment rhdh operator n &lt;namespace&gt;\
    \ ``` 2. In the editor, set the memory request to 1 GiB and the limit to 2 GiB:\
    \ ```yaml spec: containers: name: rhdh operator resources: requests: memory: &#34;1G&#34;\
    \ limits: memory: &#34;2G&#34; ``` 3. Reapply this change whenever the Operator\
    \ is actively reconciled. The pod should become healthy, using about 1.07 GiB\
    \ of memory. RHDHBUGS 664"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:21:10.905419'
    uuid: 89db36c0-ccb0-4dcd-b298-4fbd916caee4
  response: For existing Operator-backed instances of Developer Hub with the Orchestator,
    you are required to manually update your dynamic-plugins ConfigMap to set the
    version of the Orchestator plugins to 1.8.2 after the Developer Hub Operator is
    upgraded to 1.8. If this is not done, the Developer Hub instance will not be upgraded
    at all. The specific packages to update are "@redhat/backstage plugin orchestrator@1.8.2",
    "@redhat/backstage plugin orchestrator backend dynamic@1.8.2", "@redhat/backstage
    plugin scaffolder backend module orchestrator dynamic@1.8.2", and "@redhat/backstage
    plugin orchestrator form widgets@1.8.2".
  user_input: What is the required manual update procedure for the Orchestator for
    existing Operator users after upgrading to Red Hat Developer Hub 1.8?
- context:
  - "Known issues This section lists known issues in Red Hat Developer Hub 1.8. ##\
    \ Existing Operator users with Orchestator 1.7 require a manual update in their\
    \ dynamic-plugins ConfigMap If you have an existing Operator-backed instance of\
    \ Developer Hub with the Orchestrator, you must update your dynamic-plugins ConfigMap\
    \ to set the version of the Orchestrator plugins to 1.8.2 once the Developer Hub\
    \ Operator is upgraded to 1.8. Otherwise, the Developer Hub instance will not\
    \ be upgraded at all. ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic\
    \ plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml\
    \ plugins: package: &#34;@redhat/backstage plugin orchestrator@1.8.2&#34; disabled:\
    \ false package: &#34;@redhat/backstage plugin orchestrator backend dynamic@1.8.2&#34;\
    \ disabled: false dependencies: ref: sonataflow package: &#34;@redhat/backstage\
    \ plugin scaffolder backend module orchestrator dynamic@1.8.2&#34; disabled: false\
    \ package: &#34;@redhat/backstage plugin orchestrator form widgets@1.8.2&#34;\
    \ disabled: false ``` RHDHBUGS 2240 ## Deployment update error with dynamic plugin\
    \ configuration Updating the deployment configuration using the values.yaml to\
    \ include specific dynamic plugin configurations might cause an error during the\
    \ deployment process. When configuring the dynamicRoutes for the red-hat-developer-hub.backstage-plugin-dynamic-home-page\
    \ plugin, the use of the placeholder {{firstName}} in a configuration property,\
    \ for example title, can result in the following fatal deployment error: \"function\
    \ firstName not defined\". This error prevents the cluster from spinning up correctly.\
    \ ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:\
    \ dynamicRoutes: - path: / importName: DynamicHomePage config: props: title: 'Howdy\
    \ {{firstName}} or {{displayName}}' ``` RHDHBUGS 2227 ## Starting time is not\
    \ displayed correctly in Results pane when workflows are started There is an known\
    \ issue with the displayed starting time in the Orchestrator 1.8.2 plugins when\
    \ starting a workflow. When a workflow starts executing, the starting time is\
    \ not displayed correctly in the Results window of the workflow instance. It remains\
    \ this way until the workflow changes state. This will be fixed in a future release.\
    \ RHDHBUGS 2220 ## Clicking on the dedicated RHDH local guide link in the UI sidebar\
    \ also highlights the Catalog item In this update, the RHDH Local default configuration\
    \ includes built-in TechDocs. However, when selecting the new \"RHDH Local Guide\"\
    \ link in the RHDH Local UI sidebar, the Catalog link is also highlighted. There\
    \ is currently no known workaround. RHDHBUGS 2132 ## Handle installation disabled\
    \ scenario in the installed packages page When installation is disabled, the actions\
    \ on the Installed Packages page are still shown. Similarly, if the YAML file\
    \ is misconfigured, the actions appear, but the API call fails with an error.\
    \ This doesn&#8217;t break the UI, the API failure is handled gracefully, and\
    \ the correct reason for the failure is displayed in the UI. RHDHBUGS 2126 ##\
    \ Changes to the Operator default configuration do not persist across operator\
    \ upgrades Changes to the Developer Hub Operator default configuration do not\
    \ persist across operator upgrades. There is no known workaround. RHDHBUGS 2102\
    \ ## Error message when manually accessing plugins without associated entity YAML\
    \ This error occurs when a user tries to access a package or plugin that does\
    \ not have an associated entity YAML. Users will not encounter this error under\
    \ normal usage; it only appears if they manually modify the plugin or package\
    \ name in the URL. This ticket will handle this scenario more gracefully by indicating\
    \ why access to a particular plugin is not allowed. RHDHBUGS 2059 ## Hide package\
    \ for entities missing dynamicArtifact value in code editor For packages with\
    \ missing spec.dynamicArtifact value in their catalog entity, we currently show\
    \ - package: ./dynamic-plugins/dis/&#8230;&#8203; RHDHBUGS 2058 ## Quay and Argo\
    \ CD require their respective backend plugins to correctly display permissions\
    \ in the UI. ```yaml plugins: package: ./dynamic plugins/dist/backstage community\
    \ plugin quay disabled: false package: oci://ghcr.io/redhat developer/rhdh plugin\
    \ export overlays/backstage community plugin quay backend:bs_1.42.5__1.6.0!backstage\
    \ community plugin quay backend disabled: false pluginConfig: quay: apiUrl: ${QUAY_API_URL}\
    \ apiKey: ${QUAY_API_KEY} ``` ```yaml plugins: package: ./dynamic plugins/dist/roadiehq\
    \ scaffolder backend argocd dynamic disabled: true package: ./dynamic plugins/dist/backstage\
    \ community plugin redhat argocd disabled: false package: oci://ghcr.io/redhat\
    \ developer/rhdh plugin export overlays/backstage community plugin redhat argocd\
    \ backend:bs_1.42.5__0.10.0!backstage community plugin redhat argocd backend disabled:\
    \ false pluginConfig: argocd: username: \"${ARGOCD_USERNAME}\" password: \"${ARGOCD_PASSWORD}\"\
    \ appLocatorMethods: type: 'config' instances: name: argoInstance1 url: \"${ARGOCD_INSTANCE1_URL}\"\
    \ ``` For ArgoCD, you will need to update your app-config.yaml to add its id to\
    \ permission.rbac.pluginsWithPermission: ```yaml permission: enabled: true rbac:\
    \ pluginsWithPermission: argocd ``` RHDHBUGS 2038 ## MUI v5 components might render\
    \ with broken styles in non-bundled plugins Plugins that are not bundled with\
    \ Red Hat Developer Hub, meaning not part of the Red Hat Developer Hub wrappers,\
    \ might experience styling issues or broken visuals when using Material UI v5\
    \ components. 1. Workaround * Add the following code to the plugin\u2019s entry\
    \ file, such as workspaces/<pluginId>/plugins/<pluginId>/src/index.ts: ```javascript\
    \ import { unstable_ClassNameGenerator as ClassNameGenerator } from &#39;@mui/material/className&#39;;\
    \ ClassNameGenerator.configure(componentName =&gt; { return componentName.startsWith(&#39;v5\
    \ &#39;) ? componentName : `v5 ${componentName}`; }); ``` RHDHBUGS 986 ## Out-Of-Memory\
    \ errors in the Red Hat Developer Hub Operator To resolve Out-Of-Memory errors\
    \ in the Red Hat Developer Hub Operator, adjust memory settings manually: 1. Edit\
    \ the deployment: ``` kubectl edit deployment rhdh operator n &lt;namespace&gt;\
    \ ``` 2. In the editor, set the memory request to 1 GiB and the limit to 2 GiB:\
    \ ```yaml spec: containers: name: rhdh operator resources: requests: memory: &#34;1G&#34;\
    \ limits: memory: &#34;2G&#34; ``` 3. Reapply this change whenever the Operator\
    \ is actively reconciled. The pod should become healthy, using about 1.07 GiB\
    \ of memory. RHDHBUGS 664"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:21:19.637997'
    uuid: a9482bb0-7d56-48bd-aa31-fc66e469bc28
  response: "Plugins that are not bundled with Red Hat Developer Hub might experience\
    \ styling issues or broken visuals when using Material UI v5 components. To work\
    \ around this, add the following code to the plugin\u2019s entry file, such as\
    \ workspaces/<pluginId>/plugins/<pluginId>/src/index.ts: \"import { unstable_ClassNameGenerator\
    \ as ClassNameGenerator } from '@mui/material/className'; ClassNameGenerator.configure(componentName\
    \ => { return componentName.startsWith('v5 ') ? componentName : `v5 ${componentName}`;\
    \ });\""
  user_input: why do my plugins look bad with Material UI v5 and how do i fix this
- context:
  - '# Installing Red Hat Developer Hub in an air-gapped environment # Air gapped
    environment An air-gapped environment, also known as an air-gapped network or
    isolated network, ensures security by physically segregating the system or network.
    This isolation is established to prevent unauthorized access, data transfer, or
    communication between the air-gapped system and external sources. You can install
    the Red Hat Developer Hub in an air-gapped environment to ensure security and
    meet specific regulatory requirements. # Installing Red Hat Developer Hub in an
    air-gapped environment with the Operator You can install Red Hat Developer Hub
    in a fully disconnected or partially disconnected environment using the Red Hat
    Developer Hub Operator. For a list of supported platforms, see the Red Hat Developer
    Hub Life Cycle page. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:21:27.117111'
    uuid: 3683e52c-fe5a-4c9e-a8c5-f1e103a2c292
  response: You can install the Red Hat Developer Hub in an air-gapped environment
    to ensure security and meet specific regulatory requirements. To install Red Hat
    Developer Hub in a fully disconnected or partially disconnected environment, you
    can use the Red Hat Developer Hub Operator.
  user_input: Can you explane how to instal the Red Hat Develper Hub in a fully disconected
    or air-gapped envirnment?
- context:
  - '# Installing Red Hat Developer Hub in an air-gapped environment # Air gapped
    environment An air-gapped environment, also known as an air-gapped network or
    isolated network, ensures security by physically segregating the system or network.
    This isolation is established to prevent unauthorized access, data transfer, or
    communication between the air-gapped system and external sources. You can install
    the Red Hat Developer Hub in an air-gapped environment to ensure security and
    meet specific regulatory requirements. # Installing Red Hat Developer Hub in an
    air-gapped environment with the Operator You can install Red Hat Developer Hub
    in a fully disconnected or partially disconnected environment using the Red Hat
    Developer Hub Operator. For a list of supported platforms, see the Red Hat Developer
    Hub Life Cycle page. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:21:35.406643'
    uuid: 45956ac0-3b49-4f7c-ba42-bcecfc342885
  response: You can install Red Hat Developer Hub in a fully disconnected or partially
    disconnected environment using the Red Hat Developer Hub Operator.
  user_input: Red Hat Developer Hub Operator disconnected install
- context:
  - '# Installing Red Hat Developer Hub in an air-gapped environment # Air gapped
    environment An air-gapped environment, also known as an air-gapped network or
    isolated network, ensures security by physically segregating the system or network.
    This isolation is established to prevent unauthorized access, data transfer, or
    communication between the air-gapped system and external sources. You can install
    the Red Hat Developer Hub in an air-gapped environment to ensure security and
    meet specific regulatory requirements. # Installing Red Hat Developer Hub in an
    air-gapped environment with the Operator You can install Red Hat Developer Hub
    in a fully disconnected or partially disconnected environment using the Red Hat
    Developer Hub Operator. For a list of supported platforms, see the Red Hat Developer
    Hub Life Cycle page. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:21:41.657021'
    uuid: affa0534-e453-4dfc-b293-62ba83d240f8
  response: The Red Hat Developer Hub Life Cycle page contains a list of supported
    platforms for when you install Red Hat Developer Hub in a fully disconnected or
    partially disconnected environment using the Red Hat Developer Hub Operator.
  user_input: For installing with the Operator, what supported platforms is listed
    on the Red Hat Developer Hub Life Cycle page?
- context:
  - "Installing Red Hat Developer Hub in a fully disconnected environment with the\
    \ Operator In environments without internet access \u2014 whether for security,\
    \ compliance, or operational reasons \u2014 a fully disconnected installation\
    \ ensures that Red Hat Developer Hub can run reliably without external dependencies.\
    \ If your network has access to the registry through a bastion host, you can use\
    \ the helper script to install Red Hat Developer Hub by mirroring the Operator-related\
    \ images to disk and transferring them to your air-gapped environment without\
    \ any connection to the internet. You have installed Podman 5.3 or later. For\
    \ more information, see Podman Installation Instructions. You have installed Skopeo\
    \ 1.17 or later. You have installed yq 4.44 or later. You have installed the GNU\
    \ sed command line text editor. You have installed umoci CLI tool. You have an\
    \ active oc registry, podman, or skopeo session to the Red Hat Container Registry\
    \ (registry.redhat.io). For more information, see Red Hat Container Registry Authentication.\
    \ You have installed the opm CLI tool. For more information, see Installing the\
    \ opm CLI. Recommended on OpenShift Container Platform: You have installed the\
    \ oc mirror tool, with a version corresponding to the version of your OpenShift\
    \ Container Platform cluster. Make sure that your system meets the minimum sizing\
    \ requirements. See Sizing requirements for Red Hat Developer Hub. 1. Download\
    \ the mirroring script to disk by running the following command: ```terminal curl\
    \ sSLO https://raw.githubusercontent.com/redhat developer/rhdh operator/refs/heads/release\
    \ 1.8/.rhdh/scripts/prepare restricted environment.sh ``` 2. Run the mirroring\
    \ script by using the bash command with the appropriate set of options: ```terminal\
    \ bash prepare restricted environment.sh filter versions \"1.8\" to dir <my_pulled_image_location>\
    \ [- use oc mirror true] ``` where: --to-dir <my_pulled_image_location>:: Enter\
    \ the absolute path to a directory where you want to pull all of the necessary\
    \ images, for example, /home/user/rhdh-operator-mirror-dir. --use-oc-mirror true::\
    \ (Recommended on OpenShift Container Platform) Use the oc-mirror OpenShift Container\
    \ Platform CLI plugin to mirror images. [NOTE] ---- The script can take several\
    \ minutes to complete as it copies multiple images to the mirror registry. ----\
    \ 3. Transfer the directory specified by the --to-dir option to your disconnected\
    \ environment. 4. From a machine in your disconnected environment that has access\
    \ to both the cluster and the target mirror registry, run the mirroring script\
    \ by using the bash command with the appropriate set of options: ```terminal bash\
    \ <my_pulled_image_location>/install.sh from dir <my_pulled_image_location> [-\
    \ to registry <my.registry.example.com>] [- use oc mirror true] ``` where: <my_pulled_image_location>/install.sh::\
    \ Enter the downloaded installation script and the absolute path to the directory\
    \ where it is stored on your system. --from-dir <my_pulled_image_location>:: Enter\
    \ the directory where you want to pull all of the necessary images. --to-registry::\
    \ (Optional) Enter the URL for the target mirror registry where you want to mirror\
    \ the images. --use-oc-mirror true:: Recommended on OpenShift Container Platform:\
    \ Use the oc-mirror OpenShift Container Platform CLI plugin to mirror images.\
    \ [IMPORTANT] ---- If you used oc-mirror to mirror the images to disk, you must\
    \ also use oc-mirror to mirror the images from disk due to the folder layout that\
    \ oc-mirror uses. ---- [NOTE] ---- The script can take several minutes to complete\
    \ as it automatically installs the Red Hat Developer Hub Operator. ---- If you\
    \ are using Red Hat OpenShift Container Platform, the Red Hat Developer Hub Operator\
    \ is in the Installed Operators list in the web console. If you are using a supported\
    \ Kubernetes platform, you can check the list of pods running in the rhdh operator\
    \ namespace by running the following command in your terminal: ```terminal kubectl\
    \ n rhdh operator get pods ``` Use the Operator to create a Red Hat Developer\
    \ Hub instance on a supported platform. For more information, see the following\
    \ documentation for the platform that you want to use: Installing Red Hat Developer\
    \ Hub on OpenShift Container Platform with the Operator Installing Developer Hub\
    \ on EKS with the Operator Installing Developer Hub on AKS with the Operator Installing\
    \ Developer Hub on Google Cloud with the Operator Deploying Developer Hub on GKE\
    \ with the Operator ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:21:49.522946'
    uuid: e28ce2b7-86ca-4ed7-af35-151d2a00dab7
  response: 'To start a fully disconnected installation for Red Hat Developer Hub,
    you first download the mirroring script to disk by running the command: ```terminal
    curl sSLO https://raw.githubusercontent.com/redhat developer/rhdh operator/refs/heads/release
    1.8/.rhdh/scripts/prepare restricted environment.sh ```. After that, you run the
    mirroring script using the bash command with the appropriate options, such as:
    ```terminal bash prepare restricted environment.sh filter versions \"1.8\" to
    dir <my_pulled_image_location> [- use oc mirror true] ```. This script pulls all
    necessary images to the specified directory, which you then transfer to your disconnected
    environment.'
  user_input: how do i start the disconected instal for Red Hat Developer Hub?
- context:
  - "Installing Red Hat Developer Hub in a fully disconnected environment with the\
    \ Operator In environments without internet access \u2014 whether for security,\
    \ compliance, or operational reasons \u2014 a fully disconnected installation\
    \ ensures that Red Hat Developer Hub can run reliably without external dependencies.\
    \ If your network has access to the registry through a bastion host, you can use\
    \ the helper script to install Red Hat Developer Hub by mirroring the Operator-related\
    \ images to disk and transferring them to your air-gapped environment without\
    \ any connection to the internet. You have installed Podman 5.3 or later. For\
    \ more information, see Podman Installation Instructions. You have installed Skopeo\
    \ 1.17 or later. You have installed yq 4.44 or later. You have installed the GNU\
    \ sed command line text editor. You have installed umoci CLI tool. You have an\
    \ active oc registry, podman, or skopeo session to the Red Hat Container Registry\
    \ (registry.redhat.io). For more information, see Red Hat Container Registry Authentication.\
    \ You have installed the opm CLI tool. For more information, see Installing the\
    \ opm CLI. Recommended on OpenShift Container Platform: You have installed the\
    \ oc mirror tool, with a version corresponding to the version of your OpenShift\
    \ Container Platform cluster. Make sure that your system meets the minimum sizing\
    \ requirements. See Sizing requirements for Red Hat Developer Hub. 1. Download\
    \ the mirroring script to disk by running the following command: ```terminal curl\
    \ sSLO https://raw.githubusercontent.com/redhat developer/rhdh operator/refs/heads/release\
    \ 1.8/.rhdh/scripts/prepare restricted environment.sh ``` 2. Run the mirroring\
    \ script by using the bash command with the appropriate set of options: ```terminal\
    \ bash prepare restricted environment.sh filter versions \"1.8\" to dir <my_pulled_image_location>\
    \ [- use oc mirror true] ``` where: --to-dir <my_pulled_image_location>:: Enter\
    \ the absolute path to a directory where you want to pull all of the necessary\
    \ images, for example, /home/user/rhdh-operator-mirror-dir. --use-oc-mirror true::\
    \ (Recommended on OpenShift Container Platform) Use the oc-mirror OpenShift Container\
    \ Platform CLI plugin to mirror images. [NOTE] ---- The script can take several\
    \ minutes to complete as it copies multiple images to the mirror registry. ----\
    \ 3. Transfer the directory specified by the --to-dir option to your disconnected\
    \ environment. 4. From a machine in your disconnected environment that has access\
    \ to both the cluster and the target mirror registry, run the mirroring script\
    \ by using the bash command with the appropriate set of options: ```terminal bash\
    \ <my_pulled_image_location>/install.sh from dir <my_pulled_image_location> [-\
    \ to registry <my.registry.example.com>] [- use oc mirror true] ``` where: <my_pulled_image_location>/install.sh::\
    \ Enter the downloaded installation script and the absolute path to the directory\
    \ where it is stored on your system. --from-dir <my_pulled_image_location>:: Enter\
    \ the directory where you want to pull all of the necessary images. --to-registry::\
    \ (Optional) Enter the URL for the target mirror registry where you want to mirror\
    \ the images. --use-oc-mirror true:: Recommended on OpenShift Container Platform:\
    \ Use the oc-mirror OpenShift Container Platform CLI plugin to mirror images.\
    \ [IMPORTANT] ---- If you used oc-mirror to mirror the images to disk, you must\
    \ also use oc-mirror to mirror the images from disk due to the folder layout that\
    \ oc-mirror uses. ---- [NOTE] ---- The script can take several minutes to complete\
    \ as it automatically installs the Red Hat Developer Hub Operator. ---- If you\
    \ are using Red Hat OpenShift Container Platform, the Red Hat Developer Hub Operator\
    \ is in the Installed Operators list in the web console. If you are using a supported\
    \ Kubernetes platform, you can check the list of pods running in the rhdh operator\
    \ namespace by running the following command in your terminal: ```terminal kubectl\
    \ n rhdh operator get pods ``` Use the Operator to create a Red Hat Developer\
    \ Hub instance on a supported platform. For more information, see the following\
    \ documentation for the platform that you want to use: Installing Red Hat Developer\
    \ Hub on OpenShift Container Platform with the Operator Installing Developer Hub\
    \ on EKS with the Operator Installing Developer Hub on AKS with the Operator Installing\
    \ Developer Hub on Google Cloud with the Operator Deploying Developer Hub on GKE\
    \ with the Operator ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:21:58.423919'
    uuid: a7bf7aba-cdfa-4f04-af2e-11c62d844a6c
  response: For a disconnected installation, you must have installed Podman 5.3 or
    later, Skopeo 1.17 or later, yq 4.44 or later, the GNU sed command line text editor,
    and the umoci CLI tool. You also need an active oc registry, podman, or skopeo
    session to the Red Hat Container Registry (registry.redhat.io) and have the opm
    CLI tool installed. It is recommended on OpenShift Container Platform to have
    the oc mirror tool installed, with a version corresponding to the version of your
    OpenShift Container Platform cluster. Your system must also meet the minimum sizing
    requirements.
  user_input: so im trying to get this disconnected install of red hat developer hub
    working for my team and i see a list of stuff we need, what are all the tools
    and things it says we need to have installed before we start, especially for Podman
    what version does it say we need to have?
- context:
  - "Installing Red Hat Developer Hub in a fully disconnected environment with the\
    \ Operator In environments without internet access \u2014 whether for security,\
    \ compliance, or operational reasons \u2014 a fully disconnected installation\
    \ ensures that Red Hat Developer Hub can run reliably without external dependencies.\
    \ If your network has access to the registry through a bastion host, you can use\
    \ the helper script to install Red Hat Developer Hub by mirroring the Operator-related\
    \ images to disk and transferring them to your air-gapped environment without\
    \ any connection to the internet. You have installed Podman 5.3 or later. For\
    \ more information, see Podman Installation Instructions. You have installed Skopeo\
    \ 1.17 or later. You have installed yq 4.44 or later. You have installed the GNU\
    \ sed command line text editor. You have installed umoci CLI tool. You have an\
    \ active oc registry, podman, or skopeo session to the Red Hat Container Registry\
    \ (registry.redhat.io). For more information, see Red Hat Container Registry Authentication.\
    \ You have installed the opm CLI tool. For more information, see Installing the\
    \ opm CLI. Recommended on OpenShift Container Platform: You have installed the\
    \ oc mirror tool, with a version corresponding to the version of your OpenShift\
    \ Container Platform cluster. Make sure that your system meets the minimum sizing\
    \ requirements. See Sizing requirements for Red Hat Developer Hub. 1. Download\
    \ the mirroring script to disk by running the following command: ```terminal curl\
    \ sSLO https://raw.githubusercontent.com/redhat developer/rhdh operator/refs/heads/release\
    \ 1.8/.rhdh/scripts/prepare restricted environment.sh ``` 2. Run the mirroring\
    \ script by using the bash command with the appropriate set of options: ```terminal\
    \ bash prepare restricted environment.sh filter versions \"1.8\" to dir <my_pulled_image_location>\
    \ [- use oc mirror true] ``` where: --to-dir <my_pulled_image_location>:: Enter\
    \ the absolute path to a directory where you want to pull all of the necessary\
    \ images, for example, /home/user/rhdh-operator-mirror-dir. --use-oc-mirror true::\
    \ (Recommended on OpenShift Container Platform) Use the oc-mirror OpenShift Container\
    \ Platform CLI plugin to mirror images. [NOTE] ---- The script can take several\
    \ minutes to complete as it copies multiple images to the mirror registry. ----\
    \ 3. Transfer the directory specified by the --to-dir option to your disconnected\
    \ environment. 4. From a machine in your disconnected environment that has access\
    \ to both the cluster and the target mirror registry, run the mirroring script\
    \ by using the bash command with the appropriate set of options: ```terminal bash\
    \ <my_pulled_image_location>/install.sh from dir <my_pulled_image_location> [-\
    \ to registry <my.registry.example.com>] [- use oc mirror true] ``` where: <my_pulled_image_location>/install.sh::\
    \ Enter the downloaded installation script and the absolute path to the directory\
    \ where it is stored on your system. --from-dir <my_pulled_image_location>:: Enter\
    \ the directory where you want to pull all of the necessary images. --to-registry::\
    \ (Optional) Enter the URL for the target mirror registry where you want to mirror\
    \ the images. --use-oc-mirror true:: Recommended on OpenShift Container Platform:\
    \ Use the oc-mirror OpenShift Container Platform CLI plugin to mirror images.\
    \ [IMPORTANT] ---- If you used oc-mirror to mirror the images to disk, you must\
    \ also use oc-mirror to mirror the images from disk due to the folder layout that\
    \ oc-mirror uses. ---- [NOTE] ---- The script can take several minutes to complete\
    \ as it automatically installs the Red Hat Developer Hub Operator. ---- If you\
    \ are using Red Hat OpenShift Container Platform, the Red Hat Developer Hub Operator\
    \ is in the Installed Operators list in the web console. If you are using a supported\
    \ Kubernetes platform, you can check the list of pods running in the rhdh operator\
    \ namespace by running the following command in your terminal: ```terminal kubectl\
    \ n rhdh operator get pods ``` Use the Operator to create a Red Hat Developer\
    \ Hub instance on a supported platform. For more information, see the following\
    \ documentation for the platform that you want to use: Installing Red Hat Developer\
    \ Hub on OpenShift Container Platform with the Operator Installing Developer Hub\
    \ on EKS with the Operator Installing Developer Hub on AKS with the Operator Installing\
    \ Developer Hub on Google Cloud with the Operator Deploying Developer Hub on GKE\
    \ with the Operator ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:05.781414'
    uuid: ec39907b-a927-4703-b724-e7007cb3fdba
  response: To perform the installation, you must have installed Podman 5.3 or later.
    Other required tools include Skopeo 1.17 or later, yq 4.44 or later, the GNU sed
    command line text editor, the umoci CLI tool, and the opm CLI tool. You also need
    an active oc registry, podman, or skopeo session to the Red Hat Container Registry.
    On OpenShift Container Platform, it is recommended that you have the oc mirror
    tool installed, with a version corresponding to your cluster's version.
  user_input: for this disconnected install of developer hub, what version of Podman
    is needed and what other tools i have to install too?
- context:
  - 'Installing Red Hat Developer Hub in a partially disconnected environment with
    the Operator On an OpenShift Container Platform cluster operating on a restricted
    network, public resources are not available. However, deploying the Red Hat Developer
    Hub Operator and running Developer Hub requires the following public resources:
    Operator images (bundle, operator, catalog) Operands images (RHDH, PostgreSQL)
    To make these resources available, replace them with their equivalent resources
    in a mirror registry accessible to your cluster. You can use a helper script that
    mirrors the necessary images and provides the necessary configuration to ensure
    those images are used when installing the Red Hat Developer Hub Operator and creating
    Developer Hub instances. This script requires a target mirror registry. You likely
    have a target mirror registry if your cluster is already operating on a disconnected
    network. If you do not already have a target registry, and if you have an OpenShift
    Container Platform cluster, you might want to expose and leverage the internal
    cluster registry. When connected to a OpenShift Container Platform cluster, the
    helper script detects it and automatically exposes the cluster registry. If connected
    to a Kubernetes cluster, you can manually specify the target registry to mirror
    the images. You have installed Podman 5.3 or later. For more information, see
    Podman Installation Instructions. You have installed Skopeo 1.17 or later. You
    have installed yq 4.44 or later. You have installed the GNU sed command line text
    editor. You have installed umoci CLI tool. You have an active oc registry, podman,
    or Skopeo session to the Red Hat Container Registry (registry.redhat.io). For
    more information, see link:Red Hat Container Registry Authentication. You have
    an active Skopeo session with administrative access to the target mirror registry.
    For more information, see Authenticating to a registry. You have installed the
    opm CLI tool. For more information, see Installing the opm CLI. If you are using
    an OpenShift Container Platform cluster, you have the following prerequisites:
    Recommended: You have installed the oc mirror tool, with a version corresponding
    to the version of your OpenShift Container Platform cluster. If you are using
    a supported Kubernetes cluster, you have the following prerequisites: You have
    installed the Operator Lifecycle Manager (OLM) on the disconnected cluster. You
    have a mirror registry that is reachable from the disconnected cluster. Make sure
    that your system meets the minimum sizing requirements. See Sizing requirements
    for Red Hat Developer Hub. 1. In your terminal, navigate to the directory where
    you want to save the mirroring script. 2. Download the mirroring script by running
    the following command: ```terminal curl sSLO https://raw.githubusercontent.com/redhat
    developer/rhdh operator/refs/heads/release 1.8/.rhdh/scripts/prepare restricted
    environment.sh ``` 3. Run the mirroring script by using the bash command with
    the appropriate set of options: ```terminal bash prepare restricted environment.sh
    \ filter versions "1.8" \ [- to registry <my.registry.example.com>] \ [- use oc
    mirror true] ``` where: --to-registry _<my.registry.example.com>:: Enter the URL
    for the target mirror registry where you want to mirror the images. --use-oc-mirror
    true:: Optional: Use the oc-mirror OpenShift Container Platform CLI plugin to
    mirror images. [NOTE] ---- The script can take several minutes to complete as
    it copies multiple images to the mirror registry. ---- If you are using Red Hat
    OpenShift Container Platform, the Red Hat Developer Hub Operator is in the Installed
    Operators list in the web console. If you are using a supported Kubernetes platform,
    you can check the list of pods running in the rhdh operator namespace by running
    the following command in your terminal: ```terminal kubectl n rhdh operator get
    pods ``` Use the Operator to create a Red Hat Developer Hub instance on a supported
    platform. For more information, see the following documentation for the platform
    that you want to use: Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Operator Installing Developer Hub on EKS with the Operator Installing
    Developer Hub on AKS with the Operator Installing Developer Hub on Google Cloud
    with the Operator Deploying Developer Hub on GKE with the Operator # Installing
    Red Hat Developer Hub on OpenShift Container Platform in an air-gapped environment
    with the Helm chart You can install Red Hat Developer Hub in a fully disconnected
    or partially disconnected environment using the Red Hat Developer Hub Helm chart.
    ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:12.967640'
    uuid: 754bf786-5d3a-4be7-9ada-c86885665761
  response: You need to have installed Podman 5.3 or later, Skopeo 1.17 or later,
    yq 4.44 or later, the GNU sed command line text editor, the umoci CLI tool, and
    the opm CLI tool. You also need an active oc registry, podman, or Skopeo session
    to the Red Hat Container Registry (registry.redhat.io) and an active Skopeo session
    with administrative access to the target mirror registry. If using an OpenShift
    Container Platform cluster, it is recommended to have the oc mirror tool installed.
  user_input: what tools i need for Red Hat Developer Hub install?
- context:
  - 'Installing Red Hat Developer Hub in a partially disconnected environment with
    the Operator On an OpenShift Container Platform cluster operating on a restricted
    network, public resources are not available. However, deploying the Red Hat Developer
    Hub Operator and running Developer Hub requires the following public resources:
    Operator images (bundle, operator, catalog) Operands images (RHDH, PostgreSQL)
    To make these resources available, replace them with their equivalent resources
    in a mirror registry accessible to your cluster. You can use a helper script that
    mirrors the necessary images and provides the necessary configuration to ensure
    those images are used when installing the Red Hat Developer Hub Operator and creating
    Developer Hub instances. This script requires a target mirror registry. You likely
    have a target mirror registry if your cluster is already operating on a disconnected
    network. If you do not already have a target registry, and if you have an OpenShift
    Container Platform cluster, you might want to expose and leverage the internal
    cluster registry. When connected to a OpenShift Container Platform cluster, the
    helper script detects it and automatically exposes the cluster registry. If connected
    to a Kubernetes cluster, you can manually specify the target registry to mirror
    the images. You have installed Podman 5.3 or later. For more information, see
    Podman Installation Instructions. You have installed Skopeo 1.17 or later. You
    have installed yq 4.44 or later. You have installed the GNU sed command line text
    editor. You have installed umoci CLI tool. You have an active oc registry, podman,
    or Skopeo session to the Red Hat Container Registry (registry.redhat.io). For
    more information, see link:Red Hat Container Registry Authentication. You have
    an active Skopeo session with administrative access to the target mirror registry.
    For more information, see Authenticating to a registry. You have installed the
    opm CLI tool. For more information, see Installing the opm CLI. If you are using
    an OpenShift Container Platform cluster, you have the following prerequisites:
    Recommended: You have installed the oc mirror tool, with a version corresponding
    to the version of your OpenShift Container Platform cluster. If you are using
    a supported Kubernetes cluster, you have the following prerequisites: You have
    installed the Operator Lifecycle Manager (OLM) on the disconnected cluster. You
    have a mirror registry that is reachable from the disconnected cluster. Make sure
    that your system meets the minimum sizing requirements. See Sizing requirements
    for Red Hat Developer Hub. 1. In your terminal, navigate to the directory where
    you want to save the mirroring script. 2. Download the mirroring script by running
    the following command: ```terminal curl sSLO https://raw.githubusercontent.com/redhat
    developer/rhdh operator/refs/heads/release 1.8/.rhdh/scripts/prepare restricted
    environment.sh ``` 3. Run the mirroring script by using the bash command with
    the appropriate set of options: ```terminal bash prepare restricted environment.sh
    \ filter versions "1.8" \ [- to registry <my.registry.example.com>] \ [- use oc
    mirror true] ``` where: --to-registry _<my.registry.example.com>:: Enter the URL
    for the target mirror registry where you want to mirror the images. --use-oc-mirror
    true:: Optional: Use the oc-mirror OpenShift Container Platform CLI plugin to
    mirror images. [NOTE] ---- The script can take several minutes to complete as
    it copies multiple images to the mirror registry. ---- If you are using Red Hat
    OpenShift Container Platform, the Red Hat Developer Hub Operator is in the Installed
    Operators list in the web console. If you are using a supported Kubernetes platform,
    you can check the list of pods running in the rhdh operator namespace by running
    the following command in your terminal: ```terminal kubectl n rhdh operator get
    pods ``` Use the Operator to create a Red Hat Developer Hub instance on a supported
    platform. For more information, see the following documentation for the platform
    that you want to use: Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Operator Installing Developer Hub on EKS with the Operator Installing
    Developer Hub on AKS with the Operator Installing Developer Hub on Google Cloud
    with the Operator Deploying Developer Hub on GKE with the Operator # Installing
    Red Hat Developer Hub on OpenShift Container Platform in an air-gapped environment
    with the Helm chart You can install Red Hat Developer Hub in a fully disconnected
    or partially disconnected environment using the Red Hat Developer Hub Helm chart.
    ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:20.000706'
    uuid: d09e8640-c788-4405-bf90-5453457160a3
  response: To install Red Hat Developer Hub in a partially disconnected environment,
    you must have installed Podman 5.3 or later.
  user_input: According to the installation prerequisites for Red Hat Developer Hub
    in a partially disconnected environment, what specific version of Podman is required?
- context:
  - 'Installing Red Hat Developer Hub in a partially disconnected environment with
    the Operator On an OpenShift Container Platform cluster operating on a restricted
    network, public resources are not available. However, deploying the Red Hat Developer
    Hub Operator and running Developer Hub requires the following public resources:
    Operator images (bundle, operator, catalog) Operands images (RHDH, PostgreSQL)
    To make these resources available, replace them with their equivalent resources
    in a mirror registry accessible to your cluster. You can use a helper script that
    mirrors the necessary images and provides the necessary configuration to ensure
    those images are used when installing the Red Hat Developer Hub Operator and creating
    Developer Hub instances. This script requires a target mirror registry. You likely
    have a target mirror registry if your cluster is already operating on a disconnected
    network. If you do not already have a target registry, and if you have an OpenShift
    Container Platform cluster, you might want to expose and leverage the internal
    cluster registry. When connected to a OpenShift Container Platform cluster, the
    helper script detects it and automatically exposes the cluster registry. If connected
    to a Kubernetes cluster, you can manually specify the target registry to mirror
    the images. You have installed Podman 5.3 or later. For more information, see
    Podman Installation Instructions. You have installed Skopeo 1.17 or later. You
    have installed yq 4.44 or later. You have installed the GNU sed command line text
    editor. You have installed umoci CLI tool. You have an active oc registry, podman,
    or Skopeo session to the Red Hat Container Registry (registry.redhat.io). For
    more information, see link:Red Hat Container Registry Authentication. You have
    an active Skopeo session with administrative access to the target mirror registry.
    For more information, see Authenticating to a registry. You have installed the
    opm CLI tool. For more information, see Installing the opm CLI. If you are using
    an OpenShift Container Platform cluster, you have the following prerequisites:
    Recommended: You have installed the oc mirror tool, with a version corresponding
    to the version of your OpenShift Container Platform cluster. If you are using
    a supported Kubernetes cluster, you have the following prerequisites: You have
    installed the Operator Lifecycle Manager (OLM) on the disconnected cluster. You
    have a mirror registry that is reachable from the disconnected cluster. Make sure
    that your system meets the minimum sizing requirements. See Sizing requirements
    for Red Hat Developer Hub. 1. In your terminal, navigate to the directory where
    you want to save the mirroring script. 2. Download the mirroring script by running
    the following command: ```terminal curl sSLO https://raw.githubusercontent.com/redhat
    developer/rhdh operator/refs/heads/release 1.8/.rhdh/scripts/prepare restricted
    environment.sh ``` 3. Run the mirroring script by using the bash command with
    the appropriate set of options: ```terminal bash prepare restricted environment.sh
    \ filter versions "1.8" \ [- to registry <my.registry.example.com>] \ [- use oc
    mirror true] ``` where: --to-registry _<my.registry.example.com>:: Enter the URL
    for the target mirror registry where you want to mirror the images. --use-oc-mirror
    true:: Optional: Use the oc-mirror OpenShift Container Platform CLI plugin to
    mirror images. [NOTE] ---- The script can take several minutes to complete as
    it copies multiple images to the mirror registry. ---- If you are using Red Hat
    OpenShift Container Platform, the Red Hat Developer Hub Operator is in the Installed
    Operators list in the web console. If you are using a supported Kubernetes platform,
    you can check the list of pods running in the rhdh operator namespace by running
    the following command in your terminal: ```terminal kubectl n rhdh operator get
    pods ``` Use the Operator to create a Red Hat Developer Hub instance on a supported
    platform. For more information, see the following documentation for the platform
    that you want to use: Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Operator Installing Developer Hub on EKS with the Operator Installing
    Developer Hub on AKS with the Operator Installing Developer Hub on Google Cloud
    with the Operator Deploying Developer Hub on GKE with the Operator # Installing
    Red Hat Developer Hub on OpenShift Container Platform in an air-gapped environment
    with the Helm chart You can install Red Hat Developer Hub in a fully disconnected
    or partially disconnected environment using the Red Hat Developer Hub Helm chart.
    ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:27.305736'
    uuid: 79fc32e7-992f-4b81-baca-b084cf2d3444
  response: To install Developer Hub on EKS, you must use the Operator to create a
    Red Hat Developer Hub instance. For more detailed information, you should consult
    the documentation titled "Installing Developer Hub on EKS with the Operator".
  user_input: What is the specified method for installing Developer Hub on EKS?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a fully disconnected
    environment with the Helm chart If your network has access to the registry through
    a bastion host, you can use the Helm chart to install Red Hat Developer Hub by
    mirroring specified resources to disk and transferring them to your air-gapped
    environment without any connection to the internet. You have set up your workstation.
    You have an account in Red Hat Developer portal. You have access to the charts.openshift.io
    Helm chart repository. You have installed the OpenShift CLI (oc) on your workstation.
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have set up your intermediary
    host. Your host has access to the Red Hat Container Registry (registry.redhat.io).
    Your host has access to image registry on the destination host. See Exposing the
    registry. You have set up your destination host. You have installed Red Hat OpenShift
    Container Platform 4.16 or later. Your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. Create an ImageSetConfiguration
    file to specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` where: version: "1.8":: Enter the Red Hat Developer Hub
    version to mirror. 2. Mirror the resources specified in the ImageSetConfiguration.yaml
    file by running the oc-mirror command. For example: ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <mirror_archive_directory>/ ``` where: <mirror_config_directory>:: Enter the location
    of your image set configuration file on your system, for example, .user. <mirror_archive_directory>::
    Enter the location of your directory where the mirror archive will be created,
    for example, file://.user. [NOTE] ---- Running the oc-mirror command generates
    a local workspace containing the mirror archive file, the Helm chart, and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an imageContentSourcePolicy.yaml file
    that you must apply against the cluster in a later step. ---- Example output:
    ```terminal Creating archive /path/to/mirror archive/mirror_seq1_000000.tar ```
    3. Transfer the generated archive file (for example, mirror_seq1_000000.tar) to
    the air-gapped environment. 4. Connect to your air-gapped environment and make
    sure that you are also connected to the following objects: * The local target
    registry * The target OpenShift Container Platform cluster 5. From your air-gapped
    environment, mirror the resources from the archive to the target registry by running
    the oc-mirror command. For example: ```terminal oc mirror - from <mirror archive
    file> <target registry> ``` where: <mirror_archive_file>:: Enter the name of the
    file containing the resources that you want to mirror, for example,mirror_seq1_0000.tar.
    <target_registry>:: Enter the name of the target registry that you want to push
    the mirrored images to, for example, docker://registry.localhost:5000. Example
    output ```terminal Wrote release signatures to oc-mirror-workspace/results-1738075410
    Writing image mapping to oc-mirror-workspace/results-1738075410/mapping.txt Writing
    ICSP manifests to oc-mirror-workspace/results-1738075410 ``` 6. In your workspace,
    locate the imageContentSourcePolicy.yaml file by running the ls command. For example:
    ```terminal ls <workspace_directory>/<results_directory> ``` where: <workspace_directory>::
    Specifies the name of your workspace directory, for example, oc-mirror-workspace.
    <results_directory>:: Specifies the name of your results directory, for example,
    results-1738070846. 7. To mirror the Helm chart, deploy the imageContentSourcePolicy.yaml
    file in the disconnected cluster by running the oc apply command. For example:
    ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace-directory>:: Enter the name of your workspace directory,
    for example, oc-mirror-workspace. <results-directory>:: Enter the name of your
    results directory, for example, results-1738070846. 8. In your air-gapped environment,
    deploy the Helm chart to the namespace that you want to use by running the helm
    install command with namespace and set options. For example: ```terminal CLUSTER_ROUTER_BASE=$(oc
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/[.]
    \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Enter the name of your Red Hat Developer Hub instance,
    for example, my-rhdh-project. <workspace_directory>:: Enter the name of your workspace
    directory, for example, oc-mirror-workspace. <results_directory>:: Enter the name
    of your results directory, for example, results-1738070846. <archive_file>:: Enter
    the name of the archive file containing the resources that you want to mirror,
    for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>:: Enter the namespace
    that you want to deploy the Helm chart to, for example, my-rhdh-project. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:37.054956'
    uuid: 26048cd8-82a4-4b24-bae5-f93b1a6681df
  response: 'In your air-gapped environment, you deploy the Helm chart to the namespace
    you want to use by running the helm install command with namespace and set options.
    For example: `helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"`.
    In this command, `<rhdh_instance>` is the name of your Red Hat Developer Hub instance,
    `<workspace_directory>` is your workspace directory name, `<results_directory>`
    is your results directory name, `<archive_file>` is the name of the archive file
    containing the resources, and `<your_namespace>` is the namespace where you want
    to deploy the Helm chart.'
  user_input: how do i deploy the helm chrt in the air-gapped env?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a fully disconnected
    environment with the Helm chart If your network has access to the registry through
    a bastion host, you can use the Helm chart to install Red Hat Developer Hub by
    mirroring specified resources to disk and transferring them to your air-gapped
    environment without any connection to the internet. You have set up your workstation.
    You have an account in Red Hat Developer portal. You have access to the charts.openshift.io
    Helm chart repository. You have installed the OpenShift CLI (oc) on your workstation.
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have set up your intermediary
    host. Your host has access to the Red Hat Container Registry (registry.redhat.io).
    Your host has access to image registry on the destination host. See Exposing the
    registry. You have set up your destination host. You have installed Red Hat OpenShift
    Container Platform 4.16 or later. Your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. Create an ImageSetConfiguration
    file to specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` where: version: "1.8":: Enter the Red Hat Developer Hub
    version to mirror. 2. Mirror the resources specified in the ImageSetConfiguration.yaml
    file by running the oc-mirror command. For example: ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <mirror_archive_directory>/ ``` where: <mirror_config_directory>:: Enter the location
    of your image set configuration file on your system, for example, .user. <mirror_archive_directory>::
    Enter the location of your directory where the mirror archive will be created,
    for example, file://.user. [NOTE] ---- Running the oc-mirror command generates
    a local workspace containing the mirror archive file, the Helm chart, and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an imageContentSourcePolicy.yaml file
    that you must apply against the cluster in a later step. ---- Example output:
    ```terminal Creating archive /path/to/mirror archive/mirror_seq1_000000.tar ```
    3. Transfer the generated archive file (for example, mirror_seq1_000000.tar) to
    the air-gapped environment. 4. Connect to your air-gapped environment and make
    sure that you are also connected to the following objects: * The local target
    registry * The target OpenShift Container Platform cluster 5. From your air-gapped
    environment, mirror the resources from the archive to the target registry by running
    the oc-mirror command. For example: ```terminal oc mirror - from <mirror archive
    file> <target registry> ``` where: <mirror_archive_file>:: Enter the name of the
    file containing the resources that you want to mirror, for example,mirror_seq1_0000.tar.
    <target_registry>:: Enter the name of the target registry that you want to push
    the mirrored images to, for example, docker://registry.localhost:5000. Example
    output ```terminal Wrote release signatures to oc-mirror-workspace/results-1738075410
    Writing image mapping to oc-mirror-workspace/results-1738075410/mapping.txt Writing
    ICSP manifests to oc-mirror-workspace/results-1738075410 ``` 6. In your workspace,
    locate the imageContentSourcePolicy.yaml file by running the ls command. For example:
    ```terminal ls <workspace_directory>/<results_directory> ``` where: <workspace_directory>::
    Specifies the name of your workspace directory, for example, oc-mirror-workspace.
    <results_directory>:: Specifies the name of your results directory, for example,
    results-1738070846. 7. To mirror the Helm chart, deploy the imageContentSourcePolicy.yaml
    file in the disconnected cluster by running the oc apply command. For example:
    ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace-directory>:: Enter the name of your workspace directory,
    for example, oc-mirror-workspace. <results-directory>:: Enter the name of your
    results directory, for example, results-1738070846. 8. In your air-gapped environment,
    deploy the Helm chart to the namespace that you want to use by running the helm
    install command with namespace and set options. For example: ```terminal CLUSTER_ROUTER_BASE=$(oc
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/[.]
    \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Enter the name of your Red Hat Developer Hub instance,
    for example, my-rhdh-project. <workspace_directory>:: Enter the name of your workspace
    directory, for example, oc-mirror-workspace. <results_directory>:: Enter the name
    of your results directory, for example, results-1738070846. <archive_file>:: Enter
    the name of the archive file containing the resources that you want to mirror,
    for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>:: Enter the namespace
    that you want to deploy the Helm chart to, for example, my-rhdh-project. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:44.814420'
    uuid: e66351db-f895-4960-8aeb-af432b4c7f8d
  response: 'In your air-gapped environment, you can deploy the Helm chart to a specific
    namespace by using the `helm install` command with both namespace and set options.
    The command format is as follows: `helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"`.
    In this command, `<rhdh_instance>` is the name of your Red Hat Developer Hub instance,
    `<workspace_directory>` is your workspace directory name, `<results_directory>`
    is your results directory name, `<archive_file>` is the name of the archive file
    with the resources, and `<your_namespace>` is the namespace where you want to
    deploy the Helm chart.'
  user_input: Could you outline the procedure for deploying the mirrored Helm chart
    into a specific namespace within the air-gapped OpenShift environment?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a fully disconnected
    environment with the Helm chart If your network has access to the registry through
    a bastion host, you can use the Helm chart to install Red Hat Developer Hub by
    mirroring specified resources to disk and transferring them to your air-gapped
    environment without any connection to the internet. You have set up your workstation.
    You have an account in Red Hat Developer portal. You have access to the charts.openshift.io
    Helm chart repository. You have installed the OpenShift CLI (oc) on your workstation.
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have set up your intermediary
    host. Your host has access to the Red Hat Container Registry (registry.redhat.io).
    Your host has access to image registry on the destination host. See Exposing the
    registry. You have set up your destination host. You have installed Red Hat OpenShift
    Container Platform 4.16 or later. Your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. Create an ImageSetConfiguration
    file to specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` where: version: "1.8":: Enter the Red Hat Developer Hub
    version to mirror. 2. Mirror the resources specified in the ImageSetConfiguration.yaml
    file by running the oc-mirror command. For example: ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <mirror_archive_directory>/ ``` where: <mirror_config_directory>:: Enter the location
    of your image set configuration file on your system, for example, .user. <mirror_archive_directory>::
    Enter the location of your directory where the mirror archive will be created,
    for example, file://.user. [NOTE] ---- Running the oc-mirror command generates
    a local workspace containing the mirror archive file, the Helm chart, and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an imageContentSourcePolicy.yaml file
    that you must apply against the cluster in a later step. ---- Example output:
    ```terminal Creating archive /path/to/mirror archive/mirror_seq1_000000.tar ```
    3. Transfer the generated archive file (for example, mirror_seq1_000000.tar) to
    the air-gapped environment. 4. Connect to your air-gapped environment and make
    sure that you are also connected to the following objects: * The local target
    registry * The target OpenShift Container Platform cluster 5. From your air-gapped
    environment, mirror the resources from the archive to the target registry by running
    the oc-mirror command. For example: ```terminal oc mirror - from <mirror archive
    file> <target registry> ``` where: <mirror_archive_file>:: Enter the name of the
    file containing the resources that you want to mirror, for example,mirror_seq1_0000.tar.
    <target_registry>:: Enter the name of the target registry that you want to push
    the mirrored images to, for example, docker://registry.localhost:5000. Example
    output ```terminal Wrote release signatures to oc-mirror-workspace/results-1738075410
    Writing image mapping to oc-mirror-workspace/results-1738075410/mapping.txt Writing
    ICSP manifests to oc-mirror-workspace/results-1738075410 ``` 6. In your workspace,
    locate the imageContentSourcePolicy.yaml file by running the ls command. For example:
    ```terminal ls <workspace_directory>/<results_directory> ``` where: <workspace_directory>::
    Specifies the name of your workspace directory, for example, oc-mirror-workspace.
    <results_directory>:: Specifies the name of your results directory, for example,
    results-1738070846. 7. To mirror the Helm chart, deploy the imageContentSourcePolicy.yaml
    file in the disconnected cluster by running the oc apply command. For example:
    ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace-directory>:: Enter the name of your workspace directory,
    for example, oc-mirror-workspace. <results-directory>:: Enter the name of your
    results directory, for example, results-1738070846. 8. In your air-gapped environment,
    deploy the Helm chart to the namespace that you want to use by running the helm
    install command with namespace and set options. For example: ```terminal CLUSTER_ROUTER_BASE=$(oc
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/[.]
    \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Enter the name of your Red Hat Developer Hub instance,
    for example, my-rhdh-project. <workspace_directory>:: Enter the name of your workspace
    directory, for example, oc-mirror-workspace. <results_directory>:: Enter the name
    of your results directory, for example, results-1738070846. <archive_file>:: Enter
    the name of the archive file containing the resources that you want to mirror,
    for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>:: Enter the namespace
    that you want to deploy the Helm chart to, for example, my-rhdh-project. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:22:53.831052'
    uuid: 9cd2d590-c84e-4ccf-ba66-588261712182
  response: 'To install Red Hat Developer Hub in a fully disconnected environment,
    you first create an ImageSetConfiguration file to specify the resources to mirror.
    Then, you mirror those resources using the command `oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <mirror_archive_directory>/`. This creates an archive file that you must transfer
    to the air-gapped environment. In the disconnected environment, you mirror the
    resources from the archive to the target registry by running `oc mirror - from
    <mirror archive file> <target registry>`. Next, you must deploy the `imageContentSourcePolicy.yaml`
    file, which was generated in your workspace, to the disconnected cluster using
    the command `oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml`.
    Finally, you deploy the Helm chart to your chosen namespace with the `helm install`
    command, for example: `helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"`.'
  user_input: I'm trying to figure out how to install the Red Hat Developer Hub in
    our fully disconected OpenShift envirnment using the Helm chart, can you walk
    me through the whole proccess from start to finish, including the main comands
    I'll need to run to mirror the resources and then deploy it?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a partially
    disconnected environment with the Helm chart If your network has access to the
    registry.redhat.io registry and the charts.openshift.io Helm chart repository,
    you can deploy your Red Hat Developer Hub instance in your partially disconnected
    environment by mirroring the specified resources directly to the target registry.
    You have installed Red Hat OpenShift Container Platform 4.16 or later. You have
    access to the charts.openshift.io Helm chart repository. You have access to the
    registry.redhat.io. You have access to a mirror registry that can be reached from
    the disconnected cluster, for example, the OpenShift Container Platform image
    registry. For more information about exposing the OpenShift Container Platform
    image registry, see Exposing the registry. You are logged in to your target mirror
    registry and have permissions to push images to it. For more information, see
    Configuring credentials that allow images to be mirrored. You have installed the
    OpenShift CLI (oc) on your workstation. Recommended on OpenShift Container Platform:
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have an account in Red Hat Developer
    portal. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. 1. Log in to your OpenShift Container
    Platform account using the OpenShift CLI (oc) by running the following command:
    ```terminal oc login u <user> p <password> https://api.<hostname>:6443 ``` 2.
    From your disconnected cluster, log in to the image registry that you want to
    mirror, for example, the OpenShift Container Platform image registry. 3. Create
    an ImageSetConfiguration.yaml file. 4. In your ImageSetConfiguration.yaml file,
    specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` version: "1.8":: Enter the Red Hat Developer Hub version
    to mirror. 5. Mirror the resources specified in the image set configuration file
    directly to the target registry by running the oc-mirror command. For example:
    ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <target mirror registry> ``` where: <mirror_config_directory>:: Specifies the
    location of your image set configuration file on your system, for example, .user.
    <target_mirror_registry>:: Specifies the location and name of your target mirror
    registry, for example,docker://registry.example:5000. [NOTE] ---- Running the
    oc-mirror command creates a local workspace containing the Helm chart and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an automatically-generated imageContentSourcePolicy.yaml
    file that you must apply against the cluster in a later step. ---- Example output
    ```terminal Writing image mapping to oc-mirror-workspace/results-1738070846/mapping.txt
    Writing ICSP manifests to oc-mirror-workspace/results-1738070846 ``` 6. In your
    workspace, locate the imageContentSourcePolicy.yaml file by running the ls command.
    For example: ```terminal ls <workspace_directory>/<results_directory> ``` where:
    <workspace_directory>:: Specifies the name of your workspace directory, for example,
    oc-mirror-workspace. <results_directory>:: Specifies the name of your results
    directory, for example, results-1738070846. 7. To mirror the Helm chart, deploy
    the imageContentSourcePolicy.yaml file in the disconnected cluster by running
    the oc apply command. For example: ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace_directory>:: Specifies the name of your workspace directory,
    for example, oc-mirror-workspace. <results_directory>:: Specifies the name of
    your results directory, for example, results-1738070846. 8. In your air-gapped
    environment, deploy the Helm chart to the namespace that you want to use by running
    the helm install command with namespace and set options. For example: ```terminal
    CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/[.] \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Specifies the name of your Red Hat Developer Hub
    instance, for example, my-rhdh. <workspace_directory>:: Specifies the name of
    your workspace directory, for example, oc-mirror-workspace. <results_directory>::
    Specifies the name of your results directory, for example, results-1738070846.
    <archive_file>:: Specifies the name of the archive file containing the resources
    that you want to mirror, for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>::
    Specifies the namespace that you want to deploy the Helm chart to, for example,
    my-rhdh-project. Red Hat Container Registry Authentication # Installing Red Hat
    Developer Hub on a supported Kubernetes platform in an air-gapped environment
    with the Helm chart If you are using a supported Kubernetes platform in a fully
    disconnected or partially disconnected environment, you can install Red Hat Developer
    Hub by using the Helm chart. Supported Kubernetes platforms include the following:
    Microsoft Azure Kubernetes Service Amazon Elastic Kubernetes Service Google Kubernetes
    Engine ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:01.416262'
    uuid: 3cb92501-ad3c-46ae-a3b3-ca50fbece525
  response: Access to the registry.redhat.io registry is a prerequisite for deploying
    a Red Hat Developer Hub instance in a partially disconnected environment. If your
    network has access to it, you can deploy the instance by mirroring the specified
    resources directly to the target registry.
  user_input: wat is registry.redhat.io needed for?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a partially
    disconnected environment with the Helm chart If your network has access to the
    registry.redhat.io registry and the charts.openshift.io Helm chart repository,
    you can deploy your Red Hat Developer Hub instance in your partially disconnected
    environment by mirroring the specified resources directly to the target registry.
    You have installed Red Hat OpenShift Container Platform 4.16 or later. You have
    access to the charts.openshift.io Helm chart repository. You have access to the
    registry.redhat.io. You have access to a mirror registry that can be reached from
    the disconnected cluster, for example, the OpenShift Container Platform image
    registry. For more information about exposing the OpenShift Container Platform
    image registry, see Exposing the registry. You are logged in to your target mirror
    registry and have permissions to push images to it. For more information, see
    Configuring credentials that allow images to be mirrored. You have installed the
    OpenShift CLI (oc) on your workstation. Recommended on OpenShift Container Platform:
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have an account in Red Hat Developer
    portal. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. 1. Log in to your OpenShift Container
    Platform account using the OpenShift CLI (oc) by running the following command:
    ```terminal oc login u <user> p <password> https://api.<hostname>:6443 ``` 2.
    From your disconnected cluster, log in to the image registry that you want to
    mirror, for example, the OpenShift Container Platform image registry. 3. Create
    an ImageSetConfiguration.yaml file. 4. In your ImageSetConfiguration.yaml file,
    specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` version: "1.8":: Enter the Red Hat Developer Hub version
    to mirror. 5. Mirror the resources specified in the image set configuration file
    directly to the target registry by running the oc-mirror command. For example:
    ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <target mirror registry> ``` where: <mirror_config_directory>:: Specifies the
    location of your image set configuration file on your system, for example, .user.
    <target_mirror_registry>:: Specifies the location and name of your target mirror
    registry, for example,docker://registry.example:5000. [NOTE] ---- Running the
    oc-mirror command creates a local workspace containing the Helm chart and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an automatically-generated imageContentSourcePolicy.yaml
    file that you must apply against the cluster in a later step. ---- Example output
    ```terminal Writing image mapping to oc-mirror-workspace/results-1738070846/mapping.txt
    Writing ICSP manifests to oc-mirror-workspace/results-1738070846 ``` 6. In your
    workspace, locate the imageContentSourcePolicy.yaml file by running the ls command.
    For example: ```terminal ls <workspace_directory>/<results_directory> ``` where:
    <workspace_directory>:: Specifies the name of your workspace directory, for example,
    oc-mirror-workspace. <results_directory>:: Specifies the name of your results
    directory, for example, results-1738070846. 7. To mirror the Helm chart, deploy
    the imageContentSourcePolicy.yaml file in the disconnected cluster by running
    the oc apply command. For example: ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace_directory>:: Specifies the name of your workspace directory,
    for example, oc-mirror-workspace. <results_directory>:: Specifies the name of
    your results directory, for example, results-1738070846. 8. In your air-gapped
    environment, deploy the Helm chart to the namespace that you want to use by running
    the helm install command with namespace and set options. For example: ```terminal
    CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/[.] \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Specifies the name of your Red Hat Developer Hub
    instance, for example, my-rhdh. <workspace_directory>:: Specifies the name of
    your workspace directory, for example, oc-mirror-workspace. <results_directory>::
    Specifies the name of your results directory, for example, results-1738070846.
    <archive_file>:: Specifies the name of the archive file containing the resources
    that you want to mirror, for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>::
    Specifies the namespace that you want to deploy the Helm chart to, for example,
    my-rhdh-project. Red Hat Container Registry Authentication # Installing Red Hat
    Developer Hub on a supported Kubernetes platform in an air-gapped environment
    with the Helm chart If you are using a supported Kubernetes platform in a fully
    disconnected or partially disconnected environment, you can install Red Hat Developer
    Hub by using the Helm chart. Supported Kubernetes platforms include the following:
    Microsoft Azure Kubernetes Service Amazon Elastic Kubernetes Service Google Kubernetes
    Engine ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:11.378167'
    uuid: e2cfea8c-d9b1-4a67-b778-250304b4ff8d
  response: 'To install Red Hat Developer Hub on OpenShift in a partially disconnected
    environment using the Helm chart, you first need to meet several prerequisites:
    OpenShift Container Platform 4.16 or later, access to the charts.openshift.io
    Helm repository, access to registry.redhat.io, access to a mirror registry reachable
    from the cluster, login credentials for the mirror registry with push permissions,
    the OpenShift CLI (oc) installed, the oc mirror tool installed, a Red Hat Developer
    portal account, and your system must meet sizing requirements. The installation
    process is as follows: 1. Log in to your OpenShift Container Platform account
    using the `oc login` command. 2. From the disconnected cluster, log in to the
    image registry you want to mirror. 3. Create an `ImageSetConfiguration.yaml` file
    and specify the resources to mirror, such as the `redhat developer hub` chart
    from `https://charts.openshift.io`. 4. Mirror the resources to the target registry
    by running the `oc mirror` command with your configuration file. This creates
    a local workspace containing the Helm chart and an `ImageContentSourcePolicy.yaml`
    (ICSP) file. 5. Locate the `imageContentSourcePolicy.yaml` file in the results
    directory within your workspace. 6. Deploy this file in the disconnected cluster
    using the `oc apply` command. 7. Finally, in your air-gapped environment, deploy
    the Helm chart to your desired namespace by running the `helm install` command,
    pointing to the chart''s archive file in your workspace and setting the `global.clusterRouterBase`.'
  user_input: how do i install the Red Hat Developer Hub on my openshift cluster if
    its kinda disconnected, what are the steps i need to do with the helm chart?
- context:
  - 'Installing Red Hat Developer Hub on OpenShift Container Platform in a partially
    disconnected environment with the Helm chart If your network has access to the
    registry.redhat.io registry and the charts.openshift.io Helm chart repository,
    you can deploy your Red Hat Developer Hub instance in your partially disconnected
    environment by mirroring the specified resources directly to the target registry.
    You have installed Red Hat OpenShift Container Platform 4.16 or later. You have
    access to the charts.openshift.io Helm chart repository. You have access to the
    registry.redhat.io. You have access to a mirror registry that can be reached from
    the disconnected cluster, for example, the OpenShift Container Platform image
    registry. For more information about exposing the OpenShift Container Platform
    image registry, see Exposing the registry. You are logged in to your target mirror
    registry and have permissions to push images to it. For more information, see
    Configuring credentials that allow images to be mirrored. You have installed the
    OpenShift CLI (oc) on your workstation. Recommended on OpenShift Container Platform:
    You have installed the oc mirror tool, with a version corresponding to the version
    of your OpenShift Container Platform cluster. You have an account in Red Hat Developer
    portal. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. 1. Log in to your OpenShift Container
    Platform account using the OpenShift CLI (oc) by running the following command:
    ```terminal oc login u <user> p <password> https://api.<hostname>:6443 ``` 2.
    From your disconnected cluster, log in to the image registry that you want to
    mirror, for example, the OpenShift Container Platform image registry. 3. Create
    an ImageSetConfiguration.yaml file. 4. In your ImageSetConfiguration.yaml file,
    specify the resources that you want to mirror. For example: ```yaml apiVersion:
    mirror.openshift.io/v1alpha2 kind: ImageSetConfiguration mirror: helm: repositories:
    name: openshift charts url: https://charts.openshift.io charts: name: redhat developer
    hub version: "1.8" ``` version: "1.8":: Enter the Red Hat Developer Hub version
    to mirror. 5. Mirror the resources specified in the image set configuration file
    directly to the target registry by running the oc-mirror command. For example:
    ```terminal oc mirror - config=<mirror_config_directory>/ImageSetConfiguration.yaml
    <target mirror registry> ``` where: <mirror_config_directory>:: Specifies the
    location of your image set configuration file on your system, for example, .user.
    <target_mirror_registry>:: Specifies the location and name of your target mirror
    registry, for example,docker://registry.example:5000. [NOTE] ---- Running the
    oc-mirror command creates a local workspace containing the Helm chart and a ImageContentSourcePolicy
    (ICSP) manifest. The ICSP manifest contains an automatically-generated imageContentSourcePolicy.yaml
    file that you must apply against the cluster in a later step. ---- Example output
    ```terminal Writing image mapping to oc-mirror-workspace/results-1738070846/mapping.txt
    Writing ICSP manifests to oc-mirror-workspace/results-1738070846 ``` 6. In your
    workspace, locate the imageContentSourcePolicy.yaml file by running the ls command.
    For example: ```terminal ls <workspace_directory>/<results_directory> ``` where:
    <workspace_directory>:: Specifies the name of your workspace directory, for example,
    oc-mirror-workspace. <results_directory>:: Specifies the name of your results
    directory, for example, results-1738070846. 7. To mirror the Helm chart, deploy
    the imageContentSourcePolicy.yaml file in the disconnected cluster by running
    the oc apply command. For example: ```terminal oc apply f <workspace_directory>/<results_directory>/ImageContentSourcePolicy.yaml
    ``` where: <workspace_directory>:: Specifies the name of your workspace directory,
    for example, oc-mirror-workspace. <results_directory>:: Specifies the name of
    your results directory, for example, results-1738070846. 8. In your air-gapped
    environment, deploy the Helm chart to the namespace that you want to use by running
    the helm install command with namespace and set options. For example: ```terminal
    CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/[.] \.//'') helm install <rhdh_instance> <workspace_directory>/<results_directory>/charts/<archive_file>
    --namespace <your_namespace> --create-namespace \ --set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    ``` where: <rhdh_instance>:: Specifies the name of your Red Hat Developer Hub
    instance, for example, my-rhdh. <workspace_directory>:: Specifies the name of
    your workspace directory, for example, oc-mirror-workspace. <results_directory>::
    Specifies the name of your results directory, for example, results-1738070846.
    <archive_file>:: Specifies the name of the archive file containing the resources
    that you want to mirror, for example, redhat-developer-hub-1.4.1.tgz. <your_namespace>::
    Specifies the namespace that you want to deploy the Helm chart to, for example,
    my-rhdh-project. Red Hat Container Registry Authentication # Installing Red Hat
    Developer Hub on a supported Kubernetes platform in an air-gapped environment
    with the Helm chart If you are using a supported Kubernetes platform in a fully
    disconnected or partially disconnected environment, you can install Red Hat Developer
    Hub by using the Helm chart. Supported Kubernetes platforms include the following:
    Microsoft Azure Kubernetes Service Amazon Elastic Kubernetes Service Google Kubernetes
    Engine ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:19.531811'
    uuid: 5d41324d-0173-462d-8b90-2fd1cd4c7ffb
  response: 'To install Red Hat Developer Hub on OpenShift in a partially disconnected
    environment, you must meet several prerequisites: have OpenShift Container Platform
    4.16 or later installed, access to the charts.openshift.io Helm chart repository,
    access to registry.redhat.io, access to a mirror registry reachable from the cluster,
    be logged into the mirror registry with permissions to push images, have the OpenShift
    CLI (oc) installed, and have an account in the Red Hat Developer portal. The main
    steps are: 1. Log in to your OpenShift Container Platform account using the `oc
    login` command. 2. Create an `ImageSetConfiguration.yaml` file and specify the
    resources to mirror, including the `redhat developer hub` chart. 3. Run the `oc
    mirror` command to mirror the resources to the target registry, which creates
    a workspace containing the Helm chart and an `ImageContentSourcePolicy.yaml` file.
    4. Locate the `imageContentSourcePolicy.yaml` file in the workspace. 5. Apply
    this file to the disconnected cluster using the `oc apply` command. 6. Finally,
    deploy the Helm chart in your air-gapped environment using the `helm install`
    command with the appropriate namespace and set options.'
  user_input: I'm trying to instal Red Hat Developer Hub on our OpenShift Container
    Platfrom in a partialy disconnected envirnment, what are all the prerequisits
    and the main steps I need to follow to mirror the resources and deploy the helm
    chart?
- context:
  - 'Installing Red Hat Developer Hub on a supported Kubernetes platform in a fully
    disconnected environment with the Helm chart In environments without internet
    access, a fully disconnected installation ensures that Red Hat Developer Hub can
    run reliably without external dependencies. This approach involves mirroring images
    and transferring them manually to the air-gapped environment. You have installed
    Skopeo 1.17 or later You have installed Yq 4.4 or later You authenticated to registry.redhat.io
    for pulling images by using the skopeo login command. You have access to the Kubernetes
    cluster with kubectl configured You have installed Helm 3.13 or later on the air
    gapped host 1. On the mirroring host, in a terminal, fetch the Helm charts values
    by running the following commands: ```terminal helm repo add <helm_chart_repo_name>
    https://charts.openshift.io/ helm repo update helm show values <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> values.default.yaml helm pull <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> ``` where <helm_chart_repo_name>:: Specifies the name
    of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Specifies the Red Hat Developer Hub version that you want to use, for example,
    1.8.0. [NOTE] ---- The helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> command automatically creates the Helm chart archive file and downloads
    the Helm chart to your current working directory. ---- 2. Extract the image digests
    by running the following commands: ```terminal RHDH_IMAGE=$(yq ''.upstream.backstage.image
    | .registry + "/" + .repository'' values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag''
    values.default.yaml) PG_IMAGE=$(yq ''.upstream.postgresql.image | .registry +
    "/" + .repository'' values.default.yaml) PG_DIGEST=$(yq ''.upstream.postgresql.image.tag''
    values.default.yaml) ``` 3. Mirror the images to your local archive by running
    the following commands: ```terminal skopeo login registry.redhat.io skopeo copy
    - all docker://${RHDH_IMAGE}:${RHDH_DIGEST} dir:./rhdh hub skopeo copy - all docker://${PG_IMAGE}:${PG_DIGEST}
    dir:./postgresql ``` 4. Transfer the following files and directories to your air-gapped
    environment: * rhdh-hub * postgresql * Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz
    5. Load the images onto the air-gapped host by running the following commands:
    ```terminal skopeo copy - all dir:./rhdh hub docker://<mirror_registry_name>/<rhdh_repo_name>:${RHDH_DIGEST}
    skopeo copy - all dir:./postgresql docker://<mirror_registry_name>/<postgresql_repo_name>:${PG_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. 6. Create a values.yaml file for the Kubernetes platform
    that you want to use and add the following image references to the file to reflect
    local use: ```yaml upstream: backstage: image: registry: "<mirror_registry_name>"
    repository: <rhdh_repo_name> tag: "${RHDH_DIGEST}" postgresql: image: registry:
    "<mirror_registry_name>" repository: <postgresql_repo_name> tag: "${PG_DIGEST}"
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. * For AKS, use the following values.yaml file template:
    ```yaml global: host: <app_address> route: enabled: false upstream: ingress: enabled:
    true className: webapprouting.kubernetes.azure.com host: backstage: image: pullSecrets:
    rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql: image: pullSecrets:
    rhdh pull secret primary: podSecurityContext: enabled: true fsGroup: 3000 volumePermissions:
    enabled: true ``` For EKS, use the following values.yaml file template: ```yaml
    global: # TODO: Set your application domain name. host: <my_developer_hub_domain>
    route: enabled: false upstream: service: # NodePort is required for the ALB to
    route to the Service type: NodePort ingress: enabled: true annotations: kubernetes.io/ingress.class:
    alb alb.ingress.kubernetes.io/scheme: internet facing # TODO: Using an ALB HTTPS
    Listener requires a certificate for your own domain. Fill in the ARN of your certificate,
    e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl
    redirect: ''443'' # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 7. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./<helm_chart_archive_file_name> f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.4.0.tgz.
    ## Installing Red Hat Developer Hub on a supported Kubernetes platform in a partially
    disconnected environment with the Helm chart In a partially disconnected environment,
    the cluster cannot access external registries, for example, registry.redhat.io,
    but it can access an internal mirror registry. This method requires direct access
    to an internal mirror registry from the cluster. You have set up your workstation.
    You have installed Skopeo 1.17 or later You have installed Yq 4.4 or later You
    have installed Helm 3.13 or later You have an active Skopeo session against registry.redhat.io
    You have an active Skopeo session against your target mirror registry, for example,
    registry.internal.example.com You have access to the Kubernetes cluster with kubectl
    configured 1. In a terminal, download and extract the Helm chart by running the
    following commands: ```terminal helm repo add <helm_chart_repo_name> https://charts.openshift.io/
    helm repo update helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> helm show values <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> > values.default.yaml ``` where: <helm_chart_repo_name>:: Enter
    the name of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Enter the Red Hat Developer Hub version that you want to use, for example, 1.8.0.
    2. Use yq to extract the image digests by running the following commands: ```terminal
    RHDH_IMAGE=$(yq ''.upstream.backstage.image | .registry + "/" + .repository''
    values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag'' values.default.yaml)
    PG_IMAGE=$(yq'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:30.712231'
    uuid: 3c5fcb68-f6e0-45c9-b2fc-af4aa9ce6ad2
  response: "For AKS, use the following values.yaml file template:\n```yaml\nglobal:\n\
    \  host: <app_address>\n  route:\n    enabled: false\nupstream:\n  ingress:\n\
    \    enabled: true\n    className: webapprouting.kubernetes.azure.com\n  host:\n\
    \  backstage:\n    image:\n      pullSecrets: rhdh pull secret\n    podSecurityContext:\n\
    \      fsGroup: 3000\n  postgresql:\n    image:\n      pullSecrets: rhdh pull\
    \ secret\n    primary:\n      podSecurityContext:\n        enabled: true\n   \
    \     fsGroup: 3000\n      volumePermissions:\n        enabled: true\n```"
  user_input: What is the values.yaml file template for an RHDH installation on AKS?
- context:
  - 'Installing Red Hat Developer Hub on a supported Kubernetes platform in a fully
    disconnected environment with the Helm chart In environments without internet
    access, a fully disconnected installation ensures that Red Hat Developer Hub can
    run reliably without external dependencies. This approach involves mirroring images
    and transferring them manually to the air-gapped environment. You have installed
    Skopeo 1.17 or later You have installed Yq 4.4 or later You authenticated to registry.redhat.io
    for pulling images by using the skopeo login command. You have access to the Kubernetes
    cluster with kubectl configured You have installed Helm 3.13 or later on the air
    gapped host 1. On the mirroring host, in a terminal, fetch the Helm charts values
    by running the following commands: ```terminal helm repo add <helm_chart_repo_name>
    https://charts.openshift.io/ helm repo update helm show values <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> values.default.yaml helm pull <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> ``` where <helm_chart_repo_name>:: Specifies the name
    of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Specifies the Red Hat Developer Hub version that you want to use, for example,
    1.8.0. [NOTE] ---- The helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> command automatically creates the Helm chart archive file and downloads
    the Helm chart to your current working directory. ---- 2. Extract the image digests
    by running the following commands: ```terminal RHDH_IMAGE=$(yq ''.upstream.backstage.image
    | .registry + "/" + .repository'' values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag''
    values.default.yaml) PG_IMAGE=$(yq ''.upstream.postgresql.image | .registry +
    "/" + .repository'' values.default.yaml) PG_DIGEST=$(yq ''.upstream.postgresql.image.tag''
    values.default.yaml) ``` 3. Mirror the images to your local archive by running
    the following commands: ```terminal skopeo login registry.redhat.io skopeo copy
    - all docker://${RHDH_IMAGE}:${RHDH_DIGEST} dir:./rhdh hub skopeo copy - all docker://${PG_IMAGE}:${PG_DIGEST}
    dir:./postgresql ``` 4. Transfer the following files and directories to your air-gapped
    environment: * rhdh-hub * postgresql * Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz
    5. Load the images onto the air-gapped host by running the following commands:
    ```terminal skopeo copy - all dir:./rhdh hub docker://<mirror_registry_name>/<rhdh_repo_name>:${RHDH_DIGEST}
    skopeo copy - all dir:./postgresql docker://<mirror_registry_name>/<postgresql_repo_name>:${PG_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. 6. Create a values.yaml file for the Kubernetes platform
    that you want to use and add the following image references to the file to reflect
    local use: ```yaml upstream: backstage: image: registry: "<mirror_registry_name>"
    repository: <rhdh_repo_name> tag: "${RHDH_DIGEST}" postgresql: image: registry:
    "<mirror_registry_name>" repository: <postgresql_repo_name> tag: "${PG_DIGEST}"
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. * For AKS, use the following values.yaml file template:
    ```yaml global: host: <app_address> route: enabled: false upstream: ingress: enabled:
    true className: webapprouting.kubernetes.azure.com host: backstage: image: pullSecrets:
    rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql: image: pullSecrets:
    rhdh pull secret primary: podSecurityContext: enabled: true fsGroup: 3000 volumePermissions:
    enabled: true ``` For EKS, use the following values.yaml file template: ```yaml
    global: # TODO: Set your application domain name. host: <my_developer_hub_domain>
    route: enabled: false upstream: service: # NodePort is required for the ALB to
    route to the Service type: NodePort ingress: enabled: true annotations: kubernetes.io/ingress.class:
    alb alb.ingress.kubernetes.io/scheme: internet facing # TODO: Using an ALB HTTPS
    Listener requires a certificate for your own domain. Fill in the ARN of your certificate,
    e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl
    redirect: ''443'' # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 7. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./<helm_chart_archive_file_name> f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.4.0.tgz.
    ## Installing Red Hat Developer Hub on a supported Kubernetes platform in a partially
    disconnected environment with the Helm chart In a partially disconnected environment,
    the cluster cannot access external registries, for example, registry.redhat.io,
    but it can access an internal mirror registry. This method requires direct access
    to an internal mirror registry from the cluster. You have set up your workstation.
    You have installed Skopeo 1.17 or later You have installed Yq 4.4 or later You
    have installed Helm 3.13 or later You have an active Skopeo session against registry.redhat.io
    You have an active Skopeo session against your target mirror registry, for example,
    registry.internal.example.com You have access to the Kubernetes cluster with kubectl
    configured 1. In a terminal, download and extract the Helm chart by running the
    following commands: ```terminal helm repo add <helm_chart_repo_name> https://charts.openshift.io/
    helm repo update helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> helm show values <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> > values.default.yaml ``` where: <helm_chart_repo_name>:: Enter
    the name of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Enter the Red Hat Developer Hub version that you want to use, for example, 1.8.0.
    2. Use yq to extract the image digests by running the following commands: ```terminal
    RHDH_IMAGE=$(yq ''.upstream.backstage.image | .registry + "/" + .repository''
    values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag'' values.default.yaml)
    PG_IMAGE=$(yq'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:47.916818'
    uuid: 71a1122e-ccf9-4a2a-b8ce-25cc69446c72
  response: 'To extract the image digests from the values.default.yaml file, you run
    the following commands: RHDH_IMAGE=$(yq ''.upstream.backstage.image | .registry
    + "/" + .repository'' values.default.yaml), RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag''
    values.default.yaml), PG_IMAGE=$(yq ''.upstream.postgresql.image | .registry +
    "/" + .repository'' values.default.yaml), and PG_DIGEST=$(yq ''.upstream.postgresql.image.tag''
    values.default.yaml).'
  user_input: Yq command to extract image digests
- context:
  - 'Installing Red Hat Developer Hub on a supported Kubernetes platform in a fully
    disconnected environment with the Helm chart In environments without internet
    access, a fully disconnected installation ensures that Red Hat Developer Hub can
    run reliably without external dependencies. This approach involves mirroring images
    and transferring them manually to the air-gapped environment. You have installed
    Skopeo 1.17 or later You have installed Yq 4.4 or later You authenticated to registry.redhat.io
    for pulling images by using the skopeo login command. You have access to the Kubernetes
    cluster with kubectl configured You have installed Helm 3.13 or later on the air
    gapped host 1. On the mirroring host, in a terminal, fetch the Helm charts values
    by running the following commands: ```terminal helm repo add <helm_chart_repo_name>
    https://charts.openshift.io/ helm repo update helm show values <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> values.default.yaml helm pull <helm_chart_repo_name>/redhat-developer-hub
    --version <rhdh_version> ``` where <helm_chart_repo_name>:: Specifies the name
    of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Specifies the Red Hat Developer Hub version that you want to use, for example,
    1.8.0. [NOTE] ---- The helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> command automatically creates the Helm chart archive file and downloads
    the Helm chart to your current working directory. ---- 2. Extract the image digests
    by running the following commands: ```terminal RHDH_IMAGE=$(yq ''.upstream.backstage.image
    | .registry + "/" + .repository'' values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag''
    values.default.yaml) PG_IMAGE=$(yq ''.upstream.postgresql.image | .registry +
    "/" + .repository'' values.default.yaml) PG_DIGEST=$(yq ''.upstream.postgresql.image.tag''
    values.default.yaml) ``` 3. Mirror the images to your local archive by running
    the following commands: ```terminal skopeo login registry.redhat.io skopeo copy
    - all docker://${RHDH_IMAGE}:${RHDH_DIGEST} dir:./rhdh hub skopeo copy - all docker://${PG_IMAGE}:${PG_DIGEST}
    dir:./postgresql ``` 4. Transfer the following files and directories to your air-gapped
    environment: * rhdh-hub * postgresql * Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz
    5. Load the images onto the air-gapped host by running the following commands:
    ```terminal skopeo copy - all dir:./rhdh hub docker://<mirror_registry_name>/<rhdh_repo_name>:${RHDH_DIGEST}
    skopeo copy - all dir:./postgresql docker://<mirror_registry_name>/<postgresql_repo_name>:${PG_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. 6. Create a values.yaml file for the Kubernetes platform
    that you want to use and add the following image references to the file to reflect
    local use: ```yaml upstream: backstage: image: registry: "<mirror_registry_name>"
    repository: <rhdh_repo_name> tag: "${RHDH_DIGEST}" postgresql: image: registry:
    "<mirror_registry_name>" repository: <postgresql_repo_name> tag: "${PG_DIGEST}"
    ``` where <mirror_registry_name>:: Specifies the name of the target mirror registry
    that you want to push the images to, for example, registry.example.com. <rhdh_repo_name>::
    Specifies the name of the repository where your Red Hat Developer Hub image is
    stored, for example, rhdh/rhdh-hub-rhel9. This value must match the name of the
    Red Hat Developer Hub image that you loaded onto the air-gapped host. <postgresql_repo_name>::
    Specifies the name of the repository where your PostgreSQL image is stored, for
    example, rhdh/postgresql-15. * For AKS, use the following values.yaml file template:
    ```yaml global: host: <app_address> route: enabled: false upstream: ingress: enabled:
    true className: webapprouting.kubernetes.azure.com host: backstage: image: pullSecrets:
    rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql: image: pullSecrets:
    rhdh pull secret primary: podSecurityContext: enabled: true fsGroup: 3000 volumePermissions:
    enabled: true ``` For EKS, use the following values.yaml file template: ```yaml
    global: # TODO: Set your application domain name. host: <my_developer_hub_domain>
    route: enabled: false upstream: service: # NodePort is required for the ALB to
    route to the Service type: NodePort ingress: enabled: true annotations: kubernetes.io/ingress.class:
    alb alb.ingress.kubernetes.io/scheme: internet facing # TODO: Using an ALB HTTPS
    Listener requires a certificate for your own domain. Fill in the ARN of your certificate,
    e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl
    redirect: ''443'' # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 7. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./<helm_chart_archive_file_name> f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.4.0.tgz.
    ## Installing Red Hat Developer Hub on a supported Kubernetes platform in a partially
    disconnected environment with the Helm chart In a partially disconnected environment,
    the cluster cannot access external registries, for example, registry.redhat.io,
    but it can access an internal mirror registry. This method requires direct access
    to an internal mirror registry from the cluster. You have set up your workstation.
    You have installed Skopeo 1.17 or later You have installed Yq 4.4 or later You
    have installed Helm 3.13 or later You have an active Skopeo session against registry.redhat.io
    You have an active Skopeo session against your target mirror registry, for example,
    registry.internal.example.com You have access to the Kubernetes cluster with kubectl
    configured 1. In a terminal, download and extract the Helm chart by running the
    following commands: ```terminal helm repo add <helm_chart_repo_name> https://charts.openshift.io/
    helm repo update helm pull <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> helm show values <helm_chart_repo_name>/redhat-developer-hub --version
    <rhdh_version> > values.default.yaml ``` where: <helm_chart_repo_name>:: Enter
    the name of the Helm chart repository, for example, openshift-helm-charts. <rhdh_version>::
    Enter the Red Hat Developer Hub version that you want to use, for example, 1.8.0.
    2. Use yq to extract the image digests by running the following commands: ```terminal
    RHDH_IMAGE=$(yq ''.upstream.backstage.image | .registry + "/" + .repository''
    values.default.yaml) RHDH_DIGEST=$(yq ''.upstream.backstage.image.tag'' values.default.yaml)
    PG_IMAGE=$(yq'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:23:56.083665'
    uuid: 3990c499-f6c4-4acf-992f-12d435d15584
  response: 'For an installation in a fully disconnected environment, you must transfer
    the following files and directories to your air-gapped environment: the rhdh-hub
    directory, the postgresql directory, and the Helm chart archive file, for example,
    redhat-developer-hub-1.8.0.tgz.'
  user_input: To install on Kubernetes in a air-gapped place, what files and directories
    I need to transfer over?
- context:
  - '''.upstream.postgresql.image | .registry + "/" + .repository'' values.default.yaml)
    PG_DIGEST=$(yq ''.upstream.postgresql.image.tag'' values.default.yaml) ``` 3.
    Mirror the images to the internal mirror registry by entering the following commands:
    ```terminal skopeo login registry.redhat.io skopeo login _<mirror_registry_name>_
    skopeo copy - remove signatures \ docker://${PG_IMAGE}@${PG_DIGEST} \ docker://_<mirror_registry_name>_/_<postgresql_repo_name>_:${PG_DIGEST}
    skopeo copy - remove signatures \ docker://${RHDH_IMAGE}@${RHDH_DIGEST} \ docker://_<mirror_registry_name>_/_<rhdh_repo_name>_${RHDH_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the internal mirror registry,
    for example, registry.internal.example.com. <postgresql_repo_name>:: Specifies
    the name of the PostgreSQL repository, for example, rhdh/postgresql-15. <rhdh_repo_name>::
    Specifies the name of the Red Hat Developer Hub repository, for example, rhdh/rhdh-hub-rhel9.
    4. Create a values.yaml file for the Kubernetes platform that you want to use
    and add the following image references to the file to reflect local use: ```yaml
    upstream: backstage: image: registry: "_<mirror_registry_name>_" repository: _<rhdh_repo_name>_
    tag: "${RHDH_DIGEST}" postgresql: image: registry: "_<mirror_registry_name>_"
    repository: _<postgresql_repo_name>_ tag: "${PG_DIGEST}" ``` For AKS, use the
    following values.yaml file template: ```yaml global: host: <app_address> route:
    enabled: false upstream: ingress: enabled: true className: webapprouting.kubernetes.azure.com
    host: backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    3000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` For EKS, use
    the following values.yaml file template: ```yaml global: # TODO: Set your application
    domain name. host: <your Developer Hub domain name> route: enabled: false upstream:
    service: # NodePort is required for the ALB to route to the Service type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 5. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./_<helm_chart_archive_file_name>_ f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz.
    Deploying Developer Hub on AKS with the Helm chart Installing Developer Hub on
    EKS with the Helm chart Installing Developer Hub on GKE with the Helm chart'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:24:05.952828'
    uuid: 63b3abcc-b7b3-45b9-a26c-72216eda1574
  response: "For AKS, you should use the following values.yaml file template: \n```yaml\n\
    global:\n  host: <app_address>\n  route:\n    enabled: false\nupstream:\n  ingress:\n\
    \    enabled: true\n    className: webapprouting.kubernetes.azure.com\n  host:\n\
    \  backstage:\n    image:\n      pullSecrets: rhdh pull secret\n    podSecurityContext:\n\
    \      fsGroup: 3000\n  postgresql:\n    image:\n      pullSecrets: rhdh pull\
    \ secret\n    primary:\n      podSecurityContext:\n        enabled: true\n   \
    \     fsGroup: 3000\n      volumePermissions:\n        enabled: true\n```"
  user_input: As a Platform Engineer tasked with deploying Red Hat Developer Hub,
    what is the specific `values.yaml` file template that I should use to correctly
    configure the installation for the Azure Kubernetes Service, commonly referred
    to as AKS?
- context:
  - '''.upstream.postgresql.image | .registry + "/" + .repository'' values.default.yaml)
    PG_DIGEST=$(yq ''.upstream.postgresql.image.tag'' values.default.yaml) ``` 3.
    Mirror the images to the internal mirror registry by entering the following commands:
    ```terminal skopeo login registry.redhat.io skopeo login _<mirror_registry_name>_
    skopeo copy - remove signatures \ docker://${PG_IMAGE}@${PG_DIGEST} \ docker://_<mirror_registry_name>_/_<postgresql_repo_name>_:${PG_DIGEST}
    skopeo copy - remove signatures \ docker://${RHDH_IMAGE}@${RHDH_DIGEST} \ docker://_<mirror_registry_name>_/_<rhdh_repo_name>_${RHDH_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the internal mirror registry,
    for example, registry.internal.example.com. <postgresql_repo_name>:: Specifies
    the name of the PostgreSQL repository, for example, rhdh/postgresql-15. <rhdh_repo_name>::
    Specifies the name of the Red Hat Developer Hub repository, for example, rhdh/rhdh-hub-rhel9.
    4. Create a values.yaml file for the Kubernetes platform that you want to use
    and add the following image references to the file to reflect local use: ```yaml
    upstream: backstage: image: registry: "_<mirror_registry_name>_" repository: _<rhdh_repo_name>_
    tag: "${RHDH_DIGEST}" postgresql: image: registry: "_<mirror_registry_name>_"
    repository: _<postgresql_repo_name>_ tag: "${PG_DIGEST}" ``` For AKS, use the
    following values.yaml file template: ```yaml global: host: <app_address> route:
    enabled: false upstream: ingress: enabled: true className: webapprouting.kubernetes.azure.com
    host: backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    3000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` For EKS, use
    the following values.yaml file template: ```yaml global: # TODO: Set your application
    domain name. host: <your Developer Hub domain name> route: enabled: false upstream:
    service: # NodePort is required for the ALB to route to the Service type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 5. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./_<helm_chart_archive_file_name>_ f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz.
    Deploying Developer Hub on AKS with the Helm chart Installing Developer Hub on
    EKS with the Helm chart Installing Developer Hub on GKE with the Helm chart'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:24:15.021807'
    uuid: 1e6e7936-a15d-4106-aedb-c5bc82bcbfdc
  response: In the provided procedure, the `skopeo copy` command uses the `docker://`
    transport to specify the source and destination for mirroring images. The source
    for the PostgreSQL image is defined as `docker://${PG_IMAGE}@${PG_DIGEST}`, and
    its destination in the internal mirror registry is `docker://_<mirror_registry_name>_/_<postgresql_repo_name>_:${PG_DIGEST}`.
    Similarly, the source for the Red Hat Developer Hub image is `docker://${RHDH_IMAGE}@${RHDH_DIGEST}`,
    and its destination is specified as `docker://_<mirror_registry_name>_/_<rhdh_repo_name>_${RHDH_DIGEST}`.
  user_input: As a Platform Engineer following the provided procedure for mirroring
    images, could you please explain the specific role of the `docker://` transport
    in the `skopeo copy` command and detail how it is used to define both the source
    and destination for the PostgreSQL and Red Hat Developer Hub images?
- context:
  - '''.upstream.postgresql.image | .registry + "/" + .repository'' values.default.yaml)
    PG_DIGEST=$(yq ''.upstream.postgresql.image.tag'' values.default.yaml) ``` 3.
    Mirror the images to the internal mirror registry by entering the following commands:
    ```terminal skopeo login registry.redhat.io skopeo login _<mirror_registry_name>_
    skopeo copy - remove signatures \ docker://${PG_IMAGE}@${PG_DIGEST} \ docker://_<mirror_registry_name>_/_<postgresql_repo_name>_:${PG_DIGEST}
    skopeo copy - remove signatures \ docker://${RHDH_IMAGE}@${RHDH_DIGEST} \ docker://_<mirror_registry_name>_/_<rhdh_repo_name>_${RHDH_DIGEST}
    ``` where <mirror_registry_name>:: Specifies the name of the internal mirror registry,
    for example, registry.internal.example.com. <postgresql_repo_name>:: Specifies
    the name of the PostgreSQL repository, for example, rhdh/postgresql-15. <rhdh_repo_name>::
    Specifies the name of the Red Hat Developer Hub repository, for example, rhdh/rhdh-hub-rhel9.
    4. Create a values.yaml file for the Kubernetes platform that you want to use
    and add the following image references to the file to reflect local use: ```yaml
    upstream: backstage: image: registry: "_<mirror_registry_name>_" repository: _<rhdh_repo_name>_
    tag: "${RHDH_DIGEST}" postgresql: image: registry: "_<mirror_registry_name>_"
    repository: _<postgresql_repo_name>_ tag: "${PG_DIGEST}" ``` For AKS, use the
    following values.yaml file template: ```yaml global: host: <app_address> route:
    enabled: false upstream: ingress: enabled: true className: webapprouting.kubernetes.azure.com
    host: backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    3000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` For EKS, use
    the following values.yaml file template: ```yaml global: # TODO: Set your application
    domain name. host: <your Developer Hub domain name> route: enabled: false upstream:
    service: # NodePort is required for the ALB to route to the Service type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` For GKE, use the following values.yaml file template: ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 5. Install the
    Helm chart in the current namespace by running the following command: ```terminal
    helm install rhdh ./_<helm_chart_archive_file_name>_ f values.yaml ``` where <helm_chart_archive_file_name>::
    Specifies the name of the Helm chart archive file, for example, redhat-developer-hub-1.8.0.tgz.
    Deploying Developer Hub on AKS with the Helm chart Installing Developer Hub on
    EKS with the Helm chart Installing Developer Hub on GKE with the Helm chart'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:24:22.733902'
    uuid: 8ef6a015-f416-465a-b211-bcd70fb24739
  response: 'You can install the Helm chart in the current namespace by running the
    following command: `helm install rhdh ./_<helm_chart_archive_file_name>_ f values.yaml`.
    The `<helm_chart_archive_file_name>` specifies the name of the Helm chart archive
    file, such as `redhat-developer-hub-1.8.0.tgz`.'
  user_input: How do I install the Red Hat Developer Hub Helm chart?
- context:
  - 'Versioning a Software Template in Red Hat Developer Hub As a platform administrator,
    you can version Software Templates by using the existing custom actions catalog:scaffolded-from
    and catalog:template:version within the scaffolder backend module. By using these
    custom actions, you can track the scaffolder template version and the corresponding
    version of the entities created from it, which improves lifecycle management.
    You have administrator rights to Red Hat Developer Hub. To add versioning to a
    Software Template yaml file, complete the following steps: 1. Modify the Software
    Template that you want to update. 2. Complete one or both of the following tasks:
    * Include the backstage.io/template-version annotation in your template. When
    this annotation is present in your template, it is automatically used to annotate
    your catalog entity and a default version value is displayed. * Pass the backstage.io/template-version
    annotation as input to the action. This method takes precedence over the annotation
    in the template itself. It allows the user running the template to specify the
    version they wish to generate. ```yaml # ... - id: version-templateRef name: Append
    the version of this template to the entityRef action: catalog:template:version
    input: annotations: backstage.io/template-version: ${{ parameters.version }} #
    ... ``` 1. Create a catalog component using the updated Software Template. This
    step creates a new component in Backstage and optionally, pushes files to an external
    repository (For example, GitHub, GitLab). 2. Check the component in the Catalog
    UI. 1. On the Catalog page, locate the newly created catalog component. 2. Verify
    that the backstage.io/template-version annotation is present in the entity. You
    can use INSPECT ENTITY and select YAML Raw or JSON Raw view to find the annotation
    in the component definition. 3. Only if you have published the catalog component:
    Check the component file in the repository. 1. If VIEW SOURCE is present in your
    UI: Click VIEW SOURCE to open the stored component file in the repository. 2.
    Locate the file manually and verify that the backstage.io/template-version annotation
    is present. ## Enabling Software Template version update notifications in Red
    Hat Developer Hub As a platform engineer, you can enable notification alerts for
    template version updates using the @backstage-community/plugin-catalog-backend-module-scaffolder-relation-processor
    module, an extension to the catalog-backend plugin. When enabled, this module
    automatically notifies component owners whenever the Software Template used to
    generate their components is updated to a new version. This functionality uses
    the spec.scaffoldedFrom field in catalog entities. This field links Software Templates
    to the entities they have scaffolded. By tracking this relationship, the module
    helps teams stay informed and take advantage of the latest improvements or fixes.
    The plugin-catalog-backend-module-scaffolder-relation-processor module is disabled
    by default. You have installed and configured the Backstage backend notification
    plugin @backstage/plugin notifications backend. You have installed and configured
    the Backstage frontend plugin @backstage/plugin notifications. 1. To enable the
    notifications, in your Red Hat Developer Hub app-config.yaml file, add the following
    codes: 1. In the dynamicPlugins:frontend section: ```yaml frontend: backstage.plugin
    notifications: dynamicRoutes: importName: NotificationPage menuItem: config: props:
    titleCounterEnabled: true webNotificationsEnabled: false importName: NotificationsSidebarItem
    path: /notifications ``` 2. In a new section: ```yaml scaffolder: notifications:
    templateUpdate: enabled: true # Set to false to disable notifications ``` You
    can also customize the notification title and description as shown in the following
    code: ```yaml scaffolder: notifications: templateUpdate: enabled: true message:
    title: ''Custom title for $ENTITY_DISPLAY_NAME'' description: ''Custom description''
    ``` where: enabled:: Set to true to enable the notification. Default value is
    false. message:title:: Enter the notification title. message:description:: Enter
    the notification description. [NOTE] ---- Both message:title and message:description
    support the template variable $ENTITY_DISPLAY_NAME. The system automatically substitutes
    this variable with the title (or the name, if the title is missing) of the entity
    scaffolded from the updated template. ---- In your Red Hat Developer Hub instance,
    on the left navigation menu, you are able to see Notifications, or, if configured,
    the custom title. When you update the version number in the Software Template,
    you receive a notification. ## Tracking Component origin and Software Template
    version Platform engineers use custom actions within the Software Template scaffolding
    process to establish and track the dependency link between a generated entity
    (Component or Resource) and its source template. This relationship is called scaffolding
    provenance. Platform administrators use custom actions such as catalog:scaffolded-from
    and catalog:template:version in the scaffolder backend module to track the template
    version and the corresponding entity version, which simplifies lifecycle management.
    ### Configuring provenance and Software Template versioning Red Hat Developer
    Hub As a platform engineer, you must modify the Software Template YAML definition
    to ensure the required provenance information is added during the scaffolding
    process. You have administrator rights to Red Hat Developer Hub. 1. Locate the
    Software Template object YAML file where you want to add the provenance information
    and add a step that uses the catalog:scaffolded-from action. This action links
    the resulting catalog entity back to the source template. 2. Optional: To track
    the template version (for example, v1.0 versus v1.5), include the catalog:template:version
    action in the steps section. The following code block is an example to adding
    versioning action to the steps section: ```yaml steps: - id: create-provenance-annotation
    name: Append the entityRef of this template to the entityRef action: catalog:scaffolded-from
    - id: create-version-annotation name: Create Template Version Annotation action:
    catalog:template:version input: templateVersion: ${{ parameters.version }} - ...
    other steps ... ``` where: steps:input:templateVersion:: Reads the version parameter
    [NOTE] ---- The catalog:template:version action reads a version parameter defined
    in the template and applies it as an annotation to the resulting catalog entity.
    ---- 3. In your Red Hat Developer Hub app-config.yaml file, configure the catalog.locations
    section to point to the Software Template that you want to add. You might need
    to add Template to the global catalog.rules.allow list or add a granular rule
    to the location to allow for Software Templates ingestion, as shown in the following
    example: ```yaml # ... catalog: locations: type: url target: https://<repository_url>/example
    template.yaml rules: allow: [Template] # ... ``` where: catalog.locations.type::
    Enter the url type if you are importing templates from a repository, such as GitHub
    or GitLab. catalog.locations.target:: Enter the URL for the template. catalog.locations.rules.allow::
    Enter the Template'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:24:40.902700'
    uuid: e22df395-7664-4dbe-8d7d-520c21d2060a
  response: To enable notification alerts for template version updates in Red Hat
    Developer Hub, you can use the @backstage-community/plugin-catalog-backend-module-scaffolder-relation-processor
    module. This module, which is disabled by default, automatically notifies component
    owners when the Software Template used to generate their components is updated.
    This functionality relies on the spec.scaffoldedFrom field in catalog entities.
    Before you begin, you must have the Backstage backend notification plugin (@backstage/plugin
    notifications backend) and the frontend plugin (@backstage/plugin notifications)
    installed and configured. To enable the notifications, you must add specific codes
    to your Red Hat Developer Hub app-config.yaml file. First, in the dynamicPlugins:frontend
    section, add the configuration for backstage.plugin notifications. Second, in
    a new section, configure the scaffolder notifications by setting enabled to true.
    You can also customize the notification title and description, which support the
    template variable $ENTITY_DISPLAY_NAME. The system automatically substitutes this
    variable with the title of the entity scaffolded from the updated template.
  user_input: How to enable automatic notifications for software template version
    updates in Backstage for component owners using the scaffolder relation processor
    module and app-config.yaml
- context:
  - 'Versioning a Software Template in Red Hat Developer Hub As a platform administrator,
    you can version Software Templates by using the existing custom actions catalog:scaffolded-from
    and catalog:template:version within the scaffolder backend module. By using these
    custom actions, you can track the scaffolder template version and the corresponding
    version of the entities created from it, which improves lifecycle management.
    You have administrator rights to Red Hat Developer Hub. To add versioning to a
    Software Template yaml file, complete the following steps: 1. Modify the Software
    Template that you want to update. 2. Complete one or both of the following tasks:
    * Include the backstage.io/template-version annotation in your template. When
    this annotation is present in your template, it is automatically used to annotate
    your catalog entity and a default version value is displayed. * Pass the backstage.io/template-version
    annotation as input to the action. This method takes precedence over the annotation
    in the template itself. It allows the user running the template to specify the
    version they wish to generate. ```yaml # ... - id: version-templateRef name: Append
    the version of this template to the entityRef action: catalog:template:version
    input: annotations: backstage.io/template-version: ${{ parameters.version }} #
    ... ``` 1. Create a catalog component using the updated Software Template. This
    step creates a new component in Backstage and optionally, pushes files to an external
    repository (For example, GitHub, GitLab). 2. Check the component in the Catalog
    UI. 1. On the Catalog page, locate the newly created catalog component. 2. Verify
    that the backstage.io/template-version annotation is present in the entity. You
    can use INSPECT ENTITY and select YAML Raw or JSON Raw view to find the annotation
    in the component definition. 3. Only if you have published the catalog component:
    Check the component file in the repository. 1. If VIEW SOURCE is present in your
    UI: Click VIEW SOURCE to open the stored component file in the repository. 2.
    Locate the file manually and verify that the backstage.io/template-version annotation
    is present. ## Enabling Software Template version update notifications in Red
    Hat Developer Hub As a platform engineer, you can enable notification alerts for
    template version updates using the @backstage-community/plugin-catalog-backend-module-scaffolder-relation-processor
    module, an extension to the catalog-backend plugin. When enabled, this module
    automatically notifies component owners whenever the Software Template used to
    generate their components is updated to a new version. This functionality uses
    the spec.scaffoldedFrom field in catalog entities. This field links Software Templates
    to the entities they have scaffolded. By tracking this relationship, the module
    helps teams stay informed and take advantage of the latest improvements or fixes.
    The plugin-catalog-backend-module-scaffolder-relation-processor module is disabled
    by default. You have installed and configured the Backstage backend notification
    plugin @backstage/plugin notifications backend. You have installed and configured
    the Backstage frontend plugin @backstage/plugin notifications. 1. To enable the
    notifications, in your Red Hat Developer Hub app-config.yaml file, add the following
    codes: 1. In the dynamicPlugins:frontend section: ```yaml frontend: backstage.plugin
    notifications: dynamicRoutes: importName: NotificationPage menuItem: config: props:
    titleCounterEnabled: true webNotificationsEnabled: false importName: NotificationsSidebarItem
    path: /notifications ``` 2. In a new section: ```yaml scaffolder: notifications:
    templateUpdate: enabled: true # Set to false to disable notifications ``` You
    can also customize the notification title and description as shown in the following
    code: ```yaml scaffolder: notifications: templateUpdate: enabled: true message:
    title: ''Custom title for $ENTITY_DISPLAY_NAME'' description: ''Custom description''
    ``` where: enabled:: Set to true to enable the notification. Default value is
    false. message:title:: Enter the notification title. message:description:: Enter
    the notification description. [NOTE] ---- Both message:title and message:description
    support the template variable $ENTITY_DISPLAY_NAME. The system automatically substitutes
    this variable with the title (or the name, if the title is missing) of the entity
    scaffolded from the updated template. ---- In your Red Hat Developer Hub instance,
    on the left navigation menu, you are able to see Notifications, or, if configured,
    the custom title. When you update the version number in the Software Template,
    you receive a notification. ## Tracking Component origin and Software Template
    version Platform engineers use custom actions within the Software Template scaffolding
    process to establish and track the dependency link between a generated entity
    (Component or Resource) and its source template. This relationship is called scaffolding
    provenance. Platform administrators use custom actions such as catalog:scaffolded-from
    and catalog:template:version in the scaffolder backend module to track the template
    version and the corresponding entity version, which simplifies lifecycle management.
    ### Configuring provenance and Software Template versioning Red Hat Developer
    Hub As a platform engineer, you must modify the Software Template YAML definition
    to ensure the required provenance information is added during the scaffolding
    process. You have administrator rights to Red Hat Developer Hub. 1. Locate the
    Software Template object YAML file where you want to add the provenance information
    and add a step that uses the catalog:scaffolded-from action. This action links
    the resulting catalog entity back to the source template. 2. Optional: To track
    the template version (for example, v1.0 versus v1.5), include the catalog:template:version
    action in the steps section. The following code block is an example to adding
    versioning action to the steps section: ```yaml steps: - id: create-provenance-annotation
    name: Append the entityRef of this template to the entityRef action: catalog:scaffolded-from
    - id: create-version-annotation name: Create Template Version Annotation action:
    catalog:template:version input: templateVersion: ${{ parameters.version }} - ...
    other steps ... ``` where: steps:input:templateVersion:: Reads the version parameter
    [NOTE] ---- The catalog:template:version action reads a version parameter defined
    in the template and applies it as an annotation to the resulting catalog entity.
    ---- 3. In your Red Hat Developer Hub app-config.yaml file, configure the catalog.locations
    section to point to the Software Template that you want to add. You might need
    to add Template to the global catalog.rules.allow list or add a granular rule
    to the location to allow for Software Templates ingestion, as shown in the following
    example: ```yaml # ... catalog: locations: type: url target: https://<repository_url>/example
    template.yaml rules: allow: [Template] # ... ``` where: catalog.locations.type::
    Enter the url type if you are importing templates from a repository, such as GitHub
    or GitLab. catalog.locations.target:: Enter the URL for the template. catalog.locations.rules.allow::
    Enter the Template'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:24:50.789299'
    uuid: d9971fee-6889-4c65-ae65-218efd0a4ddc
  response: Platform administrators use the custom action catalog:template:version
    in the scaffolder backend module to track the template version and the corresponding
    version of the entities created from it, which simplifies and improves lifecycle
    management. The catalog:template:version action reads a version parameter defined
    in the template and applies it as an annotation to the resulting catalog entity.
  user_input: whats the purpuse of the catalog:template:version acshun?
- context:
  - 'Versioning a Software Template in Red Hat Developer Hub As a platform administrator,
    you can version Software Templates by using the existing custom actions catalog:scaffolded-from
    and catalog:template:version within the scaffolder backend module. By using these
    custom actions, you can track the scaffolder template version and the corresponding
    version of the entities created from it, which improves lifecycle management.
    You have administrator rights to Red Hat Developer Hub. To add versioning to a
    Software Template yaml file, complete the following steps: 1. Modify the Software
    Template that you want to update. 2. Complete one or both of the following tasks:
    * Include the backstage.io/template-version annotation in your template. When
    this annotation is present in your template, it is automatically used to annotate
    your catalog entity and a default version value is displayed. * Pass the backstage.io/template-version
    annotation as input to the action. This method takes precedence over the annotation
    in the template itself. It allows the user running the template to specify the
    version they wish to generate. ```yaml # ... - id: version-templateRef name: Append
    the version of this template to the entityRef action: catalog:template:version
    input: annotations: backstage.io/template-version: ${{ parameters.version }} #
    ... ``` 1. Create a catalog component using the updated Software Template. This
    step creates a new component in Backstage and optionally, pushes files to an external
    repository (For example, GitHub, GitLab). 2. Check the component in the Catalog
    UI. 1. On the Catalog page, locate the newly created catalog component. 2. Verify
    that the backstage.io/template-version annotation is present in the entity. You
    can use INSPECT ENTITY and select YAML Raw or JSON Raw view to find the annotation
    in the component definition. 3. Only if you have published the catalog component:
    Check the component file in the repository. 1. If VIEW SOURCE is present in your
    UI: Click VIEW SOURCE to open the stored component file in the repository. 2.
    Locate the file manually and verify that the backstage.io/template-version annotation
    is present. ## Enabling Software Template version update notifications in Red
    Hat Developer Hub As a platform engineer, you can enable notification alerts for
    template version updates using the @backstage-community/plugin-catalog-backend-module-scaffolder-relation-processor
    module, an extension to the catalog-backend plugin. When enabled, this module
    automatically notifies component owners whenever the Software Template used to
    generate their components is updated to a new version. This functionality uses
    the spec.scaffoldedFrom field in catalog entities. This field links Software Templates
    to the entities they have scaffolded. By tracking this relationship, the module
    helps teams stay informed and take advantage of the latest improvements or fixes.
    The plugin-catalog-backend-module-scaffolder-relation-processor module is disabled
    by default. You have installed and configured the Backstage backend notification
    plugin @backstage/plugin notifications backend. You have installed and configured
    the Backstage frontend plugin @backstage/plugin notifications. 1. To enable the
    notifications, in your Red Hat Developer Hub app-config.yaml file, add the following
    codes: 1. In the dynamicPlugins:frontend section: ```yaml frontend: backstage.plugin
    notifications: dynamicRoutes: importName: NotificationPage menuItem: config: props:
    titleCounterEnabled: true webNotificationsEnabled: false importName: NotificationsSidebarItem
    path: /notifications ``` 2. In a new section: ```yaml scaffolder: notifications:
    templateUpdate: enabled: true # Set to false to disable notifications ``` You
    can also customize the notification title and description as shown in the following
    code: ```yaml scaffolder: notifications: templateUpdate: enabled: true message:
    title: ''Custom title for $ENTITY_DISPLAY_NAME'' description: ''Custom description''
    ``` where: enabled:: Set to true to enable the notification. Default value is
    false. message:title:: Enter the notification title. message:description:: Enter
    the notification description. [NOTE] ---- Both message:title and message:description
    support the template variable $ENTITY_DISPLAY_NAME. The system automatically substitutes
    this variable with the title (or the name, if the title is missing) of the entity
    scaffolded from the updated template. ---- In your Red Hat Developer Hub instance,
    on the left navigation menu, you are able to see Notifications, or, if configured,
    the custom title. When you update the version number in the Software Template,
    you receive a notification. ## Tracking Component origin and Software Template
    version Platform engineers use custom actions within the Software Template scaffolding
    process to establish and track the dependency link between a generated entity
    (Component or Resource) and its source template. This relationship is called scaffolding
    provenance. Platform administrators use custom actions such as catalog:scaffolded-from
    and catalog:template:version in the scaffolder backend module to track the template
    version and the corresponding entity version, which simplifies lifecycle management.
    ### Configuring provenance and Software Template versioning Red Hat Developer
    Hub As a platform engineer, you must modify the Software Template YAML definition
    to ensure the required provenance information is added during the scaffolding
    process. You have administrator rights to Red Hat Developer Hub. 1. Locate the
    Software Template object YAML file where you want to add the provenance information
    and add a step that uses the catalog:scaffolded-from action. This action links
    the resulting catalog entity back to the source template. 2. Optional: To track
    the template version (for example, v1.0 versus v1.5), include the catalog:template:version
    action in the steps section. The following code block is an example to adding
    versioning action to the steps section: ```yaml steps: - id: create-provenance-annotation
    name: Append the entityRef of this template to the entityRef action: catalog:scaffolded-from
    - id: create-version-annotation name: Create Template Version Annotation action:
    catalog:template:version input: templateVersion: ${{ parameters.version }} - ...
    other steps ... ``` where: steps:input:templateVersion:: Reads the version parameter
    [NOTE] ---- The catalog:template:version action reads a version parameter defined
    in the template and applies it as an annotation to the resulting catalog entity.
    ---- 3. In your Red Hat Developer Hub app-config.yaml file, configure the catalog.locations
    section to point to the Software Template that you want to add. You might need
    to add Template to the global catalog.rules.allow list or add a granular rule
    to the location to allow for Software Templates ingestion, as shown in the following
    example: ```yaml # ... catalog: locations: type: url target: https://<repository_url>/example
    template.yaml rules: allow: [Template] # ... ``` where: catalog.locations.type::
    Enter the url type if you are importing templates from a repository, such as GitHub
    or GitLab. catalog.locations.target:: Enter the URL for the template. catalog.locations.rules.allow::
    Enter the Template'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:24:59.815943'
    uuid: eb40b090-6fa1-4a44-be01-be6217c49caf
  response: 'To version a Software Template, you can complete one or both of the following
    tasks: include the `backstage.io/template-version` annotation in your template,
    which is then automatically used to annotate your catalog entity, or pass the
    `backstage.io/template-version` annotation as input to the action, a method that
    takes precedence over the annotation in the template itself. To verify the annotation
    is present, you can check the component in the Catalog UI by locating the newly
    created component and using INSPECT ENTITY to select the YAML Raw or JSON Raw
    view. If you have published the component, you can also check the component file
    in the repository by clicking VIEW SOURCE or locating the file manually.'
  user_input: How can I use the backstage.io/template-version annotasion to version
    my software templaets, and what are the two diffrent ways to include it, and where
    can I go to verifiy that the annotasion is present on the new component I created?
- context:
  - '# Customizing Red Hat Developer Hub Authorized users can customize Red Hat Developer
    Hub (RHDH) appearance and features, such as templates, Learning Paths, Tech Radar,
    Home page, and quick access cards. # Customizing your Red Hat Developer Hub title
    You can change the default Red Hat Developer Hub display name. Custom Developer
    Hub configuration. In your custom app config.yaml file, enter your Developer Hub
    instance display name, such as <Red Hat Developer Hub>. app config.yaml excerpt
    ```yaml app: title: My custom Red Hat Developer Hub title ``` # Customizing your
    Red Hat Developer Hub base URL You can change the default Red Hat Developer Hub
    base URL. You know your desired Developer Hub external URL: https://<my_developer_hub_domain>,
    and have configured DNS to point to your Red Hat OpenShift Container Platform
    cluster. Custom Developer Hub configuration. In your custom app config.yaml file,
    enter your Developer Hub external URL, such as https://<my_developer_hub_domain>.
    app config.yaml excerpt ```yaml app: baseUrl: https://<my_developer_hub_domain>
    backend: baseUrl: https://<my_developer_hub_domain> cors: origin: https://<my_developer_hub_domain>
    ``` # Customizing Red Hat Developer Hub backend secret The default Red Hat Developer
    Hub configuration defines the Developer Hub backend secret for service to service
    authentication. You can define your custom Developer Hub backend secret. You added
    a custom Developer Hub application configuration, and have sufficient permissions
    to modify it. 1. To define the Developer Hub backend secret, add to your custom
    <my_product_secrets>.txt file the BACKEND_SECRET environment variable with a base64
    encoded string. Use a unique value for each Developer Hub instance. ```yaml $
    echo > <my_product_secrets>.txt "BACKEND_SECRET=$(node -p ''require("crypto").randomBytes(24).toString("base64")'')"
    ``` <my_product_secrets>.txt example ``` BACKEND_SECRET=3E2/rIPuZNFCtYHoxVP8wjriffnN1q/z
    ``` 2. Add your backend secret to your custom app-config.yaml file. app-config.yaml
    excerpt defining the backend secret ```yaml backend: auth: externalAccess: type:
    legacy options: subject: legacy default config secret: "${BACKEND_SECRET}" ```
    # About Software Templates Software Templates in Red Hat Developer Hub provide
    a streamlined way to create software components and publish them to different
    version control repositories such as Git. Platform engineers create and maintain
    Software Templates in Red Hat Developer Hub. ## rule to allow new Software Templates
    to be added to the catalog. After creating a component with the updated template,
    verify the provenance annotations in the resulting Catalog Entity YAML. 1. In
    the Red Hat Developer Hub navigation menu, go to Catalog and locate the newly
    created catalog component. 2. To view the underlying data that links the entity
    to the template, select the INSPECT ENTITY option. 3. To verify provenance annotations,
    complete the following steps: 1. Select the YAML Raw or JSON Raw view and verify
    the presence of the data item for the scaffoldedFrom link. 2. Optional: If versioning
    was included, verify the presence of the backstage.io/template-version annotation.
    [NOTE] ---- If you publish the catalog component to an external repository (such
    as Git), the component file in that repository must also contain the backstage.io/template-version
    annotation. ---- ### Viewing Software Template dependencies As a developer, you
    can track which entities were created from a specific Software Template. When
    a platform engineer configures provenance on a template, you can quickly identify
    the complete dependency and impact map of that template by viewing all linked
    components and resources in the Catalog. To view all components created from a
    specific template, complete the following steps: 1. In the Red Hat Developer Hub
    navigation menu, click Catalog, use the filters to find and select the Software
    Template you wish to inspect. 2. In the Software Template detail page, click the
    Dependencies tab. This view lists all catalog entities such as components, resources,
    and systems that reference this template, including any version information if
    configured. 10 tips for better Backstage Software Templates Enabling the GitHub
    authentication provider Backstage documentation Writing Templates Backstage documentation
    Built in actions Backstage documentation Writing Custom Actions # Customizing
    the Learning Paths in Red Hat Developer Hub In Red Hat Developer Hub, you can
    configure Learning Paths by hosting the required data externally, and using the
    built-in proxy to deliver this data rather than the default. You can provide Learning
    Paths data from the following sources: A JSON file hosted on a web server, such
    as GitHub or GitLab. A dedicated service that provides the Learning Paths data
    in JSON format using an API. ## About Learning Paths You can use the Learning
    Paths plugin in Red Hat Developer Hub to integrate customized e-learning content
    into the developer workflows. By using Learning Paths, you can create a collaborative
    learning culture, boost productivity, and ensure that teams stay updated with
    relevant best practices and technologies. The overall purpose is to accelerate
    onboarding, address skill gaps, ensure regulatory compliance, promote best practices,
    and facilitate product updates. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:25:09.630966'
    uuid: d4ca0078-5bf5-4356-8ebe-00d026526bf8
  response: In Red Hat Developer Hub, you can configure Learning Paths by hosting
    the required data externally. One of the sources you can use to provide this data
    is a JSON file hosted on a web server, such as GitLab.
  user_input: How can I use GitLab for Red Hat Developer Hub Learning Paths?
- context:
  - '# Customizing Red Hat Developer Hub Authorized users can customize Red Hat Developer
    Hub (RHDH) appearance and features, such as templates, Learning Paths, Tech Radar,
    Home page, and quick access cards. # Customizing your Red Hat Developer Hub title
    You can change the default Red Hat Developer Hub display name. Custom Developer
    Hub configuration. In your custom app config.yaml file, enter your Developer Hub
    instance display name, such as <Red Hat Developer Hub>. app config.yaml excerpt
    ```yaml app: title: My custom Red Hat Developer Hub title ``` # Customizing your
    Red Hat Developer Hub base URL You can change the default Red Hat Developer Hub
    base URL. You know your desired Developer Hub external URL: https://<my_developer_hub_domain>,
    and have configured DNS to point to your Red Hat OpenShift Container Platform
    cluster. Custom Developer Hub configuration. In your custom app config.yaml file,
    enter your Developer Hub external URL, such as https://<my_developer_hub_domain>.
    app config.yaml excerpt ```yaml app: baseUrl: https://<my_developer_hub_domain>
    backend: baseUrl: https://<my_developer_hub_domain> cors: origin: https://<my_developer_hub_domain>
    ``` # Customizing Red Hat Developer Hub backend secret The default Red Hat Developer
    Hub configuration defines the Developer Hub backend secret for service to service
    authentication. You can define your custom Developer Hub backend secret. You added
    a custom Developer Hub application configuration, and have sufficient permissions
    to modify it. 1. To define the Developer Hub backend secret, add to your custom
    <my_product_secrets>.txt file the BACKEND_SECRET environment variable with a base64
    encoded string. Use a unique value for each Developer Hub instance. ```yaml $
    echo > <my_product_secrets>.txt "BACKEND_SECRET=$(node -p ''require("crypto").randomBytes(24).toString("base64")'')"
    ``` <my_product_secrets>.txt example ``` BACKEND_SECRET=3E2/rIPuZNFCtYHoxVP8wjriffnN1q/z
    ``` 2. Add your backend secret to your custom app-config.yaml file. app-config.yaml
    excerpt defining the backend secret ```yaml backend: auth: externalAccess: type:
    legacy options: subject: legacy default config secret: "${BACKEND_SECRET}" ```
    # About Software Templates Software Templates in Red Hat Developer Hub provide
    a streamlined way to create software components and publish them to different
    version control repositories such as Git. Platform engineers create and maintain
    Software Templates in Red Hat Developer Hub. ## rule to allow new Software Templates
    to be added to the catalog. After creating a component with the updated template,
    verify the provenance annotations in the resulting Catalog Entity YAML. 1. In
    the Red Hat Developer Hub navigation menu, go to Catalog and locate the newly
    created catalog component. 2. To view the underlying data that links the entity
    to the template, select the INSPECT ENTITY option. 3. To verify provenance annotations,
    complete the following steps: 1. Select the YAML Raw or JSON Raw view and verify
    the presence of the data item for the scaffoldedFrom link. 2. Optional: If versioning
    was included, verify the presence of the backstage.io/template-version annotation.
    [NOTE] ---- If you publish the catalog component to an external repository (such
    as Git), the component file in that repository must also contain the backstage.io/template-version
    annotation. ---- ### Viewing Software Template dependencies As a developer, you
    can track which entities were created from a specific Software Template. When
    a platform engineer configures provenance on a template, you can quickly identify
    the complete dependency and impact map of that template by viewing all linked
    components and resources in the Catalog. To view all components created from a
    specific template, complete the following steps: 1. In the Red Hat Developer Hub
    navigation menu, click Catalog, use the filters to find and select the Software
    Template you wish to inspect. 2. In the Software Template detail page, click the
    Dependencies tab. This view lists all catalog entities such as components, resources,
    and systems that reference this template, including any version information if
    configured. 10 tips for better Backstage Software Templates Enabling the GitHub
    authentication provider Backstage documentation Writing Templates Backstage documentation
    Built in actions Backstage documentation Writing Custom Actions # Customizing
    the Learning Paths in Red Hat Developer Hub In Red Hat Developer Hub, you can
    configure Learning Paths by hosting the required data externally, and using the
    built-in proxy to deliver this data rather than the default. You can provide Learning
    Paths data from the following sources: A JSON file hosted on a web server, such
    as GitHub or GitLab. A dedicated service that provides the Learning Paths data
    in JSON format using an API. ## About Learning Paths You can use the Learning
    Paths plugin in Red Hat Developer Hub to integrate customized e-learning content
    into the developer workflows. By using Learning Paths, you can create a collaborative
    learning culture, boost productivity, and ensure that teams stay updated with
    relevant best practices and technologies. The overall purpose is to accelerate
    onboarding, address skill gaps, ensure regulatory compliance, promote best practices,
    and facilitate product updates. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:25:18.746215'
    uuid: c44997fb-97f1-479c-8739-ba93d80a8876
  response: In Red Hat Developer Hub, Software Templates provide a streamlined way
    to create software components and publish them to version control repositories
    like Git. Platform engineers are the ones who create and maintain these Software
    Templates. For developers, they can track which entities were created from a specific
    Software Template. When a platform engineer configures provenance on a template,
    it allows for the quick identification of the complete dependency and impact map
    of that template by viewing all linked components and resources in the Catalog.
  user_input: So I am the platform engineer and I am looking at this Red Hat Developer
    Hub and I see the thing about Software Templates, but I dont really get it, what
    is they for and why do I have to create and maintain them, what is the point for
    my developers using them?
- context:
  - '# Customizing Red Hat Developer Hub Authorized users can customize Red Hat Developer
    Hub (RHDH) appearance and features, such as templates, Learning Paths, Tech Radar,
    Home page, and quick access cards. # Customizing your Red Hat Developer Hub title
    You can change the default Red Hat Developer Hub display name. Custom Developer
    Hub configuration. In your custom app config.yaml file, enter your Developer Hub
    instance display name, such as <Red Hat Developer Hub>. app config.yaml excerpt
    ```yaml app: title: My custom Red Hat Developer Hub title ``` # Customizing your
    Red Hat Developer Hub base URL You can change the default Red Hat Developer Hub
    base URL. You know your desired Developer Hub external URL: https://<my_developer_hub_domain>,
    and have configured DNS to point to your Red Hat OpenShift Container Platform
    cluster. Custom Developer Hub configuration. In your custom app config.yaml file,
    enter your Developer Hub external URL, such as https://<my_developer_hub_domain>.
    app config.yaml excerpt ```yaml app: baseUrl: https://<my_developer_hub_domain>
    backend: baseUrl: https://<my_developer_hub_domain> cors: origin: https://<my_developer_hub_domain>
    ``` # Customizing Red Hat Developer Hub backend secret The default Red Hat Developer
    Hub configuration defines the Developer Hub backend secret for service to service
    authentication. You can define your custom Developer Hub backend secret. You added
    a custom Developer Hub application configuration, and have sufficient permissions
    to modify it. 1. To define the Developer Hub backend secret, add to your custom
    <my_product_secrets>.txt file the BACKEND_SECRET environment variable with a base64
    encoded string. Use a unique value for each Developer Hub instance. ```yaml $
    echo > <my_product_secrets>.txt "BACKEND_SECRET=$(node -p ''require("crypto").randomBytes(24).toString("base64")'')"
    ``` <my_product_secrets>.txt example ``` BACKEND_SECRET=3E2/rIPuZNFCtYHoxVP8wjriffnN1q/z
    ``` 2. Add your backend secret to your custom app-config.yaml file. app-config.yaml
    excerpt defining the backend secret ```yaml backend: auth: externalAccess: type:
    legacy options: subject: legacy default config secret: "${BACKEND_SECRET}" ```
    # About Software Templates Software Templates in Red Hat Developer Hub provide
    a streamlined way to create software components and publish them to different
    version control repositories such as Git. Platform engineers create and maintain
    Software Templates in Red Hat Developer Hub. ## rule to allow new Software Templates
    to be added to the catalog. After creating a component with the updated template,
    verify the provenance annotations in the resulting Catalog Entity YAML. 1. In
    the Red Hat Developer Hub navigation menu, go to Catalog and locate the newly
    created catalog component. 2. To view the underlying data that links the entity
    to the template, select the INSPECT ENTITY option. 3. To verify provenance annotations,
    complete the following steps: 1. Select the YAML Raw or JSON Raw view and verify
    the presence of the data item for the scaffoldedFrom link. 2. Optional: If versioning
    was included, verify the presence of the backstage.io/template-version annotation.
    [NOTE] ---- If you publish the catalog component to an external repository (such
    as Git), the component file in that repository must also contain the backstage.io/template-version
    annotation. ---- ### Viewing Software Template dependencies As a developer, you
    can track which entities were created from a specific Software Template. When
    a platform engineer configures provenance on a template, you can quickly identify
    the complete dependency and impact map of that template by viewing all linked
    components and resources in the Catalog. To view all components created from a
    specific template, complete the following steps: 1. In the Red Hat Developer Hub
    navigation menu, click Catalog, use the filters to find and select the Software
    Template you wish to inspect. 2. In the Software Template detail page, click the
    Dependencies tab. This view lists all catalog entities such as components, resources,
    and systems that reference this template, including any version information if
    configured. 10 tips for better Backstage Software Templates Enabling the GitHub
    authentication provider Backstage documentation Writing Templates Backstage documentation
    Built in actions Backstage documentation Writing Custom Actions # Customizing
    the Learning Paths in Red Hat Developer Hub In Red Hat Developer Hub, you can
    configure Learning Paths by hosting the required data externally, and using the
    built-in proxy to deliver this data rather than the default. You can provide Learning
    Paths data from the following sources: A JSON file hosted on a web server, such
    as GitHub or GitLab. A dedicated service that provides the Learning Paths data
    in JSON format using an API. ## About Learning Paths You can use the Learning
    Paths plugin in Red Hat Developer Hub to integrate customized e-learning content
    into the developer workflows. By using Learning Paths, you can create a collaborative
    learning culture, boost productivity, and ensure that teams stay updated with
    relevant best practices and technologies. The overall purpose is to accelerate
    onboarding, address skill gaps, ensure regulatory compliance, promote best practices,
    and facilitate product updates. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:25:29.097110'
    uuid: 46100c0a-15e8-479f-b6a4-ab531c980e43
  response: 'To customize the Red Hat Developer Hub, you can change the display name
    by entering your desired title in your custom app config.yaml file under `app:
    title:`. The base URL can be changed by entering your external URL in the same
    custom app config.yaml file under `app: baseUrl`, `backend: baseUrl`, and `cors:
    origin`. To customize the backend secret, you first define the `BACKEND_SECRET`
    environment variable with a base64 encoded string in your custom `<my_product_secrets>.txt`
    file. After that, you add your backend secret to your custom app-config.yaml file
    under `backend: auth: externalAccess:`, setting the secret to `"${BACKEND_SECRET}"`.'
  user_input: As a platform lead, how do I perform initial setup and customization
    for Red Hat Developer Hub, specifically changing the display title, base URL,
    and backend secret?
- context:
  - 'Customizing the Learning Paths by using a hosted JSON file For ease of use and
    simplicity, you can configure the Learning Paths by using a hosted JSON file.
    1. Publish the JSON file containing your Learning Paths data to a web server,
    such as GitHub or Gitlab. You can find an example at https://raw.githubusercontent.com/redhat-developer/rhdh/release-1.8/packages/app/public/learning-paths/data.json.
    2. Configure the Developer Hub proxy to access the Learning Paths data from the
    hosted JSON file, by adding the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub'': target: <target> pathRewrite: ''^/api/proxy/developer
    hub/learning paths'': ''<learning_path.json>'' changeOrigin: true secure: true
    ``` <target>:: Enter the hosted JSON file base URL, such as https://raw.githubusercontent.com.
    <learning_path.json>:: Enter the hosted JSON file path without the base URL, such
    as ''/redhat-developer/rhdh/main/packages/app/public/learning-paths/data.json''
    [TIP] ---- When also configuring the home page, due to the use of overlapping
    pathRewrites for both the learning-path and homepage quick access proxies, create
    the learning-paths configuration (^api/proxy/developer-hub/learning-paths) before
    you create the homepage configuration (^/api/proxy/developer-hub). For example:
    ```yaml proxy: endpoints: ''/developer hub'': target: https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer hub/learning paths'': ''/redhat developer/rhdh/main/packages/app/public/learning
    paths/data.json'' ''^/api/proxy/developer hub/tech radar'': ''/redhat developer/rhdh/main/packages/app/public/tech
    radar/data default.json'' ''^/api/proxy/developer hub'': ''/redhat developer/rhdh/main/packages/app/public/homepage/data.json''
    changeOrigin: true secure: true ``` ---- Customizing the Home page in Red Hat
    Developer Hub ## Customizing the Learning Paths by using a customization service
    For advanced scenarios, you can host your Red Hat Developer Hub customization
    service to provide data to all configurable Developer Hub pages, such as the Learning
    Paths. You can even use a different service for each page. 1. Deploy your Developer
    Hub customization service on the same OpenShift Container Platform cluster as
    your Developer Hub instance. You can find an example at red-hat-developer-hub-customization-provider,
    that provides the same data as default Developer Hub data. The customization service
    provides a Learning Paths data URL such as: http://<rhdh-customization-provider>/learning-paths.
    2. Configure the Developer Hub proxy to use your dedicated service to provide
    the Learning Path data, add the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub/learning paths'': target: <learning_path_data_url>
    changeOrigin: true qsecure: true 1 ``` Change to "false" in case of using self
    hosted cluster with a self-signed certificate ## Starting and completing lessons
    in Learning Paths As a developer, you can start a course and complete the lessons
    at your own pace. 1. You can log in to developers.redhat.com 2. Your platform
    engineer has granted you access to the Learning Paths plugin. To start a course
    in Learning Paths, complete the following steps: 1. In your Red Hat Developer
    Hub navigation menu, click Learning Paths. 2. Select the tile for the course you
    would like to begin. [NOTE] ---- This action redirects you to the main page of
    the course in the Red Hat Developers site. ---- # Configuring the global header
    in Red Hat Developer Hub As an administrator, you can configure the Red Hat Developer
    Hub global header to create a consistent and flexible navigation bar across your
    Developer Hub instance. By default, the Developer Hub global header includes the
    following components: Self service button provides quick access to a variety of
    templates, enabling users to efficiently set up services, backend and front end
    plugins within Developer Hub Support button that can link an internal or external
    support page Notifications button displays alerts and updates from plugins and
    external services Search input field allows users to find services, components,
    documentation, and other resources within Developer Hub Plugin extension capabilities
    provide a preinstalled and enabled catalog of available plugins in Developer Hub
    User profile drop down menu provides access to profile settings, appearance customization,
    Developer Hub metadata, and a logout button ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:25:44.858552'
    uuid: 5f4501de-c1ae-4412-b50a-c6663fbc77a2
  response: When using a customization service for advanced scenarios to provide data
    for pages like the Learning Paths, you must deploy your Developer Hub customization
    service on the same OpenShift Container Platform cluster as your Developer Hub
    instance.
  user_input: I'm tryin to set up a customizaton service for the Learning Paths in
    Developer Hub, what are the specific deployment requirments for doing this on
    our OpenShift Container Platform cluster?
- context:
  - 'Customizing the Learning Paths by using a hosted JSON file For ease of use and
    simplicity, you can configure the Learning Paths by using a hosted JSON file.
    1. Publish the JSON file containing your Learning Paths data to a web server,
    such as GitHub or Gitlab. You can find an example at https://raw.githubusercontent.com/redhat-developer/rhdh/release-1.8/packages/app/public/learning-paths/data.json.
    2. Configure the Developer Hub proxy to access the Learning Paths data from the
    hosted JSON file, by adding the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub'': target: <target> pathRewrite: ''^/api/proxy/developer
    hub/learning paths'': ''<learning_path.json>'' changeOrigin: true secure: true
    ``` <target>:: Enter the hosted JSON file base URL, such as https://raw.githubusercontent.com.
    <learning_path.json>:: Enter the hosted JSON file path without the base URL, such
    as ''/redhat-developer/rhdh/main/packages/app/public/learning-paths/data.json''
    [TIP] ---- When also configuring the home page, due to the use of overlapping
    pathRewrites for both the learning-path and homepage quick access proxies, create
    the learning-paths configuration (^api/proxy/developer-hub/learning-paths) before
    you create the homepage configuration (^/api/proxy/developer-hub). For example:
    ```yaml proxy: endpoints: ''/developer hub'': target: https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer hub/learning paths'': ''/redhat developer/rhdh/main/packages/app/public/learning
    paths/data.json'' ''^/api/proxy/developer hub/tech radar'': ''/redhat developer/rhdh/main/packages/app/public/tech
    radar/data default.json'' ''^/api/proxy/developer hub'': ''/redhat developer/rhdh/main/packages/app/public/homepage/data.json''
    changeOrigin: true secure: true ``` ---- Customizing the Home page in Red Hat
    Developer Hub ## Customizing the Learning Paths by using a customization service
    For advanced scenarios, you can host your Red Hat Developer Hub customization
    service to provide data to all configurable Developer Hub pages, such as the Learning
    Paths. You can even use a different service for each page. 1. Deploy your Developer
    Hub customization service on the same OpenShift Container Platform cluster as
    your Developer Hub instance. You can find an example at red-hat-developer-hub-customization-provider,
    that provides the same data as default Developer Hub data. The customization service
    provides a Learning Paths data URL such as: http://<rhdh-customization-provider>/learning-paths.
    2. Configure the Developer Hub proxy to use your dedicated service to provide
    the Learning Path data, add the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub/learning paths'': target: <learning_path_data_url>
    changeOrigin: true qsecure: true 1 ``` Change to "false" in case of using self
    hosted cluster with a self-signed certificate ## Starting and completing lessons
    in Learning Paths As a developer, you can start a course and complete the lessons
    at your own pace. 1. You can log in to developers.redhat.com 2. Your platform
    engineer has granted you access to the Learning Paths plugin. To start a course
    in Learning Paths, complete the following steps: 1. In your Red Hat Developer
    Hub navigation menu, click Learning Paths. 2. Select the tile for the course you
    would like to begin. [NOTE] ---- This action redirects you to the main page of
    the course in the Red Hat Developers site. ---- # Configuring the global header
    in Red Hat Developer Hub As an administrator, you can configure the Red Hat Developer
    Hub global header to create a consistent and flexible navigation bar across your
    Developer Hub instance. By default, the Developer Hub global header includes the
    following components: Self service button provides quick access to a variety of
    templates, enabling users to efficiently set up services, backend and front end
    plugins within Developer Hub Support button that can link an internal or external
    support page Notifications button displays alerts and updates from plugins and
    external services Search input field allows users to find services, components,
    documentation, and other resources within Developer Hub Plugin extension capabilities
    provide a preinstalled and enabled catalog of available plugins in Developer Hub
    User profile drop down menu provides access to profile settings, appearance customization,
    Developer Hub metadata, and a logout button ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:25:54.112956'
    uuid: b2a6a5b1-276b-4367-b0c8-bbac3c8a6909
  response: There are two methods for customizing Learning Paths. For ease of use
    and simplicity, you can configure them using a hosted JSON file by publishing
    the file to a web server and configuring the Developer Hub proxy in the app-config.yaml
    file to access it. For advanced scenarios, you can use a customization service
    by deploying your Red Hat Developer Hub customization service on the same OpenShift
    Container Platform cluster as your Developer Hub instance and configuring the
    proxy to use your dedicated service to provide the Learning Path data.
  user_input: What methods are available for customizing the Learning Paths?
- context:
  - 'Customizing the Learning Paths by using a hosted JSON file For ease of use and
    simplicity, you can configure the Learning Paths by using a hosted JSON file.
    1. Publish the JSON file containing your Learning Paths data to a web server,
    such as GitHub or Gitlab. You can find an example at https://raw.githubusercontent.com/redhat-developer/rhdh/release-1.8/packages/app/public/learning-paths/data.json.
    2. Configure the Developer Hub proxy to access the Learning Paths data from the
    hosted JSON file, by adding the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub'': target: <target> pathRewrite: ''^/api/proxy/developer
    hub/learning paths'': ''<learning_path.json>'' changeOrigin: true secure: true
    ``` <target>:: Enter the hosted JSON file base URL, such as https://raw.githubusercontent.com.
    <learning_path.json>:: Enter the hosted JSON file path without the base URL, such
    as ''/redhat-developer/rhdh/main/packages/app/public/learning-paths/data.json''
    [TIP] ---- When also configuring the home page, due to the use of overlapping
    pathRewrites for both the learning-path and homepage quick access proxies, create
    the learning-paths configuration (^api/proxy/developer-hub/learning-paths) before
    you create the homepage configuration (^/api/proxy/developer-hub). For example:
    ```yaml proxy: endpoints: ''/developer hub'': target: https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer hub/learning paths'': ''/redhat developer/rhdh/main/packages/app/public/learning
    paths/data.json'' ''^/api/proxy/developer hub/tech radar'': ''/redhat developer/rhdh/main/packages/app/public/tech
    radar/data default.json'' ''^/api/proxy/developer hub'': ''/redhat developer/rhdh/main/packages/app/public/homepage/data.json''
    changeOrigin: true secure: true ``` ---- Customizing the Home page in Red Hat
    Developer Hub ## Customizing the Learning Paths by using a customization service
    For advanced scenarios, you can host your Red Hat Developer Hub customization
    service to provide data to all configurable Developer Hub pages, such as the Learning
    Paths. You can even use a different service for each page. 1. Deploy your Developer
    Hub customization service on the same OpenShift Container Platform cluster as
    your Developer Hub instance. You can find an example at red-hat-developer-hub-customization-provider,
    that provides the same data as default Developer Hub data. The customization service
    provides a Learning Paths data URL such as: http://<rhdh-customization-provider>/learning-paths.
    2. Configure the Developer Hub proxy to use your dedicated service to provide
    the Learning Path data, add the following to the app-config.yaml file: ```yaml
    proxy: endpoints: ''/developer hub/learning paths'': target: <learning_path_data_url>
    changeOrigin: true qsecure: true 1 ``` Change to "false" in case of using self
    hosted cluster with a self-signed certificate ## Starting and completing lessons
    in Learning Paths As a developer, you can start a course and complete the lessons
    at your own pace. 1. You can log in to developers.redhat.com 2. Your platform
    engineer has granted you access to the Learning Paths plugin. To start a course
    in Learning Paths, complete the following steps: 1. In your Red Hat Developer
    Hub navigation menu, click Learning Paths. 2. Select the tile for the course you
    would like to begin. [NOTE] ---- This action redirects you to the main page of
    the course in the Red Hat Developers site. ---- # Configuring the global header
    in Red Hat Developer Hub As an administrator, you can configure the Red Hat Developer
    Hub global header to create a consistent and flexible navigation bar across your
    Developer Hub instance. By default, the Developer Hub global header includes the
    following components: Self service button provides quick access to a variety of
    templates, enabling users to efficiently set up services, backend and front end
    plugins within Developer Hub Support button that can link an internal or external
    support page Notifications button displays alerts and updates from plugins and
    external services Search input field allows users to find services, components,
    documentation, and other resources within Developer Hub Plugin extension capabilities
    provide a preinstalled and enabled catalog of available plugins in Developer Hub
    User profile drop down menu provides access to profile settings, appearance customization,
    Developer Hub metadata, and a logout button ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:26:01.831404'
    uuid: d5640023-2aae-4c3b-9307-52f8571810a0
  response: 'To configure the Developer Hub proxy to access Learning Paths data from
    a hosted JSON file, you must add a proxy endpoint to the app-config.yaml file
    with the following structure: `proxy: endpoints: ''/developer hub'': target: <target>
    pathRewrite: ''^/api/proxy/developer hub/learning paths'': ''<learning_path.json>''
    changeOrigin: true secure: true`. In this configuration, `<target>` should be
    the base URL of the hosted JSON file, such as https://raw.githubusercontent.com,
    and `<learning_path.json>` is the path to the file without the base URL, for example,
    ''/redhat-developer/rhdh/main/packages/app/public/learning-paths/data.json''.
    When also configuring the home page, the learning-paths configuration should be
    created before the homepage configuration due to overlapping pathRewrites.'
  user_input: How do I configure the proxy in the app-config.yaml file to use a hosted
    JSON file for Learning Paths?
- context:
  - 'Customizing your Red Hat Developer Hub global header You can use the red-hat-developer-hub.backstage-plugin-global-header
    dynamic plugin to extend the global header with additional buttons and customize
    the order and position of icons and features. Additionally, you can create and
    integrate your custom dynamic header plugins using the mount points provided by
    this new header feature, allowing you to further tailor to suit your needs. For
    more information about enabling dynamic plugins, see Installing and viewing plugins
    in Red Hat Developer Hub. ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-header
    disabled: false pluginConfig: app: sidebar: search: false settings: false dynamicPlugins:
    frontend: default.main-menu-items: menuItems: default.create: title: '''' red-hat-developer-hub.backstage-plugin-global-header:
    # the default enabled dynamic header plugin mountPoints: - mountPoint: application/header
    importName: GlobalHeader config: position: above-main-content 4 - mountPoint:
    global.header/component importName: SearchComponent config: priority: 100 - mountPoint:
    global.header/component importName: Spacer config: priority: 99 props: growFactor:
    0 - mountPoint: global.header/component importName: HeaderIconButton config: priority:
    90 props: title: Self-service icon: add to: create - mountPoint: global.header/component
    importName: SupportButton config: priority: 80 - mountPoint: global.header/component
    importName: NotificationButton config: priority: 70 - mountPoint: global.header/component
    importName: Divider config: priority: 50 - mountPoint: global.header/component
    importName: ProfileDropdown config: priority: 10 - mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts - mountPoint: global.header/profile importName: LogoutButton
    config: priority: 10 ``` where: search:: Enter false to hide the Search modal
    in the sidebar menu. Enter true to display the Search modal in the sidebar menu.
    settings:: Enter false to hides the Settings button in the sidebar menu. Enter
    true to display the Settings button in the sidebar menu. default.main-menu-items::
    Enter this field to hide the Self-service button from the sidebar menu. Remove
    this field to display the Self-service button in the sidebar menu. position::
    Enter above-main-content to position the header above the main content. Enter
    above-sidebar to position the header above the sidebar. To extend the functionality
    of the default global header, include any of the following attributes in your
    global header entry: mountPoint:: Specifies the location of the header. Use application/header
    to specify it as a global header. You can configure several global headers at
    different positions by adding entries to the mountPoints field. importName:: Specifies
    the component exported by the global header plugin. The red-hat-developer-hub.backstage-plugin-global-header
    package (enabled by default) offers the following header components as possible
    mount point values: * SearchComponent: Adds a search bar (enabled by default).
    * Spacer: Adds spacing in the header to position buttons at the end. Useful when
    you disable SearchComponent. * HeaderIconButton: Adds an icon button. By default,
    the Self-service icon button remains enabled. * SupportButton: Adds a Support
    icon button, allowing users to configure a link to an internal or external page.
    Enabled by default but requires additional configuration to display. * NotificationButton:
    Adds a Notifications icon button to display unread notifications in real time
    and navigate to the Notifications page. Enabled by default (requires the notifications
    plugin). * Divider: Adds a vertical divider. By default, a divider appears between
    the profile dropdown and other header components. * ProfileDropdown: Adds a profile
    dropdown showing the logged-in user''s name. By default, it contains two menu
    items. * MenuItemLink: Adds a link item in a dropdown menu. By default, the profile
    dropdown includes a link to the Settings page. * LogoutButton: Adds a logout button
    in the profile dropdown (enabled by default). * CreateDropdown: Adds a Self-service
    dropdown button (disabled by default). The menu items are configurable. * SoftwareTemplatesSection:
    Adds a list of software template links to the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. * RegisterAComponentSection: Adds
    a link to the Register a Component page in the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. config.position:: Specifies the position
    of the header. Supported values are above-main-content and above-sidebar. You
    must configure the support URL in the app config.yaml file to display the Support
    button in the header. You must install the notifications plugin to display the
    Notifications button in the header. 1. Copy the default configuration and modify
    the field values to suit your needs. You can adjust the priority value of each
    header component to control its position. Additionally, you can enable or disable
    components by adding or removing them from the configuration. To ensure that the
    remaining header buttons align with the end of the header before the profile dropdown
    button, set config.props.growFactor to 1 in the Spacer mount point to enable the
    Spacer component. For example: ```yaml mountPoint: global.header/component importName:
    Spacer config: priority: 100 props: growFactor: 1 ``` 2. To use your custom header,
    you must install it as a dynamic plugin by adding your plugin configuration to
    your app-config-dynamic.yaml file. For example: ```yaml package: <npm_or_oci_package
    reference> disabled: false pluginConfig: dynamicPlugins: frontend: <package_name>:
    mountPoints: mountPoint: application/header importName: <application_header_name>
    config: position: above main content mountPoint: global.header/component importName:
    <header_component_name> config: priority: 100 mountPoint: global.header/component
    importName: <header_component_name> config: priority: 90 ``` where: <npm_or_oci_package-reference>::
    Specifies the package name. <application_header_name>:: Specifies the name of
    the application header. For example: MyHeader <header_component_name>:: Specifies
    the name of the header component. For example: MyHeaderComponent [NOTE] ---- importName
    is an optional name referencing the value returned by the scaffolder field extension
    API. ---- 3. Optional: To disable the global header, set the value of the disabled
    field to true in your dynamic-plugins.yaml file. For example: ```yaml package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header disabled:
    true ``` ## Mount points for dynamic plugin integration You can customize the
    application header in Developer Hub using mount points for dynamic plugins. These
    mount points give flexibility in configuring the position of the header, its components
    and dropdown menus. You can create a customized experience with the following
    enhancements: application/header:: Controls the header position. Use config.position
    to set placement as either above-main-content or above-sidebar. global.header/component::
    Configures header components. Use config.priority to set the order of components,
    and pass properties (including CSS styles) via config.props. Self-service button::
    ```yaml mountPoint: global.header/component importName: HeaderIconButton config:
    priority: 80 props: title: Self service icon: add to: create ``` Spacer element::
    ```yaml mountPoint: global.header/component importName: Spacer config: priority:
    99 props: growFactor: 0 ```'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:26:09.051628'
    uuid: 9f5f8be6-c10a-4e3a-9f96-9399f9cbd883
  response: The SupportButton adds a Support icon button, allowing users to configure
    a link to an internal or external page. It is enabled by default but requires
    additional configuration to display. To make the Support button appear in the
    header, you must configure the support URL in the app config.yaml file.
  user_input: How do I get the SupportButton to actually show up in the Red Hat Developer
    Hub header?
- context:
  - 'Customizing your Red Hat Developer Hub global header You can use the red-hat-developer-hub.backstage-plugin-global-header
    dynamic plugin to extend the global header with additional buttons and customize
    the order and position of icons and features. Additionally, you can create and
    integrate your custom dynamic header plugins using the mount points provided by
    this new header feature, allowing you to further tailor to suit your needs. For
    more information about enabling dynamic plugins, see Installing and viewing plugins
    in Red Hat Developer Hub. ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-header
    disabled: false pluginConfig: app: sidebar: search: false settings: false dynamicPlugins:
    frontend: default.main-menu-items: menuItems: default.create: title: '''' red-hat-developer-hub.backstage-plugin-global-header:
    # the default enabled dynamic header plugin mountPoints: - mountPoint: application/header
    importName: GlobalHeader config: position: above-main-content 4 - mountPoint:
    global.header/component importName: SearchComponent config: priority: 100 - mountPoint:
    global.header/component importName: Spacer config: priority: 99 props: growFactor:
    0 - mountPoint: global.header/component importName: HeaderIconButton config: priority:
    90 props: title: Self-service icon: add to: create - mountPoint: global.header/component
    importName: SupportButton config: priority: 80 - mountPoint: global.header/component
    importName: NotificationButton config: priority: 70 - mountPoint: global.header/component
    importName: Divider config: priority: 50 - mountPoint: global.header/component
    importName: ProfileDropdown config: priority: 10 - mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts - mountPoint: global.header/profile importName: LogoutButton
    config: priority: 10 ``` where: search:: Enter false to hide the Search modal
    in the sidebar menu. Enter true to display the Search modal in the sidebar menu.
    settings:: Enter false to hides the Settings button in the sidebar menu. Enter
    true to display the Settings button in the sidebar menu. default.main-menu-items::
    Enter this field to hide the Self-service button from the sidebar menu. Remove
    this field to display the Self-service button in the sidebar menu. position::
    Enter above-main-content to position the header above the main content. Enter
    above-sidebar to position the header above the sidebar. To extend the functionality
    of the default global header, include any of the following attributes in your
    global header entry: mountPoint:: Specifies the location of the header. Use application/header
    to specify it as a global header. You can configure several global headers at
    different positions by adding entries to the mountPoints field. importName:: Specifies
    the component exported by the global header plugin. The red-hat-developer-hub.backstage-plugin-global-header
    package (enabled by default) offers the following header components as possible
    mount point values: * SearchComponent: Adds a search bar (enabled by default).
    * Spacer: Adds spacing in the header to position buttons at the end. Useful when
    you disable SearchComponent. * HeaderIconButton: Adds an icon button. By default,
    the Self-service icon button remains enabled. * SupportButton: Adds a Support
    icon button, allowing users to configure a link to an internal or external page.
    Enabled by default but requires additional configuration to display. * NotificationButton:
    Adds a Notifications icon button to display unread notifications in real time
    and navigate to the Notifications page. Enabled by default (requires the notifications
    plugin). * Divider: Adds a vertical divider. By default, a divider appears between
    the profile dropdown and other header components. * ProfileDropdown: Adds a profile
    dropdown showing the logged-in user''s name. By default, it contains two menu
    items. * MenuItemLink: Adds a link item in a dropdown menu. By default, the profile
    dropdown includes a link to the Settings page. * LogoutButton: Adds a logout button
    in the profile dropdown (enabled by default). * CreateDropdown: Adds a Self-service
    dropdown button (disabled by default). The menu items are configurable. * SoftwareTemplatesSection:
    Adds a list of software template links to the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. * RegisterAComponentSection: Adds
    a link to the Register a Component page in the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. config.position:: Specifies the position
    of the header. Supported values are above-main-content and above-sidebar. You
    must configure the support URL in the app config.yaml file to display the Support
    button in the header. You must install the notifications plugin to display the
    Notifications button in the header. 1. Copy the default configuration and modify
    the field values to suit your needs. You can adjust the priority value of each
    header component to control its position. Additionally, you can enable or disable
    components by adding or removing them from the configuration. To ensure that the
    remaining header buttons align with the end of the header before the profile dropdown
    button, set config.props.growFactor to 1 in the Spacer mount point to enable the
    Spacer component. For example: ```yaml mountPoint: global.header/component importName:
    Spacer config: priority: 100 props: growFactor: 1 ``` 2. To use your custom header,
    you must install it as a dynamic plugin by adding your plugin configuration to
    your app-config-dynamic.yaml file. For example: ```yaml package: <npm_or_oci_package
    reference> disabled: false pluginConfig: dynamicPlugins: frontend: <package_name>:
    mountPoints: mountPoint: application/header importName: <application_header_name>
    config: position: above main content mountPoint: global.header/component importName:
    <header_component_name> config: priority: 100 mountPoint: global.header/component
    importName: <header_component_name> config: priority: 90 ``` where: <npm_or_oci_package-reference>::
    Specifies the package name. <application_header_name>:: Specifies the name of
    the application header. For example: MyHeader <header_component_name>:: Specifies
    the name of the header component. For example: MyHeaderComponent [NOTE] ---- importName
    is an optional name referencing the value returned by the scaffolder field extension
    API. ---- 3. Optional: To disable the global header, set the value of the disabled
    field to true in your dynamic-plugins.yaml file. For example: ```yaml package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header disabled:
    true ``` ## Mount points for dynamic plugin integration You can customize the
    application header in Developer Hub using mount points for dynamic plugins. These
    mount points give flexibility in configuring the position of the header, its components
    and dropdown menus. You can create a customized experience with the following
    enhancements: application/header:: Controls the header position. Use config.position
    to set placement as either above-main-content or above-sidebar. global.header/component::
    Configures header components. Use config.priority to set the order of components,
    and pass properties (including CSS styles) via config.props. Self-service button::
    ```yaml mountPoint: global.header/component importName: HeaderIconButton config:
    priority: 80 props: title: Self service icon: add to: create ``` Spacer element::
    ```yaml mountPoint: global.header/component importName: Spacer config: priority:
    99 props: growFactor: 0 ```'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:26:17.799056'
    uuid: 4031cb01-05dd-4557-844b-9a6e28b33616
  response: 'The red-hat-developer-hub.backstage-plugin-global-header package offers
    the following header components as possible mount point values for importName:
    SearchComponent, which adds a search bar; Spacer, which adds spacing in the header;
    HeaderIconButton, which adds an icon button; SupportButton, which adds a Support
    icon button; NotificationButton, which adds a Notifications icon button; Divider,
    which adds a vertical divider; ProfileDropdown, which adds a profile dropdown
    for the logged-in user; MenuItemLink, which adds a link item in a dropdown menu;
    LogoutButton, which adds a logout button in the profile dropdown; CreateDropdown,
    which adds a Self-service dropdown button; SoftwareTemplatesSection, which adds
    a list of software template links to the Self-service dropdown menu; and RegisterAComponentSection,
    which adds a link to the Register a Component page in the Self-service dropdown
    menu.'
  user_input: i need to customize the GlobalHeader but im not sure what all the options
    are, like for the mountPoint global.header/component what are all the possible
    values for importName that the red-hat-developer-hub.backstage-plugin-global-header
    package gives me?
- context:
  - 'Customizing your Red Hat Developer Hub global header You can use the red-hat-developer-hub.backstage-plugin-global-header
    dynamic plugin to extend the global header with additional buttons and customize
    the order and position of icons and features. Additionally, you can create and
    integrate your custom dynamic header plugins using the mount points provided by
    this new header feature, allowing you to further tailor to suit your needs. For
    more information about enabling dynamic plugins, see Installing and viewing plugins
    in Red Hat Developer Hub. ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-header
    disabled: false pluginConfig: app: sidebar: search: false settings: false dynamicPlugins:
    frontend: default.main-menu-items: menuItems: default.create: title: '''' red-hat-developer-hub.backstage-plugin-global-header:
    # the default enabled dynamic header plugin mountPoints: - mountPoint: application/header
    importName: GlobalHeader config: position: above-main-content 4 - mountPoint:
    global.header/component importName: SearchComponent config: priority: 100 - mountPoint:
    global.header/component importName: Spacer config: priority: 99 props: growFactor:
    0 - mountPoint: global.header/component importName: HeaderIconButton config: priority:
    90 props: title: Self-service icon: add to: create - mountPoint: global.header/component
    importName: SupportButton config: priority: 80 - mountPoint: global.header/component
    importName: NotificationButton config: priority: 70 - mountPoint: global.header/component
    importName: Divider config: priority: 50 - mountPoint: global.header/component
    importName: ProfileDropdown config: priority: 10 - mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts - mountPoint: global.header/profile importName: LogoutButton
    config: priority: 10 ``` where: search:: Enter false to hide the Search modal
    in the sidebar menu. Enter true to display the Search modal in the sidebar menu.
    settings:: Enter false to hides the Settings button in the sidebar menu. Enter
    true to display the Settings button in the sidebar menu. default.main-menu-items::
    Enter this field to hide the Self-service button from the sidebar menu. Remove
    this field to display the Self-service button in the sidebar menu. position::
    Enter above-main-content to position the header above the main content. Enter
    above-sidebar to position the header above the sidebar. To extend the functionality
    of the default global header, include any of the following attributes in your
    global header entry: mountPoint:: Specifies the location of the header. Use application/header
    to specify it as a global header. You can configure several global headers at
    different positions by adding entries to the mountPoints field. importName:: Specifies
    the component exported by the global header plugin. The red-hat-developer-hub.backstage-plugin-global-header
    package (enabled by default) offers the following header components as possible
    mount point values: * SearchComponent: Adds a search bar (enabled by default).
    * Spacer: Adds spacing in the header to position buttons at the end. Useful when
    you disable SearchComponent. * HeaderIconButton: Adds an icon button. By default,
    the Self-service icon button remains enabled. * SupportButton: Adds a Support
    icon button, allowing users to configure a link to an internal or external page.
    Enabled by default but requires additional configuration to display. * NotificationButton:
    Adds a Notifications icon button to display unread notifications in real time
    and navigate to the Notifications page. Enabled by default (requires the notifications
    plugin). * Divider: Adds a vertical divider. By default, a divider appears between
    the profile dropdown and other header components. * ProfileDropdown: Adds a profile
    dropdown showing the logged-in user''s name. By default, it contains two menu
    items. * MenuItemLink: Adds a link item in a dropdown menu. By default, the profile
    dropdown includes a link to the Settings page. * LogoutButton: Adds a logout button
    in the profile dropdown (enabled by default). * CreateDropdown: Adds a Self-service
    dropdown button (disabled by default). The menu items are configurable. * SoftwareTemplatesSection:
    Adds a list of software template links to the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. * RegisterAComponentSection: Adds
    a link to the Register a Component page in the Self-service dropdown menu (disabled
    by default). You must enable CreateDropdown. config.position:: Specifies the position
    of the header. Supported values are above-main-content and above-sidebar. You
    must configure the support URL in the app config.yaml file to display the Support
    button in the header. You must install the notifications plugin to display the
    Notifications button in the header. 1. Copy the default configuration and modify
    the field values to suit your needs. You can adjust the priority value of each
    header component to control its position. Additionally, you can enable or disable
    components by adding or removing them from the configuration. To ensure that the
    remaining header buttons align with the end of the header before the profile dropdown
    button, set config.props.growFactor to 1 in the Spacer mount point to enable the
    Spacer component. For example: ```yaml mountPoint: global.header/component importName:
    Spacer config: priority: 100 props: growFactor: 1 ``` 2. To use your custom header,
    you must install it as a dynamic plugin by adding your plugin configuration to
    your app-config-dynamic.yaml file. For example: ```yaml package: <npm_or_oci_package
    reference> disabled: false pluginConfig: dynamicPlugins: frontend: <package_name>:
    mountPoints: mountPoint: application/header importName: <application_header_name>
    config: position: above main content mountPoint: global.header/component importName:
    <header_component_name> config: priority: 100 mountPoint: global.header/component
    importName: <header_component_name> config: priority: 90 ``` where: <npm_or_oci_package-reference>::
    Specifies the package name. <application_header_name>:: Specifies the name of
    the application header. For example: MyHeader <header_component_name>:: Specifies
    the name of the header component. For example: MyHeaderComponent [NOTE] ---- importName
    is an optional name referencing the value returned by the scaffolder field extension
    API. ---- 3. Optional: To disable the global header, set the value of the disabled
    field to true in your dynamic-plugins.yaml file. For example: ```yaml package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header disabled:
    true ``` ## Mount points for dynamic plugin integration You can customize the
    application header in Developer Hub using mount points for dynamic plugins. These
    mount points give flexibility in configuring the position of the header, its components
    and dropdown menus. You can create a customized experience with the following
    enhancements: application/header:: Controls the header position. Use config.position
    to set placement as either above-main-content or above-sidebar. global.header/component::
    Configures header components. Use config.priority to set the order of components,
    and pass properties (including CSS styles) via config.props. Self-service button::
    ```yaml mountPoint: global.header/component importName: HeaderIconButton config:
    priority: 80 props: title: Self service icon: add to: create ``` Spacer element::
    ```yaml mountPoint: global.header/component importName: Spacer config: priority:
    99 props: growFactor: 0 ```'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:26:25.850035'
    uuid: 2a32834b-184f-4f5d-ba1e-2427eaadc5ce
  response: The `HeaderIconButton` is a header component offered by the `red-hat-developer-hub.backstage-plugin-global-header`
    package, and its function is to add an icon button to the global header. By default,
    the Self-service icon button, which is an implementation of the `HeaderIconButton`,
    remains enabled. To configure this component, you use the `global.header/component`
    mount point and set the `importName` to `HeaderIconButton`. The configuration
    includes a `config` block to set the component's `priority` and a `props` block
    to define properties such as its `title`, `icon`, and `to` destination.
  user_input: Considering the goal of customizing the Red Hat Developer Hub's global
    header to better suit our enterprise needs, could you please provide a detailed
    explanation of the `HeaderIconButton` component, including its specific function,
    its default implementation, and the necessary configuration properties as outlined
    in the provided documentation?
- context:
  - 'Divider element:: ```yaml mountPoints: mountPoint: global.header/component importName:
    Divider config: priority: 150 ``` global.header/profile:: Configures the profile
    dropdown list when the ProfileDropdown component is enabled. * To add a settings
    link to the profile dropdown, use the following code: ```yaml mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts ``` global.header/create:: Configures the create dropdown
    list when the CreateDropdown component is enabled. * To add a section for registering
    a component, use the following code: ```yaml mountPoint: global.header/create
    importName: RegisterAComponentSection config: props: growFactor: 0 ``` ## Configuring
    the logo in the global header You can configure a company logo in the global header
    of the Red Hat Developer Hub (RHDH) to reflect your company&#8217;s branding.
    CompanyLogo is part of the global header by default and offers full control over
    the theming, navigation behavior, sizing, and fallback options. This component
    supports the following props, which are provided through configuration: logo:
    The base64 encoded logo image. to: The redirect path for when users click the
    logo is ''/catalog''. width: The logo width is optional and defaults to 150 px.
    height: The logo height is optional and defaults to 40 px. 1. To display a custom
    company logo in the global header, update the configuration with a mount point
    for CompanyLogo: ```yaml # ...rest of the global header configuration red-hat-developer-hub.backstage-plugin-global-header:
    mountPoints: - mountPoint: application/header importName: GlobalHeader config:
    # Supported values: above-main-content | above-sidebar position: above-main-content
    mountPoint: global.header/component importName: CompanyLogo config: priority:
    200 props: # Path to navigate when users click the logo: to: ''/catalog'' width:
    300 height: 200 logo: <string> or <object> # Logo can be a base64 string or theme
    specific object # Example 1: Single logo for all themes # logo: "<base64_encoded_images>"
    # Example 2: Theme-specific logos # logo: dark: ''data:image/png;base64,...''
    # Used in dark theme light: ''data:image/png;base64,...'' # Used in light theme
    ``` 2. (Optional) If you do not provide logo props to the CompanyLogo component,
    the component instead uses values defined under app.branding in your app-config.yaml
    file. You can configure the CompanyLogo as shown in the following configuration:
    ```yaml app: branding: fullLogoWidth: 220 # Fallback width fullLogo: <string>
    or <object> #fullLogo can be a base64 string or theme-specific object # Example
    1: Single logo for all themes #fullLogo: "<base64_encoded_image> # Example 2:
    Theme-specific logos #fullLogo: dark: ''data:image/png;base64,...'' # Used in
    dark theme light: ''data:image/png;base64,...'' # Used in light theme ``` CompanyLogo
    uses the following configuration elements to control fallback and sizing behavior:
    * Logo source priority * The component selects the logo source in the following
    order: First, CompanyLogo props (logo, logo.light, logo.dark), then, app.branding.fullLogo.
    If you do not provide a logo through either, the component displays the default
    Developer Hub theme-specific logo. * Logo width priority * The component applies
    the first available value from props.width, then app.branding.fullLogoWidth from
    app-config.yaml. If you do not specify the width using either, the component applies
    a default width (150 px). [NOTE] ---- CompanyLogo preserves the images aspect
    ratio and never crops or distorts it. If the configured width results in a height
    greater than the maximum allowed (default: 40px), the image is automatically scaled
    down. As a result, adjusting only the width may not visibly change the logo unless
    the height is also configured. Increasing the logo height increases the height
    of the global header. The component first applies the value from props.height.
    If you do not specify the height, the component applies a default height (40px).
    ---- 1. The logo appears correctly in the global header. 2. Click the logo to
    confirm it redirects to the path you defined in props.to. 3. Toggle between light
    and dark themes to ensure the correct logo loads in each. 4. (Optional) Temporarily
    remove the CompanyLogo props to test the fallback to app.branding.fullLogo. ##
    Enabling logo in the sidebar You can configure a logo in the sidebar of the Red
    Hat Developer Hub (RHDH). 1. To display the logo exclusively in the sidebar, set
    the value of the app.sidebar.logo parameter to true as shown in the following
    example: ```yaml app: sidebar: logo: true ``` [NOTE] ---- To display the logo
    in only the sidebar, remove the CompanyLogo component from the configuration.
    ---- 2. To display the same logo in the sidebar for all themes, update the configuration
    as shown in the following configuration: ```yaml app: sidebar: logo: true branding:
    fullLogoWidth: 220 fullLogo: ''data:image/svg+xml;base64,...'' ``` 3. For theme-specific
    logos, you can configure the sidebar logo as shown in the following configuration:
    ```yaml app: sidebar: logo: true branding: fullLogoWidth: 220 fullLogo: light:
    ''data:image/svg+xml;base64,...'' dark: ''data:image/svg+xml;base64,...'' ```
    1. The logo appears correctly in the sidebar. 2. Toggle between light and dark
    themes to ensure the correct logo loads in each. ## Displaying the preferred username
    in the profile dropdown You can display the preferred username in the global header
    profile drop-down list by configuring spec.profile.displayName in the user entity.
    When not configured, the application falls back to a metadata.title. If neither
    is configured, it defaults to a user-friendly name generated by the useProfileInfo
    hook. 1. To configure spec.profile.displayName, use the following code: ```yaml
    apiVersion: backstage.io/v1alpha1 kind: User metadata: # Required unique username
    name: <my_display_name> # Optional preferred title title: <display_name_title>
    spec: profile: # Optional preferred display name (highest priority) displayName:
    <my_display_name> memberOf: [janus-authors] ``` 2. To configure metadata.title
    rather than spec.profile.displayname, use the following code: ```yaml apiVersion:
    backstage.io/v1alpha1 kind: User metadata: # Required unique username name: <my_display_name>
    # Optional preferred title title: <display_name_title> spec: memberOf: [janus
    authors] ``` 3. To configure neither spec.profile.displayname or metadata.title,
    use the following code: ```yaml apiVersion: backstage.io/v1alpha1 kind: User metadata:
    # Required unique username name: <my_display_name> spec: memberOf: [janus authors]
    ``` [NOTE] ---- The application falls back to metadata.name when you do not register
    the user entity. ---- ## Quicklinks and Starred Items in the global header The
    Quicklinks matrix and Starred Items drop-down list are enabled by default and
    appear in the global header without requiring additional configuration. The Quicklinks
    matrix, organized by sections (for example, Documentation or Developer Tools),
    allows users to quickly access internal or'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:26:32.657827'
    uuid: 0885cf89-1268-4d93-9e5a-01e89f388c73
  response: 'To display a custom company logo in the global header, you must update
    the configuration with a mount point for CompanyLogo. This component is part of
    the global header by default and supports several props provided through configuration.
    These include: ''logo'', which is the base64 encoded logo image; ''to'', the redirect
    path for when users click the logo; ''width'', which is optional and defaults
    to 150 px; and ''height'', which is also optional and defaults to 40 px.'
  user_input: How do I configure the CompanyLogo in the Red Hat Developer Hub global
    header and what properties does it support?
- context:
  - 'Divider element:: ```yaml mountPoints: mountPoint: global.header/component importName:
    Divider config: priority: 150 ``` global.header/profile:: Configures the profile
    dropdown list when the ProfileDropdown component is enabled. * To add a settings
    link to the profile dropdown, use the following code: ```yaml mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts ``` global.header/create:: Configures the create dropdown
    list when the CreateDropdown component is enabled. * To add a section for registering
    a component, use the following code: ```yaml mountPoint: global.header/create
    importName: RegisterAComponentSection config: props: growFactor: 0 ``` ## Configuring
    the logo in the global header You can configure a company logo in the global header
    of the Red Hat Developer Hub (RHDH) to reflect your company&#8217;s branding.
    CompanyLogo is part of the global header by default and offers full control over
    the theming, navigation behavior, sizing, and fallback options. This component
    supports the following props, which are provided through configuration: logo:
    The base64 encoded logo image. to: The redirect path for when users click the
    logo is ''/catalog''. width: The logo width is optional and defaults to 150 px.
    height: The logo height is optional and defaults to 40 px. 1. To display a custom
    company logo in the global header, update the configuration with a mount point
    for CompanyLogo: ```yaml # ...rest of the global header configuration red-hat-developer-hub.backstage-plugin-global-header:
    mountPoints: - mountPoint: application/header importName: GlobalHeader config:
    # Supported values: above-main-content | above-sidebar position: above-main-content
    mountPoint: global.header/component importName: CompanyLogo config: priority:
    200 props: # Path to navigate when users click the logo: to: ''/catalog'' width:
    300 height: 200 logo: <string> or <object> # Logo can be a base64 string or theme
    specific object # Example 1: Single logo for all themes # logo: "<base64_encoded_images>"
    # Example 2: Theme-specific logos # logo: dark: ''data:image/png;base64,...''
    # Used in dark theme light: ''data:image/png;base64,...'' # Used in light theme
    ``` 2. (Optional) If you do not provide logo props to the CompanyLogo component,
    the component instead uses values defined under app.branding in your app-config.yaml
    file. You can configure the CompanyLogo as shown in the following configuration:
    ```yaml app: branding: fullLogoWidth: 220 # Fallback width fullLogo: <string>
    or <object> #fullLogo can be a base64 string or theme-specific object # Example
    1: Single logo for all themes #fullLogo: "<base64_encoded_image> # Example 2:
    Theme-specific logos #fullLogo: dark: ''data:image/png;base64,...'' # Used in
    dark theme light: ''data:image/png;base64,...'' # Used in light theme ``` CompanyLogo
    uses the following configuration elements to control fallback and sizing behavior:
    * Logo source priority * The component selects the logo source in the following
    order: First, CompanyLogo props (logo, logo.light, logo.dark), then, app.branding.fullLogo.
    If you do not provide a logo through either, the component displays the default
    Developer Hub theme-specific logo. * Logo width priority * The component applies
    the first available value from props.width, then app.branding.fullLogoWidth from
    app-config.yaml. If you do not specify the width using either, the component applies
    a default width (150 px). [NOTE] ---- CompanyLogo preserves the images aspect
    ratio and never crops or distorts it. If the configured width results in a height
    greater than the maximum allowed (default: 40px), the image is automatically scaled
    down. As a result, adjusting only the width may not visibly change the logo unless
    the height is also configured. Increasing the logo height increases the height
    of the global header. The component first applies the value from props.height.
    If you do not specify the height, the component applies a default height (40px).
    ---- 1. The logo appears correctly in the global header. 2. Click the logo to
    confirm it redirects to the path you defined in props.to. 3. Toggle between light
    and dark themes to ensure the correct logo loads in each. 4. (Optional) Temporarily
    remove the CompanyLogo props to test the fallback to app.branding.fullLogo. ##
    Enabling logo in the sidebar You can configure a logo in the sidebar of the Red
    Hat Developer Hub (RHDH). 1. To display the logo exclusively in the sidebar, set
    the value of the app.sidebar.logo parameter to true as shown in the following
    example: ```yaml app: sidebar: logo: true ``` [NOTE] ---- To display the logo
    in only the sidebar, remove the CompanyLogo component from the configuration.
    ---- 2. To display the same logo in the sidebar for all themes, update the configuration
    as shown in the following configuration: ```yaml app: sidebar: logo: true branding:
    fullLogoWidth: 220 fullLogo: ''data:image/svg+xml;base64,...'' ``` 3. For theme-specific
    logos, you can configure the sidebar logo as shown in the following configuration:
    ```yaml app: sidebar: logo: true branding: fullLogoWidth: 220 fullLogo: light:
    ''data:image/svg+xml;base64,...'' dark: ''data:image/svg+xml;base64,...'' ```
    1. The logo appears correctly in the sidebar. 2. Toggle between light and dark
    themes to ensure the correct logo loads in each. ## Displaying the preferred username
    in the profile dropdown You can display the preferred username in the global header
    profile drop-down list by configuring spec.profile.displayName in the user entity.
    When not configured, the application falls back to a metadata.title. If neither
    is configured, it defaults to a user-friendly name generated by the useProfileInfo
    hook. 1. To configure spec.profile.displayName, use the following code: ```yaml
    apiVersion: backstage.io/v1alpha1 kind: User metadata: # Required unique username
    name: <my_display_name> # Optional preferred title title: <display_name_title>
    spec: profile: # Optional preferred display name (highest priority) displayName:
    <my_display_name> memberOf: [janus-authors] ``` 2. To configure metadata.title
    rather than spec.profile.displayname, use the following code: ```yaml apiVersion:
    backstage.io/v1alpha1 kind: User metadata: # Required unique username name: <my_display_name>
    # Optional preferred title title: <display_name_title> spec: memberOf: [janus
    authors] ``` 3. To configure neither spec.profile.displayname or metadata.title,
    use the following code: ```yaml apiVersion: backstage.io/v1alpha1 kind: User metadata:
    # Required unique username name: <my_display_name> spec: memberOf: [janus authors]
    ``` [NOTE] ---- The application falls back to metadata.name when you do not register
    the user entity. ---- ## Quicklinks and Starred Items in the global header The
    Quicklinks matrix and Starred Items drop-down list are enabled by default and
    appear in the global header without requiring additional configuration. The Quicklinks
    matrix, organized by sections (for example, Documentation or Developer Tools),
    allows users to quickly access internal or'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:26:40.642006'
    uuid: 0a4b0ec7-6c32-4682-94df-accee93642e4
  response: To display the preferred username in the global header profile drop-down
    list, you need to configure `spec.profile.displayName` in the user entity. If
    this is not configured, the application will fall back to `metadata.title`. If
    neither of these is configured, it will default to a user-friendly name generated
    by the `useProfileInfo` hook. When the user entity is not registered, the application
    falls back to `metadata.name`.
  user_input: How do I show the username in the ProfileDropdwn?
- context:
  - 'Divider element:: ```yaml mountPoints: mountPoint: global.header/component importName:
    Divider config: priority: 150 ``` global.header/profile:: Configures the profile
    dropdown list when the ProfileDropdown component is enabled. * To add a settings
    link to the profile dropdown, use the following code: ```yaml mountPoint: global.header/profile
    importName: MenuItemLink config: priority: 100 props: title: Settings link: /settings
    icon: manageAccounts ``` global.header/create:: Configures the create dropdown
    list when the CreateDropdown component is enabled. * To add a section for registering
    a component, use the following code: ```yaml mountPoint: global.header/create
    importName: RegisterAComponentSection config: props: growFactor: 0 ``` ## Configuring
    the logo in the global header You can configure a company logo in the global header
    of the Red Hat Developer Hub (RHDH) to reflect your company&#8217;s branding.
    CompanyLogo is part of the global header by default and offers full control over
    the theming, navigation behavior, sizing, and fallback options. This component
    supports the following props, which are provided through configuration: logo:
    The base64 encoded logo image. to: The redirect path for when users click the
    logo is ''/catalog''. width: The logo width is optional and defaults to 150 px.
    height: The logo height is optional and defaults to 40 px. 1. To display a custom
    company logo in the global header, update the configuration with a mount point
    for CompanyLogo: ```yaml # ...rest of the global header configuration red-hat-developer-hub.backstage-plugin-global-header:
    mountPoints: - mountPoint: application/header importName: GlobalHeader config:
    # Supported values: above-main-content | above-sidebar position: above-main-content
    mountPoint: global.header/component importName: CompanyLogo config: priority:
    200 props: # Path to navigate when users click the logo: to: ''/catalog'' width:
    300 height: 200 logo: <string> or <object> # Logo can be a base64 string or theme
    specific object # Example 1: Single logo for all themes # logo: "<base64_encoded_images>"
    # Example 2: Theme-specific logos # logo: dark: ''data:image/png;base64,...''
    # Used in dark theme light: ''data:image/png;base64,...'' # Used in light theme
    ``` 2. (Optional) If you do not provide logo props to the CompanyLogo component,
    the component instead uses values defined under app.branding in your app-config.yaml
    file. You can configure the CompanyLogo as shown in the following configuration:
    ```yaml app: branding: fullLogoWidth: 220 # Fallback width fullLogo: <string>
    or <object> #fullLogo can be a base64 string or theme-specific object # Example
    1: Single logo for all themes #fullLogo: "<base64_encoded_image> # Example 2:
    Theme-specific logos #fullLogo: dark: ''data:image/png;base64,...'' # Used in
    dark theme light: ''data:image/png;base64,...'' # Used in light theme ``` CompanyLogo
    uses the following configuration elements to control fallback and sizing behavior:
    * Logo source priority * The component selects the logo source in the following
    order: First, CompanyLogo props (logo, logo.light, logo.dark), then, app.branding.fullLogo.
    If you do not provide a logo through either, the component displays the default
    Developer Hub theme-specific logo. * Logo width priority * The component applies
    the first available value from props.width, then app.branding.fullLogoWidth from
    app-config.yaml. If you do not specify the width using either, the component applies
    a default width (150 px). [NOTE] ---- CompanyLogo preserves the images aspect
    ratio and never crops or distorts it. If the configured width results in a height
    greater than the maximum allowed (default: 40px), the image is automatically scaled
    down. As a result, adjusting only the width may not visibly change the logo unless
    the height is also configured. Increasing the logo height increases the height
    of the global header. The component first applies the value from props.height.
    If you do not specify the height, the component applies a default height (40px).
    ---- 1. The logo appears correctly in the global header. 2. Click the logo to
    confirm it redirects to the path you defined in props.to. 3. Toggle between light
    and dark themes to ensure the correct logo loads in each. 4. (Optional) Temporarily
    remove the CompanyLogo props to test the fallback to app.branding.fullLogo. ##
    Enabling logo in the sidebar You can configure a logo in the sidebar of the Red
    Hat Developer Hub (RHDH). 1. To display the logo exclusively in the sidebar, set
    the value of the app.sidebar.logo parameter to true as shown in the following
    example: ```yaml app: sidebar: logo: true ``` [NOTE] ---- To display the logo
    in only the sidebar, remove the CompanyLogo component from the configuration.
    ---- 2. To display the same logo in the sidebar for all themes, update the configuration
    as shown in the following configuration: ```yaml app: sidebar: logo: true branding:
    fullLogoWidth: 220 fullLogo: ''data:image/svg+xml;base64,...'' ``` 3. For theme-specific
    logos, you can configure the sidebar logo as shown in the following configuration:
    ```yaml app: sidebar: logo: true branding: fullLogoWidth: 220 fullLogo: light:
    ''data:image/svg+xml;base64,...'' dark: ''data:image/svg+xml;base64,...'' ```
    1. The logo appears correctly in the sidebar. 2. Toggle between light and dark
    themes to ensure the correct logo loads in each. ## Displaying the preferred username
    in the profile dropdown You can display the preferred username in the global header
    profile drop-down list by configuring spec.profile.displayName in the user entity.
    When not configured, the application falls back to a metadata.title. If neither
    is configured, it defaults to a user-friendly name generated by the useProfileInfo
    hook. 1. To configure spec.profile.displayName, use the following code: ```yaml
    apiVersion: backstage.io/v1alpha1 kind: User metadata: # Required unique username
    name: <my_display_name> # Optional preferred title title: <display_name_title>
    spec: profile: # Optional preferred display name (highest priority) displayName:
    <my_display_name> memberOf: [janus-authors] ``` 2. To configure metadata.title
    rather than spec.profile.displayname, use the following code: ```yaml apiVersion:
    backstage.io/v1alpha1 kind: User metadata: # Required unique username name: <my_display_name>
    # Optional preferred title title: <display_name_title> spec: memberOf: [janus
    authors] ``` 3. To configure neither spec.profile.displayname or metadata.title,
    use the following code: ```yaml apiVersion: backstage.io/v1alpha1 kind: User metadata:
    # Required unique username name: <my_display_name> spec: memberOf: [janus authors]
    ``` [NOTE] ---- The application falls back to metadata.name when you do not register
    the user entity. ---- ## Quicklinks and Starred Items in the global header The
    Quicklinks matrix and Starred Items drop-down list are enabled by default and
    appear in the global header without requiring additional configuration. The Quicklinks
    matrix, organized by sections (for example, Documentation or Developer Tools),
    allows users to quickly access internal or'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:26:48.500165'
    uuid: d37ec726-1e71-429e-929a-2c16914b1961
  response: 'The CompanyLogo component selects the logo source in the following order:
    first, it uses the CompanyLogo props (logo, logo.light, logo.dark), and then it
    uses app.branding.fullLogo. If a logo is not provided through either of these
    methods, the component will display the default Developer Hub theme-specific logo.'
  user_input: How does Backstage prioritize the source for the company logo?
- context:
  - 'external resources. The Starred Items drop-down list contains entities and pages
    that the user has starred. The default configuration includes the following components:
    StarredDropdown:: Display the Starred Items menu in the global header by default,
    as shown in the following configuration: ```yaml # Group: Global Header package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header mountPoint:
    global.header/component importName: StarredDropdown config: priority: 85 ``` ApplicationLauncherDropdown::
    Provide the Quicklinks matrix (application launcher) by default, as shown in the
    following configuration: ```yaml # Group: Global Header package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin global header mountPoint: global.header/component
    importName: ApplicationLauncherDropdown config: priority: 82 ``` MenuItemLink
    entries:: Define sections, titles, icons, and links within the Quicklinks matrix.
    The default configuration includes links to the Developer Hub documentation and
    an RHDH Local, as shown in the following configurations: ```yaml mountPoint: global.header/application
    launcher importName: MenuItemLink config: section: Documentation priority: 150
    props: title: Developer Hub icon: developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` [NOTE] ---- When upgrading
    from previous versions, the installer does not overwrite your existing dynamic-plugins.yaml
    configuration. If you had not configured Starred Items or Quicklinks previously,
    they remain disabled after the upgrade and must be manually enabled. ---- ## Enabling
    Quicklinks and Starred Items after an upgrade If you upgrade from Red Hat Developer
    Hub 1.6 or earlier, Red Hat Developer Hub does not automatically enable the Quicklinks
    and Starred Items features. You must manually configure these features to display
    them in the global header. 1. You have access to your Red Hat Developer Hub configuration
    files. 2. You have administrative permissions to modify ConfigMaps (if using the
    Operator). 1. Locate your dynamic-plugin configuration. * Operator deployment:
    The configuration is stored in a ConfigMap referenced by your Backstage custom
    resource (CR). * Helm deployment: The configuration is in your values.yaml file
    or separate configuration files. 2. Enable the global header plugin. Ensure that
    the red-hat-developer-hub-backstage-plugin-global-header entry exists under the
    plugins: list and that disabled is set to false. 3. Verify that you enabled the
    global header plugin. Confirm that you listed the red-hat-developer-hub-backstage-plugin-global-header
    plugin under plugins: with disabled: false (or without a disabled property): ```yaml
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin global
    header disabled: false ``` 4. Add the required components. Under the mountPoints
    section of the plugin, add the components as shown in the following example: ```yaml
    mountPoints: mountPoint: application/header importName: GlobalHeader config: position:
    above sidebar mountPoint: global.header/component importName: StarredDropdown
    config: priority: 85 mountPoint: global.header/component importName: ApplicationLauncherDropdown
    config: priority: 82 mountPoint: global.header/component importName: MenuItemLink
    config: section: Documentation priority: 150 props: title: Developer Hub icon:
    developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` 5. Apply the configuration.
    * Operator deployment: Update the ConfigMap and allow the Operator to reconcile
    the changes. * Helm deployment: Apply your updated configuration using helm upgrade.
    6. Verify the features are enabled. After the Red Hat Developer Hub instance restarts,
    confirm that the star icon and Quicklinks matrix appear in the global header.
    # Configuring a floating action button in Red Hat Developer Hub You can use the
    floating action button plugin to configure any action as a floating button in
    the Developer Hub instance. The floating action button plugin is enabled by default.
    You can also configure floating action buttons to display as submenu options within
    the main floating action button by assigning the floating action buttons to the
    same slot field of your dynamic-plugins.yaml file. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:27:08.823054'
    uuid: 44930fb3-6cbf-4fdc-a57d-e5f38a48b6a4
  response: 'The StarredDropdown component is configured to display the Starred Items
    menu in the global header by default. The configuration is as follows: package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header, mountPoint:
    global.header/component, importName: StarredDropdown, and config: priority: 85.'
  user_input: StarredDropdown configuration example
- context:
  - 'external resources. The Starred Items drop-down list contains entities and pages
    that the user has starred. The default configuration includes the following components:
    StarredDropdown:: Display the Starred Items menu in the global header by default,
    as shown in the following configuration: ```yaml # Group: Global Header package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header mountPoint:
    global.header/component importName: StarredDropdown config: priority: 85 ``` ApplicationLauncherDropdown::
    Provide the Quicklinks matrix (application launcher) by default, as shown in the
    following configuration: ```yaml # Group: Global Header package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin global header mountPoint: global.header/component
    importName: ApplicationLauncherDropdown config: priority: 82 ``` MenuItemLink
    entries:: Define sections, titles, icons, and links within the Quicklinks matrix.
    The default configuration includes links to the Developer Hub documentation and
    an RHDH Local, as shown in the following configurations: ```yaml mountPoint: global.header/application
    launcher importName: MenuItemLink config: section: Documentation priority: 150
    props: title: Developer Hub icon: developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` [NOTE] ---- When upgrading
    from previous versions, the installer does not overwrite your existing dynamic-plugins.yaml
    configuration. If you had not configured Starred Items or Quicklinks previously,
    they remain disabled after the upgrade and must be manually enabled. ---- ## Enabling
    Quicklinks and Starred Items after an upgrade If you upgrade from Red Hat Developer
    Hub 1.6 or earlier, Red Hat Developer Hub does not automatically enable the Quicklinks
    and Starred Items features. You must manually configure these features to display
    them in the global header. 1. You have access to your Red Hat Developer Hub configuration
    files. 2. You have administrative permissions to modify ConfigMaps (if using the
    Operator). 1. Locate your dynamic-plugin configuration. * Operator deployment:
    The configuration is stored in a ConfigMap referenced by your Backstage custom
    resource (CR). * Helm deployment: The configuration is in your values.yaml file
    or separate configuration files. 2. Enable the global header plugin. Ensure that
    the red-hat-developer-hub-backstage-plugin-global-header entry exists under the
    plugins: list and that disabled is set to false. 3. Verify that you enabled the
    global header plugin. Confirm that you listed the red-hat-developer-hub-backstage-plugin-global-header
    plugin under plugins: with disabled: false (or without a disabled property): ```yaml
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin global
    header disabled: false ``` 4. Add the required components. Under the mountPoints
    section of the plugin, add the components as shown in the following example: ```yaml
    mountPoints: mountPoint: application/header importName: GlobalHeader config: position:
    above sidebar mountPoint: global.header/component importName: StarredDropdown
    config: priority: 85 mountPoint: global.header/component importName: ApplicationLauncherDropdown
    config: priority: 82 mountPoint: global.header/component importName: MenuItemLink
    config: section: Documentation priority: 150 props: title: Developer Hub icon:
    developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` 5. Apply the configuration.
    * Operator deployment: Update the ConfigMap and allow the Operator to reconcile
    the changes. * Helm deployment: Apply your updated configuration using helm upgrade.
    6. Verify the features are enabled. After the Red Hat Developer Hub instance restarts,
    confirm that the star icon and Quicklinks matrix appear in the global header.
    # Configuring a floating action button in Red Hat Developer Hub You can use the
    floating action button plugin to configure any action as a floating button in
    the Developer Hub instance. The floating action button plugin is enabled by default.
    You can also configure floating action buttons to display as submenu options within
    the main floating action button by assigning the floating action buttons to the
    same slot field of your dynamic-plugins.yaml file. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:27:17.126606'
    uuid: a66783ae-a39c-4666-a306-7b370ad0c6d1
  response: The StarredDropdown component is configured to display the Starred Items
    menu in the global header by default. The configuration specifies the package
    as './dynamic plugins/dist/red hat developer hub backstage plugin global header',
    the mountPoint as 'global.header/component', the importName as 'StarredDropdown',
    and includes a config with a priority of 85.
  user_input: How is the StarredDropdown component configured to display in the global
    header?
- context:
  - 'external resources. The Starred Items drop-down list contains entities and pages
    that the user has starred. The default configuration includes the following components:
    StarredDropdown:: Display the Starred Items menu in the global header by default,
    as shown in the following configuration: ```yaml # Group: Global Header package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin global header mountPoint:
    global.header/component importName: StarredDropdown config: priority: 85 ``` ApplicationLauncherDropdown::
    Provide the Quicklinks matrix (application launcher) by default, as shown in the
    following configuration: ```yaml # Group: Global Header package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin global header mountPoint: global.header/component
    importName: ApplicationLauncherDropdown config: priority: 82 ``` MenuItemLink
    entries:: Define sections, titles, icons, and links within the Quicklinks matrix.
    The default configuration includes links to the Developer Hub documentation and
    an RHDH Local, as shown in the following configurations: ```yaml mountPoint: global.header/application
    launcher importName: MenuItemLink config: section: Documentation priority: 150
    props: title: Developer Hub icon: developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` [NOTE] ---- When upgrading
    from previous versions, the installer does not overwrite your existing dynamic-plugins.yaml
    configuration. If you had not configured Starred Items or Quicklinks previously,
    they remain disabled after the upgrade and must be manually enabled. ---- ## Enabling
    Quicklinks and Starred Items after an upgrade If you upgrade from Red Hat Developer
    Hub 1.6 or earlier, Red Hat Developer Hub does not automatically enable the Quicklinks
    and Starred Items features. You must manually configure these features to display
    them in the global header. 1. You have access to your Red Hat Developer Hub configuration
    files. 2. You have administrative permissions to modify ConfigMaps (if using the
    Operator). 1. Locate your dynamic-plugin configuration. * Operator deployment:
    The configuration is stored in a ConfigMap referenced by your Backstage custom
    resource (CR). * Helm deployment: The configuration is in your values.yaml file
    or separate configuration files. 2. Enable the global header plugin. Ensure that
    the red-hat-developer-hub-backstage-plugin-global-header entry exists under the
    plugins: list and that disabled is set to false. 3. Verify that you enabled the
    global header plugin. Confirm that you listed the red-hat-developer-hub-backstage-plugin-global-header
    plugin under plugins: with disabled: false (or without a disabled property): ```yaml
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin global
    header disabled: false ``` 4. Add the required components. Under the mountPoints
    section of the plugin, add the components as shown in the following example: ```yaml
    mountPoints: mountPoint: application/header importName: GlobalHeader config: position:
    above sidebar mountPoint: global.header/component importName: StarredDropdown
    config: priority: 85 mountPoint: global.header/component importName: ApplicationLauncherDropdown
    config: priority: 82 mountPoint: global.header/component importName: MenuItemLink
    config: section: Documentation priority: 150 props: title: Developer Hub icon:
    developerHub link: https://docs.redhat.com/en/documentation/red_hat_developer_hub
    mountPoint: global.header/application launcher importName: MenuItemLink config:
    section: Developer Tools priority: 100 props: title: RHDH Local icon: developerHub
    link: https://github.com/redhat developer/rhdh local ``` 5. Apply the configuration.
    * Operator deployment: Update the ConfigMap and allow the Operator to reconcile
    the changes. * Helm deployment: Apply your updated configuration using helm upgrade.
    6. Verify the features are enabled. After the Red Hat Developer Hub instance restarts,
    confirm that the star icon and Quicklinks matrix appear in the global header.
    # Configuring a floating action button in Red Hat Developer Hub You can use the
    floating action button plugin to configure any action as a floating button in
    the Developer Hub instance. The floating action button plugin is enabled by default.
    You can also configure floating action buttons to display as submenu options within
    the main floating action button by assigning the floating action buttons to the
    same slot field of your dynamic-plugins.yaml file. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:27:24.530432'
    uuid: 3e1f14e8-ebf1-4f0b-a698-098b099509d8
  response: To provide the Quicklinks matrix, you must configure the `ApplicationLauncherDropdown`
    component, which has a default priority of 82. Additionally, you define the specific
    links within the matrix using `MenuItemLink` entries. These entries allow you
    to specify sections, titles, icons, and links, with the default configuration
    including links to the Developer Hub documentation and an RHDH Local.
  user_input: Could you detail the necessary configuration components for providing
    the Quicklinks matrix within the Red Hat Developer Hub global header?
- context:
  - 'Configuring a floating action button as a dynamic plugin You can configure the
    floating action button as a dynamic plugin to perform actions or open an internal
    or external link. You must have sufficient permissions as a platform engineer.
    To configure a floating action button as a dynamic plugin, complete any of the
    following tasks: Specify the global.floatingactionbutton/config mount point in
    your app config dynamic.yaml file. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of the floating action button configuration mountPoints: - mountPoint:
    global.floatingactionbutton/config importName: BulkImportPage config: slot: ''page-end''
    icon: <svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 24 24"
    height="24px" viewBox="0 0 24 24" width="24px" fill="#e8eaed"><g><rect fill="none"
    height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # End of the floating action button configuration appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    (Required) The import name with an associated component to the mount point. frontend:mountPoints:importName:icon::
    Use the svg value to display a black BulkImportPage icon. * To configure an action
    as a floating action button that opens an external link, specify the global.floatingactionbutton/config
    mount point in your dynamic-plugins.yaml file within the backstage-plugin-global-floating-action-button
    plugin. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    mountPoints: - mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid"><path
    d="M200.134 0l55.555 117.514-55.555 117.518h-47.295l55.555-117.518L152.84 0h47.295zM110.08
    99.836l20.056-38.092-2.29-8.868L102.847 0H55.552l48.647 102.898 5.881-3.062zm17.766
    74.433l-17.333-39.034-6.314-3.101-48.647 102.898h47.295l25-52.88v-7.883z" fill="#40B4E5"/><path
    d="M152.842 235.032L97.287 117.514 152.842 0h47.295l-55.555 117.514 55.555 117.518h-47.295zm-97.287
    0L0 117.514 55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' - mountPoint:
    global.floatingactionbutton/config importName: NullComponent config: icon: github
    label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat-developer/rhdh-plugins
    ``` frontend:mountPoints:importName:: Enter the import name with an associated
    component to the mount point. frontend:mountPoints:importName:icon:: (Optional)
    Enter the icon in Scalable Vector Graphics (SVG) format to display the Quay icon.
    * To configure a floating action button that contains a submenu, define the global.floatingactionbutton/config
    mount point in the same slot field in your dynamic-plugins.yaml file for multiple
    actions. The default slot is page-end when not specified. For example: ```yaml
    - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # end of fab config appIcons: - name: bulkImportIcon importName: BulkImportIcon
    dynamicRoutes: - path: /bulk-import/repositories importName: BulkImportPage menuItem:
    icon: bulkImportIcon text: Bulk import package: ./dynamic plugins/dist/red hat
    developer hub backstage plugin global floating action button disabled: false pluginConfig:
    dynamicPlugins: frontend: red hat developer hub.backstage plugin global floating
    action button: mountPoints: mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: github label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat
    developer/rhdh plugins mountPoint: global.floatingactionbutton/config importName:
    NullComponent config: icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg"
    preserveAspectRatio="xMidYMid"><path d="M200.134 0l55.555 117.514 55.555 117.518h
    47.295l55.555 117.518L152.84 0h47.295zM110.08 99.836l20.056 38.092 2.29 8.868L102.847
    0H55.552l48.647 102.898 5.881 3.062zm17.766 74.433l 17.333 39.034 6.314 3.101
    48.647 102.898h47.295l25 52.88v 7.883z" fill="#40B4E5"/><path d="M152.842 235.032L97.287
    117.514 152.842 0h47.295l 55.555 117.514 55.555 117.518h 47.295zm 97.287 0L0 117.514
    55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' ```
    frontend:mountPoints:importName:: (Required) The import name with an associated
    component to the mount point. * To configure a floating action button to display
    only on specific pages, configure the global.floatingactionbutton/config mount
    point in the backstage-plugin-global-floating-action-button plugin and set the
    visibleOnPaths property as shown in the following example: ```yaml - package:
    ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import disabled:
    false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    visibleOnPaths: [''/catalog'', ''/settings''] # end of fab config appIcons: -
    name: bulkImportIcon importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories
    importName: BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ```
    frontend:mountPoints:importName:: Enter the import name with an associated component
    to the mount point. * To hide a floating action button on specific pages, configure
    the global.floatingactionbutton/config mount point in the backstage-plugin-global-floating-action-button
    plugin and set the excludeOnPaths property as shown in the following example:
    ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    excludeOnPaths: [''/bulk-import''] # end of fab config appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    Enter the import name with an associated component to the mount point. ## Translation
    support The Global Floating Action Button plugin supports internationalization
    (i18n) through translation keys. You can use labelKey and toolTipKey properties
    to provide translation keys instead of static text. Example for using translation
    keys in dynamic configuration: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    translationResources: - importName: globalFloatingActionButtonTranslations ref:
    globalFloatingActionButtonTranslationRef mountPoints: - mountPoint: application/listener
    importName: DynamicGlobalFloatingActionButton - mountPoint: global.floatingactionbutton/config
    importName: NullComponent config: icon: github label: ''GitHub'' # Fallback text
    labelKey: ''fab.github.label'' # Translation key toolTip: ''GitHub Repository''
    # Fallback text toolTipKey: ''fab.github.tooltip'' # Translation key to: https://github.com/redhat-developer/rhdh-plugins
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    color: ''success'' icon: search label: ''Create'' # Fallback text labelKey: ''fab.create.label''
    # Translation key toolTip: ''Create entity'' # Fallback text toolTipKey: ''fab.create.tooltip''
    # Translation key to: ''/create'' showLabel: true ``` ## Enabling floating action
    button localization in RHDH You can enable translation key support for floating
    action buttons, so that users can onboard in their preferred language. In Developer
    Hub, all existing and newly created floating action buttons support localization
    using dedicated translation keys. The Global Floating Action Button plugin supports
    internationalization (i18n) through translation keys. You can use labelKey and
    toolTipKey'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:27:33.195534'
    uuid: b3dc81f4-1f57-4a6d-b5cc-e3b27cd4009b
  response: To configure a floating action button that opens an external link for
    Git, you specify the `global.floatingactionbutton/config` mount point in your
    `dynamic-plugins.yaml` file. The configuration uses `NullComponent` as the `importName`
    and includes a `config` section where the `icon` is `github`, the `label` is 'Git',
    the `toolTip` is 'Github', and the `to` property is set to `https://github.com/redhat-developer/rhdh-plugins`.
  user_input: How can I configure a floating action button for Git?
- context:
  - 'Configuring a floating action button as a dynamic plugin You can configure the
    floating action button as a dynamic plugin to perform actions or open an internal
    or external link. You must have sufficient permissions as a platform engineer.
    To configure a floating action button as a dynamic plugin, complete any of the
    following tasks: Specify the global.floatingactionbutton/config mount point in
    your app config dynamic.yaml file. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of the floating action button configuration mountPoints: - mountPoint:
    global.floatingactionbutton/config importName: BulkImportPage config: slot: ''page-end''
    icon: <svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 24 24"
    height="24px" viewBox="0 0 24 24" width="24px" fill="#e8eaed"><g><rect fill="none"
    height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # End of the floating action button configuration appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    (Required) The import name with an associated component to the mount point. frontend:mountPoints:importName:icon::
    Use the svg value to display a black BulkImportPage icon. * To configure an action
    as a floating action button that opens an external link, specify the global.floatingactionbutton/config
    mount point in your dynamic-plugins.yaml file within the backstage-plugin-global-floating-action-button
    plugin. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    mountPoints: - mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid"><path
    d="M200.134 0l55.555 117.514-55.555 117.518h-47.295l55.555-117.518L152.84 0h47.295zM110.08
    99.836l20.056-38.092-2.29-8.868L102.847 0H55.552l48.647 102.898 5.881-3.062zm17.766
    74.433l-17.333-39.034-6.314-3.101-48.647 102.898h47.295l25-52.88v-7.883z" fill="#40B4E5"/><path
    d="M152.842 235.032L97.287 117.514 152.842 0h47.295l-55.555 117.514 55.555 117.518h-47.295zm-97.287
    0L0 117.514 55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' - mountPoint:
    global.floatingactionbutton/config importName: NullComponent config: icon: github
    label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat-developer/rhdh-plugins
    ``` frontend:mountPoints:importName:: Enter the import name with an associated
    component to the mount point. frontend:mountPoints:importName:icon:: (Optional)
    Enter the icon in Scalable Vector Graphics (SVG) format to display the Quay icon.
    * To configure a floating action button that contains a submenu, define the global.floatingactionbutton/config
    mount point in the same slot field in your dynamic-plugins.yaml file for multiple
    actions. The default slot is page-end when not specified. For example: ```yaml
    - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # end of fab config appIcons: - name: bulkImportIcon importName: BulkImportIcon
    dynamicRoutes: - path: /bulk-import/repositories importName: BulkImportPage menuItem:
    icon: bulkImportIcon text: Bulk import package: ./dynamic plugins/dist/red hat
    developer hub backstage plugin global floating action button disabled: false pluginConfig:
    dynamicPlugins: frontend: red hat developer hub.backstage plugin global floating
    action button: mountPoints: mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: github label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat
    developer/rhdh plugins mountPoint: global.floatingactionbutton/config importName:
    NullComponent config: icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg"
    preserveAspectRatio="xMidYMid"><path d="M200.134 0l55.555 117.514 55.555 117.518h
    47.295l55.555 117.518L152.84 0h47.295zM110.08 99.836l20.056 38.092 2.29 8.868L102.847
    0H55.552l48.647 102.898 5.881 3.062zm17.766 74.433l 17.333 39.034 6.314 3.101
    48.647 102.898h47.295l25 52.88v 7.883z" fill="#40B4E5"/><path d="M152.842 235.032L97.287
    117.514 152.842 0h47.295l 55.555 117.514 55.555 117.518h 47.295zm 97.287 0L0 117.514
    55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' ```
    frontend:mountPoints:importName:: (Required) The import name with an associated
    component to the mount point. * To configure a floating action button to display
    only on specific pages, configure the global.floatingactionbutton/config mount
    point in the backstage-plugin-global-floating-action-button plugin and set the
    visibleOnPaths property as shown in the following example: ```yaml - package:
    ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import disabled:
    false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    visibleOnPaths: [''/catalog'', ''/settings''] # end of fab config appIcons: -
    name: bulkImportIcon importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories
    importName: BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ```
    frontend:mountPoints:importName:: Enter the import name with an associated component
    to the mount point. * To hide a floating action button on specific pages, configure
    the global.floatingactionbutton/config mount point in the backstage-plugin-global-floating-action-button
    plugin and set the excludeOnPaths property as shown in the following example:
    ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    excludeOnPaths: [''/bulk-import''] # end of fab config appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    Enter the import name with an associated component to the mount point. ## Translation
    support The Global Floating Action Button plugin supports internationalization
    (i18n) through translation keys. You can use labelKey and toolTipKey properties
    to provide translation keys instead of static text. Example for using translation
    keys in dynamic configuration: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    translationResources: - importName: globalFloatingActionButtonTranslations ref:
    globalFloatingActionButtonTranslationRef mountPoints: - mountPoint: application/listener
    importName: DynamicGlobalFloatingActionButton - mountPoint: global.floatingactionbutton/config
    importName: NullComponent config: icon: github label: ''GitHub'' # Fallback text
    labelKey: ''fab.github.label'' # Translation key toolTip: ''GitHub Repository''
    # Fallback text toolTipKey: ''fab.github.tooltip'' # Translation key to: https://github.com/redhat-developer/rhdh-plugins
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    color: ''success'' icon: search label: ''Create'' # Fallback text labelKey: ''fab.create.label''
    # Translation key toolTip: ''Create entity'' # Fallback text toolTipKey: ''fab.create.tooltip''
    # Translation key to: ''/create'' showLabel: true ``` ## Enabling floating action
    button localization in RHDH You can enable translation key support for floating
    action buttons, so that users can onboard in their preferred language. In Developer
    Hub, all existing and newly created floating action buttons support localization
    using dedicated translation keys. The Global Floating Action Button plugin supports
    internationalization (i18n) through translation keys. You can use labelKey and
    toolTipKey'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:27:43.039232'
    uuid: bc941808-1753-4858-a010-96e87fa1f11e
  response: 'To configure a floating action button to display only on specific pages,
    you must configure the global.floatingactionbutton/config mount point in the backstage-plugin-global-floating-action-button
    plugin and set the visibleOnPaths property. An example provided shows setting
    this property as: visibleOnPaths: [''/catalog'', ''/settings''].'
  user_input: how i make backstage floating button show only on some pages?
- context:
  - 'Configuring a floating action button as a dynamic plugin You can configure the
    floating action button as a dynamic plugin to perform actions or open an internal
    or external link. You must have sufficient permissions as a platform engineer.
    To configure a floating action button as a dynamic plugin, complete any of the
    following tasks: Specify the global.floatingactionbutton/config mount point in
    your app config dynamic.yaml file. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of the floating action button configuration mountPoints: - mountPoint:
    global.floatingactionbutton/config importName: BulkImportPage config: slot: ''page-end''
    icon: <svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 24 24"
    height="24px" viewBox="0 0 24 24" width="24px" fill="#e8eaed"><g><rect fill="none"
    height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # End of the floating action button configuration appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    (Required) The import name with an associated component to the mount point. frontend:mountPoints:importName:icon::
    Use the svg value to display a black BulkImportPage icon. * To configure an action
    as a floating action button that opens an external link, specify the global.floatingactionbutton/config
    mount point in your dynamic-plugins.yaml file within the backstage-plugin-global-floating-action-button
    plugin. For example: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    mountPoints: - mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg" preserveAspectRatio="xMidYMid"><path
    d="M200.134 0l55.555 117.514-55.555 117.518h-47.295l55.555-117.518L152.84 0h47.295zM110.08
    99.836l20.056-38.092-2.29-8.868L102.847 0H55.552l48.647 102.898 5.881-3.062zm17.766
    74.433l-17.333-39.034-6.314-3.101-48.647 102.898h47.295l25-52.88v-7.883z" fill="#40B4E5"/><path
    d="M152.842 235.032L97.287 117.514 152.842 0h47.295l-55.555 117.514 55.555 117.518h-47.295zm-97.287
    0L0 117.514 55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' - mountPoint:
    global.floatingactionbutton/config importName: NullComponent config: icon: github
    label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat-developer/rhdh-plugins
    ``` frontend:mountPoints:importName:: Enter the import name with an associated
    component to the mount point. frontend:mountPoints:importName:icon:: (Optional)
    Enter the icon in Scalable Vector Graphics (SVG) format to display the Quay icon.
    * To configure a floating action button that contains a submenu, define the global.floatingactionbutton/config
    mount point in the same slot field in your dynamic-plugins.yaml file for multiple
    actions. The default slot is page-end when not specified. For example: ```yaml
    - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # Start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    # end of fab config appIcons: - name: bulkImportIcon importName: BulkImportIcon
    dynamicRoutes: - path: /bulk-import/repositories importName: BulkImportPage menuItem:
    icon: bulkImportIcon text: Bulk import package: ./dynamic plugins/dist/red hat
    developer hub backstage plugin global floating action button disabled: false pluginConfig:
    dynamicPlugins: frontend: red hat developer hub.backstage plugin global floating
    action button: mountPoints: mountPoint: application/listener importName: DynamicGlobalFloatingActionButton
    mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    icon: github label: ''Git'' toolTip: ''Github'' to: https://github.com/redhat
    developer/rhdh plugins mountPoint: global.floatingactionbutton/config importName:
    NullComponent config: icon: ''<svg viewBox="0 0 250 300" xmlns="http://www.w3.org/2000/svg"
    preserveAspectRatio="xMidYMid"><path d="M200.134 0l55.555 117.514 55.555 117.518h
    47.295l55.555 117.518L152.84 0h47.295zM110.08 99.836l20.056 38.092 2.29 8.868L102.847
    0H55.552l48.647 102.898 5.881 3.062zm17.766 74.433l 17.333 39.034 6.314 3.101
    48.647 102.898h47.295l25 52.88v 7.883z" fill="#40B4E5"/><path d="M152.842 235.032L97.287
    117.514 152.842 0h47.295l 55.555 117.514 55.555 117.518h 47.295zm 97.287 0L0 117.514
    55.555 0h47.296L47.295 117.514l55.556 117.518H55.555z" fill="#003764"/></svg>''
    label: ''Quay'' showLabel: true toolTip: ''Quay'' to: ''https://quay.io'' ```
    frontend:mountPoints:importName:: (Required) The import name with an associated
    component to the mount point. * To configure a floating action button to display
    only on specific pages, configure the global.floatingactionbutton/config mount
    point in the backstage-plugin-global-floating-action-button plugin and set the
    visibleOnPaths property as shown in the following example: ```yaml - package:
    ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import disabled:
    false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    visibleOnPaths: [''/catalog'', ''/settings''] # end of fab config appIcons: -
    name: bulkImportIcon importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories
    importName: BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ```
    frontend:mountPoints:importName:: Enter the import name with an associated component
    to the mount point. * To hide a floating action button on specific pages, configure
    the global.floatingactionbutton/config mount point in the backstage-plugin-global-floating-action-button
    plugin and set the excludeOnPaths property as shown in the following example:
    ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-bulk-import:
    # start of fab config mountPoints: - mountPoint: global.floatingactionbutton/config
    importName: BulkImportPage 1 config: slot: ''page-end'' icon: <svg xmlns="http://www.w3.org/2000/svg"
    enable-background="new 0 0 24 24" height="24px" viewBox="0 0 24 24" width="24px"
    fill="#e8eaed"><g><rect fill="none" height="24" width="24"/></g><g><path d="M11,7L9.6,8.4l2.6,2.6H2v2h10.2l-2.6,2.6L11,17l5-5L11,7z
    M20,19h-8v2h8c1.1,0,2-0.9,2-2V5c0-1.1-0.9-2-2-2h-8v2h8V19z"/></g></svg> label:
    ''Bulk import'' toolTip: ''Register multiple repositories in bulk'' to: /bulk-import/repositories
    excludeOnPaths: [''/bulk-import''] # end of fab config appIcons: - name: bulkImportIcon
    importName: BulkImportIcon dynamicRoutes: - path: /bulk-import/repositories importName:
    BulkImportPage menuItem: icon: bulkImportIcon text: Bulk import ``` frontend:mountPoints:importName::
    Enter the import name with an associated component to the mount point. ## Translation
    support The Global Floating Action Button plugin supports internationalization
    (i18n) through translation keys. You can use labelKey and toolTipKey properties
    to provide translation keys instead of static text. Example for using translation
    keys in dynamic configuration: ```yaml - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-global-floating-action-button
    disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-global-floating-action-button:
    translationResources: - importName: globalFloatingActionButtonTranslations ref:
    globalFloatingActionButtonTranslationRef mountPoints: - mountPoint: application/listener
    importName: DynamicGlobalFloatingActionButton - mountPoint: global.floatingactionbutton/config
    importName: NullComponent config: icon: github label: ''GitHub'' # Fallback text
    labelKey: ''fab.github.label'' # Translation key toolTip: ''GitHub Repository''
    # Fallback text toolTipKey: ''fab.github.tooltip'' # Translation key to: https://github.com/redhat-developer/rhdh-plugins
    - mountPoint: global.floatingactionbutton/config importName: NullComponent config:
    color: ''success'' icon: search label: ''Create'' # Fallback text labelKey: ''fab.create.label''
    # Translation key toolTip: ''Create entity'' # Fallback text toolTipKey: ''fab.create.tooltip''
    # Translation key to: ''/create'' showLabel: true ``` ## Enabling floating action
    button localization in RHDH You can enable translation key support for floating
    action buttons, so that users can onboard in their preferred language. In Developer
    Hub, all existing and newly created floating action buttons support localization
    using dedicated translation keys. The Global Floating Action Button plugin supports
    internationalization (i18n) through translation keys. You can use labelKey and
    toolTipKey'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:27:51.742979'
    uuid: 112a5681-c316-44bd-9043-41280c9a8ed9
  response: 'To configure a floating action button that opens an external link, such
    as to a Git repository, you must specify the `global.floatingactionbutton/config`
    mount point within the `backstage-plugin-global-floating-action-button` plugin
    in your `dynamic-plugins.yaml` file. The example configuration provided is: `mountPoint:
    global.floatingactionbutton/config`, `importName: NullComponent`, and a `config`
    section with the properties `icon: github`, `label: ''Git''`, `toolTip: ''Github''`,
    and `to: https://github.com/redhat-developer/rhdh-plugins`.'
  user_input: According to the documentation, what is the specific configuration required
    in the dynamic-plugins.yaml file to implement a floating action button that functions
    as an external link to a Git repository?
- context:
  - 'properties to provide translation keys instead of static text. The plugin provides
    the following built-in translation keys organized under the fab namespace: fab.create.label
    "Create" fab.create.tooltip "Create entity" fab.docs.label "Docs" fab.docs.tooltip
    "Documentation" fab.apis.label "APIs" fab.apis.tooltip "API Documentation" fab.github.label
    "GitHub" fab.github.tooltip "GitHub Repository" fab.bulkImport.label "Bulk Import"
    fab.bulkImport.tooltip "Register multiple repositories in bulk" fab.quay.label
    "Quay" fab.quay.tooltip "Quay Container Registry" The plugin includes translations
    for the following supported languages: English (default) French (fr) To ensure
    backward compatibility while providing translation support when available, the
    following order is used to resolve string translations: 1. If the labelKey is
    provided, the plugin will attempt to resolve the translation key 2. If the translation
    key is found, it will be used as the label 3. If the translation key is not found,
    the plugin will fall back to the label property [NOTE] ---- The same logic applies
    to toolTipKey and toolTip. ---- ### Internal translation implementation The plugin
    uses a centralized translation system where: The useTranslation() hook is called
    in components that render floating action buttons to ensure proper translation
    context initialization The translation function (t) is passed down to child components
    that need to resolve translation keys This internal architecture prevents infinite
    re render loops and ensures stable component rendering All components that use
    CustomFab must provide the translation function as a prop [NOTE] ---- When extending
    or modifying the plugin components, ensure that the useTranslation() hook is called
    in parent components and the t prop is passed to CustomFab instances to maintain
    proper translation functionality and prevent rendering issues. ---- ## Floating
    action button parameters Use the parameters as shown in the following table to
    configure your floating action button plugin. [NOTE] ---- If multiple floating
    button actions are assigned to the same slot value, the floating buttons are displayed
    as submenu options within the main floating action button. ---- # Customizing
    the Quickstart plugin ## About Quickstarts The Quickstart plugin provides guided
    onboarding for adminstrators of Red Hat Developer Hub. It displays a customizable
    drawer interface with interactive quickstart steps that help users get familiar
    with the platform. [NOTE] ---- If RBAC is enabled, Quickstart is only accesible
    to users with administrator permissions. ---- The Quickstart plugin is enabled
    by default and includes the following components: Set up authentication:: Set
    up secure login credentials to protect your account from unauthorized access.
    Configure RBAC:: Assign roles and permissions to control who can view, create,
    or edit resources, ensuring secure and efficient collaboration. Configure Git::
    Connect your Git providers, such as GitHub to manage code, automate workflows,
    and integrate with platform features. Manage plugins:: Browse and install extensions
    to add features, connect with external tools, and customize your experience. ##
    Customizing your Red Hat Developer Hub Quickstart As an administrator, you can
    configure the Red Hat Developer Hub Quickstart plugin to create customized onboarding
    for your Developer Hub users. You must have administrator permissions. 1. Update
    your app-config.yaml with the following code: ```yaml app: quickstart: - title:
    ''Welcome to Developer Hub'' description: ''Learn the basics of navigating the
    Developer Hub interface'' icon: ''home'' roles: [''admin'', ''developer''] # Show
    to both roles cta: text: ''Get Started'' link: ''/catalog'' - title: ''Create
    Your First Component'' description: ''Follow our guide to register your first
    software component'' icon: ''code'' roles: [''admin'', ''developer''] # Show to
    both roles cta: text: ''Create Component'' link: ''/catalog-import'' - title:
    ''Explore Templates'' description: ''Discover available software templates to
    bootstrap new projects'' icon: ''template'' roles: [''admin'', ''developer'']
    # Show to both roles cta: text: ''Browse Templates'' link: ''/create'' ``` where:
    title:: Enter the display title for the quickstart step. description:: Enter the
    brief description of what the step covers. icon:: (Optional) Enter the icon identifier.
    You can use a full image URL, a valid SVG path, or one of the following common
    keys: * home * group * category * extension * school * add * list * layers * star
    * favorite * bookmarks * queryStats * chart * business * storefront * folder *
    cloud * monitor * feedback * validate * security * help * support * quickstart
    * notifications * manageAccounts * logout * developerHub * account * admin * roles:
    Optional: Enter an array of user roles that must see this quickstart item. Supported
    values: [''admin'', ''developer'']. If not specified, defaults to [''admin''].
    * cta * text: Optional: Enter the CTA button text. * link: Optional: Enter the
    CTA target URL or route. ### Disabling the Quickstart plugin The Quickstart plugin
    is pre-loaded in Developer Hub with basic configuration properties, and enabled
    by default. To disable the Quickstart plugin, set the disabled property to true
    as shown in the following code: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/red hat developer hub backstage plugin
    quickstart disabled: true ``` ## Using Quickstart onboarding steps You can use
    the Quickstart onboarding steps to learn more about the administrator features
    of RHDH. (Optional) If RBAC is enabled, you must have administrator permissions
    to access to the Quickstart feature. To start a Quickstart step in Red Hat Developer
    Hub, complete the following steps: 1. In your RHDH navigation menu, click the
    Help (?) icon. 2. In the dropdown menu, click Quick start. 3. Select the Quickstart
    step that you would like to begin. 4. To close the Quickstart drawer, click Hide.
    ![About Quickstarts] [NOTE] ---- Your overall progress is tracked and displayed
    as a progress bar and a progress percentage in the Quickstart footer. ---- ##
    Enabling Quickstart localization in RHDH You can enable translation key support
    for Quickstart titles, descriptions, and CTAs, so that users can onboard in their
    preferred language. In Developer Hub, all existing and newly created Quickstart
    steps support localization using dedicated translation keys (titleKey, descriptionKey,
    cta.textKey). [NOTE] ---- If a translation key is present but the corresponding
    localized string is missing, the system defaults to the original text defined
    in the Quickstart configuration (title, description, text). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:28:00.743986'
    uuid: 5020ed20-5275-49e0-a08a-e8d2bba2f1e8
  response: The Quickstart plugin is enabled by default. To disable it, you must set
    the "disabled" property to true for the "red hat developer hub backstage plugin
    quickstart" package within your configuration files.
  user_input: How do I disable the default Quickstart plugin in my Backstage-based
    Red Hat Developer Hub instance?
- context:
  - 'properties to provide translation keys instead of static text. The plugin provides
    the following built-in translation keys organized under the fab namespace: fab.create.label
    "Create" fab.create.tooltip "Create entity" fab.docs.label "Docs" fab.docs.tooltip
    "Documentation" fab.apis.label "APIs" fab.apis.tooltip "API Documentation" fab.github.label
    "GitHub" fab.github.tooltip "GitHub Repository" fab.bulkImport.label "Bulk Import"
    fab.bulkImport.tooltip "Register multiple repositories in bulk" fab.quay.label
    "Quay" fab.quay.tooltip "Quay Container Registry" The plugin includes translations
    for the following supported languages: English (default) French (fr) To ensure
    backward compatibility while providing translation support when available, the
    following order is used to resolve string translations: 1. If the labelKey is
    provided, the plugin will attempt to resolve the translation key 2. If the translation
    key is found, it will be used as the label 3. If the translation key is not found,
    the plugin will fall back to the label property [NOTE] ---- The same logic applies
    to toolTipKey and toolTip. ---- ### Internal translation implementation The plugin
    uses a centralized translation system where: The useTranslation() hook is called
    in components that render floating action buttons to ensure proper translation
    context initialization The translation function (t) is passed down to child components
    that need to resolve translation keys This internal architecture prevents infinite
    re render loops and ensures stable component rendering All components that use
    CustomFab must provide the translation function as a prop [NOTE] ---- When extending
    or modifying the plugin components, ensure that the useTranslation() hook is called
    in parent components and the t prop is passed to CustomFab instances to maintain
    proper translation functionality and prevent rendering issues. ---- ## Floating
    action button parameters Use the parameters as shown in the following table to
    configure your floating action button plugin. [NOTE] ---- If multiple floating
    button actions are assigned to the same slot value, the floating buttons are displayed
    as submenu options within the main floating action button. ---- # Customizing
    the Quickstart plugin ## About Quickstarts The Quickstart plugin provides guided
    onboarding for adminstrators of Red Hat Developer Hub. It displays a customizable
    drawer interface with interactive quickstart steps that help users get familiar
    with the platform. [NOTE] ---- If RBAC is enabled, Quickstart is only accesible
    to users with administrator permissions. ---- The Quickstart plugin is enabled
    by default and includes the following components: Set up authentication:: Set
    up secure login credentials to protect your account from unauthorized access.
    Configure RBAC:: Assign roles and permissions to control who can view, create,
    or edit resources, ensuring secure and efficient collaboration. Configure Git::
    Connect your Git providers, such as GitHub to manage code, automate workflows,
    and integrate with platform features. Manage plugins:: Browse and install extensions
    to add features, connect with external tools, and customize your experience. ##
    Customizing your Red Hat Developer Hub Quickstart As an administrator, you can
    configure the Red Hat Developer Hub Quickstart plugin to create customized onboarding
    for your Developer Hub users. You must have administrator permissions. 1. Update
    your app-config.yaml with the following code: ```yaml app: quickstart: - title:
    ''Welcome to Developer Hub'' description: ''Learn the basics of navigating the
    Developer Hub interface'' icon: ''home'' roles: [''admin'', ''developer''] # Show
    to both roles cta: text: ''Get Started'' link: ''/catalog'' - title: ''Create
    Your First Component'' description: ''Follow our guide to register your first
    software component'' icon: ''code'' roles: [''admin'', ''developer''] # Show to
    both roles cta: text: ''Create Component'' link: ''/catalog-import'' - title:
    ''Explore Templates'' description: ''Discover available software templates to
    bootstrap new projects'' icon: ''template'' roles: [''admin'', ''developer'']
    # Show to both roles cta: text: ''Browse Templates'' link: ''/create'' ``` where:
    title:: Enter the display title for the quickstart step. description:: Enter the
    brief description of what the step covers. icon:: (Optional) Enter the icon identifier.
    You can use a full image URL, a valid SVG path, or one of the following common
    keys: * home * group * category * extension * school * add * list * layers * star
    * favorite * bookmarks * queryStats * chart * business * storefront * folder *
    cloud * monitor * feedback * validate * security * help * support * quickstart
    * notifications * manageAccounts * logout * developerHub * account * admin * roles:
    Optional: Enter an array of user roles that must see this quickstart item. Supported
    values: [''admin'', ''developer'']. If not specified, defaults to [''admin''].
    * cta * text: Optional: Enter the CTA button text. * link: Optional: Enter the
    CTA target URL or route. ### Disabling the Quickstart plugin The Quickstart plugin
    is pre-loaded in Developer Hub with basic configuration properties, and enabled
    by default. To disable the Quickstart plugin, set the disabled property to true
    as shown in the following code: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/red hat developer hub backstage plugin
    quickstart disabled: true ``` ## Using Quickstart onboarding steps You can use
    the Quickstart onboarding steps to learn more about the administrator features
    of RHDH. (Optional) If RBAC is enabled, you must have administrator permissions
    to access to the Quickstart feature. To start a Quickstart step in Red Hat Developer
    Hub, complete the following steps: 1. In your RHDH navigation menu, click the
    Help (?) icon. 2. In the dropdown menu, click Quick start. 3. Select the Quickstart
    step that you would like to begin. 4. To close the Quickstart drawer, click Hide.
    ![About Quickstarts] [NOTE] ---- Your overall progress is tracked and displayed
    as a progress bar and a progress percentage in the Quickstart footer. ---- ##
    Enabling Quickstart localization in RHDH You can enable translation key support
    for Quickstart titles, descriptions, and CTAs, so that users can onboard in their
    preferred language. In Developer Hub, all existing and newly created Quickstart
    steps support localization using dedicated translation keys (titleKey, descriptionKey,
    cta.textKey). [NOTE] ---- If a translation key is present but the corresponding
    localized string is missing, the system defaults to the original text defined
    in the Quickstart configuration (title, description, text). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:28:09.958934'
    uuid: 757ce64e-35cb-476f-a951-ac52856b7e40
  response: The Quickstart plugin is enabled by default and includes a component called
    "Configure Git" which is for connecting Git providers, such as GitHub, to manage
    code, automate workflows, and integrate with platform features. To use this, a
    user must click the Help (?) icon in the RHDH navigation menu, click "Quick start"
    in the dropdown menu, and then select the Quickstart step they want to begin.
  user_input: How can I use the Red Hat Developer Hub Quickstart plugin to guide my
    team through the process of connecting their GitHub providers to manage code and
    automate workflows?
- context:
  - 'properties to provide translation keys instead of static text. The plugin provides
    the following built-in translation keys organized under the fab namespace: fab.create.label
    "Create" fab.create.tooltip "Create entity" fab.docs.label "Docs" fab.docs.tooltip
    "Documentation" fab.apis.label "APIs" fab.apis.tooltip "API Documentation" fab.github.label
    "GitHub" fab.github.tooltip "GitHub Repository" fab.bulkImport.label "Bulk Import"
    fab.bulkImport.tooltip "Register multiple repositories in bulk" fab.quay.label
    "Quay" fab.quay.tooltip "Quay Container Registry" The plugin includes translations
    for the following supported languages: English (default) French (fr) To ensure
    backward compatibility while providing translation support when available, the
    following order is used to resolve string translations: 1. If the labelKey is
    provided, the plugin will attempt to resolve the translation key 2. If the translation
    key is found, it will be used as the label 3. If the translation key is not found,
    the plugin will fall back to the label property [NOTE] ---- The same logic applies
    to toolTipKey and toolTip. ---- ### Internal translation implementation The plugin
    uses a centralized translation system where: The useTranslation() hook is called
    in components that render floating action buttons to ensure proper translation
    context initialization The translation function (t) is passed down to child components
    that need to resolve translation keys This internal architecture prevents infinite
    re render loops and ensures stable component rendering All components that use
    CustomFab must provide the translation function as a prop [NOTE] ---- When extending
    or modifying the plugin components, ensure that the useTranslation() hook is called
    in parent components and the t prop is passed to CustomFab instances to maintain
    proper translation functionality and prevent rendering issues. ---- ## Floating
    action button parameters Use the parameters as shown in the following table to
    configure your floating action button plugin. [NOTE] ---- If multiple floating
    button actions are assigned to the same slot value, the floating buttons are displayed
    as submenu options within the main floating action button. ---- # Customizing
    the Quickstart plugin ## About Quickstarts The Quickstart plugin provides guided
    onboarding for adminstrators of Red Hat Developer Hub. It displays a customizable
    drawer interface with interactive quickstart steps that help users get familiar
    with the platform. [NOTE] ---- If RBAC is enabled, Quickstart is only accesible
    to users with administrator permissions. ---- The Quickstart plugin is enabled
    by default and includes the following components: Set up authentication:: Set
    up secure login credentials to protect your account from unauthorized access.
    Configure RBAC:: Assign roles and permissions to control who can view, create,
    or edit resources, ensuring secure and efficient collaboration. Configure Git::
    Connect your Git providers, such as GitHub to manage code, automate workflows,
    and integrate with platform features. Manage plugins:: Browse and install extensions
    to add features, connect with external tools, and customize your experience. ##
    Customizing your Red Hat Developer Hub Quickstart As an administrator, you can
    configure the Red Hat Developer Hub Quickstart plugin to create customized onboarding
    for your Developer Hub users. You must have administrator permissions. 1. Update
    your app-config.yaml with the following code: ```yaml app: quickstart: - title:
    ''Welcome to Developer Hub'' description: ''Learn the basics of navigating the
    Developer Hub interface'' icon: ''home'' roles: [''admin'', ''developer''] # Show
    to both roles cta: text: ''Get Started'' link: ''/catalog'' - title: ''Create
    Your First Component'' description: ''Follow our guide to register your first
    software component'' icon: ''code'' roles: [''admin'', ''developer''] # Show to
    both roles cta: text: ''Create Component'' link: ''/catalog-import'' - title:
    ''Explore Templates'' description: ''Discover available software templates to
    bootstrap new projects'' icon: ''template'' roles: [''admin'', ''developer'']
    # Show to both roles cta: text: ''Browse Templates'' link: ''/create'' ``` where:
    title:: Enter the display title for the quickstart step. description:: Enter the
    brief description of what the step covers. icon:: (Optional) Enter the icon identifier.
    You can use a full image URL, a valid SVG path, or one of the following common
    keys: * home * group * category * extension * school * add * list * layers * star
    * favorite * bookmarks * queryStats * chart * business * storefront * folder *
    cloud * monitor * feedback * validate * security * help * support * quickstart
    * notifications * manageAccounts * logout * developerHub * account * admin * roles:
    Optional: Enter an array of user roles that must see this quickstart item. Supported
    values: [''admin'', ''developer'']. If not specified, defaults to [''admin''].
    * cta * text: Optional: Enter the CTA button text. * link: Optional: Enter the
    CTA target URL or route. ### Disabling the Quickstart plugin The Quickstart plugin
    is pre-loaded in Developer Hub with basic configuration properties, and enabled
    by default. To disable the Quickstart plugin, set the disabled property to true
    as shown in the following code: ```yaml global: dynamic: includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/red hat developer hub backstage plugin
    quickstart disabled: true ``` ## Using Quickstart onboarding steps You can use
    the Quickstart onboarding steps to learn more about the administrator features
    of RHDH. (Optional) If RBAC is enabled, you must have administrator permissions
    to access to the Quickstart feature. To start a Quickstart step in Red Hat Developer
    Hub, complete the following steps: 1. In your RHDH navigation menu, click the
    Help (?) icon. 2. In the dropdown menu, click Quick start. 3. Select the Quickstart
    step that you would like to begin. 4. To close the Quickstart drawer, click Hide.
    ![About Quickstarts] [NOTE] ---- Your overall progress is tracked and displayed
    as a progress bar and a progress percentage in the Quickstart footer. ---- ##
    Enabling Quickstart localization in RHDH You can enable translation key support
    for Quickstart titles, descriptions, and CTAs, so that users can onboard in their
    preferred language. In Developer Hub, all existing and newly created Quickstart
    steps support localization using dedicated translation keys (titleKey, descriptionKey,
    cta.textKey). [NOTE] ---- If a translation key is present but the corresponding
    localized string is missing, the system defaults to the original text defined
    in the Quickstart configuration (title, description, text). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:28:18.348480'
    uuid: ed980e5a-faa2-42ae-ac20-7173aed2ea41
  response: 'The plugin provides the following built-in translation keys for Quay,
    organized under the fab namespace: the key for the label is "fab.quay.label" with
    the static text "Quay", and the key for the tooltip is "fab.quay.tooltip" with
    the static text "Quay Container Registry".'
  user_input: What are the specific built-in translation keys and their corresponding
    static text values for the Quay Container Registry in the floating action button
    plugin?
- context:
  - "1. For all Quickstart steps (both existing and new) in your configuration file,\
    \ you must define both the original text and the new localization keys. For example,\
    \ in the quickstart section of your custom app-config.yaml file, add the titleKey,\
    \ descriptionKey, and textKey values, as follows: app-config.yaml fragment ```yaml\
    \ app: quickstart: # Existing Quickstart steps should also be updated with keys\
    \ - title: 'Setup Authentication' titleKey: steps.setupAuth.title description:\
    \ 'Learn the basics of navigating the Developer Hub interface' descriptionKey:\
    \ steps.setupAuth.description icon: 'home' cta: text: 'Get Started' textKey: steps.setupAuth.ctaTitle\
    \ link: '/catalog' # ... ``` where: title:: (Mandatory) Fallback for the title.\
    \ titleKey:: Key for the translated title. description:: (Mandatory) Fallback\
    \ for the description. descriptionKey:: Key for the translated description. text::\
    \ (Mandatory) Fallback for the CTA text. textKey:: Key for the translated CTA\
    \ text. 2. In your dynamic-plugins.yaml file, add the translationResources section\
    \ to your red-hat-developer-hub-backstage-plugin-quickstart configuration, as\
    \ follows: app-config.yaml fragment ```yaml plugins: - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-quickstart\
    \ disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-quickstart:\
    \ # translationResources definition is required for translations to work translationResources:\
    \ - importName: quickstartTranslations ref: quickstartTranslationRef # ... other\
    \ configurations like mountPoints ... ``` where: importName:: Enter the name used\
    \ to reference the import. ref:: Reference to the resource definition. 3. In your\
    \ translation file, map the keys from the first step to the localized strings\
    \ for each supported language. allTranslations.json fragment ```yaml \"plugin.quickstart\"\
    : { \"en\": { \"steps.setupAuth.title\": \"Manage plugins EN\", \"steps.setupAuth.description\"\
    : \"EN Browse and install extensions to add features, connect with external tools,\
    \ and customize your experience.\", \"steps.setupAuth.ctaTitle\": \"Start\" },\
    \ \"fr\": { \"steps.setupAuth.title\": \"G\xE9rer les plugins FR\", \"steps.setupAuth.description\"\
    : \"FR Parcourez et installez des extensions pour ajouter des fonctionnalit\xE9\
    s, vous connecter \xE0 des outils externes et personnaliser votre exp\xE9rience.\"\
    , \"steps.setupAuth.ctaTitle\": \"Commencer\" } } ``` # Customizing the Tech Radar\
    \ page in Red Hat Developer Hub In Red Hat Developer Hub, the Tech Radar page\
    \ is provided by the tech-radar dynamic plugin, which is disabled by default.\
    \ For information about enabling dynamic plugins in Red Hat Developer Hub see\
    \ Configuring dynamic plugins. In Red Hat Developer Hub, you can configure Learning\
    \ Paths by passing the data into the app-config.yaml file as a proxy. The base\
    \ Tech Radar URL must include the /developer-hub/tech-radar proxy. [NOTE] ----\
    \ Due to the use of overlapping pathRewrites for both the tech-radar and homepage\
    \ quick access proxies, you must create the tech-radar configuration (^api/proxy/developer-hub/tech-radar)\
    \ before you create the homepage configuration (^/api/proxy/developer-hub). For\
    \ more information about customizing the Home page in Red Hat Developer Hub, see\
    \ Customizing the Home page in Red Hat Developer Hub. ---- You can provide data\
    \ to the Tech Radar page from the following sources: JSON files hosted on GitHub\
    \ or GitLab. A dedicated service that provides the Tech Radar data in JSON format\
    \ using an API. ## Customizing the Tech Radar page by using a JSON file For ease\
    \ of use and simplicity, you can configure the Tech Radar page by using a hosted\
    \ JSON file. You have specified the data sources for the Tech Radar plugin in\
    \ the integrations section of the app config.yaml file. For example, you have\
    \ enabled Developer Hub integration with GitHub. You have enabled the ./dynamic\
    \ plugins/dist/backstage community plugin tech radar and /dynamic plugins/dist/backstage\
    \ community plugin tech radar backend dynamic plugins. 1. Publish the JSON file\
    \ containing your Tech Radar data to a web server, such as GitHub or Gitlab. You\
    \ can find an example at https://raw.githubusercontent.com/backstage/community-plugins/main/workspaces/tech-radar/plugins/tech-radar-common/src/sampleTechRadarResponse.json.\
    \ 2. Configure Developer Hub to access the Tech Radar data from the hosted JSON\
    \ files, by adding the following to the app-config.yaml file: ```yaml techRadar:\
    \ url: <tech_radar_data_url> ``` <tech_radar_data_url>:: Enter the Tech Radar\
    \ data hosted JSON URL. ## Customizing the Tech Radar page by using a customization\
    \ service For advanced scenarios, you can host your Red Hat Developer Hub customization\
    \ service to provide data to all configurable Developer Hub pages, such as the\
    \ Tech Radar page. You can even use a different service for each page. You have\
    \ specified the data sources for the Tech Radar plugin in the integrations section\
    \ of the app config.yaml file. For example, you have enabled Developer Hub integration\
    \ with GitHub. You have enabled the ./dynamic plugins/dist/backstage community\
    \ plugin tech radar and /dynamic plugins/dist/backstage community plugin tech\
    \ radar backend dynamic plugins. 1. Deploy your Developer Hub customization service\
    \ on the same OpenShift Container Platform cluster as your Developer Hub instance.\
    \ You can find an example at red-hat-developer-hub-customization-provider, that\
    \ provides the same data as default Developer Hub data. The customization service\
    \ provides a Tech Radar data URL such as: http://<rhdh-customization-provider>/tech-radar.\
    \ 2. Add the dedicated service as an allowed host by adding the following code\
    \ to the app-config.yaml file: ```yaml backend: reading: allow: host: '<rhdh_customization_provider_base_url>'\
    \ ``` <rhdh_customization_provider_base_url>:: Enter the base URL of your Tech\
    \ Radar data URL, such as: <rhdh-customization-provider>. 3. Add the following\
    \ to the app-config.yaml file: ```yaml techRadar: url: <tech_radar_data_url> ```\
    \ <tech_radar_data_url>:: Enter your Tech Radar data URL, such as: http://<rhdh-customization-provider>/tech-radar.\
    \ # Customizing Red Hat Developer Hub appearance By modifying the visual aspects\
    \ of the interface, organizations can align Red Hat Developer Hub with their branding\
    \ guidelines and improve the overall user experience. The following default theme\
    \ configurations are available for Red Hat Developer Hub: The Red Hat Developer\
    \ Hub theme:: Default theme configurations to make your developer portal look\
    \ like a standard Red Hat Developer Hub instance. For more information, see The\
    \ Backstage theme:: Default theme configurations to make your developer portal\
    \ look like a standard Backstage instance. For more information, see You can change\
    \ or disable particular parameters in a default theme or create a fully customized\
    \ theme by modifying the app-config.yaml file. From the app-config.yaml file,\
    \ you can customize common theme components, including the following components:\
    \ Company name and logo Font color, size, and style of text in paragraphs, headings,\
    \ headers, and buttons Header color, gradient, and shape Button color Navigation\
    \ indicator color You can also customize some components from the Developer Hub\
    \ GUI, such as the theme mode (Light Theme, Dark Theme, or Auto). ## Customizing\
    \ the theme mode for your Developer Hub instance You can choose one of the following\
    \ theme modes for your"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:28:27.570859'
    uuid: 3a17c91f-b0f6-4c64-ad3b-c24d041dc471
  response: 'To customize the Tech Radar page using a hosted JSON file, you must first
    publish the JSON file with your Tech Radar data to a web server, such as GitHub
    or GitLab. An example of such a file can be found at https://raw.githubusercontent.com/backstage/community-plugins/main/workspaces/tech-radar/plugins/tech-radar-common/src/sampleTechRadarResponse.json.
    After the file is published, you configure the Developer Hub to access it by adding
    `techRadar: url: <tech_radar_data_url>` to the app-config.yaml file, where `<tech_radar_data_url>`
    is the URL of your hosted JSON data. Prerequisites for this configuration are
    that you have specified the data sources for the Tech Radar plugin in the integrations
    section of the app-config.yaml file and have enabled the `./dynamic plugins/dist/backstage
    community plugin tech radar` and `/dynamic plugins/dist/backstage community plugin
    tech radar backend` dynamic plugins.'
  user_input: so for my team i need to setup the tech radar page and the docs say
    i can use a JSON file for the data, what are all the steps i gotta do to configure
    the developer hub to use a hosted JSON file for the tech radar page data?
- context:
  - "1. For all Quickstart steps (both existing and new) in your configuration file,\
    \ you must define both the original text and the new localization keys. For example,\
    \ in the quickstart section of your custom app-config.yaml file, add the titleKey,\
    \ descriptionKey, and textKey values, as follows: app-config.yaml fragment ```yaml\
    \ app: quickstart: # Existing Quickstart steps should also be updated with keys\
    \ - title: 'Setup Authentication' titleKey: steps.setupAuth.title description:\
    \ 'Learn the basics of navigating the Developer Hub interface' descriptionKey:\
    \ steps.setupAuth.description icon: 'home' cta: text: 'Get Started' textKey: steps.setupAuth.ctaTitle\
    \ link: '/catalog' # ... ``` where: title:: (Mandatory) Fallback for the title.\
    \ titleKey:: Key for the translated title. description:: (Mandatory) Fallback\
    \ for the description. descriptionKey:: Key for the translated description. text::\
    \ (Mandatory) Fallback for the CTA text. textKey:: Key for the translated CTA\
    \ text. 2. In your dynamic-plugins.yaml file, add the translationResources section\
    \ to your red-hat-developer-hub-backstage-plugin-quickstart configuration, as\
    \ follows: app-config.yaml fragment ```yaml plugins: - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-quickstart\
    \ disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-quickstart:\
    \ # translationResources definition is required for translations to work translationResources:\
    \ - importName: quickstartTranslations ref: quickstartTranslationRef # ... other\
    \ configurations like mountPoints ... ``` where: importName:: Enter the name used\
    \ to reference the import. ref:: Reference to the resource definition. 3. In your\
    \ translation file, map the keys from the first step to the localized strings\
    \ for each supported language. allTranslations.json fragment ```yaml \"plugin.quickstart\"\
    : { \"en\": { \"steps.setupAuth.title\": \"Manage plugins EN\", \"steps.setupAuth.description\"\
    : \"EN Browse and install extensions to add features, connect with external tools,\
    \ and customize your experience.\", \"steps.setupAuth.ctaTitle\": \"Start\" },\
    \ \"fr\": { \"steps.setupAuth.title\": \"G\xE9rer les plugins FR\", \"steps.setupAuth.description\"\
    : \"FR Parcourez et installez des extensions pour ajouter des fonctionnalit\xE9\
    s, vous connecter \xE0 des outils externes et personnaliser votre exp\xE9rience.\"\
    , \"steps.setupAuth.ctaTitle\": \"Commencer\" } } ``` # Customizing the Tech Radar\
    \ page in Red Hat Developer Hub In Red Hat Developer Hub, the Tech Radar page\
    \ is provided by the tech-radar dynamic plugin, which is disabled by default.\
    \ For information about enabling dynamic plugins in Red Hat Developer Hub see\
    \ Configuring dynamic plugins. In Red Hat Developer Hub, you can configure Learning\
    \ Paths by passing the data into the app-config.yaml file as a proxy. The base\
    \ Tech Radar URL must include the /developer-hub/tech-radar proxy. [NOTE] ----\
    \ Due to the use of overlapping pathRewrites for both the tech-radar and homepage\
    \ quick access proxies, you must create the tech-radar configuration (^api/proxy/developer-hub/tech-radar)\
    \ before you create the homepage configuration (^/api/proxy/developer-hub). For\
    \ more information about customizing the Home page in Red Hat Developer Hub, see\
    \ Customizing the Home page in Red Hat Developer Hub. ---- You can provide data\
    \ to the Tech Radar page from the following sources: JSON files hosted on GitHub\
    \ or GitLab. A dedicated service that provides the Tech Radar data in JSON format\
    \ using an API. ## Customizing the Tech Radar page by using a JSON file For ease\
    \ of use and simplicity, you can configure the Tech Radar page by using a hosted\
    \ JSON file. You have specified the data sources for the Tech Radar plugin in\
    \ the integrations section of the app config.yaml file. For example, you have\
    \ enabled Developer Hub integration with GitHub. You have enabled the ./dynamic\
    \ plugins/dist/backstage community plugin tech radar and /dynamic plugins/dist/backstage\
    \ community plugin tech radar backend dynamic plugins. 1. Publish the JSON file\
    \ containing your Tech Radar data to a web server, such as GitHub or Gitlab. You\
    \ can find an example at https://raw.githubusercontent.com/backstage/community-plugins/main/workspaces/tech-radar/plugins/tech-radar-common/src/sampleTechRadarResponse.json.\
    \ 2. Configure Developer Hub to access the Tech Radar data from the hosted JSON\
    \ files, by adding the following to the app-config.yaml file: ```yaml techRadar:\
    \ url: <tech_radar_data_url> ``` <tech_radar_data_url>:: Enter the Tech Radar\
    \ data hosted JSON URL. ## Customizing the Tech Radar page by using a customization\
    \ service For advanced scenarios, you can host your Red Hat Developer Hub customization\
    \ service to provide data to all configurable Developer Hub pages, such as the\
    \ Tech Radar page. You can even use a different service for each page. You have\
    \ specified the data sources for the Tech Radar plugin in the integrations section\
    \ of the app config.yaml file. For example, you have enabled Developer Hub integration\
    \ with GitHub. You have enabled the ./dynamic plugins/dist/backstage community\
    \ plugin tech radar and /dynamic plugins/dist/backstage community plugin tech\
    \ radar backend dynamic plugins. 1. Deploy your Developer Hub customization service\
    \ on the same OpenShift Container Platform cluster as your Developer Hub instance.\
    \ You can find an example at red-hat-developer-hub-customization-provider, that\
    \ provides the same data as default Developer Hub data. The customization service\
    \ provides a Tech Radar data URL such as: http://<rhdh-customization-provider>/tech-radar.\
    \ 2. Add the dedicated service as an allowed host by adding the following code\
    \ to the app-config.yaml file: ```yaml backend: reading: allow: host: '<rhdh_customization_provider_base_url>'\
    \ ``` <rhdh_customization_provider_base_url>:: Enter the base URL of your Tech\
    \ Radar data URL, such as: <rhdh-customization-provider>. 3. Add the following\
    \ to the app-config.yaml file: ```yaml techRadar: url: <tech_radar_data_url> ```\
    \ <tech_radar_data_url>:: Enter your Tech Radar data URL, such as: http://<rhdh-customization-provider>/tech-radar.\
    \ # Customizing Red Hat Developer Hub appearance By modifying the visual aspects\
    \ of the interface, organizations can align Red Hat Developer Hub with their branding\
    \ guidelines and improve the overall user experience. The following default theme\
    \ configurations are available for Red Hat Developer Hub: The Red Hat Developer\
    \ Hub theme:: Default theme configurations to make your developer portal look\
    \ like a standard Red Hat Developer Hub instance. For more information, see The\
    \ Backstage theme:: Default theme configurations to make your developer portal\
    \ look like a standard Backstage instance. For more information, see You can change\
    \ or disable particular parameters in a default theme or create a fully customized\
    \ theme by modifying the app-config.yaml file. From the app-config.yaml file,\
    \ you can customize common theme components, including the following components:\
    \ Company name and logo Font color, size, and style of text in paragraphs, headings,\
    \ headers, and buttons Header color, gradient, and shape Button color Navigation\
    \ indicator color You can also customize some components from the Developer Hub\
    \ GUI, such as the theme mode (Light Theme, Dark Theme, or Auto). ## Customizing\
    \ the theme mode for your Developer Hub instance You can choose one of the following\
    \ theme modes for your"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:28:39.655780'
    uuid: 08e41ec4-89c4-4277-a4b9-a13bf6d1f694
  response: 'To use a JSON file from GitHub for the Tech Radar page, you must have
    already specified GitHub as a data source in the integrations section of the app-config.yaml
    file and enabled the `./dynamic plugins/dist/backstage community plugin tech radar`
    and `/dynamic plugins/dist/backstage community plugin tech radar backend` dynamic
    plugins. The process is to first publish the JSON file containing your Tech Radar
    data to a web server, such as GitHub. After that, you must configure the Developer
    Hub to access the data by adding `techRadar: url: <tech_radar_data_url>` to the
    `app-config.yaml` file, where `<tech_radar_data_url>` is the URL of the hosted
    JSON file.'
  user_input: What are the prerequisites and steps for configuring the Tech Radar
    page in Red Hat Developer Hub using a JSON data file hosted on GitHub?
- context:
  - "1. For all Quickstart steps (both existing and new) in your configuration file,\
    \ you must define both the original text and the new localization keys. For example,\
    \ in the quickstart section of your custom app-config.yaml file, add the titleKey,\
    \ descriptionKey, and textKey values, as follows: app-config.yaml fragment ```yaml\
    \ app: quickstart: # Existing Quickstart steps should also be updated with keys\
    \ - title: 'Setup Authentication' titleKey: steps.setupAuth.title description:\
    \ 'Learn the basics of navigating the Developer Hub interface' descriptionKey:\
    \ steps.setupAuth.description icon: 'home' cta: text: 'Get Started' textKey: steps.setupAuth.ctaTitle\
    \ link: '/catalog' # ... ``` where: title:: (Mandatory) Fallback for the title.\
    \ titleKey:: Key for the translated title. description:: (Mandatory) Fallback\
    \ for the description. descriptionKey:: Key for the translated description. text::\
    \ (Mandatory) Fallback for the CTA text. textKey:: Key for the translated CTA\
    \ text. 2. In your dynamic-plugins.yaml file, add the translationResources section\
    \ to your red-hat-developer-hub-backstage-plugin-quickstart configuration, as\
    \ follows: app-config.yaml fragment ```yaml plugins: - package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-quickstart\
    \ disabled: false pluginConfig: dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-quickstart:\
    \ # translationResources definition is required for translations to work translationResources:\
    \ - importName: quickstartTranslations ref: quickstartTranslationRef # ... other\
    \ configurations like mountPoints ... ``` where: importName:: Enter the name used\
    \ to reference the import. ref:: Reference to the resource definition. 3. In your\
    \ translation file, map the keys from the first step to the localized strings\
    \ for each supported language. allTranslations.json fragment ```yaml \"plugin.quickstart\"\
    : { \"en\": { \"steps.setupAuth.title\": \"Manage plugins EN\", \"steps.setupAuth.description\"\
    : \"EN Browse and install extensions to add features, connect with external tools,\
    \ and customize your experience.\", \"steps.setupAuth.ctaTitle\": \"Start\" },\
    \ \"fr\": { \"steps.setupAuth.title\": \"G\xE9rer les plugins FR\", \"steps.setupAuth.description\"\
    : \"FR Parcourez et installez des extensions pour ajouter des fonctionnalit\xE9\
    s, vous connecter \xE0 des outils externes et personnaliser votre exp\xE9rience.\"\
    , \"steps.setupAuth.ctaTitle\": \"Commencer\" } } ``` # Customizing the Tech Radar\
    \ page in Red Hat Developer Hub In Red Hat Developer Hub, the Tech Radar page\
    \ is provided by the tech-radar dynamic plugin, which is disabled by default.\
    \ For information about enabling dynamic plugins in Red Hat Developer Hub see\
    \ Configuring dynamic plugins. In Red Hat Developer Hub, you can configure Learning\
    \ Paths by passing the data into the app-config.yaml file as a proxy. The base\
    \ Tech Radar URL must include the /developer-hub/tech-radar proxy. [NOTE] ----\
    \ Due to the use of overlapping pathRewrites for both the tech-radar and homepage\
    \ quick access proxies, you must create the tech-radar configuration (^api/proxy/developer-hub/tech-radar)\
    \ before you create the homepage configuration (^/api/proxy/developer-hub). For\
    \ more information about customizing the Home page in Red Hat Developer Hub, see\
    \ Customizing the Home page in Red Hat Developer Hub. ---- You can provide data\
    \ to the Tech Radar page from the following sources: JSON files hosted on GitHub\
    \ or GitLab. A dedicated service that provides the Tech Radar data in JSON format\
    \ using an API. ## Customizing the Tech Radar page by using a JSON file For ease\
    \ of use and simplicity, you can configure the Tech Radar page by using a hosted\
    \ JSON file. You have specified the data sources for the Tech Radar plugin in\
    \ the integrations section of the app config.yaml file. For example, you have\
    \ enabled Developer Hub integration with GitHub. You have enabled the ./dynamic\
    \ plugins/dist/backstage community plugin tech radar and /dynamic plugins/dist/backstage\
    \ community plugin tech radar backend dynamic plugins. 1. Publish the JSON file\
    \ containing your Tech Radar data to a web server, such as GitHub or Gitlab. You\
    \ can find an example at https://raw.githubusercontent.com/backstage/community-plugins/main/workspaces/tech-radar/plugins/tech-radar-common/src/sampleTechRadarResponse.json.\
    \ 2. Configure Developer Hub to access the Tech Radar data from the hosted JSON\
    \ files, by adding the following to the app-config.yaml file: ```yaml techRadar:\
    \ url: <tech_radar_data_url> ``` <tech_radar_data_url>:: Enter the Tech Radar\
    \ data hosted JSON URL. ## Customizing the Tech Radar page by using a customization\
    \ service For advanced scenarios, you can host your Red Hat Developer Hub customization\
    \ service to provide data to all configurable Developer Hub pages, such as the\
    \ Tech Radar page. You can even use a different service for each page. You have\
    \ specified the data sources for the Tech Radar plugin in the integrations section\
    \ of the app config.yaml file. For example, you have enabled Developer Hub integration\
    \ with GitHub. You have enabled the ./dynamic plugins/dist/backstage community\
    \ plugin tech radar and /dynamic plugins/dist/backstage community plugin tech\
    \ radar backend dynamic plugins. 1. Deploy your Developer Hub customization service\
    \ on the same OpenShift Container Platform cluster as your Developer Hub instance.\
    \ You can find an example at red-hat-developer-hub-customization-provider, that\
    \ provides the same data as default Developer Hub data. The customization service\
    \ provides a Tech Radar data URL such as: http://<rhdh-customization-provider>/tech-radar.\
    \ 2. Add the dedicated service as an allowed host by adding the following code\
    \ to the app-config.yaml file: ```yaml backend: reading: allow: host: '<rhdh_customization_provider_base_url>'\
    \ ``` <rhdh_customization_provider_base_url>:: Enter the base URL of your Tech\
    \ Radar data URL, such as: <rhdh-customization-provider>. 3. Add the following\
    \ to the app-config.yaml file: ```yaml techRadar: url: <tech_radar_data_url> ```\
    \ <tech_radar_data_url>:: Enter your Tech Radar data URL, such as: http://<rhdh-customization-provider>/tech-radar.\
    \ # Customizing Red Hat Developer Hub appearance By modifying the visual aspects\
    \ of the interface, organizations can align Red Hat Developer Hub with their branding\
    \ guidelines and improve the overall user experience. The following default theme\
    \ configurations are available for Red Hat Developer Hub: The Red Hat Developer\
    \ Hub theme:: Default theme configurations to make your developer portal look\
    \ like a standard Red Hat Developer Hub instance. For more information, see The\
    \ Backstage theme:: Default theme configurations to make your developer portal\
    \ look like a standard Backstage instance. For more information, see You can change\
    \ or disable particular parameters in a default theme or create a fully customized\
    \ theme by modifying the app-config.yaml file. From the app-config.yaml file,\
    \ you can customize common theme components, including the following components:\
    \ Company name and logo Font color, size, and style of text in paragraphs, headings,\
    \ headers, and buttons Header color, gradient, and shape Button color Navigation\
    \ indicator color You can also customize some components from the Developer Hub\
    \ GUI, such as the theme mode (Light Theme, Dark Theme, or Auto). ## Customizing\
    \ the theme mode for your Developer Hub instance You can choose one of the following\
    \ theme modes for your"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:28:46.619284'
    uuid: 9d02e656-4982-46a1-8b58-9395b940cc8f
  response: 'You can provide data to the Tech Radar page from JSON files hosted on
    GitLab. To do this, you must first publish the JSON file containing your Tech
    Radar data to a web server, such as GitLab. Afterwards, you need to configure
    Developer Hub to access the data from the hosted JSON file by adding the following
    to the app-config.yaml file: `techRadar: url: <tech_radar_data_url>`, where `<tech_radar_data_url>`
    is the URL of the hosted JSON data.'
  user_input: For customizing the Tech Radar page in Red Hat Developer Hub, i want
    to use a JSON file from our GitLab instance, what is the way to do that, like
    what are the steps for publishing the file and then configuring Developer Hub
    to use that data source?
- context:
  - 'Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub, theme configurations
    are used to change the look and feel of different UI components. So, you might
    notice changes in different UI components, such as buttons, tabs, sidebars, cards,
    and tables along with some changes in background color and font used on the RHDH
    pages. ---- The default theme mode is Auto, which automatically sets the light
    or dark theme based on your system preferences. You are logged in to the Developer
    Hub web console. 1. From the Developer Hub web console, click Settings. 2. From
    the Appearance panel, click Light, Dark, or Auto to change the theme mode. ![custom
    theme mode 1] ## Customizing the branding logo of your Developer Hub instance
    You can customize the branding logo of your Developer Hub instance by configuring
    the branding section in the app-config.yaml file, as shown in the following example:
    ```yaml app: branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO} 1 iconLogo: ${BASE64_EMBEDDED_ICON_LOGO}
    2 ``` fullLogo:: Enter the logo on the expanded (pinned) sidebar as a base64 encoded
    image. iconLogo:: Enter the logo on the collapsed (unpinned) sidebar as a base64
    encoded image. You can format the BASE64_EMBEDDED_FULL_LOGO environment variable
    as follows: ```yaml BASE64_EMBEDDED_FULL_LOGO: "data:_<media_type>_;base64,<base64_data>"
    ``` The following example demonstrates how to customize the BASE64_EMBEDDED_FULL_LOGO
    using the data:_<media_type>;base64,<base64_data>_ format: ```yaml SVGLOGOBASE64=$(base64
    i logo.svg) BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,$SVGLOGOBASE64"
    ``` Replace image/svg+xml with the correct media type for your image (for example,
    image/png and image/jpeg), and adjust the file extension accordingly. As a result,
    you can embed the logo directly without referencing an external file. You can
    also customize the width of the branding logo by setting a value for the fullLogoWidth
    field in the branding section, as shown in the following example: ```yaml app:
    branding: fullLogoWidth: 110px # ... ``` fullLogoWidth:: The default value for
    the logo width is 110px. The following units are supported: integer, px, em, rem,
    percentage. ## About the sidebar menu items for your Developer Hub instance The
    sidebar menu in Red Hat Developer Hub consists of two main parts that you can
    configure: Dynamic plugin menu items:: Your preferences and your active plugins
    define dynamically one part of the sidebar menu. Main menu items:: The core navigation
    structure of sidebar is static. * Dynamic plugin menu items: These items are displayed
    beneath the main menu and can be customized based on the plugins installed. The
    main menu items section is dynamic and can change based on your preferences and
    installed plugins. ### Customizing the sidebar menu items for your Developer Hub
    instance Customize the main menu items using the following steps: 1. Open the
    app-config.yaml file. 1. To customize the order and parent-child relationships
    for the main menu items, use the dynamicPlugins.frontend.default.main-menu-items.menuItems
    field. 2. For dynamic plugin menu items, use the dynamicPlugins.frontend.<package_name>.menuItems
    field. ```yaml dynamicPlugins: frontend: default.main menu items: menuItems: default.home:
    title: Home icon: home priority: 100 enabled: true default.my group: title: My
    Group icon: group priority: 90 enabled: true default.catalog: title: Catalog icon:
    category to: catalog priority: 80 enabled: true default.apis: title: APIs icon:
    extension to: api docs priority: 70 enabled: true default.learning path: title:
    Learning Paths icon: school, to: learning paths priority: 60 enabled: true default.create:
    title: Self service icon: add to: create priority: 50 enabled: true ``` ### Enabling
    sidebar menu items localization in RHDH You can add translation key support for
    sidebar menu items, so that users can onboard in their preferred language. In
    Developer Hub, all existing and newly created sidebar menu items support localization
    using the titleKey translation key. [NOTE] ---- If a translation key is present
    but the corresponding localized string is missing, the system defaults to the
    original text defined in the sidebar menu items configuration (title). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application. 1. For sidebar menu items in your configuration file,
    you must define both the original text and the new localization keys. For example,
    in the dynamicPlugins.frontend.default.main-menu-items.menuItems.default.favorites
    section of your app-config.yaml file, add the titleKey, as follows: Example app-config.yaml
    fragment ```yaml dynamicPlugins: frontend: default.main menu items: menuItems:
    default.favorites: title: Favorites titleKey: menuItem.favorites icon: favorite
    priority: 100 enabled: true ``` 2. In your translation file, map the titleKey
    from the first step to the localized strings for each supported language. Example
    allTranslations.json fragment ```yaml { "rhdh": { "en": { "menuItem.favorites":
    "Favorites" }, "fr": { "menuItem.favorites": "Favoris" } } } ``` ### Configuring
    a dynamic plugin menu item for your Developer Hub instance Configure a dynamic
    plugin menu item using the following step: In the app config.yaml file, update
    the menuItems section of your <plugin_name> plugin. For example: ```yaml dynamicPlugins:
    frontend: _<plugin_name>_: menuItems: <menu_item_name>: icon: # home | group |
    category | extension | school | _<my_icon>_ title: _<plugin_page_title>_ priority:
    10 parent: favorites enabled: true ``` <plugin_name>:: Enter the plugin name.
    This name is the same as the scalprum.name key in the package.json file. <menu_item_name>::
    Enter a unique name in the main sidebar navigation for either a standalone menu
    item or a parent menu item. If this field specifies a plugin menu item, the name
    of the menu item must match the name using in the corresponding path in dynamicRoutes.
    For example, if dynamicRoutes defines path: /my-plugin, then menu_item_name must
    be defined as my-plugin. icon:: (Optional) Enter the icon name. You can use any
    of the following icons: * Default icons, such as home, group, category, extension,
    and school. To use default icons, set the icon as an (" ") empty string. * A custom
    icon, where <my_icon> specifies the name of your custom icon * An SVG icon, such
    as: icon: <svg width="20px" height="20px" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"
    fill="#ffffff">&#8230;&#8203;</svg> * An HTML image, such as: icon: https://img.icons8.com/ios-glyphs/20/FFFFFF/shop.png
    title:: (Optional) Enter the menu item title. Omit it when the title is already
    specified in the dynamicRoutes configuration under menuItem.text. To hide the
    title from the sidebar, set the title as an (" ") empty string. priority:: (Optional)
    Enter an integer value to set the order in which menu items'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:28:54.508371'
    uuid: 6be53892-0f1e-4436-8eee-22ad5194b838
  response: 'To enable localization for sidebar menu items in Red Hat Developer Hub,
    you can use the `titleKey` translation key. First, for the desired sidebar menu
    item in your configuration file (such as `app-config.yaml`), you must define both
    the original text using `title` and the new localization key using `titleKey`.
    For example, for a ''Favorites'' menu item, you would add `titleKey: menuItem.favorites`.
    Second, in your translation file, you must map that `titleKey` to the localized
    strings for each language you support. It is important to note that if a translation
    key is present but the corresponding localized string is missing, or if no translation
    key is defined, the system will default to displaying the original text from the
    `title` field.'
  user_input: How do I enable localization for sidebar menu items in Red Hat Developer
    Hub using the titleKey translation key in the app-config.yaml file?
- context:
  - 'Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub, theme configurations
    are used to change the look and feel of different UI components. So, you might
    notice changes in different UI components, such as buttons, tabs, sidebars, cards,
    and tables along with some changes in background color and font used on the RHDH
    pages. ---- The default theme mode is Auto, which automatically sets the light
    or dark theme based on your system preferences. You are logged in to the Developer
    Hub web console. 1. From the Developer Hub web console, click Settings. 2. From
    the Appearance panel, click Light, Dark, or Auto to change the theme mode. ![custom
    theme mode 1] ## Customizing the branding logo of your Developer Hub instance
    You can customize the branding logo of your Developer Hub instance by configuring
    the branding section in the app-config.yaml file, as shown in the following example:
    ```yaml app: branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO} 1 iconLogo: ${BASE64_EMBEDDED_ICON_LOGO}
    2 ``` fullLogo:: Enter the logo on the expanded (pinned) sidebar as a base64 encoded
    image. iconLogo:: Enter the logo on the collapsed (unpinned) sidebar as a base64
    encoded image. You can format the BASE64_EMBEDDED_FULL_LOGO environment variable
    as follows: ```yaml BASE64_EMBEDDED_FULL_LOGO: "data:_<media_type>_;base64,<base64_data>"
    ``` The following example demonstrates how to customize the BASE64_EMBEDDED_FULL_LOGO
    using the data:_<media_type>;base64,<base64_data>_ format: ```yaml SVGLOGOBASE64=$(base64
    i logo.svg) BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,$SVGLOGOBASE64"
    ``` Replace image/svg+xml with the correct media type for your image (for example,
    image/png and image/jpeg), and adjust the file extension accordingly. As a result,
    you can embed the logo directly without referencing an external file. You can
    also customize the width of the branding logo by setting a value for the fullLogoWidth
    field in the branding section, as shown in the following example: ```yaml app:
    branding: fullLogoWidth: 110px # ... ``` fullLogoWidth:: The default value for
    the logo width is 110px. The following units are supported: integer, px, em, rem,
    percentage. ## About the sidebar menu items for your Developer Hub instance The
    sidebar menu in Red Hat Developer Hub consists of two main parts that you can
    configure: Dynamic plugin menu items:: Your preferences and your active plugins
    define dynamically one part of the sidebar menu. Main menu items:: The core navigation
    structure of sidebar is static. * Dynamic plugin menu items: These items are displayed
    beneath the main menu and can be customized based on the plugins installed. The
    main menu items section is dynamic and can change based on your preferences and
    installed plugins. ### Customizing the sidebar menu items for your Developer Hub
    instance Customize the main menu items using the following steps: 1. Open the
    app-config.yaml file. 1. To customize the order and parent-child relationships
    for the main menu items, use the dynamicPlugins.frontend.default.main-menu-items.menuItems
    field. 2. For dynamic plugin menu items, use the dynamicPlugins.frontend.<package_name>.menuItems
    field. ```yaml dynamicPlugins: frontend: default.main menu items: menuItems: default.home:
    title: Home icon: home priority: 100 enabled: true default.my group: title: My
    Group icon: group priority: 90 enabled: true default.catalog: title: Catalog icon:
    category to: catalog priority: 80 enabled: true default.apis: title: APIs icon:
    extension to: api docs priority: 70 enabled: true default.learning path: title:
    Learning Paths icon: school, to: learning paths priority: 60 enabled: true default.create:
    title: Self service icon: add to: create priority: 50 enabled: true ``` ### Enabling
    sidebar menu items localization in RHDH You can add translation key support for
    sidebar menu items, so that users can onboard in their preferred language. In
    Developer Hub, all existing and newly created sidebar menu items support localization
    using the titleKey translation key. [NOTE] ---- If a translation key is present
    but the corresponding localized string is missing, the system defaults to the
    original text defined in the sidebar menu items configuration (title). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application. 1. For sidebar menu items in your configuration file,
    you must define both the original text and the new localization keys. For example,
    in the dynamicPlugins.frontend.default.main-menu-items.menuItems.default.favorites
    section of your app-config.yaml file, add the titleKey, as follows: Example app-config.yaml
    fragment ```yaml dynamicPlugins: frontend: default.main menu items: menuItems:
    default.favorites: title: Favorites titleKey: menuItem.favorites icon: favorite
    priority: 100 enabled: true ``` 2. In your translation file, map the titleKey
    from the first step to the localized strings for each supported language. Example
    allTranslations.json fragment ```yaml { "rhdh": { "en": { "menuItem.favorites":
    "Favorites" }, "fr": { "menuItem.favorites": "Favoris" } } } ``` ### Configuring
    a dynamic plugin menu item for your Developer Hub instance Configure a dynamic
    plugin menu item using the following step: In the app config.yaml file, update
    the menuItems section of your <plugin_name> plugin. For example: ```yaml dynamicPlugins:
    frontend: _<plugin_name>_: menuItems: <menu_item_name>: icon: # home | group |
    category | extension | school | _<my_icon>_ title: _<plugin_page_title>_ priority:
    10 parent: favorites enabled: true ``` <plugin_name>:: Enter the plugin name.
    This name is the same as the scalprum.name key in the package.json file. <menu_item_name>::
    Enter a unique name in the main sidebar navigation for either a standalone menu
    item or a parent menu item. If this field specifies a plugin menu item, the name
    of the menu item must match the name using in the corresponding path in dynamicRoutes.
    For example, if dynamicRoutes defines path: /my-plugin, then menu_item_name must
    be defined as my-plugin. icon:: (Optional) Enter the icon name. You can use any
    of the following icons: * Default icons, such as home, group, category, extension,
    and school. To use default icons, set the icon as an (" ") empty string. * A custom
    icon, where <my_icon> specifies the name of your custom icon * An SVG icon, such
    as: icon: <svg width="20px" height="20px" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"
    fill="#ffffff">&#8230;&#8203;</svg> * An HTML image, such as: icon: https://img.icons8.com/ios-glyphs/20/FFFFFF/shop.png
    title:: (Optional) Enter the menu item title. Omit it when the title is already
    specified in the dynamicRoutes configuration under menuItem.text. To hide the
    title from the sidebar, set the title as an (" ") empty string. priority:: (Optional)
    Enter an integer value to set the order in which menu items'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:04.230819'
    uuid: 7db7e7ce-dc6e-44cc-8c70-673c305e7eb7
  response: 'You can format the BASE64_EMBEDDED_FULL_LOGO environment variable using
    the format: \"data:<media_type>;base64,<base64_data>\". An example of this is:
    `SVGLOGOBASE64=$(base64 i logo.svg)` and `BASE64_EMBEDDED_FULL_LOGO=\"data:image/svg+xml;base64,$SVGLOGOBASE64\"`.
    You need to replace `image/svg+xml` with the correct media type for your image,
    such as `image/png` or `image/jpeg`.'
  user_input: how do i format the BASE64_EMBEDDED_FULL_LOGO envirnment varible?
- context:
  - 'Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub, theme configurations
    are used to change the look and feel of different UI components. So, you might
    notice changes in different UI components, such as buttons, tabs, sidebars, cards,
    and tables along with some changes in background color and font used on the RHDH
    pages. ---- The default theme mode is Auto, which automatically sets the light
    or dark theme based on your system preferences. You are logged in to the Developer
    Hub web console. 1. From the Developer Hub web console, click Settings. 2. From
    the Appearance panel, click Light, Dark, or Auto to change the theme mode. ![custom
    theme mode 1] ## Customizing the branding logo of your Developer Hub instance
    You can customize the branding logo of your Developer Hub instance by configuring
    the branding section in the app-config.yaml file, as shown in the following example:
    ```yaml app: branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO} 1 iconLogo: ${BASE64_EMBEDDED_ICON_LOGO}
    2 ``` fullLogo:: Enter the logo on the expanded (pinned) sidebar as a base64 encoded
    image. iconLogo:: Enter the logo on the collapsed (unpinned) sidebar as a base64
    encoded image. You can format the BASE64_EMBEDDED_FULL_LOGO environment variable
    as follows: ```yaml BASE64_EMBEDDED_FULL_LOGO: "data:_<media_type>_;base64,<base64_data>"
    ``` The following example demonstrates how to customize the BASE64_EMBEDDED_FULL_LOGO
    using the data:_<media_type>;base64,<base64_data>_ format: ```yaml SVGLOGOBASE64=$(base64
    i logo.svg) BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,$SVGLOGOBASE64"
    ``` Replace image/svg+xml with the correct media type for your image (for example,
    image/png and image/jpeg), and adjust the file extension accordingly. As a result,
    you can embed the logo directly without referencing an external file. You can
    also customize the width of the branding logo by setting a value for the fullLogoWidth
    field in the branding section, as shown in the following example: ```yaml app:
    branding: fullLogoWidth: 110px # ... ``` fullLogoWidth:: The default value for
    the logo width is 110px. The following units are supported: integer, px, em, rem,
    percentage. ## About the sidebar menu items for your Developer Hub instance The
    sidebar menu in Red Hat Developer Hub consists of two main parts that you can
    configure: Dynamic plugin menu items:: Your preferences and your active plugins
    define dynamically one part of the sidebar menu. Main menu items:: The core navigation
    structure of sidebar is static. * Dynamic plugin menu items: These items are displayed
    beneath the main menu and can be customized based on the plugins installed. The
    main menu items section is dynamic and can change based on your preferences and
    installed plugins. ### Customizing the sidebar menu items for your Developer Hub
    instance Customize the main menu items using the following steps: 1. Open the
    app-config.yaml file. 1. To customize the order and parent-child relationships
    for the main menu items, use the dynamicPlugins.frontend.default.main-menu-items.menuItems
    field. 2. For dynamic plugin menu items, use the dynamicPlugins.frontend.<package_name>.menuItems
    field. ```yaml dynamicPlugins: frontend: default.main menu items: menuItems: default.home:
    title: Home icon: home priority: 100 enabled: true default.my group: title: My
    Group icon: group priority: 90 enabled: true default.catalog: title: Catalog icon:
    category to: catalog priority: 80 enabled: true default.apis: title: APIs icon:
    extension to: api docs priority: 70 enabled: true default.learning path: title:
    Learning Paths icon: school, to: learning paths priority: 60 enabled: true default.create:
    title: Self service icon: add to: create priority: 50 enabled: true ``` ### Enabling
    sidebar menu items localization in RHDH You can add translation key support for
    sidebar menu items, so that users can onboard in their preferred language. In
    Developer Hub, all existing and newly created sidebar menu items support localization
    using the titleKey translation key. [NOTE] ---- If a translation key is present
    but the corresponding localized string is missing, the system defaults to the
    original text defined in the sidebar menu items configuration (title). If no translation
    key is defined at all, the original text is displayed. ---- You have enabled localization
    in your RHDH application. 1. For sidebar menu items in your configuration file,
    you must define both the original text and the new localization keys. For example,
    in the dynamicPlugins.frontend.default.main-menu-items.menuItems.default.favorites
    section of your app-config.yaml file, add the titleKey, as follows: Example app-config.yaml
    fragment ```yaml dynamicPlugins: frontend: default.main menu items: menuItems:
    default.favorites: title: Favorites titleKey: menuItem.favorites icon: favorite
    priority: 100 enabled: true ``` 2. In your translation file, map the titleKey
    from the first step to the localized strings for each supported language. Example
    allTranslations.json fragment ```yaml { "rhdh": { "en": { "menuItem.favorites":
    "Favorites" }, "fr": { "menuItem.favorites": "Favoris" } } } ``` ### Configuring
    a dynamic plugin menu item for your Developer Hub instance Configure a dynamic
    plugin menu item using the following step: In the app config.yaml file, update
    the menuItems section of your <plugin_name> plugin. For example: ```yaml dynamicPlugins:
    frontend: _<plugin_name>_: menuItems: <menu_item_name>: icon: # home | group |
    category | extension | school | _<my_icon>_ title: _<plugin_page_title>_ priority:
    10 parent: favorites enabled: true ``` <plugin_name>:: Enter the plugin name.
    This name is the same as the scalprum.name key in the package.json file. <menu_item_name>::
    Enter a unique name in the main sidebar navigation for either a standalone menu
    item or a parent menu item. If this field specifies a plugin menu item, the name
    of the menu item must match the name using in the corresponding path in dynamicRoutes.
    For example, if dynamicRoutes defines path: /my-plugin, then menu_item_name must
    be defined as my-plugin. icon:: (Optional) Enter the icon name. You can use any
    of the following icons: * Default icons, such as home, group, category, extension,
    and school. To use default icons, set the icon as an (" ") empty string. * A custom
    icon, where <my_icon> specifies the name of your custom icon * An SVG icon, such
    as: icon: <svg width="20px" height="20px" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"
    fill="#ffffff">&#8230;&#8203;</svg> * An HTML image, such as: icon: https://img.icons8.com/ios-glyphs/20/FFFFFF/shop.png
    title:: (Optional) Enter the menu item title. Omit it when the title is already
    specified in the dynamicRoutes configuration under menuItem.text. To hide the
    title from the sidebar, set the title as an (" ") empty string. priority:: (Optional)
    Enter an integer value to set the order in which menu items'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:29:13.627184'
    uuid: b874f17a-575a-4973-9375-2c1c1cc180c1
  response: To customize the main menu items in your Developer Hub instance, you must
    first open the app-config.yaml file. Within that file, you can customize the order
    and parent-child relationships for the main menu items by using the dynamicPlugins.frontend.default.main-menu-items.menuItems
    field.
  user_input: What are the specific steps required to customize the main sidebar menu
    items within our RHDH instance?
- context:
  - 'appear in the sidebar. parent:: (Optional) Enter the parent menu item under which
    the current item is nested. If this field is used, the parent menu item must be
    defined elsewhere in the menuItems configuration of any enabled plugin. You can
    define this field for each section. enabled:: (Optional) Enter false to hide the
    menu item from the sidebar. Enter true to display the menu item in the sidebar.
    ```yaml dynamicPlugins: frontend: _<package_name>_: dynamicRoutes: path: /my plugin
    module: CustomModule importName: FooPluginPage menuItem: icon: fooIcon text: Foo
    Plugin Page menuItems: my plugin: priority: 10 parent: favorites favorites: icon:
    favorite title: Favorites priority: 100 ``` my-plugin:: Enter the value of the
    path field in dynamicRoutes. priority:: Enter an integer value to set the order
    in which plugins appear in the parent menu item. parent:: Enter the parent menu
    item id to nest this plugin under, such as favorites. favorites:: Configuration
    for the parent menu item. title:: Displays the title name for the parent menu
    item. ### Modifying or adding a custom menu items for your Developer Hub instance
    Modify a main menu item or add a custom menu item using the following step: In
    the app config.yaml file, add a section to the default.main menu items > menuItems
    section. Use the default. prefix to identify the key as a main menu item. ```yaml
    dynamicPlugins: frontend: default.main-menu-items: menuItems: default._<menu_group_parent_item_name>_:
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<menu_group_parent_title>_
    priority: 10 default._<menu_item_name>_: parent: _<menu_group_parent_item_name>_
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<my_menu_title>_
    to: _<path_to_the_menu_target_page>_ priority: 100 enabled: true ``` default.<menu_group_parent_item_name>::
    (Optional) Enter the menu group parent item name to configure static main menu
    items. If no default.<menu_item_name> has a parent value set, this field is not
    needed. icon:: Enter the menu icon. Required for parent menu items. title:: Enter
    the menu group title. Required for parent menu items. priority:: (Optional) Enter
    the order of this menu item within its menu level. default.<menu_item_name>::
    Enter the menu item name for which you want to override the default value. Add
    the default. prefix to identify a main menu item. parent:: (Optional) Enter the
    parent menu item for this item. Required if <menu_item_name> is specified as the
    child of any menu items. icon:: (Optional) Enter the menu icon. To use the default
    icon, set the icon as an (" ") empty string. title:: (Optional) Enter the menu
    group title. Only required for adding a new custom main menu item. To hide a default
    main menu item title from the sidebar, set the title as an (" ") empty string.
    to:: (Optional) Enter the path that the menu item navigates to. If it is not set,
    it defaults to the home page. priority:: (Optional) Enter the order of this menu
    item within its menu level. enabled:: (Optional) If this field is used to display
    the menu item in the sidebar, set the value to true. To hide the menu item from
    the sidebar, set the value to false. ```yaml default.main menu items: menuItems:
    default.catalog: icon: category title: My Catalog priority: 5 default.learning
    path: title: '''' default.parentlist: title: Overview icon: bookmarks default.home:
    parent: default.parentlist default.references: title: References icon: school
    to: /references enabled: true ``` icon:: (Optional) Enter the icon name, such
    as category, bookmarks`, school, etc. to change the default icon. title:: Enter
    an empty string '''' to hide the learning path from the default sidebar. default.parentlist::
    Enter the parent menu items. parent:: Enter the parent menu under which to nest
    the the menu entry, such as default.parentlist. title:: Enter the menu entry name,
    such as My Catalog, Overview or References. to:: Enter the page to redirect to.
    For example, default.references redirects to the /references page. enabled:: (Optional)
    Enter true to display the menu item in the sidebar. Enter false to hide the menu
    item from the sidebar. ## Configuring entity tab titles Red Hat Developer Hub
    provides a default opinionated tab set for catalog entity views. For consistency
    with your organization needs, you can rename, reorder, remove, and add tab titles.
    For each tab to modify, enter your desired values in the entityTabs section in
    your app config.yaml file: ```yaml upstream: backstage: appConfig: dynamicPlugins:
    frontend: <plugin_name>: entityTabs: mountPoint: <mount_point> path: <path> title:
    <title> priority: <priority> ``` <plugin_name>:: Enter the plugin name, such as
    backstage-community.plugin-topology. mountPoint:: Enter the tab mountpoint, such
    as entity.page.topology. path:: Enter the tab path, such as /topology. title::
    Enter the tab title, such as Topology. priority:: Optional. To reorder tabs, enter
    the tab priority, such as 42. Higher priority appears first. To remove a tab,
    enter a negative value, such as -1. ## Configuring entity detail tab layout Each
    Red Hat Developer Hub entity detail tab has a default opinionated layout. For
    consistency with your organization needs, you can change the entity detail tab
    content when the plugin that contributes the tab content allows a configuration.
    The plugin that contributes the tab content allows a configuration, such as Developer
    Hub plugins defining a default configuration in a config section. Copy the plugin
    default configuration in your app config.yaml file, and change the layout properties.
    ```yaml global: dynamic: plugins: package: <package_location> disabled: false
    pluginConfig: dynamicPlugins: frontend: <plugin_name>: mountPoints: mountPoint:
    <mount_point> importName: <import_name> config: layout: gridColumn: lg: span 6
    xs: span 12 ``` package:: Enter your package location, such as ./dynamic-plugins/dist/backstage-community-plugin-tekton.
    <plugin_name>:: Enter your plugin name, such as: backstage-community.plugin-tekton.
    mountPoint:: Copy the mount point defined in the plugin default configuration,
    such as: entity.page.ci/cards. importName:: Copy the import name defined in the
    plugin default configuration, such as: TektonCI. layout:: Enter your layout configuration.
    The tab content is displayed in a responsive grid that uses a 12 column-grid and
    supports different breakpoints (xs, sm, md, lg, xl) that can be specified for
    a CSS property, such as gridColumn. The example uses 6 of the 12 columns to show
    two Tekton CI cards side-by-side on large (lg) screens (span 6 columns) and show
    them among themselves (xs and above span 12 columns). ## Customizing the theme
    mode color'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:23.075369'
    uuid: fdc2850c-02f0-4838-b882-1bed53a4847d
  response: To configure entity tab titles for consistency with your organization's
    needs, you can rename, reorder, remove, and add tabs by entering your desired
    values in the `entityTabs` section in your `app-config.yaml` file. For each tab
    you wish to modify, you need to specify the `<plugin_name>`, the tab `mountPoint`
    (such as `entity.page.topology`), the tab `path` (like `/topology`), and the desired
    `title`. To reorder tabs, you can optionally enter a `priority`; a higher priority
    value will cause the tab to appear first. If you need to remove a tab, you can
    do so by entering a negative value, such as -1, for its priority.
  user_input: As I work to streamline our developer platform, I need to customize
    the default interface to align with our organization's specific needs; could you
    please explain the complete process for modifying the default opinionated tab
    set for catalog entity views using the `entityTabs` configuration in the `app-config.yaml`
    file, including how to rename, reorder, and remove tabs?
- context:
  - 'appear in the sidebar. parent:: (Optional) Enter the parent menu item under which
    the current item is nested. If this field is used, the parent menu item must be
    defined elsewhere in the menuItems configuration of any enabled plugin. You can
    define this field for each section. enabled:: (Optional) Enter false to hide the
    menu item from the sidebar. Enter true to display the menu item in the sidebar.
    ```yaml dynamicPlugins: frontend: _<package_name>_: dynamicRoutes: path: /my plugin
    module: CustomModule importName: FooPluginPage menuItem: icon: fooIcon text: Foo
    Plugin Page menuItems: my plugin: priority: 10 parent: favorites favorites: icon:
    favorite title: Favorites priority: 100 ``` my-plugin:: Enter the value of the
    path field in dynamicRoutes. priority:: Enter an integer value to set the order
    in which plugins appear in the parent menu item. parent:: Enter the parent menu
    item id to nest this plugin under, such as favorites. favorites:: Configuration
    for the parent menu item. title:: Displays the title name for the parent menu
    item. ### Modifying or adding a custom menu items for your Developer Hub instance
    Modify a main menu item or add a custom menu item using the following step: In
    the app config.yaml file, add a section to the default.main menu items > menuItems
    section. Use the default. prefix to identify the key as a main menu item. ```yaml
    dynamicPlugins: frontend: default.main-menu-items: menuItems: default._<menu_group_parent_item_name>_:
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<menu_group_parent_title>_
    priority: 10 default._<menu_item_name>_: parent: _<menu_group_parent_item_name>_
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<my_menu_title>_
    to: _<path_to_the_menu_target_page>_ priority: 100 enabled: true ``` default.<menu_group_parent_item_name>::
    (Optional) Enter the menu group parent item name to configure static main menu
    items. If no default.<menu_item_name> has a parent value set, this field is not
    needed. icon:: Enter the menu icon. Required for parent menu items. title:: Enter
    the menu group title. Required for parent menu items. priority:: (Optional) Enter
    the order of this menu item within its menu level. default.<menu_item_name>::
    Enter the menu item name for which you want to override the default value. Add
    the default. prefix to identify a main menu item. parent:: (Optional) Enter the
    parent menu item for this item. Required if <menu_item_name> is specified as the
    child of any menu items. icon:: (Optional) Enter the menu icon. To use the default
    icon, set the icon as an (" ") empty string. title:: (Optional) Enter the menu
    group title. Only required for adding a new custom main menu item. To hide a default
    main menu item title from the sidebar, set the title as an (" ") empty string.
    to:: (Optional) Enter the path that the menu item navigates to. If it is not set,
    it defaults to the home page. priority:: (Optional) Enter the order of this menu
    item within its menu level. enabled:: (Optional) If this field is used to display
    the menu item in the sidebar, set the value to true. To hide the menu item from
    the sidebar, set the value to false. ```yaml default.main menu items: menuItems:
    default.catalog: icon: category title: My Catalog priority: 5 default.learning
    path: title: '''' default.parentlist: title: Overview icon: bookmarks default.home:
    parent: default.parentlist default.references: title: References icon: school
    to: /references enabled: true ``` icon:: (Optional) Enter the icon name, such
    as category, bookmarks`, school, etc. to change the default icon. title:: Enter
    an empty string '''' to hide the learning path from the default sidebar. default.parentlist::
    Enter the parent menu items. parent:: Enter the parent menu under which to nest
    the the menu entry, such as default.parentlist. title:: Enter the menu entry name,
    such as My Catalog, Overview or References. to:: Enter the page to redirect to.
    For example, default.references redirects to the /references page. enabled:: (Optional)
    Enter true to display the menu item in the sidebar. Enter false to hide the menu
    item from the sidebar. ## Configuring entity tab titles Red Hat Developer Hub
    provides a default opinionated tab set for catalog entity views. For consistency
    with your organization needs, you can rename, reorder, remove, and add tab titles.
    For each tab to modify, enter your desired values in the entityTabs section in
    your app config.yaml file: ```yaml upstream: backstage: appConfig: dynamicPlugins:
    frontend: <plugin_name>: entityTabs: mountPoint: <mount_point> path: <path> title:
    <title> priority: <priority> ``` <plugin_name>:: Enter the plugin name, such as
    backstage-community.plugin-topology. mountPoint:: Enter the tab mountpoint, such
    as entity.page.topology. path:: Enter the tab path, such as /topology. title::
    Enter the tab title, such as Topology. priority:: Optional. To reorder tabs, enter
    the tab priority, such as 42. Higher priority appears first. To remove a tab,
    enter a negative value, such as -1. ## Configuring entity detail tab layout Each
    Red Hat Developer Hub entity detail tab has a default opinionated layout. For
    consistency with your organization needs, you can change the entity detail tab
    content when the plugin that contributes the tab content allows a configuration.
    The plugin that contributes the tab content allows a configuration, such as Developer
    Hub plugins defining a default configuration in a config section. Copy the plugin
    default configuration in your app config.yaml file, and change the layout properties.
    ```yaml global: dynamic: plugins: package: <package_location> disabled: false
    pluginConfig: dynamicPlugins: frontend: <plugin_name>: mountPoints: mountPoint:
    <mount_point> importName: <import_name> config: layout: gridColumn: lg: span 6
    xs: span 12 ``` package:: Enter your package location, such as ./dynamic-plugins/dist/backstage-community-plugin-tekton.
    <plugin_name>:: Enter your plugin name, such as: backstage-community.plugin-tekton.
    mountPoint:: Copy the mount point defined in the plugin default configuration,
    such as: entity.page.ci/cards. importName:: Copy the import name defined in the
    plugin default configuration, such as: TektonCI. layout:: Enter your layout configuration.
    The tab content is displayed in a responsive grid that uses a 12 column-grid and
    supports different breakpoints (xs, sm, md, lg, xl) that can be specified for
    a CSS property, such as gridColumn. The example uses 6 of the 12 columns to show
    two Tekton CI cards side-by-side on large (lg) screens (span 6 columns) and show
    them among themselves (xs and above span 12 columns). ## Customizing the theme
    mode color'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:30.650524'
    uuid: 08ebd3a6-2b98-4b22-bd60-c78b131990b2
  response: 'To nest a menu item, you use the optional `parent` field. The parent
    menu item must be defined elsewhere in the `menuItems` configuration. For dynamic
    plugins, you can enter the parent menu item id, such as `favorites`, to nest a
    plugin under it. For main menu items in the `app-config.yaml` file, you can add
    a `parent` field under a `default.<menu_item_name>` section; this is required
    if the item is specified as a child. The parent itself, identified as `default.<menu_group_parent_item_name>`,
    must be configured and requires an `icon` and `title`. For example, to nest the
    `default.home` menu entry, you would specify its parent as `parent: default.parentlist`.'
  user_input: How do I configure a parent menu item to nest other menu items in Red
    Hat Developer Hub?
- context:
  - 'appear in the sidebar. parent:: (Optional) Enter the parent menu item under which
    the current item is nested. If this field is used, the parent menu item must be
    defined elsewhere in the menuItems configuration of any enabled plugin. You can
    define this field for each section. enabled:: (Optional) Enter false to hide the
    menu item from the sidebar. Enter true to display the menu item in the sidebar.
    ```yaml dynamicPlugins: frontend: _<package_name>_: dynamicRoutes: path: /my plugin
    module: CustomModule importName: FooPluginPage menuItem: icon: fooIcon text: Foo
    Plugin Page menuItems: my plugin: priority: 10 parent: favorites favorites: icon:
    favorite title: Favorites priority: 100 ``` my-plugin:: Enter the value of the
    path field in dynamicRoutes. priority:: Enter an integer value to set the order
    in which plugins appear in the parent menu item. parent:: Enter the parent menu
    item id to nest this plugin under, such as favorites. favorites:: Configuration
    for the parent menu item. title:: Displays the title name for the parent menu
    item. ### Modifying or adding a custom menu items for your Developer Hub instance
    Modify a main menu item or add a custom menu item using the following step: In
    the app config.yaml file, add a section to the default.main menu items > menuItems
    section. Use the default. prefix to identify the key as a main menu item. ```yaml
    dynamicPlugins: frontend: default.main-menu-items: menuItems: default._<menu_group_parent_item_name>_:
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<menu_group_parent_title>_
    priority: 10 default._<menu_item_name>_: parent: _<menu_group_parent_item_name>_
    icon: # home | group | category | extension | school | _<my_icon>_ title: _<my_menu_title>_
    to: _<path_to_the_menu_target_page>_ priority: 100 enabled: true ``` default.<menu_group_parent_item_name>::
    (Optional) Enter the menu group parent item name to configure static main menu
    items. If no default.<menu_item_name> has a parent value set, this field is not
    needed. icon:: Enter the menu icon. Required for parent menu items. title:: Enter
    the menu group title. Required for parent menu items. priority:: (Optional) Enter
    the order of this menu item within its menu level. default.<menu_item_name>::
    Enter the menu item name for which you want to override the default value. Add
    the default. prefix to identify a main menu item. parent:: (Optional) Enter the
    parent menu item for this item. Required if <menu_item_name> is specified as the
    child of any menu items. icon:: (Optional) Enter the menu icon. To use the default
    icon, set the icon as an (" ") empty string. title:: (Optional) Enter the menu
    group title. Only required for adding a new custom main menu item. To hide a default
    main menu item title from the sidebar, set the title as an (" ") empty string.
    to:: (Optional) Enter the path that the menu item navigates to. If it is not set,
    it defaults to the home page. priority:: (Optional) Enter the order of this menu
    item within its menu level. enabled:: (Optional) If this field is used to display
    the menu item in the sidebar, set the value to true. To hide the menu item from
    the sidebar, set the value to false. ```yaml default.main menu items: menuItems:
    default.catalog: icon: category title: My Catalog priority: 5 default.learning
    path: title: '''' default.parentlist: title: Overview icon: bookmarks default.home:
    parent: default.parentlist default.references: title: References icon: school
    to: /references enabled: true ``` icon:: (Optional) Enter the icon name, such
    as category, bookmarks`, school, etc. to change the default icon. title:: Enter
    an empty string '''' to hide the learning path from the default sidebar. default.parentlist::
    Enter the parent menu items. parent:: Enter the parent menu under which to nest
    the the menu entry, such as default.parentlist. title:: Enter the menu entry name,
    such as My Catalog, Overview or References. to:: Enter the page to redirect to.
    For example, default.references redirects to the /references page. enabled:: (Optional)
    Enter true to display the menu item in the sidebar. Enter false to hide the menu
    item from the sidebar. ## Configuring entity tab titles Red Hat Developer Hub
    provides a default opinionated tab set for catalog entity views. For consistency
    with your organization needs, you can rename, reorder, remove, and add tab titles.
    For each tab to modify, enter your desired values in the entityTabs section in
    your app config.yaml file: ```yaml upstream: backstage: appConfig: dynamicPlugins:
    frontend: <plugin_name>: entityTabs: mountPoint: <mount_point> path: <path> title:
    <title> priority: <priority> ``` <plugin_name>:: Enter the plugin name, such as
    backstage-community.plugin-topology. mountPoint:: Enter the tab mountpoint, such
    as entity.page.topology. path:: Enter the tab path, such as /topology. title::
    Enter the tab title, such as Topology. priority:: Optional. To reorder tabs, enter
    the tab priority, such as 42. Higher priority appears first. To remove a tab,
    enter a negative value, such as -1. ## Configuring entity detail tab layout Each
    Red Hat Developer Hub entity detail tab has a default opinionated layout. For
    consistency with your organization needs, you can change the entity detail tab
    content when the plugin that contributes the tab content allows a configuration.
    The plugin that contributes the tab content allows a configuration, such as Developer
    Hub plugins defining a default configuration in a config section. Copy the plugin
    default configuration in your app config.yaml file, and change the layout properties.
    ```yaml global: dynamic: plugins: package: <package_location> disabled: false
    pluginConfig: dynamicPlugins: frontend: <plugin_name>: mountPoints: mountPoint:
    <mount_point> importName: <import_name> config: layout: gridColumn: lg: span 6
    xs: span 12 ``` package:: Enter your package location, such as ./dynamic-plugins/dist/backstage-community-plugin-tekton.
    <plugin_name>:: Enter your plugin name, such as: backstage-community.plugin-tekton.
    mountPoint:: Copy the mount point defined in the plugin default configuration,
    such as: entity.page.ci/cards. importName:: Copy the import name defined in the
    plugin default configuration, such as: TektonCI. layout:: Enter your layout configuration.
    The tab content is displayed in a responsive grid that uses a 12 column-grid and
    supports different breakpoints (xs, sm, md, lg, xl) that can be specified for
    a CSS property, such as gridColumn. The example uses 6 of the 12 columns to show
    two Tekton CI cards side-by-side on large (lg) screens (span 6 columns) and show
    them among themselves (xs and above span 12 columns). ## Customizing the theme
    mode color'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:38.705084'
    uuid: 1727cac0-66d6-42c0-b73f-576a209ed7fc
  response: To add a custom main menu item to the sidebar, you must modify the `app-config.yaml`
    file by adding a section to `default.main menu items > menuItems`. For a new item,
    you must define its name with a `default.` prefix, and configure its properties.
    For example, to add a 'References' item, you would specify `default.references`,
    and then set the `title` to 'References', the `icon` to 'school', and the `to`
    field to the path it navigates to, such as `/references`. You can also set its
    `priority` to control its order. To hide a default menu item from the sidebar,
    there are two methods described. For the 'learning path' specifically, you can
    set its `title` to an empty string `''`. More generally, for any menu item, you
    can set the optional `enabled` field to `false` to hide it from the sidebar.
  user_input: As a Platform Engineer responsible for our Developer Hub instance, could
    you provide a detailed explanation of the specific configuration steps within
    the app-config.yaml file for both adding a new custom main menu item to the sidebar
    and hiding a default menu item, such as the learning path, from being displayed?
- context:
  - 'palettes for your Developer Hub instance You can customize the color palettes
    of the light and dark theme modes in your Developer Hub instance by configuring
    the light.palette and dark.palette parameters in the branding.theme section of
    the app-config.yaml file, as shown in the following example: ```yaml app: branding:
    theme: light: palette: primary: main: <light_primary_color> navigation: indicator:
    <light_indicator_color> pageTheme: default: backgroundColor: [<light_background_color_1>,
    <light_background_color_2>] dark: palette: primary: main: <dark_primary_color>
    navigation: indicator: <dark_indicator_color> pageTheme: default: backgroundColor:
    [<dark_background_color_1>, <dark_background_color_2>] # ... ``` light|dark::
    Enter the theme name: light or dark. palette.primary:main:: Enter the palette
    main primary color, such as #ffffff or white. palette.navigation:indicator:: Enter
    the palette navigation indicator color, which is a vertical bar that indicates
    the selected tab in the navigation panel, such as #FF0000 or red. pageTheme:default:backgroundColor::
    Enter the default page theme background color, such as #ffffff or white. ## Customizing
    the page theme header for your Developer Hub instance You can customize the header
    color for the light and dark theme modes in your Developer Hub instance by modifying
    the branding.theme section of the app-config.yaml file. You can also customize
    the page headers for additional Developer Hub pages, such as the Home, Catalog,
    and APIs pages. ```yaml app: branding: theme: light: palette: {} pageTheme: default:
    backgroundColor: "<default_light_background_color>" fontColor: "<default_light_font_color>"
    shape: none apis: backgroundColor: "<apis_light_background_color>" fontColor:
    "<apis_light_font_color>" shape: none dark: palette: {} pageTheme: default: backgroundColor:
    "<default_dark_background_color>" fontColor: "<default_dark_font_color>" shape:
    none # ... ``` light:: Enter the theme mode, such as light or dark. default::
    Enter the default page theme configuration backgroundColor:: Enter the page header
    background color, such as #ffffff or white. fontColor:: Enter the page header
    text color, such as #000000 or black. shape:: Enter the page header pattern, such
    as wave, round, or none. apis:: Enter the page id to configure, such as apis or
    home. ## Customizing the font for your Developer Hub instance You can configure
    the typography section of the app-config.yaml file to change the default font
    family and size of the page text, as well as the font family and size of each
    heading level, as shown in the following example: ```yaml app: branding: theme:
    light: typography: fontFamily: "Times New Roman" htmlFontSize: 11 # smaller is
    bigger h1: fontFamily: "Times New Roman" fontSize: 40 h2: fontFamily: "Times New
    Roman" fontSize: 30 h3: fontFamily: "Times New Roman" fontSize: 30 h4: fontFamily:
    "Times New Roman" fontSize: 30 h5: fontFamily: "Times New Roman" fontSize: 30
    h6: fontFamily: "Times New Roman" fontSize: 30 dark: typography: fontFamily: "Times
    New Roman" htmlFontSize: 11 # smaller is bigger h1: fontFamily: "Times New Roman"
    fontSize: 40 h2: fontFamily: "Times New Roman" fontSize: 30 h3: fontFamily: "Times
    New Roman" fontSize: 30 h4: fontFamily: "Times New Roman" fontSize: 30 h5: fontFamily:
    "Times New Roman" fontSize: 30 h6: fontFamily: "Times New Roman" fontSize: 30
    # ... ``` ## Default Red Hat Developer Hub theme You can use the default Red Hat
    Developer Hub theme configurations to make your Developer Hub instance look like
    a standard Red Hat Developer Hub instance. You can also modify the app-config.yaml
    file to customize or disable particular parameters. ### Default Red Hat Developer
    Hub theme color palette The app-config.yaml file uses the following configurations
    for the default Red Hat Developer Hub color palette: ```yaml app: branding: theme:
    light: variant: "rhdh" mode: "light" palette: background: default: "#F8F8F8" paper:
    "#FFFFFF" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" mode: "light" navigation:
    background: "#222427" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#222427" pinSidebarButton:
    background: "#BDBDBD" icon: "#181818" primary: main: "#0066CC" secondary: main:
    "#8476D1" status: aborted: "#757575" error: "#E22134" ok: "#1DB954" pending: "#FFED51"
    running: "#1F5493" warning: "#FF9800" tabbar: indicator: "#9BF0E1" textContrast:
    "#000000" textSubtle: "#6E6E6E" textVerySubtle: "#DDD" warningBackground: "#F59B23"
    warningText: "#000000" text: primary: "#151515" secondary: "#757575" rhdh: general:
    disabledBackground: "#D2D2D2" disabled: "#6A6E73" searchBarBorderColor: "#E4E4E4"
    formControlBackgroundColor: "#FFF" mainSectionBackgroundColor: "#FFF" headerBottomBorderColor:
    "#C7C7C7" cardBackgroundColor: "#FFF" sidebarBackgroundColor: "#212427" cardBorderColor:
    "#C7C7C7" tableTitleColor: "#181818" tableSubtitleColor: "#616161" tableColumnTitleColor:
    "#151515" tableRowHover: "#F5F5F5" tableBorderColor: "#E0E0E0" tableBackgroundColor:
    "#FFF" tabsBottomBorderColor: "#D2D2D2" contrastText: "#FFF" primary: main: "#0066CC"
    focusVisibleBorder: "#0066CC" secondary: main: "#8476D1" focusVisibleBorder: "#8476D1"
    cards: headerTextColor: "#151515" headerBackgroundColor: "#FFF" headerBackgroundImage:
    "none" dark: variant: "rhdh" mode: "dark" palette: background: default: "#333333"
    paper: "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#0f1214" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#0f1214" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: main: "#1FA7F8" secondary: main:
    "#B2A3FF" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88" pending: "#FEF071"
    running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1" textContrast:
    "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground: "#F59B23"
    warningText: "#000000" rhdh: general: disabledBackground: "#444548" disabled:
    "#AAABAC" searchBarBorderColor: "#57585a" formControlBackgroundColor: "#36373A"
    mainSectionBackgroundColor: "#0f1214" headerBottomBorderColor: "#A3A3A3" cardBackgroundColor:
    "#292929" sidebarBackgroundColor: "#1b1d21" cardBorderColor: "#A3A3A3" tableTitleColor:
    "#E0E0E0" tableSubtitleColor: "#E0E0E0" tableColumnTitleColor: "#E0E0E0" tableRowHover:
    "#0f1214" tableBorderColor: "#515151" tableBackgroundColor: "#1b1d21" tabsBottomBorderColor:
    "#444548" contrastText: "#FFF" primary: main: "#1FA7F8" focusVisibleBorder: "#ADD6FF"
    secondary: main: "#B2A3FF" focusVisibleBorder: "#D0C7FF" cards: headerTextColor:
    "#FFF" headerBackgroundColor: "#0f1214" headerBackgroundImage: "none" ``` Alternatively,
    you can use the following variant and mode values in the app-config.yaml file
    to apply the previous default configuration: ```yaml app: branding: theme: light:
    variant: "rhdh" mode: "light" dark: variant: "rhdh" mode: "dark" ``` ### Default
    Red Hat Developer Hub page themes The default Developer Hub header color is white
    in light mode and black in dark mode, as shown in the following app-config.yaml
    file configuration: ```yaml app: branding: theme: light: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#ffffff" dark: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#0f1214" ``` ## Default Backstage
    theme You can use the default Backstage theme configurations to make your Developer
    Hub instance look like a standard Backstage instance. You can also modify the
    app-config.yaml file to customize or disable particular parameters. ### Default
    Backstage theme'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:46.830881'
    uuid: 6bdf402b-37b9-4431-a3c0-16df6bd1be87
  response: You can change the default font by configuring the typography section
    of the app-config.yaml file. This allows you to modify the font family for the
    page text and for each heading level (h1 through h6). As shown in the provided
    example, you would set the `fontFamily` property to "Times New Roman" under the
    `typography` section for both light and dark themes, as well as for each individual
    heading level from h1 to h6.
  user_input: how to configure the app-config.yaml file to change the default font
    family to Times New Roman for all page text and headings in the Developer Hub
    instance
- context:
  - 'palettes for your Developer Hub instance You can customize the color palettes
    of the light and dark theme modes in your Developer Hub instance by configuring
    the light.palette and dark.palette parameters in the branding.theme section of
    the app-config.yaml file, as shown in the following example: ```yaml app: branding:
    theme: light: palette: primary: main: <light_primary_color> navigation: indicator:
    <light_indicator_color> pageTheme: default: backgroundColor: [<light_background_color_1>,
    <light_background_color_2>] dark: palette: primary: main: <dark_primary_color>
    navigation: indicator: <dark_indicator_color> pageTheme: default: backgroundColor:
    [<dark_background_color_1>, <dark_background_color_2>] # ... ``` light|dark::
    Enter the theme name: light or dark. palette.primary:main:: Enter the palette
    main primary color, such as #ffffff or white. palette.navigation:indicator:: Enter
    the palette navigation indicator color, which is a vertical bar that indicates
    the selected tab in the navigation panel, such as #FF0000 or red. pageTheme:default:backgroundColor::
    Enter the default page theme background color, such as #ffffff or white. ## Customizing
    the page theme header for your Developer Hub instance You can customize the header
    color for the light and dark theme modes in your Developer Hub instance by modifying
    the branding.theme section of the app-config.yaml file. You can also customize
    the page headers for additional Developer Hub pages, such as the Home, Catalog,
    and APIs pages. ```yaml app: branding: theme: light: palette: {} pageTheme: default:
    backgroundColor: "<default_light_background_color>" fontColor: "<default_light_font_color>"
    shape: none apis: backgroundColor: "<apis_light_background_color>" fontColor:
    "<apis_light_font_color>" shape: none dark: palette: {} pageTheme: default: backgroundColor:
    "<default_dark_background_color>" fontColor: "<default_dark_font_color>" shape:
    none # ... ``` light:: Enter the theme mode, such as light or dark. default::
    Enter the default page theme configuration backgroundColor:: Enter the page header
    background color, such as #ffffff or white. fontColor:: Enter the page header
    text color, such as #000000 or black. shape:: Enter the page header pattern, such
    as wave, round, or none. apis:: Enter the page id to configure, such as apis or
    home. ## Customizing the font for your Developer Hub instance You can configure
    the typography section of the app-config.yaml file to change the default font
    family and size of the page text, as well as the font family and size of each
    heading level, as shown in the following example: ```yaml app: branding: theme:
    light: typography: fontFamily: "Times New Roman" htmlFontSize: 11 # smaller is
    bigger h1: fontFamily: "Times New Roman" fontSize: 40 h2: fontFamily: "Times New
    Roman" fontSize: 30 h3: fontFamily: "Times New Roman" fontSize: 30 h4: fontFamily:
    "Times New Roman" fontSize: 30 h5: fontFamily: "Times New Roman" fontSize: 30
    h6: fontFamily: "Times New Roman" fontSize: 30 dark: typography: fontFamily: "Times
    New Roman" htmlFontSize: 11 # smaller is bigger h1: fontFamily: "Times New Roman"
    fontSize: 40 h2: fontFamily: "Times New Roman" fontSize: 30 h3: fontFamily: "Times
    New Roman" fontSize: 30 h4: fontFamily: "Times New Roman" fontSize: 30 h5: fontFamily:
    "Times New Roman" fontSize: 30 h6: fontFamily: "Times New Roman" fontSize: 30
    # ... ``` ## Default Red Hat Developer Hub theme You can use the default Red Hat
    Developer Hub theme configurations to make your Developer Hub instance look like
    a standard Red Hat Developer Hub instance. You can also modify the app-config.yaml
    file to customize or disable particular parameters. ### Default Red Hat Developer
    Hub theme color palette The app-config.yaml file uses the following configurations
    for the default Red Hat Developer Hub color palette: ```yaml app: branding: theme:
    light: variant: "rhdh" mode: "light" palette: background: default: "#F8F8F8" paper:
    "#FFFFFF" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" mode: "light" navigation:
    background: "#222427" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#222427" pinSidebarButton:
    background: "#BDBDBD" icon: "#181818" primary: main: "#0066CC" secondary: main:
    "#8476D1" status: aborted: "#757575" error: "#E22134" ok: "#1DB954" pending: "#FFED51"
    running: "#1F5493" warning: "#FF9800" tabbar: indicator: "#9BF0E1" textContrast:
    "#000000" textSubtle: "#6E6E6E" textVerySubtle: "#DDD" warningBackground: "#F59B23"
    warningText: "#000000" text: primary: "#151515" secondary: "#757575" rhdh: general:
    disabledBackground: "#D2D2D2" disabled: "#6A6E73" searchBarBorderColor: "#E4E4E4"
    formControlBackgroundColor: "#FFF" mainSectionBackgroundColor: "#FFF" headerBottomBorderColor:
    "#C7C7C7" cardBackgroundColor: "#FFF" sidebarBackgroundColor: "#212427" cardBorderColor:
    "#C7C7C7" tableTitleColor: "#181818" tableSubtitleColor: "#616161" tableColumnTitleColor:
    "#151515" tableRowHover: "#F5F5F5" tableBorderColor: "#E0E0E0" tableBackgroundColor:
    "#FFF" tabsBottomBorderColor: "#D2D2D2" contrastText: "#FFF" primary: main: "#0066CC"
    focusVisibleBorder: "#0066CC" secondary: main: "#8476D1" focusVisibleBorder: "#8476D1"
    cards: headerTextColor: "#151515" headerBackgroundColor: "#FFF" headerBackgroundImage:
    "none" dark: variant: "rhdh" mode: "dark" palette: background: default: "#333333"
    paper: "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#0f1214" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#0f1214" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: main: "#1FA7F8" secondary: main:
    "#B2A3FF" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88" pending: "#FEF071"
    running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1" textContrast:
    "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground: "#F59B23"
    warningText: "#000000" rhdh: general: disabledBackground: "#444548" disabled:
    "#AAABAC" searchBarBorderColor: "#57585a" formControlBackgroundColor: "#36373A"
    mainSectionBackgroundColor: "#0f1214" headerBottomBorderColor: "#A3A3A3" cardBackgroundColor:
    "#292929" sidebarBackgroundColor: "#1b1d21" cardBorderColor: "#A3A3A3" tableTitleColor:
    "#E0E0E0" tableSubtitleColor: "#E0E0E0" tableColumnTitleColor: "#E0E0E0" tableRowHover:
    "#0f1214" tableBorderColor: "#515151" tableBackgroundColor: "#1b1d21" tabsBottomBorderColor:
    "#444548" contrastText: "#FFF" primary: main: "#1FA7F8" focusVisibleBorder: "#ADD6FF"
    secondary: main: "#B2A3FF" focusVisibleBorder: "#D0C7FF" cards: headerTextColor:
    "#FFF" headerBackgroundColor: "#0f1214" headerBackgroundImage: "none" ``` Alternatively,
    you can use the following variant and mode values in the app-config.yaml file
    to apply the previous default configuration: ```yaml app: branding: theme: light:
    variant: "rhdh" mode: "light" dark: variant: "rhdh" mode: "dark" ``` ### Default
    Red Hat Developer Hub page themes The default Developer Hub header color is white
    in light mode and black in dark mode, as shown in the following app-config.yaml
    file configuration: ```yaml app: branding: theme: light: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#ffffff" dark: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#0f1214" ``` ## Default Backstage
    theme You can use the default Backstage theme configurations to make your Developer
    Hub instance look like a standard Backstage instance. You can also modify the
    app-config.yaml file to customize or disable particular parameters. ### Default
    Backstage theme'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:29:54.260632'
    uuid: 168c1237-4485-4e49-80cb-69ac9eea9c84
  response: 'To use the "Times New Roman" font in your Developer Hub instance, you
    need to configure the typography section of the app-config.yaml file. This allows
    you to change the default font family for the page text and for each heading level.
    In the example provided, `fontFamily: "Times New Roman"` is set for the general
    typography and for each heading from h1 to h6 under both the light and dark theme
    configurations.'
  user_input: how to configure developer hub to use Times New Roman font in app-config.yaml
- context:
  - 'palettes for your Developer Hub instance You can customize the color palettes
    of the light and dark theme modes in your Developer Hub instance by configuring
    the light.palette and dark.palette parameters in the branding.theme section of
    the app-config.yaml file, as shown in the following example: ```yaml app: branding:
    theme: light: palette: primary: main: <light_primary_color> navigation: indicator:
    <light_indicator_color> pageTheme: default: backgroundColor: [<light_background_color_1>,
    <light_background_color_2>] dark: palette: primary: main: <dark_primary_color>
    navigation: indicator: <dark_indicator_color> pageTheme: default: backgroundColor:
    [<dark_background_color_1>, <dark_background_color_2>] # ... ``` light|dark::
    Enter the theme name: light or dark. palette.primary:main:: Enter the palette
    main primary color, such as #ffffff or white. palette.navigation:indicator:: Enter
    the palette navigation indicator color, which is a vertical bar that indicates
    the selected tab in the navigation panel, such as #FF0000 or red. pageTheme:default:backgroundColor::
    Enter the default page theme background color, such as #ffffff or white. ## Customizing
    the page theme header for your Developer Hub instance You can customize the header
    color for the light and dark theme modes in your Developer Hub instance by modifying
    the branding.theme section of the app-config.yaml file. You can also customize
    the page headers for additional Developer Hub pages, such as the Home, Catalog,
    and APIs pages. ```yaml app: branding: theme: light: palette: {} pageTheme: default:
    backgroundColor: "<default_light_background_color>" fontColor: "<default_light_font_color>"
    shape: none apis: backgroundColor: "<apis_light_background_color>" fontColor:
    "<apis_light_font_color>" shape: none dark: palette: {} pageTheme: default: backgroundColor:
    "<default_dark_background_color>" fontColor: "<default_dark_font_color>" shape:
    none # ... ``` light:: Enter the theme mode, such as light or dark. default::
    Enter the default page theme configuration backgroundColor:: Enter the page header
    background color, such as #ffffff or white. fontColor:: Enter the page header
    text color, such as #000000 or black. shape:: Enter the page header pattern, such
    as wave, round, or none. apis:: Enter the page id to configure, such as apis or
    home. ## Customizing the font for your Developer Hub instance You can configure
    the typography section of the app-config.yaml file to change the default font
    family and size of the page text, as well as the font family and size of each
    heading level, as shown in the following example: ```yaml app: branding: theme:
    light: typography: fontFamily: "Times New Roman" htmlFontSize: 11 # smaller is
    bigger h1: fontFamily: "Times New Roman" fontSize: 40 h2: fontFamily: "Times New
    Roman" fontSize: 30 h3: fontFamily: "Times New Roman" fontSize: 30 h4: fontFamily:
    "Times New Roman" fontSize: 30 h5: fontFamily: "Times New Roman" fontSize: 30
    h6: fontFamily: "Times New Roman" fontSize: 30 dark: typography: fontFamily: "Times
    New Roman" htmlFontSize: 11 # smaller is bigger h1: fontFamily: "Times New Roman"
    fontSize: 40 h2: fontFamily: "Times New Roman" fontSize: 30 h3: fontFamily: "Times
    New Roman" fontSize: 30 h4: fontFamily: "Times New Roman" fontSize: 30 h5: fontFamily:
    "Times New Roman" fontSize: 30 h6: fontFamily: "Times New Roman" fontSize: 30
    # ... ``` ## Default Red Hat Developer Hub theme You can use the default Red Hat
    Developer Hub theme configurations to make your Developer Hub instance look like
    a standard Red Hat Developer Hub instance. You can also modify the app-config.yaml
    file to customize or disable particular parameters. ### Default Red Hat Developer
    Hub theme color palette The app-config.yaml file uses the following configurations
    for the default Red Hat Developer Hub color palette: ```yaml app: branding: theme:
    light: variant: "rhdh" mode: "light" palette: background: default: "#F8F8F8" paper:
    "#FFFFFF" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" mode: "light" navigation:
    background: "#222427" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#222427" pinSidebarButton:
    background: "#BDBDBD" icon: "#181818" primary: main: "#0066CC" secondary: main:
    "#8476D1" status: aborted: "#757575" error: "#E22134" ok: "#1DB954" pending: "#FFED51"
    running: "#1F5493" warning: "#FF9800" tabbar: indicator: "#9BF0E1" textContrast:
    "#000000" textSubtle: "#6E6E6E" textVerySubtle: "#DDD" warningBackground: "#F59B23"
    warningText: "#000000" text: primary: "#151515" secondary: "#757575" rhdh: general:
    disabledBackground: "#D2D2D2" disabled: "#6A6E73" searchBarBorderColor: "#E4E4E4"
    formControlBackgroundColor: "#FFF" mainSectionBackgroundColor: "#FFF" headerBottomBorderColor:
    "#C7C7C7" cardBackgroundColor: "#FFF" sidebarBackgroundColor: "#212427" cardBorderColor:
    "#C7C7C7" tableTitleColor: "#181818" tableSubtitleColor: "#616161" tableColumnTitleColor:
    "#151515" tableRowHover: "#F5F5F5" tableBorderColor: "#E0E0E0" tableBackgroundColor:
    "#FFF" tabsBottomBorderColor: "#D2D2D2" contrastText: "#FFF" primary: main: "#0066CC"
    focusVisibleBorder: "#0066CC" secondary: main: "#8476D1" focusVisibleBorder: "#8476D1"
    cards: headerTextColor: "#151515" headerBackgroundColor: "#FFF" headerBackgroundImage:
    "none" dark: variant: "rhdh" mode: "dark" palette: background: default: "#333333"
    paper: "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#0f1214" indicator: "#0066CC" color: "#ffffff" selectedColor: "#ffffff"
    navItem: hoverBackground: "#3c3f42" submenu: background: "#0f1214" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: main: "#1FA7F8" secondary: main:
    "#B2A3FF" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88" pending: "#FEF071"
    running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1" textContrast:
    "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground: "#F59B23"
    warningText: "#000000" rhdh: general: disabledBackground: "#444548" disabled:
    "#AAABAC" searchBarBorderColor: "#57585a" formControlBackgroundColor: "#36373A"
    mainSectionBackgroundColor: "#0f1214" headerBottomBorderColor: "#A3A3A3" cardBackgroundColor:
    "#292929" sidebarBackgroundColor: "#1b1d21" cardBorderColor: "#A3A3A3" tableTitleColor:
    "#E0E0E0" tableSubtitleColor: "#E0E0E0" tableColumnTitleColor: "#E0E0E0" tableRowHover:
    "#0f1214" tableBorderColor: "#515151" tableBackgroundColor: "#1b1d21" tabsBottomBorderColor:
    "#444548" contrastText: "#FFF" primary: main: "#1FA7F8" focusVisibleBorder: "#ADD6FF"
    secondary: main: "#B2A3FF" focusVisibleBorder: "#D0C7FF" cards: headerTextColor:
    "#FFF" headerBackgroundColor: "#0f1214" headerBackgroundImage: "none" ``` Alternatively,
    you can use the following variant and mode values in the app-config.yaml file
    to apply the previous default configuration: ```yaml app: branding: theme: light:
    variant: "rhdh" mode: "light" dark: variant: "rhdh" mode: "dark" ``` ### Default
    Red Hat Developer Hub page themes The default Developer Hub header color is white
    in light mode and black in dark mode, as shown in the following app-config.yaml
    file configuration: ```yaml app: branding: theme: light: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#ffffff" dark: palette: {} defaultPageTheme:
    default pageTheme: default: backgroundColor: "#0f1214" ``` ## Default Backstage
    theme You can use the default Backstage theme configurations to make your Developer
    Hub instance look like a standard Backstage instance. You can also modify the
    app-config.yaml file to customize or disable particular parameters. ### Default
    Backstage theme'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:00.627775'
    uuid: c31ecffd-6b27-42f8-9cc3-f8129dc03037
  response: "To make your Developer Hub instance look like a standard Red Hat Developer\
    \ Hub instance, you can use the default theme configurations in the app-config.yaml\
    \ file. The default color palette configuration is as follows:\n```yaml\napp:\n\
    \  branding:\n    theme:\n      light:\n        variant: \"rhdh\"\n        mode:\
    \ \"light\"\n        palette:\n          background:\n            default: \"\
    #F8F8F8\"\n            paper: \"#FFFFFF\"\n          banner:\n            closeButtonColor:\
    \ \"#FFFFFF\"\n            error: \"#E22134\"\n            info: \"#2E77D0\"\n\
    \            link: \"#000000\"\n            text: \"#FFFFFF\"\n            warning:\
    \ \"#FF9800\"\n          border: \"#E6E6E6\"\n          bursts:\n            backgroundColor:\n\
    \              default: \"#7C3699\"\n            fontColor: \"#FEFEFE\"\n    \
    \        gradient:\n              linear: \"linear-gradient(-137deg, #4BB8A5 0%,\
    \ #187656 100%)\"\n          slackChannelText: \"#ddd\"\n          errorBackground:\
    \ \"#FFEBEE\"\n          errorText: \"#CA001B\"\n          gold: \"#FFD600\"\n\
    \          highlight: \"#FFFBCC\"\n          infoBackground: \"#ebf5ff\"\n   \
    \       infoText: \"#004e8a\"\n          link: \"#0A6EBE\"\n          linkHover:\
    \ \"#2196F3\"\n          mode: \"light\"\n          navigation:\n            background:\
    \ \"#222427\"\n            indicator: \"#0066CC\"\n            color: \"#ffffff\"\
    \n            selectedColor: \"#ffffff\"\n            navItem:\n             \
    \ hoverBackground: \"#3c3f42\"\n            submenu:\n              background:\
    \ \"#222427\"\n          pinSidebarButton:\n            background: \"#BDBDBD\"\
    \n            icon: \"#181818\"\n          primary:\n            main: \"#0066CC\"\
    \n          secondary:\n            main: \"#8476D1\"\n          status:\n   \
    \         aborted: \"#757575\"\n            error: \"#E22134\"\n            ok:\
    \ \"#1DB954\"\n            pending: \"#FFED51\"\n            running: \"#1F5493\"\
    \n            warning: \"#FF9800\"\n          tabbar:\n            indicator:\
    \ \"#9BF0E1\"\n          textContrast: \"#000000\"\n          textSubtle: \"#6E6E6E\"\
    \n          textVerySubtle: \"#DDD\"\n          warningBackground: \"#F59B23\"\
    \n          warningText: \"#000000\"\n          text:\n            primary: \"\
    #151515\"\n            secondary: \"#757575\"\n          rhdh:\n            general:\n\
    \              disabledBackground: \"#D2D2D2\"\n              disabled: \"#6A6E73\"\
    \n              searchBarBorderColor: \"#E4E4E4\"\n              formControlBackgroundColor:\
    \ \"#FFF\"\n              mainSectionBackgroundColor: \"#FFF\"\n             \
    \ headerBottomBorderColor: \"#C7C7C7\"\n              cardBackgroundColor: \"\
    #FFF\"\n              sidebarBackgroundColor: \"#212427\"\n              cardBorderColor:\
    \ \"#C7C7C7\"\n              tableTitleColor: \"#181818\"\n              tableSubtitleColor:\
    \ \"#616161\"\n              tableColumnTitleColor: \"#151515\"\n            \
    \  tableRowHover: \"#F5F5F5\"\n              tableBorderColor: \"#E0E0E0\"\n \
    \             tableBackgroundColor: \"#FFF\"\n              tabsBottomBorderColor:\
    \ \"#D2D2D2\"\n              contrastText: \"#FFF\"\n            primary:\n  \
    \            main: \"#0066CC\"\n              focusVisibleBorder: \"#0066CC\"\n\
    \            secondary:\n              main: \"#8476D1\"\n              focusVisibleBorder:\
    \ \"#8476D1\"\n            cards:\n              headerTextColor: \"#151515\"\n\
    \              headerBackgroundColor: \"#FFF\"\n              headerBackgroundImage:\
    \ \"none\"\n      dark:\n        variant: \"rhdh\"\n        mode: \"dark\"\n \
    \       palette:\n          background:\n            default: \"#333333\"\n  \
    \          paper: \"#424242\"\n          banner:\n            closeButtonColor:\
    \ \"#FFFFFF\"\n            error: \"#E22134\"\n            info: \"#2E77D0\"\n\
    \            link: \"#000000\"\n            text: \"#FFFFFF\"\n            warning:\
    \ \"#FF9800\"\n          border: \"#E6E6E6\"\n          bursts:\n            backgroundColor:\n\
    \              default: \"#7C3699\"\n            fontColor: \"#FEFEFE\"\n    \
    \        gradient:\n              linear: \"linear-gradient(-137deg, #4BB8A5 0%,\
    \ #187656 100%)\"\n          slackChannelText: \"#ddd\"\n          errorBackground:\
    \ \"#FFEBEE\"\n          errorText: \"#CA001B\"\n          gold: \"#FFD600\"\n\
    \          highlight: \"#FFFBCC\"\n          infoBackground: \"#ebf5ff\"\n   \
    \       infoText: \"#004e8a\"\n          link: \"#9CC9FF\"\n          linkHover:\
    \ \"#82BAFD\"\n          mode: \"dark\"\n          navigation:\n            background:\
    \ \"#0f1214\"\n            indicator: \"#0066CC\"\n            color: \"#ffffff\"\
    \n            selectedColor: \"#ffffff\"\n            navItem:\n             \
    \ hoverBackground: \"#3c3f42\"\n            submenu:\n              background:\
    \ \"#0f1214\"\n          pinSidebarButton:\n            background: \"#BDBDBD\"\
    \n            icon: \"#404040\"\n          primary:\n            main: \"#1FA7F8\"\
    \n          secondary:\n            main: \"#B2A3FF\"\n          status:\n   \
    \         aborted: \"#9E9E9E\"\n            error: \"#F84C55\"\n            ok:\
    \ \"#71CF88\"\n            pending: \"#FEF071\"\n            running: \"#3488E3\"\
    \n            warning: \"#FFB84D\"\n          tabbar:\n            indicator:\
    \ \"#9BF0E1\"\n          textContrast: \"#FFFFFF\"\n          textSubtle: \"#CCCCCC\"\
    \n          textVerySubtle: \"#727272\"\n          warningBackground: \"#F59B23\"\
    \n          warningText: \"#000000\"\n          rhdh:\n            general:\n\
    \              disabledBackground: \"#444548\"\n              disabled: \"#AAABAC\"\
    \n              searchBarBorderColor: \"#57585a\"\n              formControlBackgroundColor:\
    \ \"#36373A\"\n              mainSectionBackgroundColor: \"#0f1214\"\n       \
    \       headerBottomBorderColor: \"#A3A3A3\"\n              cardBackgroundColor:\
    \ \"#292929\"\n              sidebarBackgroundColor: \"#1b1d21\"\n           \
    \   cardBorderColor: \"#A3A3A3\"\n              tableTitleColor: \"#E0E0E0\"\n\
    \              tableSubtitleColor: \"#E0E0E0\"\n              tableColumnTitleColor:\
    \ \"#E0E0E0\"\n              tableRowHover: \"#0f1214\"\n              tableBorderColor:\
    \ \"#515151\"\n              tableBackgroundColor: \"#1b1d21\"\n             \
    \ tabsBottomBorderColor: \"#444548\"\n              contrastText: \"#FFF\"\n \
    \           primary:\n              main: \"#1FA7F8\"\n              focusVisibleBorder:\
    \ \"#ADD6FF\"\n            secondary:\n              main: \"#B2A3FF\"\n     \
    \         focusVisibleBorder: \"#D0C7FF\"\n            cards:\n              headerTextColor:\
    \ \"#FFF\"\n              headerBackgroundColor: \"#0f1214\"\n              headerBackgroundImage:\
    \ \"none\"\n```\nAlternatively, you can use the following variant and mode values\
    \ to apply the previous default configuration:\n```yaml\napp:\n  branding:\n \
    \   theme:\n      light:\n        variant: \"rhdh\"\n        mode: \"light\"\n\
    \      dark:\n        variant: \"rhdh\"\n        mode: \"dark\"\n```\nAdditionally,\
    \ the default Developer Hub header color is white in light mode and black in dark\
    \ mode, as shown in the following configuration:\n```yaml\napp:\n  branding:\n\
    \    theme:\n      light:\n        palette: {}\n        defaultPageTheme: default\n\
    \        pageTheme:\n          default:\n            backgroundColor: \"#ffffff\"\
    \n      dark:\n        palette: {}\n        defaultPageTheme: default\n      \
    \  pageTheme:\n          default:\n            backgroundColor: \"#0f1214\"\n\
    ```"
  user_input: What are the specific YAML configurations I need to use in the app-config.yaml
    file to apply the default Red Hat Developer Hub theme, including the color palettes
    for both light and dark modes?
- context:
  - 'color palette The app-config.yaml file uses the following configurations for
    the default Backstage color palette: ```yaml app: branding: theme: light: variant:
    "backstage" mode: "light" palette: background: default: "#F8F8F8" paper: "#FFFFFF"
    banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0" link: "#000000"
    text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" navigation: background:
    "#171717" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground: "#404040"
    selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton: background:
    "#BDBDBD" icon: "#181818" primary: main: "#1F5493" status: aborted: "#757575"
    error: "#E22134" ok: "#1DB954" pending: "#FFED51" running: "#1F5493" warning:
    "#FF9800" tabbar: indicator: "#9BF0E1" textContrast: "#000000" textSubtle: "#6E6E6E"
    textVerySubtle: "#DDD" warningBackground: "#F59B23" warningText: "#000000" dark:
    variant: "backstage" mode: "dark" palette: background: default: "#333333" paper:
    "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#424242" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground:
    "#404040" selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: dark: "#82BAFD" main: "#9CC9FF"
    secondary: main: "#FF88B2" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88"
    pending: "#FEF071" running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1"
    textContrast: "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground:
    "#F59B23" warningText: "#000000" ``` Alternatively, you can use the following
    variant and mode values in the app-config.yaml file to apply the previous default
    configuration: ```yaml app: branding: theme: light: variant: "backstage" mode:
    "light" dark: variant: "backstage" mode: "dark" ``` ### Default Backstage page
    themes The default Backstage header color is white in light mode and black in
    dark mode, as shown in the following app-config.yaml file configuration: ```yaml
    app: branding: theme: light: palette: {} defaultPageTheme: default pageTheme:
    default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff'' shape: wave
    documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea fontColor:
    ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA''] # purpleSky
    fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'', ''#0049A1'']
    # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor: [''#0027AF'',
    ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library: backgroundColor:
    [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape: wave other:
    backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor: ''#ffffff''
    shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange fontColor:
    ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B''] # teal fontColor:
    ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'', ''#187656''] # greens
    fontColor: ''#ffffff'' shape: wave dark: palette: {} defaultPageTheme: default
    pageTheme: default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff''
    shape: wave documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea
    fontColor: ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA'']
    # purpleSky fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'',
    ''#0049A1''] # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor:
    [''#0027AF'', ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library:
    backgroundColor: [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape:
    wave other: backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor:
    ''#ffffff'' shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange
    fontColor: ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B'']
    # teal fontColor: ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'',
    ''#187656''] # greens fontColor: ''#ffffff'' shape: wave ``` ## Loading a custom
    Developer Hub theme by using a dynamic plugin You can load a custom Developer
    Hub theme from a dynamic plugin. 1. Export a theme provider function in your dynamic
    plugin, for example: Sample myTheme.ts fragment ```javascript import { lightTheme
    } from ''./lightTheme''; // some custom theme import { UnifiedThemeProvider }
    from ''@backstage/theme''; export const lightThemeProvider = ({ children }: {
    children: ReactNode }) => ( <UnifiedThemeProvider theme={lightTheme} children={children}
    /> ); ``` For more information about creating a custom theme, see Backstage documentation
    - Creating a Custom Theme. 2. Configure Developer Hub to load the theme in the
    UI by using the themes configuration field: app-config.yaml fragment ```yaml dynamicPlugins:
    frontend: example.my custom theme plugin: themes: id: light title: Light variant:
    light icon: someIconReference importName: lightThemeProvider ``` id:: Enter your
    theme ID, such as my_theme. Enter dark to override the default Developer Hub dark
    theme. Enter light to override the default Developer Hub light theme. The theme
    is available in the Developer Hub Settings page. ## Custom component options for
    your Developer Hub instance There are two component variants that you can use
    to customize various components of your Developer Hub theme: Patternfly MUI In
    addition to assigning a component variant to each parameter in the light or dark
    theme mode configurations, you can toggle the rippleEffect on or off. The following
    code shows the options that you can use in the app-config.yaml file to configure
    the theme components for your Developer Hub instance: ```yaml app: branding: theme:
    light: options: rippleEffect: off / on paper: patternfly / mui buttons: patternfly
    / mui inputs: patternfly / mui accordions: patternfly / mui sidebars: patternfly
    / mui pages: patternfly / mui headers: patternfly / mui toolbars: patternfly /
    mui dialogs: patternfly / mui cards: patternfly / mui tables: patternfly / mui
    tabs: patternfly / mui dark: options: rippleEffect: off / on paper: patternfly
    / mui buttons: patternfly / mui inputs: patternfly / mui accordions: patternfly
    / mui sidebars: patternfly / mui pages: patternfly / mui headers: patternfly /
    mui toolbars: patternfly / mui dialogs: patternfly / mui cards: patternfly / mui
    tables: patternfly / mui tabs: patternfly / mui ``` # Customizing the Home page
    When using your RHDH app-config.yaml file, you can do any of the following tasks:
    Customize and extend the default Home page layout with additional cards that appear
    based on the plugins you have installed and enabled. Change quick access links.
    Add, reorganize, and remove the available homepage cards. ## Available homepage
    cards As an administrative user, you can easily integrate custom features or content
    from any installed plugin into your Home page layout. You can use the additional
    cards available for configuration based on the frontend plugins you enable. The
    following is a list of the available homepage cards: Search bar Quick access Headline
    Markdown Placeholder Catalog starred entities Featured docs [NOTE] ---- Each card
    can have a layouts definition and'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:09.915997'
    uuid: 6db62262-2b1e-427c-a2df-1992a0f75798
  response: You can configure the theme in the app-config.yaml file. This file is
    used for setting the default Backstage color palette for both light and dark modes.
    You can also define default page themes, which include settings for background
    color and font color for different page types like 'documentation', 'service',
    and 'website'. Alternatively, you can load a custom theme from a dynamic plugin
    by exporting a theme provider function and configuring it in the app-config.yaml
    file. There are also custom component options that can be configured, allowing
    you to choose between 'Patternfly' and 'MUI' variants for components such as buttons,
    inputs, and cards, and to toggle the 'rippleEffect'.
  user_input: how do i configer backstge theme?
- context:
  - 'color palette The app-config.yaml file uses the following configurations for
    the default Backstage color palette: ```yaml app: branding: theme: light: variant:
    "backstage" mode: "light" palette: background: default: "#F8F8F8" paper: "#FFFFFF"
    banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0" link: "#000000"
    text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" navigation: background:
    "#171717" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground: "#404040"
    selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton: background:
    "#BDBDBD" icon: "#181818" primary: main: "#1F5493" status: aborted: "#757575"
    error: "#E22134" ok: "#1DB954" pending: "#FFED51" running: "#1F5493" warning:
    "#FF9800" tabbar: indicator: "#9BF0E1" textContrast: "#000000" textSubtle: "#6E6E6E"
    textVerySubtle: "#DDD" warningBackground: "#F59B23" warningText: "#000000" dark:
    variant: "backstage" mode: "dark" palette: background: default: "#333333" paper:
    "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#424242" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground:
    "#404040" selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: dark: "#82BAFD" main: "#9CC9FF"
    secondary: main: "#FF88B2" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88"
    pending: "#FEF071" running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1"
    textContrast: "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground:
    "#F59B23" warningText: "#000000" ``` Alternatively, you can use the following
    variant and mode values in the app-config.yaml file to apply the previous default
    configuration: ```yaml app: branding: theme: light: variant: "backstage" mode:
    "light" dark: variant: "backstage" mode: "dark" ``` ### Default Backstage page
    themes The default Backstage header color is white in light mode and black in
    dark mode, as shown in the following app-config.yaml file configuration: ```yaml
    app: branding: theme: light: palette: {} defaultPageTheme: default pageTheme:
    default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff'' shape: wave
    documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea fontColor:
    ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA''] # purpleSky
    fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'', ''#0049A1'']
    # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor: [''#0027AF'',
    ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library: backgroundColor:
    [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape: wave other:
    backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor: ''#ffffff''
    shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange fontColor:
    ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B''] # teal fontColor:
    ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'', ''#187656''] # greens
    fontColor: ''#ffffff'' shape: wave dark: palette: {} defaultPageTheme: default
    pageTheme: default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff''
    shape: wave documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea
    fontColor: ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA'']
    # purpleSky fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'',
    ''#0049A1''] # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor:
    [''#0027AF'', ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library:
    backgroundColor: [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape:
    wave other: backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor:
    ''#ffffff'' shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange
    fontColor: ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B'']
    # teal fontColor: ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'',
    ''#187656''] # greens fontColor: ''#ffffff'' shape: wave ``` ## Loading a custom
    Developer Hub theme by using a dynamic plugin You can load a custom Developer
    Hub theme from a dynamic plugin. 1. Export a theme provider function in your dynamic
    plugin, for example: Sample myTheme.ts fragment ```javascript import { lightTheme
    } from ''./lightTheme''; // some custom theme import { UnifiedThemeProvider }
    from ''@backstage/theme''; export const lightThemeProvider = ({ children }: {
    children: ReactNode }) => ( <UnifiedThemeProvider theme={lightTheme} children={children}
    /> ); ``` For more information about creating a custom theme, see Backstage documentation
    - Creating a Custom Theme. 2. Configure Developer Hub to load the theme in the
    UI by using the themes configuration field: app-config.yaml fragment ```yaml dynamicPlugins:
    frontend: example.my custom theme plugin: themes: id: light title: Light variant:
    light icon: someIconReference importName: lightThemeProvider ``` id:: Enter your
    theme ID, such as my_theme. Enter dark to override the default Developer Hub dark
    theme. Enter light to override the default Developer Hub light theme. The theme
    is available in the Developer Hub Settings page. ## Custom component options for
    your Developer Hub instance There are two component variants that you can use
    to customize various components of your Developer Hub theme: Patternfly MUI In
    addition to assigning a component variant to each parameter in the light or dark
    theme mode configurations, you can toggle the rippleEffect on or off. The following
    code shows the options that you can use in the app-config.yaml file to configure
    the theme components for your Developer Hub instance: ```yaml app: branding: theme:
    light: options: rippleEffect: off / on paper: patternfly / mui buttons: patternfly
    / mui inputs: patternfly / mui accordions: patternfly / mui sidebars: patternfly
    / mui pages: patternfly / mui headers: patternfly / mui toolbars: patternfly /
    mui dialogs: patternfly / mui cards: patternfly / mui tables: patternfly / mui
    tabs: patternfly / mui dark: options: rippleEffect: off / on paper: patternfly
    / mui buttons: patternfly / mui inputs: patternfly / mui accordions: patternfly
    / mui sidebars: patternfly / mui pages: patternfly / mui headers: patternfly /
    mui toolbars: patternfly / mui dialogs: patternfly / mui cards: patternfly / mui
    tables: patternfly / mui tabs: patternfly / mui ``` # Customizing the Home page
    When using your RHDH app-config.yaml file, you can do any of the following tasks:
    Customize and extend the default Home page layout with additional cards that appear
    based on the plugins you have installed and enabled. Change quick access links.
    Add, reorganize, and remove the available homepage cards. ## Available homepage
    cards As an administrative user, you can easily integrate custom features or content
    from any installed plugin into your Home page layout. You can use the additional
    cards available for configuration based on the frontend plugins you enable. The
    following is a list of the available homepage cards: Search bar Quick access Headline
    Markdown Placeholder Catalog starred entities Featured docs [NOTE] ---- Each card
    can have a layouts definition and'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:16.630016'
    uuid: a5d448cf-5d56-4358-b4d2-f6b08baf85d2
  response: 'There are two component variants that you can use to customize various
    components of your Developer Hub theme: Patternfly and MUI. These variants can
    be assigned to components such as paper, buttons, inputs, accordions, sidebars,
    pages, headers, toolbars, dialogs, cards, tables, and tabs in the app-config.yaml
    file. In addition to these variants, you can also toggle the rippleEffect on or
    off.'
  user_input: Wut are the component varients I can use to custmize our Developer Hub
    theme?
- context:
  - 'color palette The app-config.yaml file uses the following configurations for
    the default Backstage color palette: ```yaml app: branding: theme: light: variant:
    "backstage" mode: "light" palette: background: default: "#F8F8F8" paper: "#FFFFFF"
    banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0" link: "#000000"
    text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#0A6EBE" linkHover: "#2196F3" navigation: background:
    "#171717" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground: "#404040"
    selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton: background:
    "#BDBDBD" icon: "#181818" primary: main: "#1F5493" status: aborted: "#757575"
    error: "#E22134" ok: "#1DB954" pending: "#FFED51" running: "#1F5493" warning:
    "#FF9800" tabbar: indicator: "#9BF0E1" textContrast: "#000000" textSubtle: "#6E6E6E"
    textVerySubtle: "#DDD" warningBackground: "#F59B23" warningText: "#000000" dark:
    variant: "backstage" mode: "dark" palette: background: default: "#333333" paper:
    "#424242" banner: closeButtonColor: "#FFFFFF" error: "#E22134" info: "#2E77D0"
    link: "#000000" text: "#FFFFFF" warning: "#FF9800" border: "#E6E6E6" bursts: backgroundColor:
    default: "#7C3699" fontColor: "#FEFEFE" gradient: linear: "linear-gradient(-137deg,
    #4BB8A5 0%, #187656 100%)" slackChannelText: "#ddd" errorBackground: "#FFEBEE"
    errorText: "#CA001B" gold: "#FFD600" highlight: "#FFFBCC" infoBackground: "#ebf5ff"
    infoText: "#004e8a" link: "#9CC9FF" linkHover: "#82BAFD" mode: "dark" navigation:
    background: "#424242" color: "#b5b5b5" indicator: "#9BF0E1" navItem: hoverBackground:
    "#404040" selectedColor: "#FFF" submenu: background: "#404040" pinSidebarButton:
    background: "#BDBDBD" icon: "#404040" primary: dark: "#82BAFD" main: "#9CC9FF"
    secondary: main: "#FF88B2" status: aborted: "#9E9E9E" error: "#F84C55" ok: "#71CF88"
    pending: "#FEF071" running: "#3488E3" warning: "#FFB84D" tabbar: indicator: "#9BF0E1"
    textContrast: "#FFFFFF" textSubtle: "#CCCCCC" textVerySubtle: "#727272" warningBackground:
    "#F59B23" warningText: "#000000" ``` Alternatively, you can use the following
    variant and mode values in the app-config.yaml file to apply the previous default
    configuration: ```yaml app: branding: theme: light: variant: "backstage" mode:
    "light" dark: variant: "backstage" mode: "dark" ``` ### Default Backstage page
    themes The default Backstage header color is white in light mode and black in
    dark mode, as shown in the following app-config.yaml file configuration: ```yaml
    app: branding: theme: light: palette: {} defaultPageTheme: default pageTheme:
    default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff'' shape: wave
    documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea fontColor:
    ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA''] # purpleSky
    fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'', ''#0049A1'']
    # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor: [''#0027AF'',
    ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library: backgroundColor:
    [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape: wave other:
    backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor: ''#ffffff''
    shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange fontColor:
    ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B''] # teal fontColor:
    ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'', ''#187656''] # greens
    fontColor: ''#ffffff'' shape: wave dark: palette: {} defaultPageTheme: default
    pageTheme: default: backgroundColor: [''#005B4B''] # teal fontColor: ''#ffffff''
    shape: wave documentation: backgroundColor: [''#C8077A'', ''#C2297D''] # pinkSea
    fontColor: ''#ffffff'' shape: wave2 tool: backgroundColor: [''#8912CA'', ''#3E00EA'']
    # purpleSky fontColor: ''#ffffff'' shape: round service: backgroundColor: [''#006D8F'',
    ''#0049A1''] # marineBlue fontColor: ''#ffffff'' shape: wave website: backgroundColor:
    [''#0027AF'', ''#270094''] # veryBlue fontColor: ''#ffffff'' shape: wave library:
    backgroundColor: [''#98002B'', ''#8D1134''] # rubyRed fontColor: ''#ffffff'' shape:
    wave other: backgroundColor: [''#171717'', ''#383838''] # darkGrey fontColor:
    ''#ffffff'' shape: wave app: backgroundColor: [''#BE2200'', ''#A41D00''] # toastyOrange
    fontColor: ''#ffffff'' shape: shapes.wave apis: backgroundColor: [''#005B4B'']
    # teal fontColor: ''#ffffff'' shape: wave2 card: backgroundColor: [''#4BB8A5'',
    ''#187656''] # greens fontColor: ''#ffffff'' shape: wave ``` ## Loading a custom
    Developer Hub theme by using a dynamic plugin You can load a custom Developer
    Hub theme from a dynamic plugin. 1. Export a theme provider function in your dynamic
    plugin, for example: Sample myTheme.ts fragment ```javascript import { lightTheme
    } from ''./lightTheme''; // some custom theme import { UnifiedThemeProvider }
    from ''@backstage/theme''; export const lightThemeProvider = ({ children }: {
    children: ReactNode }) => ( <UnifiedThemeProvider theme={lightTheme} children={children}
    /> ); ``` For more information about creating a custom theme, see Backstage documentation
    - Creating a Custom Theme. 2. Configure Developer Hub to load the theme in the
    UI by using the themes configuration field: app-config.yaml fragment ```yaml dynamicPlugins:
    frontend: example.my custom theme plugin: themes: id: light title: Light variant:
    light icon: someIconReference importName: lightThemeProvider ``` id:: Enter your
    theme ID, such as my_theme. Enter dark to override the default Developer Hub dark
    theme. Enter light to override the default Developer Hub light theme. The theme
    is available in the Developer Hub Settings page. ## Custom component options for
    your Developer Hub instance There are two component variants that you can use
    to customize various components of your Developer Hub theme: Patternfly MUI In
    addition to assigning a component variant to each parameter in the light or dark
    theme mode configurations, you can toggle the rippleEffect on or off. The following
    code shows the options that you can use in the app-config.yaml file to configure
    the theme components for your Developer Hub instance: ```yaml app: branding: theme:
    light: options: rippleEffect: off / on paper: patternfly / mui buttons: patternfly
    / mui inputs: patternfly / mui accordions: patternfly / mui sidebars: patternfly
    / mui pages: patternfly / mui headers: patternfly / mui toolbars: patternfly /
    mui dialogs: patternfly / mui cards: patternfly / mui tables: patternfly / mui
    tabs: patternfly / mui dark: options: rippleEffect: off / on paper: patternfly
    / mui buttons: patternfly / mui inputs: patternfly / mui accordions: patternfly
    / mui sidebars: patternfly / mui pages: patternfly / mui headers: patternfly /
    mui toolbars: patternfly / mui dialogs: patternfly / mui cards: patternfly / mui
    tables: patternfly / mui tabs: patternfly / mui ``` # Customizing the Home page
    When using your RHDH app-config.yaml file, you can do any of the following tasks:
    Customize and extend the default Home page layout with additional cards that appear
    based on the plugins you have installed and enabled. Change quick access links.
    Add, reorganize, and remove the available homepage cards. ## Available homepage
    cards As an administrative user, you can easily integrate custom features or content
    from any installed plugin into your Home page layout. You can use the additional
    cards available for configuration based on the frontend plugins you enable. The
    following is a list of the available homepage cards: Search bar Quick access Headline
    Markdown Placeholder Catalog starred entities Featured docs [NOTE] ---- Each card
    can have a layouts definition and'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:22.771281'
    uuid: f4133685-9619-4e9c-a170-59bffc2f7ce9
  response: In the app-config.yaml file, you can use two component variants, Patternfly
    and MUI, to customize various components of your Developer Hub theme. In addition
    to toggling the rippleEffect on or off, you can assign a component variant to
    parameters in the light or dark theme mode configurations for components including
    paper, buttons, inputs, accordions, sidebars, pages, headers, toolbars, dialogs,
    cards, tables, and tabs.
  user_input: how can i use the YAML to change the component options like for buttons
    and tables so they are standard for my devs?
- context:
  - 'Customizing the Home page cards As an administrator, you can customize the layout
    and content of the Home page to create a tailored user experience. This includes
    integrating various specialized cards into the primary view. The Home page layout
    uses a 12-column grid system. You can precisely define the position (x), width
    (w), and height (h) for each card across multiple screen breakpoints: Extra large
    (xl) Large (lg) Medium (md) Small (sm) Extra small (xs) Extra extra small (xxs)
    The default Home page is as shown in the following app-config.yaml file configuration:
    ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } - mountPoint: home.page/cards importName:
    QuickAccessCard config: layouts: xl: { w: 7, h: 8 } lg: { w: 7, h: 8 } md: { w:
    7, h: 8 } sm: { w: 12, h: 8 } xs: { w: 12, h: 8 } xxs: { w: 12, h: 8 } - mountPoint:
    home.page/cards importName: CatalogStarredEntitiesCard config: layouts: xl: {
    w: 5, h: 4, x: 7 } lg: { w: 5, h: 4, x: 7 } md: { w: 5, h: 4, x: 7 } sm: { w:
    12, h: 4 } xs: { w: 12, h: 4 } xxs: { w: 12, h: 4 } ``` You have administrative
    access and can modify the app config.yaml file for dynamic plugin configurations.
    Configure different cards for your Home page in Red Hat Developer Hub as shown
    in the following code: Search:: You can use the SearchBar card to provide essential
    search functionality directly on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } props: path: /search queryParam: query
    ``` Quick access:: You can use the QuickAccessCard card to function as a customizable
    shortcut panel. ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: QuickAccessCard config:
    layouts: xl: { h: 8 } lg: { h: 8 } md: { h: 8 } sm: { h: 8 } xs: { h: 8 } xxs:
    { h: 8 } props: title: Quick Access path: /quickaccess ``` Headline:: You can
    use the Headline card to display important information. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: Headline config: layouts: xl: { h: 1
    } lg: { h: 1 } md: { h: 1 } sm: { h: 1 } xs: { h: 1 } xxs: { h: 1 } props: title:
    Important info ``` Markdown:: You can use the Markdown card to display richly
    formatted content directly within the Home page layout. This card uses Markdown
    syntax to present structured information, such as lists and links (documentation
    and plugin repositories). ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: MarkdownCard config: layouts:
    xl: { w: 6, h: 4 } lg: { w: 6, h: 4 } md: { w: 6, h: 4 } sm: { w: 6, h: 4 } xs:
    { w: 6, h: 4 } xxs: { w: 6, h: 4 } props: title: Company links content: | ###
    RHDH * [Website](https://developers.redhat.com/rhdh/overview) * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    - mountPoint: home.page/cards importName: Markdown config: layouts: xl: { w: 6,
    h: 4, x: 6 } lg: { w: 6, h: 4, x: 6 } md: { w: 6, h: 4, x: 6 } sm: { w: 6, h:
    4, x: 6 } xs: { w: 6, h: 4, x: 6 } xxs: { w: 6, h: 4, x: 6 } props: title: Important
    company links content: | ### RHDH * [Website](https://developers.redhat.com/rhdh/overview)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    ``` Placeholder:: You can use the Placeholder card as a utility element for reserving
    space or for layout testing on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: Placeholder config: layouts: xl: { w: 1, h: 1 } lg:
    { w: 1, h: 1 } md: { w: 1, h: 1 } sm: { w: 1, h: 1 } xs: { w: 1, h: 1 } xxs: {
    w: 1, h: 1 } props: showBorder: true debugContent: ''1'' ``` Catalog starred entities::
    You can use the CatalogStarredEntitiesCard card to provide a dedicated space on
    the Home page for users to view catalog entities that they have marked as starred.
    ```yaml dynamicPlugins: frontend: red hat developer hub.backstage plugin dynamic
    home page: mountPoints: mountPoint: home.page/cards importName: CatalogStarredEntitiesCard
    ``` Featured docs:: You can use the FeaturedDocsCard card as a way to highlight
    specific documentation within Red Hat Developer Hub, as it is available for deployment
    on the Home page. ```yaml dynamicPlugins: frontend: red hat developer hub.backstage
    plugin dynamic home page: mountPoints: mountPoint: home.page/cards importName:
    FeaturedDocsCard ``` EntitySection:: You can use the EntitySection card to create
    a visually engaging section that highlights catalog entities of various kinds,
    such as Component, API, Resource, and System. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: EntitySection config: layouts: xl: { w: 12, h: 6 }
    lg: { w: 12, h: 6 } md: { w: 12, h: 6 } sm: { w: 12, h: 6 } xs: { w: 12, h: 6
    } xxs: { w: 12, h: 14.5 } ``` OnboardingSection:: You can use the OnboardingSection
    card to quickly discover learning resources within RHDH. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config: layouts: xl:
    { w: 12, h: 5 } lg: { w: 12, h:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:31.271573'
    uuid: 62a36ff0-5f54-4555-a208-2b22cd631c54
  response: 'As an administrator, you can customize the layout and content of the
    Home page in Red Hat Developer Hub by configuring different cards. The available
    cards include: the SearchBar card for search functionality; the QuickAccessCard,
    which functions as a customizable shortcut panel; the Headline card to display
    important information; the Markdown card for richly formatted content like lists
    and links; the Placeholder card for reserving space or layout testing; the CatalogStarredEntitiesCard
    for users to view their starred catalog entities; the FeaturedDocsCard to highlight
    specific documentation; the EntitySection card to highlight various catalog entities
    such as Component, API, Resource, and System; and the OnboardingSection card for
    discovering learning resources.'
  user_input: how do i customize the Red Hat Developer Hub homepage for my team, what
    kind of cards is there for me to add to it?
- context:
  - 'Customizing the Home page cards As an administrator, you can customize the layout
    and content of the Home page to create a tailored user experience. This includes
    integrating various specialized cards into the primary view. The Home page layout
    uses a 12-column grid system. You can precisely define the position (x), width
    (w), and height (h) for each card across multiple screen breakpoints: Extra large
    (xl) Large (lg) Medium (md) Small (sm) Extra small (xs) Extra extra small (xxs)
    The default Home page is as shown in the following app-config.yaml file configuration:
    ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } - mountPoint: home.page/cards importName:
    QuickAccessCard config: layouts: xl: { w: 7, h: 8 } lg: { w: 7, h: 8 } md: { w:
    7, h: 8 } sm: { w: 12, h: 8 } xs: { w: 12, h: 8 } xxs: { w: 12, h: 8 } - mountPoint:
    home.page/cards importName: CatalogStarredEntitiesCard config: layouts: xl: {
    w: 5, h: 4, x: 7 } lg: { w: 5, h: 4, x: 7 } md: { w: 5, h: 4, x: 7 } sm: { w:
    12, h: 4 } xs: { w: 12, h: 4 } xxs: { w: 12, h: 4 } ``` You have administrative
    access and can modify the app config.yaml file for dynamic plugin configurations.
    Configure different cards for your Home page in Red Hat Developer Hub as shown
    in the following code: Search:: You can use the SearchBar card to provide essential
    search functionality directly on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } props: path: /search queryParam: query
    ``` Quick access:: You can use the QuickAccessCard card to function as a customizable
    shortcut panel. ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: QuickAccessCard config:
    layouts: xl: { h: 8 } lg: { h: 8 } md: { h: 8 } sm: { h: 8 } xs: { h: 8 } xxs:
    { h: 8 } props: title: Quick Access path: /quickaccess ``` Headline:: You can
    use the Headline card to display important information. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: Headline config: layouts: xl: { h: 1
    } lg: { h: 1 } md: { h: 1 } sm: { h: 1 } xs: { h: 1 } xxs: { h: 1 } props: title:
    Important info ``` Markdown:: You can use the Markdown card to display richly
    formatted content directly within the Home page layout. This card uses Markdown
    syntax to present structured information, such as lists and links (documentation
    and plugin repositories). ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: MarkdownCard config: layouts:
    xl: { w: 6, h: 4 } lg: { w: 6, h: 4 } md: { w: 6, h: 4 } sm: { w: 6, h: 4 } xs:
    { w: 6, h: 4 } xxs: { w: 6, h: 4 } props: title: Company links content: | ###
    RHDH * [Website](https://developers.redhat.com/rhdh/overview) * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    - mountPoint: home.page/cards importName: Markdown config: layouts: xl: { w: 6,
    h: 4, x: 6 } lg: { w: 6, h: 4, x: 6 } md: { w: 6, h: 4, x: 6 } sm: { w: 6, h:
    4, x: 6 } xs: { w: 6, h: 4, x: 6 } xxs: { w: 6, h: 4, x: 6 } props: title: Important
    company links content: | ### RHDH * [Website](https://developers.redhat.com/rhdh/overview)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    ``` Placeholder:: You can use the Placeholder card as a utility element for reserving
    space or for layout testing on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: Placeholder config: layouts: xl: { w: 1, h: 1 } lg:
    { w: 1, h: 1 } md: { w: 1, h: 1 } sm: { w: 1, h: 1 } xs: { w: 1, h: 1 } xxs: {
    w: 1, h: 1 } props: showBorder: true debugContent: ''1'' ``` Catalog starred entities::
    You can use the CatalogStarredEntitiesCard card to provide a dedicated space on
    the Home page for users to view catalog entities that they have marked as starred.
    ```yaml dynamicPlugins: frontend: red hat developer hub.backstage plugin dynamic
    home page: mountPoints: mountPoint: home.page/cards importName: CatalogStarredEntitiesCard
    ``` Featured docs:: You can use the FeaturedDocsCard card as a way to highlight
    specific documentation within Red Hat Developer Hub, as it is available for deployment
    on the Home page. ```yaml dynamicPlugins: frontend: red hat developer hub.backstage
    plugin dynamic home page: mountPoints: mountPoint: home.page/cards importName:
    FeaturedDocsCard ``` EntitySection:: You can use the EntitySection card to create
    a visually engaging section that highlights catalog entities of various kinds,
    such as Component, API, Resource, and System. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: EntitySection config: layouts: xl: { w: 12, h: 6 }
    lg: { w: 12, h: 6 } md: { w: 12, h: 6 } sm: { w: 12, h: 6 } xs: { w: 12, h: 6
    } xxs: { w: 12, h: 14.5 } ``` OnboardingSection:: You can use the OnboardingSection
    card to quickly discover learning resources within RHDH. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config: layouts: xl:
    { w: 12, h: 5 } lg: { w: 12, h:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:39.302064'
    uuid: 4f413b0b-132e-4dc8-8965-bf73e5e892d1
  response: You can use the Markdown card to display richly formatted content directly
    within the Home page layout. This card uses Markdown syntax to present structured
    information, such as lists and links for documentation and plugin repositories.
  user_input: wat is the MarkdownCard for?
- context:
  - 'Customizing the Home page cards As an administrator, you can customize the layout
    and content of the Home page to create a tailored user experience. This includes
    integrating various specialized cards into the primary view. The Home page layout
    uses a 12-column grid system. You can precisely define the position (x), width
    (w), and height (h) for each card across multiple screen breakpoints: Extra large
    (xl) Large (lg) Medium (md) Small (sm) Extra small (xs) Extra extra small (xxs)
    The default Home page is as shown in the following app-config.yaml file configuration:
    ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } - mountPoint: home.page/cards importName:
    QuickAccessCard config: layouts: xl: { w: 7, h: 8 } lg: { w: 7, h: 8 } md: { w:
    7, h: 8 } sm: { w: 12, h: 8 } xs: { w: 12, h: 8 } xxs: { w: 12, h: 8 } - mountPoint:
    home.page/cards importName: CatalogStarredEntitiesCard config: layouts: xl: {
    w: 5, h: 4, x: 7 } lg: { w: 5, h: 4, x: 7 } md: { w: 5, h: 4, x: 7 } sm: { w:
    12, h: 4 } xs: { w: 12, h: 4 } xxs: { w: 12, h: 4 } ``` You have administrative
    access and can modify the app config.yaml file for dynamic plugin configurations.
    Configure different cards for your Home page in Red Hat Developer Hub as shown
    in the following code: Search:: You can use the SearchBar card to provide essential
    search functionality directly on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: SearchBar config: layouts: xl: { w: 10, h: 1, x: 1
    } lg: { w: 10, h: 1, x: 1 } md: { w: 10, h: 1, x: 1 } sm: { w: 10, h: 1, x: 1
    } xs: { w: 12, h: 1 } xxs: { w: 12, h: 1 } props: path: /search queryParam: query
    ``` Quick access:: You can use the QuickAccessCard card to function as a customizable
    shortcut panel. ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: QuickAccessCard config:
    layouts: xl: { h: 8 } lg: { h: 8 } md: { h: 8 } sm: { h: 8 } xs: { h: 8 } xxs:
    { h: 8 } props: title: Quick Access path: /quickaccess ``` Headline:: You can
    use the Headline card to display important information. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: Headline config: layouts: xl: { h: 1
    } lg: { h: 1 } md: { h: 1 } sm: { h: 1 } xs: { h: 1 } xxs: { h: 1 } props: title:
    Important info ``` Markdown:: You can use the Markdown card to display richly
    formatted content directly within the Home page layout. This card uses Markdown
    syntax to present structured information, such as lists and links (documentation
    and plugin repositories). ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: MarkdownCard config: layouts:
    xl: { w: 6, h: 4 } lg: { w: 6, h: 4 } md: { w: 6, h: 4 } sm: { w: 6, h: 4 } xs:
    { w: 6, h: 4 } xxs: { w: 6, h: 4 } props: title: Company links content: | ###
    RHDH * [Website](https://developers.redhat.com/rhdh/overview) * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    - mountPoint: home.page/cards importName: Markdown config: layouts: xl: { w: 6,
    h: 4, x: 6 } lg: { w: 6, h: 4, x: 6 } md: { w: 6, h: 4, x: 6 } sm: { w: 6, h:
    4, x: 6 } xs: { w: 6, h: 4, x: 6 } xxs: { w: 6, h: 4, x: 6 } props: title: Important
    company links content: | ### RHDH * [Website](https://developers.redhat.com/rhdh/overview)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Documentation](https://docs.redhat.com/en/documentation/red_hat_developer_hub/)
    * [Backstage Community Plugins](https://github.com/backstage/community-plugins)
    * [RHDH Plugins](https://github.com/redhat-developer/rhdh-plugins) * [RHDH Hub](https://github.com/redhat-developer/rhdh)
    ``` Placeholder:: You can use the Placeholder card as a utility element for reserving
    space or for layout testing on the Home page. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: Placeholder config: layouts: xl: { w: 1, h: 1 } lg:
    { w: 1, h: 1 } md: { w: 1, h: 1 } sm: { w: 1, h: 1 } xs: { w: 1, h: 1 } xxs: {
    w: 1, h: 1 } props: showBorder: true debugContent: ''1'' ``` Catalog starred entities::
    You can use the CatalogStarredEntitiesCard card to provide a dedicated space on
    the Home page for users to view catalog entities that they have marked as starred.
    ```yaml dynamicPlugins: frontend: red hat developer hub.backstage plugin dynamic
    home page: mountPoints: mountPoint: home.page/cards importName: CatalogStarredEntitiesCard
    ``` Featured docs:: You can use the FeaturedDocsCard card as a way to highlight
    specific documentation within Red Hat Developer Hub, as it is available for deployment
    on the Home page. ```yaml dynamicPlugins: frontend: red hat developer hub.backstage
    plugin dynamic home page: mountPoints: mountPoint: home.page/cards importName:
    FeaturedDocsCard ``` EntitySection:: You can use the EntitySection card to create
    a visually engaging section that highlights catalog entities of various kinds,
    such as Component, API, Resource, and System. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: EntitySection config: layouts: xl: { w: 12, h: 6 }
    lg: { w: 12, h: 6 } md: { w: 12, h: 6 } sm: { w: 12, h: 6 } xs: { w: 12, h: 6
    } xxs: { w: 12, h: 14.5 } ``` OnboardingSection:: You can use the OnboardingSection
    card to quickly discover learning resources within RHDH. ```yaml dynamicPlugins:
    frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config: layouts: xl:
    { w: 12, h: 5 } lg: { w: 12, h:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:47.041459'
    uuid: 4b9053d3-13bc-41b8-a65e-a5092d4423d3
  response: The OnboardingSection card is used to enable the quick discovery of learning
    resources within RHDH.
  user_input: What is the primary function of the OnboardingSection card when customizing
    the Home page for our developers?
- context:
  - '5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 12 } ``` TemplateSection:: You can use the TemplateSection card to quickly
    explore and initiate software templates in RHDH. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: TemplateSection config: layouts: xl: { w: 12, h: 5
    } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h:
    5 } xxs: { w: 12, h: 14 } ``` ## Defining the layout of the Red Hat Developer
    Hub Home page The Home page uses a 12-column grid to position your cards. You
    can use the optimal parameters to define the layout of your Developer Hub Home
    page. Include the following optimal parameters in each of your breakpoints: width
    (w) height (h) position (x and y) Configure your Developer Hub app config.yaml
    configuration file by choosing one of the following options: Use the full space
    on smaller windows and half of the space on larger windows as follows: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: a placeholder
    ``` Show the cards side by side by defining the x parameter as shown in the following
    example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    6, h: 2, x: 6 } lg: { w: 6, h: 2, x: 6 } md: { w: 6, h: 2, x: 6 } sm: { w: 12,
    h: 2, x: 0 } xs: { w: 12, h: 2, x: 0 } xxs: { w: 12, h: 2, x: 0 } props: showBorder:
    true debugContent: right ``` However, you can see a second card below this card
    by default. Show the cards in three columns by defining the x parameter as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 4, h: 2 } lg: { w: 4, h: 2 } md: { w: 4, h: 2 } sm: { w: 6, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    4, h: 2, x: 4 } lg: { w: 4, h: 2, x: 4 } md: { w: 4, h: 2, x: 4 } sm: { w: 6,
    h: 2, x: 6 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true
    debugContent: center - mountPoint: home.page/cards importName: Placeholder config:
    layouts: xl: { w: 4, h: 2, x: 8 } lg: { w: 4, h: 2, x: 8 } md: { w: 4, h: 2, x:
    8 } sm: { w: 6, h: 2 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder:
    true debugContent: right ``` ## Customizing your dynamic homepage to optimize
    your workflow You can customize your homepage to suit your preferences using the
    drag-and-drop, resizing, and widget management functionality. You can do the following
    actions with the customizable homepage: Drag and drop: Move cards around the layout
    Resize: Adjust card dimensions Add widget: Select from available cards to add
    to the homepage Remove cards: Delete cards from the homepage Restore defaults:
    Reset to the original card configuration User persistence: Settings are saved
    depending on how you use Backstage Storage API Additional cards automatically
    appear based on the installed and enabled plugins. The plugins provide the following
    two main components: DynamicHomePage: The read only homepage that displays configured
    cards without your customization. DynamicCustomizableHomePage: The interactive
    homepage that allows users to move, resize, and manage cards. The default homepage
    displays the OnboardingSection, the EntitySection, and the TemplateSection cards
    by default. These cards define the default width (w) and height (h) for the cards
    at various responsiveness levels. The homepage automatically loads the following
    configuration: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: OnboardingSection config: layouts: xl: { w: 12, h:
    6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w: 12, h: 8 } xs: { w: 12, h:
    9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards importName: EntitySection
    config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h: 7 } md: { w: 12, h: 8 } sm:
    { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12, h: 15 } - mountPoint: home.page/cards
    importName: TemplateSection config: layouts: xl: { w: 12, h: 5 } lg: { w: 12,
    h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 13 } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } ``` You can arrange the
    cards and adjust their dimensions using the drag and drop and resize functionality.
    The following is an example of an interactive homepage where you can add, remove,
    move, and resize cards: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicCustomizableHomePage mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:30:56.472206'
    uuid: 642fd3ed-1fff-46d6-99ad-22fcb3f1fb14
  response: 'The default homepage displays the OnboardingSection card by default.
    The configuration, which is loaded automatically, defines the default width (w)
    and height (h) for the card at various responsiveness levels. The layouts are
    configured as follows: xl: { w: 12, h: 6 }, lg: { w: 12, h: 6 }, md: { w: 12,
    h: 7 }, sm: { w: 12, h: 8 }, xs: { w: 12, h: 9 }, and xxs: { w: 12, h: 14 }.'
  user_input: How is the OnbordingSectoin card configured by defalt on the homepage
    for our new devs?
- context:
  - '5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 12 } ``` TemplateSection:: You can use the TemplateSection card to quickly
    explore and initiate software templates in RHDH. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: TemplateSection config: layouts: xl: { w: 12, h: 5
    } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h:
    5 } xxs: { w: 12, h: 14 } ``` ## Defining the layout of the Red Hat Developer
    Hub Home page The Home page uses a 12-column grid to position your cards. You
    can use the optimal parameters to define the layout of your Developer Hub Home
    page. Include the following optimal parameters in each of your breakpoints: width
    (w) height (h) position (x and y) Configure your Developer Hub app config.yaml
    configuration file by choosing one of the following options: Use the full space
    on smaller windows and half of the space on larger windows as follows: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: a placeholder
    ``` Show the cards side by side by defining the x parameter as shown in the following
    example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    6, h: 2, x: 6 } lg: { w: 6, h: 2, x: 6 } md: { w: 6, h: 2, x: 6 } sm: { w: 12,
    h: 2, x: 0 } xs: { w: 12, h: 2, x: 0 } xxs: { w: 12, h: 2, x: 0 } props: showBorder:
    true debugContent: right ``` However, you can see a second card below this card
    by default. Show the cards in three columns by defining the x parameter as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 4, h: 2 } lg: { w: 4, h: 2 } md: { w: 4, h: 2 } sm: { w: 6, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    4, h: 2, x: 4 } lg: { w: 4, h: 2, x: 4 } md: { w: 4, h: 2, x: 4 } sm: { w: 6,
    h: 2, x: 6 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true
    debugContent: center - mountPoint: home.page/cards importName: Placeholder config:
    layouts: xl: { w: 4, h: 2, x: 8 } lg: { w: 4, h: 2, x: 8 } md: { w: 4, h: 2, x:
    8 } sm: { w: 6, h: 2 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder:
    true debugContent: right ``` ## Customizing your dynamic homepage to optimize
    your workflow You can customize your homepage to suit your preferences using the
    drag-and-drop, resizing, and widget management functionality. You can do the following
    actions with the customizable homepage: Drag and drop: Move cards around the layout
    Resize: Adjust card dimensions Add widget: Select from available cards to add
    to the homepage Remove cards: Delete cards from the homepage Restore defaults:
    Reset to the original card configuration User persistence: Settings are saved
    depending on how you use Backstage Storage API Additional cards automatically
    appear based on the installed and enabled plugins. The plugins provide the following
    two main components: DynamicHomePage: The read only homepage that displays configured
    cards without your customization. DynamicCustomizableHomePage: The interactive
    homepage that allows users to move, resize, and manage cards. The default homepage
    displays the OnboardingSection, the EntitySection, and the TemplateSection cards
    by default. These cards define the default width (w) and height (h) for the cards
    at various responsiveness levels. The homepage automatically loads the following
    configuration: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: OnboardingSection config: layouts: xl: { w: 12, h:
    6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w: 12, h: 8 } xs: { w: 12, h:
    9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards importName: EntitySection
    config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h: 7 } md: { w: 12, h: 8 } sm:
    { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12, h: 15 } - mountPoint: home.page/cards
    importName: TemplateSection config: layouts: xl: { w: 12, h: 5 } lg: { w: 12,
    h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 13 } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } ``` You can arrange the
    cards and adjust their dimensions using the drag and drop and resize functionality.
    The following is an example of an interactive homepage where you can add, remove,
    move, and resize cards: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicCustomizableHomePage mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:03.632215'
    uuid: 6a6a6625-af3f-4376-9b41-04d55a641a9f
  response: 'In the Developer Hub app config.yaml file, you can use the Placeholder
    to define layouts. For example, to use the full space on smaller windows and half
    on larger windows, you can set the width (w) to 6 for xl, lg, and md layouts,
    and 12 for sm, xs, and xxs. To show cards side by side, you can define the x parameter
    for a second Placeholder card, setting x to 6 for larger layouts. To show cards
    in three columns, you can define the x parameter for multiple Placeholder cards,
    such as setting one at x: 4 and another at x: 8 for larger layouts.'
  user_input: how i use placeholder for layout?
- context:
  - '5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 12 } ``` TemplateSection:: You can use the TemplateSection card to quickly
    explore and initiate software templates in RHDH. ```yaml dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-dynamic-home-page: mountPoints: - mountPoint:
    home.page/cards importName: TemplateSection config: layouts: xl: { w: 12, h: 5
    } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h:
    5 } xxs: { w: 12, h: 14 } ``` ## Defining the layout of the Red Hat Developer
    Hub Home page The Home page uses a 12-column grid to position your cards. You
    can use the optimal parameters to define the layout of your Developer Hub Home
    page. Include the following optimal parameters in each of your breakpoints: width
    (w) height (h) position (x and y) Configure your Developer Hub app config.yaml
    configuration file by choosing one of the following options: Use the full space
    on smaller windows and half of the space on larger windows as follows: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: a placeholder
    ``` Show the cards side by side by defining the x parameter as shown in the following
    example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 6, h: 2 } lg: { w: 6, h: 2 } md: { w: 6, h: 2 } sm: { w: 12, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    6, h: 2, x: 6 } lg: { w: 6, h: 2, x: 6 } md: { w: 6, h: 2, x: 6 } sm: { w: 12,
    h: 2, x: 0 } xs: { w: 12, h: 2, x: 0 } xxs: { w: 12, h: 2, x: 0 } props: showBorder:
    true debugContent: right ``` However, you can see a second card below this card
    by default. Show the cards in three columns by defining the x parameter as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    mountPoints: - mountPoint: home.page/cards importName: Placeholder config: layouts:
    xl: { w: 4, h: 2 } lg: { w: 4, h: 2 } md: { w: 4, h: 2 } sm: { w: 6, h: 2 } xs:
    { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true debugContent: left
    - mountPoint: home.page/cards importName: Placeholder config: layouts: xl: { w:
    4, h: 2, x: 4 } lg: { w: 4, h: 2, x: 4 } md: { w: 4, h: 2, x: 4 } sm: { w: 6,
    h: 2, x: 6 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder: true
    debugContent: center - mountPoint: home.page/cards importName: Placeholder config:
    layouts: xl: { w: 4, h: 2, x: 8 } lg: { w: 4, h: 2, x: 8 } md: { w: 4, h: 2, x:
    8 } sm: { w: 6, h: 2 } xs: { w: 12, h: 2 } xxs: { w: 12, h: 2 } props: showBorder:
    true debugContent: right ``` ## Customizing your dynamic homepage to optimize
    your workflow You can customize your homepage to suit your preferences using the
    drag-and-drop, resizing, and widget management functionality. You can do the following
    actions with the customizable homepage: Drag and drop: Move cards around the layout
    Resize: Adjust card dimensions Add widget: Select from available cards to add
    to the homepage Remove cards: Delete cards from the homepage Restore defaults:
    Reset to the original card configuration User persistence: Settings are saved
    depending on how you use Backstage Storage API Additional cards automatically
    appear based on the installed and enabled plugins. The plugins provide the following
    two main components: DynamicHomePage: The read only homepage that displays configured
    cards without your customization. DynamicCustomizableHomePage: The interactive
    homepage that allows users to move, resize, and manage cards. The default homepage
    displays the OnboardingSection, the EntitySection, and the TemplateSection cards
    by default. These cards define the default width (w) and height (h) for the cards
    at various responsiveness levels. The homepage automatically loads the following
    configuration: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage mountPoints: - mountPoint:
    home.page/cards importName: OnboardingSection config: layouts: xl: { w: 12, h:
    6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w: 12, h: 8 } xs: { w: 12, h:
    9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards importName: EntitySection
    config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h: 7 } md: { w: 12, h: 8 } sm:
    { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12, h: 15 } - mountPoint: home.page/cards
    importName: TemplateSection config: layouts: xl: { w: 12, h: 5 } lg: { w: 12,
    h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5 } xs: { w: 12, h: 7 } xxs: { w: 12,
    h: 13 } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } ``` You can arrange the
    cards and adjust their dimensions using the drag and drop and resize functionality.
    The following is an example of an interactive homepage where you can add, remove,
    move, and resize cards: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicCustomizableHomePage mountPoints:
    - mountPoint: home.page/cards importName: OnboardingSection config:'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:12.347925'
    uuid: 18c309fb-ab8d-413f-be78-561e46af274e
  response: 'To show cards side by side using the "Placeholder" card, you must define
    the x parameter. For the second card, the layouts configuration would be: `xl:
    { w: 6, h: 2, x: 6 }`, `lg: { w: 6, h: 2, x: 6 }`, `md: { w: 6, h: 2, x: 6 }`,
    `sm: { w: 12, h: 2, x: 0 }`, `xs: { w: 12, h: 2, x: 0 }`, and `xxs: { w: 12, h:
    2, x: 0 }`. To show cards in three columns, you also define the x parameter. For
    the center card, the configuration includes `xl: { w: 4, h: 2, x: 4 }`, `lg: {
    w: 4, h: 2, x: 4 }`, `md: { w: 4, h: 2, x: 4 }`, and `sm: { w: 6, h: 2, x: 6 }`.
    For the right card, the configuration includes `xl: { w: 4, h: 2, x: 8 }`, `lg:
    { w: 4, h: 2, x: 8 }`, and `md: { w: 4, h: 2, x: 8 }`.'
  user_input: hey so im trying to configure the developer hub homepage and i see these
    examples using a "Placeholder" card, how do i use that to make the cards show
    up next to each other like side by side or even in three columns, what is the
    yaml config for the x parameter to make that happen?
- context:
  - 'layouts: xl: { w: 12, h: 6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w:
    12, h: 8 } xs: { w: 12, h: 9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards
    importName: EntitySection config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h:
    7 } md: { w: 12, h: 8 } sm: { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12,
    h: 15 } - mountPoint: home.page/cards importName: TemplateSection config: layouts:
    xl: { w: 12, h: 5 } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5
    } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } # Additional cards available in
    "Add widget" dialog - mountPoint: home.page/cards importName: RecentlyVisitedCard
    - mountPoint: home.page/cards importName: TopVisitedCard ``` You can change the
    title by overriding the title property of the dynamic homepage plugin as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    for customizable homepage config: props: title: ''Howdy {{firstName}} or {{displayName}}''
    ``` The title property supports two variables: * {{displayName}}: This contains
    the full displayName of the catalog entity. * {{firstName}}: This contains the
    first part (separated by a space) of the displayName. * You can use a subtitle
    property which is not used by default as shown in the following example: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    config: props: title: Our custom RHDH instance subtitle: ''Hello {{displayName}}''
    ``` ## Customizing QuickAccessCard card icons on the Red Hat Developer Hub homepage
    As an administrator, you can customize the QuickAccessCard card icons on the Red
    Hat Developer Hub homepage to enhance its visual appeal and user experience. You
    can integrate custom branding or standard icons by leveraging a remote JSON configuration
    file. 1. Add the JSON Data source. The QuickAccessCard card on the homepage supports
    loading data from a JSON file. This JSON file can be hosted in your GitHub repository
    or any accessible endpoint. 2. Configure the Proxy in your RHDH app-config.yaml
    file. To allow the homepage to fetch data from the hosted JSON file, add the following
    proxy configuration to your RHDH app-config.yaml file: ```yaml proxy: endpoints:
    # customize your backstage instance ''/developer-hub'': target: https://raw.githubusercontent.com/
    # For example, https://raw.githubusercontent.com/ pathRewrite: ''^/api/proxy/developer-hub$'':
    <path-to-your>.json # For example, /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true ``` The following table lists the supported icon
    types: [NOTE] ---- SVGs must be valid strings when stored inside JSON (use single
    quotes inside <svg>). ---- The following is an example of a JSON file: ```yaml
    [ { "title": "Community", "isExpanded": true, "links": [ { "iconUrl": "https://img.icons8.com/ios/50/globe--v1.png",
    "label": "Website", "url": "https://developers.redhat.com/" }, { "iconUrl": "https://img.icons8.com/ios/50/link--v1.png",
    "label": "Blog", "url": "https://developers.redhat.com/blog" }, { "iconUrl": "github",
    "label": "GitHub", "url": "https://github.com/redhat-developer" }, { "iconUrl":
    "https://img.icons8.com/color/48/slack.png", "label": "Slack", "url": "https://join.slack.com/xyz"
    }, { "iconUrl": "https://img.icons8.com/color/48/youtube-squared.png", "label":
    "Videos for developers", "url": "https://developers.redhat.com/videos" }, { "iconUrl":
    "<svg xmlns=''http://www.w3.org/2000/svg'' xml:space=''preserve'' width=''2048''
    height=''2048'' style=''shape-rendering:geometricPrecision;text-rendering:geometricPrecision;image-rendering:optimizeQuality;fill-rule:evenodd;clip-rule:evenodd''><defs><style>.fil0{fill:none}.fil4{fill:#bdbdbd;fill-rule:nonzero}</style></defs><g
    id=''Layer_x0020_1''><path class=''fil0'' d=''M0 0h2048v2048H0z''/><path class=''fil0''
    d=''M255.999 255.999h1536v1536h-1536z''/><path class=''fil0'' d=''M256 256h1536v1536H256z''/><g
    id=''_342647616''><path id=''_342648000'' style=''fill:#e53935;fill-rule:nonzero''
    d=''m273.04 666.226 737.28-367.843 13.68-6.824 13.68 6.824 737.28 367.843 17.04
    8.503v234.834L993.281 1418.52 255.999 909.563V674.729z''/><path id=''_342647880''
    style=''fill:#fff'' d=''M609.28 711.961h829.439V1541.4H609.28z''/><path id=''_342647808''
    style=''fill:#c62828;fill-rule:nonzero'' d=''m1024 1279.73 723.6-361.079 44.4-22.156v859.945H255.999V896.495l44.402
    22.156z''/><path id=''_342647736'' class=''fil4'' d=''M1331.2 896.285H716.716v-61.442H1331.2z''/><path
    id=''_342647688'' class=''fil4'' d=''M1203.22 1049.88H844.698v-61.439h358.522z''/></g></g></svg>",
    "label": "Mailing List", "url": "https://groups.google.com/g/xyz" }, ] } ] ```
    # Customizing the Quick access card To access the Home page in Red Hat Developer
    Hub, the base URL must include the /developer-hub proxy. You can configure the
    Home page by passing the data into the app-config.yaml file as a proxy. You can
    provide data to the Home page from the following sources: JSON files hosted on
    GitHub or GitLab. A dedicated service that provides the Home page data in JSON
    format using an API. ## Using hosted JSON files to provide data to the Quick access
    card You have installed Red Hat Developer Hub by using either the Operator or
    Helm chart. See Installing Red Hat Developer Hub on OpenShift Container Platform.
    To access the data from the JSON files, add the following code to the app config.yaml
    Developer Hub configuration file: Add the following code to the app config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: <DOMAIN_URL> # i.e https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer-hub'': <path to json file> # i.e /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true # Change to "false" in case of using self hosted
    cluster with a self-signed certificate headers: <HEADER_KEY>: <HEADER_VALUE> #
    optional and can be passed as needed i.e Authorization can be passed for private
    GitHub repo and PRIVATE-TOKEN can be passed for private GitLab repo ``` ## Using
    a dedicated service to provide data to the Quick access card When using a dedicated
    service, you can do the following tasks: Use the same service to provide the data
    to all configurable Developer Hub pages or use a different service for each page.
    Use the red hat developer hub customization provider as an example service, which
    provides data for both the Home and Tech Radar pages. The red hat developer hub
    customization provider service provides the same data as default Developer Hub
    data. You can fork the red hat developer hub customization provider service repository
    from GitHub and modify it with your own data, if required. Deploy the red hat
    developer hub customization provider service and the Developer Hub Helm chart
    on the same cluster. You have installed the Red Hat Developer Hub using Helm chart.
    For more information, see Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Helm chart. To use a separate service to provide the Home page
    data, complete the following steps: 1. In the Red Hat OpenShift Container Platform
    web console, click +Add > Import from Git. 2. Enter the URL of your Git repository
    into the Git Repo URL field. To use the red-hat-developer-hub-customization-provider
    service, add the URL for the red-hat-developer-hub-customization-provider repository'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:22.200778'
    uuid: 3f090ab6-d2c8-4207-8802-879a16ed5b99
  response: To provide data to the Quick access card from a JSON file hosted on GitLab,
    you must add a proxy endpoint to the app-config.yaml file. For a private GitLab
    repository, this configuration can include an optional `headers` section. The
    documentation specifies that a `PRIVATE-TOKEN` can be passed as a header for authentication
    with a private GitLab repository.
  user_input: As a Platform Engineer tasked with customizing our Red Hat Developer
    Hub instance, what is the documented method for configuring the proxy in the app-config.yaml
    file to fetch data for the Quick access card from a JSON file hosted in a private
    GitLab repository, and what specific header is mentioned for handling authentication?
- context:
  - 'layouts: xl: { w: 12, h: 6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w:
    12, h: 8 } xs: { w: 12, h: 9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards
    importName: EntitySection config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h:
    7 } md: { w: 12, h: 8 } sm: { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12,
    h: 15 } - mountPoint: home.page/cards importName: TemplateSection config: layouts:
    xl: { w: 12, h: 5 } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5
    } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } # Additional cards available in
    "Add widget" dialog - mountPoint: home.page/cards importName: RecentlyVisitedCard
    - mountPoint: home.page/cards importName: TopVisitedCard ``` You can change the
    title by overriding the title property of the dynamic homepage plugin as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    for customizable homepage config: props: title: ''Howdy {{firstName}} or {{displayName}}''
    ``` The title property supports two variables: * {{displayName}}: This contains
    the full displayName of the catalog entity. * {{firstName}}: This contains the
    first part (separated by a space) of the displayName. * You can use a subtitle
    property which is not used by default as shown in the following example: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    config: props: title: Our custom RHDH instance subtitle: ''Hello {{displayName}}''
    ``` ## Customizing QuickAccessCard card icons on the Red Hat Developer Hub homepage
    As an administrator, you can customize the QuickAccessCard card icons on the Red
    Hat Developer Hub homepage to enhance its visual appeal and user experience. You
    can integrate custom branding or standard icons by leveraging a remote JSON configuration
    file. 1. Add the JSON Data source. The QuickAccessCard card on the homepage supports
    loading data from a JSON file. This JSON file can be hosted in your GitHub repository
    or any accessible endpoint. 2. Configure the Proxy in your RHDH app-config.yaml
    file. To allow the homepage to fetch data from the hosted JSON file, add the following
    proxy configuration to your RHDH app-config.yaml file: ```yaml proxy: endpoints:
    # customize your backstage instance ''/developer-hub'': target: https://raw.githubusercontent.com/
    # For example, https://raw.githubusercontent.com/ pathRewrite: ''^/api/proxy/developer-hub$'':
    <path-to-your>.json # For example, /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true ``` The following table lists the supported icon
    types: [NOTE] ---- SVGs must be valid strings when stored inside JSON (use single
    quotes inside <svg>). ---- The following is an example of a JSON file: ```yaml
    [ { "title": "Community", "isExpanded": true, "links": [ { "iconUrl": "https://img.icons8.com/ios/50/globe--v1.png",
    "label": "Website", "url": "https://developers.redhat.com/" }, { "iconUrl": "https://img.icons8.com/ios/50/link--v1.png",
    "label": "Blog", "url": "https://developers.redhat.com/blog" }, { "iconUrl": "github",
    "label": "GitHub", "url": "https://github.com/redhat-developer" }, { "iconUrl":
    "https://img.icons8.com/color/48/slack.png", "label": "Slack", "url": "https://join.slack.com/xyz"
    }, { "iconUrl": "https://img.icons8.com/color/48/youtube-squared.png", "label":
    "Videos for developers", "url": "https://developers.redhat.com/videos" }, { "iconUrl":
    "<svg xmlns=''http://www.w3.org/2000/svg'' xml:space=''preserve'' width=''2048''
    height=''2048'' style=''shape-rendering:geometricPrecision;text-rendering:geometricPrecision;image-rendering:optimizeQuality;fill-rule:evenodd;clip-rule:evenodd''><defs><style>.fil0{fill:none}.fil4{fill:#bdbdbd;fill-rule:nonzero}</style></defs><g
    id=''Layer_x0020_1''><path class=''fil0'' d=''M0 0h2048v2048H0z''/><path class=''fil0''
    d=''M255.999 255.999h1536v1536h-1536z''/><path class=''fil0'' d=''M256 256h1536v1536H256z''/><g
    id=''_342647616''><path id=''_342648000'' style=''fill:#e53935;fill-rule:nonzero''
    d=''m273.04 666.226 737.28-367.843 13.68-6.824 13.68 6.824 737.28 367.843 17.04
    8.503v234.834L993.281 1418.52 255.999 909.563V674.729z''/><path id=''_342647880''
    style=''fill:#fff'' d=''M609.28 711.961h829.439V1541.4H609.28z''/><path id=''_342647808''
    style=''fill:#c62828;fill-rule:nonzero'' d=''m1024 1279.73 723.6-361.079 44.4-22.156v859.945H255.999V896.495l44.402
    22.156z''/><path id=''_342647736'' class=''fil4'' d=''M1331.2 896.285H716.716v-61.442H1331.2z''/><path
    id=''_342647688'' class=''fil4'' d=''M1203.22 1049.88H844.698v-61.439h358.522z''/></g></g></svg>",
    "label": "Mailing List", "url": "https://groups.google.com/g/xyz" }, ] } ] ```
    # Customizing the Quick access card To access the Home page in Red Hat Developer
    Hub, the base URL must include the /developer-hub proxy. You can configure the
    Home page by passing the data into the app-config.yaml file as a proxy. You can
    provide data to the Home page from the following sources: JSON files hosted on
    GitHub or GitLab. A dedicated service that provides the Home page data in JSON
    format using an API. ## Using hosted JSON files to provide data to the Quick access
    card You have installed Red Hat Developer Hub by using either the Operator or
    Helm chart. See Installing Red Hat Developer Hub on OpenShift Container Platform.
    To access the data from the JSON files, add the following code to the app config.yaml
    Developer Hub configuration file: Add the following code to the app config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: <DOMAIN_URL> # i.e https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer-hub'': <path to json file> # i.e /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true # Change to "false" in case of using self hosted
    cluster with a self-signed certificate headers: <HEADER_KEY>: <HEADER_VALUE> #
    optional and can be passed as needed i.e Authorization can be passed for private
    GitHub repo and PRIVATE-TOKEN can be passed for private GitLab repo ``` ## Using
    a dedicated service to provide data to the Quick access card When using a dedicated
    service, you can do the following tasks: Use the same service to provide the data
    to all configurable Developer Hub pages or use a different service for each page.
    Use the red hat developer hub customization provider as an example service, which
    provides data for both the Home and Tech Radar pages. The red hat developer hub
    customization provider service provides the same data as default Developer Hub
    data. You can fork the red hat developer hub customization provider service repository
    from GitHub and modify it with your own data, if required. Deploy the red hat
    developer hub customization provider service and the Developer Hub Helm chart
    on the same cluster. You have installed the Red Hat Developer Hub using Helm chart.
    For more information, see Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Helm chart. To use a separate service to provide the Home page
    data, complete the following steps: 1. In the Red Hat OpenShift Container Platform
    web console, click +Add > Import from Git. 2. Enter the URL of your Git repository
    into the Git Repo URL field. To use the red-hat-developer-hub-customization-provider
    service, add the URL for the red-hat-developer-hub-customization-provider repository'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:32.784331'
    uuid: 404b7d94-a156-4ac5-a0b7-782797e0cbcb
  response: You can provide data to the Home page from JSON files hosted on GitLab.
    To use a private GitLab repository, you can pass a PRIVATE-TOKEN as a header in
    the proxy configuration within the app-config.yaml file.
  user_input: how do i use a privet gitlab repo?
- context:
  - 'layouts: xl: { w: 12, h: 6 } lg: { w: 12, h: 6 } md: { w: 12, h: 7 } sm: { w:
    12, h: 8 } xs: { w: 12, h: 9 } xxs: { w: 12, h: 14 } - mountPoint: home.page/cards
    importName: EntitySection config: layouts: xl: { w: 12, h: 7 } lg: { w: 12, h:
    7 } md: { w: 12, h: 8 } sm: { w: 12, h: 9 } xs: { w: 12, h: 11 } xxs: { w: 12,
    h: 15 } - mountPoint: home.page/cards importName: TemplateSection config: layouts:
    xl: { w: 12, h: 5 } lg: { w: 12, h: 5 } md: { w: 12, h: 5 } sm: { w: 12, h: 5
    } xs: { w: 12, h: 7.5 } xxs: { w: 12, h: 13.5 } # Additional cards available in
    "Add widget" dialog - mountPoint: home.page/cards importName: RecentlyVisitedCard
    - mountPoint: home.page/cards importName: TopVisitedCard ``` You can change the
    title by overriding the title property of the dynamic homepage plugin as shown
    in the following example: ```yaml dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    for customizable homepage config: props: title: ''Howdy {{firstName}} or {{displayName}}''
    ``` The title property supports two variables: * {{displayName}}: This contains
    the full displayName of the catalog entity. * {{firstName}}: This contains the
    first part (separated by a space) of the displayName. * You can use a subtitle
    property which is not used by default as shown in the following example: ```yaml
    dynamicPlugins: frontend: red-hat-developer-hub.backstage-plugin-dynamic-home-page:
    dynamicRoutes: - path: / importName: DynamicHomePage # or DynamicCustomizableHomePage
    config: props: title: Our custom RHDH instance subtitle: ''Hello {{displayName}}''
    ``` ## Customizing QuickAccessCard card icons on the Red Hat Developer Hub homepage
    As an administrator, you can customize the QuickAccessCard card icons on the Red
    Hat Developer Hub homepage to enhance its visual appeal and user experience. You
    can integrate custom branding or standard icons by leveraging a remote JSON configuration
    file. 1. Add the JSON Data source. The QuickAccessCard card on the homepage supports
    loading data from a JSON file. This JSON file can be hosted in your GitHub repository
    or any accessible endpoint. 2. Configure the Proxy in your RHDH app-config.yaml
    file. To allow the homepage to fetch data from the hosted JSON file, add the following
    proxy configuration to your RHDH app-config.yaml file: ```yaml proxy: endpoints:
    # customize your backstage instance ''/developer-hub'': target: https://raw.githubusercontent.com/
    # For example, https://raw.githubusercontent.com/ pathRewrite: ''^/api/proxy/developer-hub$'':
    <path-to-your>.json # For example, /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true ``` The following table lists the supported icon
    types: [NOTE] ---- SVGs must be valid strings when stored inside JSON (use single
    quotes inside <svg>). ---- The following is an example of a JSON file: ```yaml
    [ { "title": "Community", "isExpanded": true, "links": [ { "iconUrl": "https://img.icons8.com/ios/50/globe--v1.png",
    "label": "Website", "url": "https://developers.redhat.com/" }, { "iconUrl": "https://img.icons8.com/ios/50/link--v1.png",
    "label": "Blog", "url": "https://developers.redhat.com/blog" }, { "iconUrl": "github",
    "label": "GitHub", "url": "https://github.com/redhat-developer" }, { "iconUrl":
    "https://img.icons8.com/color/48/slack.png", "label": "Slack", "url": "https://join.slack.com/xyz"
    }, { "iconUrl": "https://img.icons8.com/color/48/youtube-squared.png", "label":
    "Videos for developers", "url": "https://developers.redhat.com/videos" }, { "iconUrl":
    "<svg xmlns=''http://www.w3.org/2000/svg'' xml:space=''preserve'' width=''2048''
    height=''2048'' style=''shape-rendering:geometricPrecision;text-rendering:geometricPrecision;image-rendering:optimizeQuality;fill-rule:evenodd;clip-rule:evenodd''><defs><style>.fil0{fill:none}.fil4{fill:#bdbdbd;fill-rule:nonzero}</style></defs><g
    id=''Layer_x0020_1''><path class=''fil0'' d=''M0 0h2048v2048H0z''/><path class=''fil0''
    d=''M255.999 255.999h1536v1536h-1536z''/><path class=''fil0'' d=''M256 256h1536v1536H256z''/><g
    id=''_342647616''><path id=''_342648000'' style=''fill:#e53935;fill-rule:nonzero''
    d=''m273.04 666.226 737.28-367.843 13.68-6.824 13.68 6.824 737.28 367.843 17.04
    8.503v234.834L993.281 1418.52 255.999 909.563V674.729z''/><path id=''_342647880''
    style=''fill:#fff'' d=''M609.28 711.961h829.439V1541.4H609.28z''/><path id=''_342647808''
    style=''fill:#c62828;fill-rule:nonzero'' d=''m1024 1279.73 723.6-361.079 44.4-22.156v859.945H255.999V896.495l44.402
    22.156z''/><path id=''_342647736'' class=''fil4'' d=''M1331.2 896.285H716.716v-61.442H1331.2z''/><path
    id=''_342647688'' class=''fil4'' d=''M1203.22 1049.88H844.698v-61.439h358.522z''/></g></g></svg>",
    "label": "Mailing List", "url": "https://groups.google.com/g/xyz" }, ] } ] ```
    # Customizing the Quick access card To access the Home page in Red Hat Developer
    Hub, the base URL must include the /developer-hub proxy. You can configure the
    Home page by passing the data into the app-config.yaml file as a proxy. You can
    provide data to the Home page from the following sources: JSON files hosted on
    GitHub or GitLab. A dedicated service that provides the Home page data in JSON
    format using an API. ## Using hosted JSON files to provide data to the Quick access
    card You have installed Red Hat Developer Hub by using either the Operator or
    Helm chart. See Installing Red Hat Developer Hub on OpenShift Container Platform.
    To access the data from the JSON files, add the following code to the app config.yaml
    Developer Hub configuration file: Add the following code to the app config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: <DOMAIN_URL> # i.e https://raw.githubusercontent.com/
    pathRewrite: ''^/api/proxy/developer-hub'': <path to json file> # i.e /redhat-developer/rhdh/main/packages/app/public/homepage/data.json
    changeOrigin: true secure: true # Change to "false" in case of using self hosted
    cluster with a self-signed certificate headers: <HEADER_KEY>: <HEADER_VALUE> #
    optional and can be passed as needed i.e Authorization can be passed for private
    GitHub repo and PRIVATE-TOKEN can be passed for private GitLab repo ``` ## Using
    a dedicated service to provide data to the Quick access card When using a dedicated
    service, you can do the following tasks: Use the same service to provide the data
    to all configurable Developer Hub pages or use a different service for each page.
    Use the red hat developer hub customization provider as an example service, which
    provides data for both the Home and Tech Radar pages. The red hat developer hub
    customization provider service provides the same data as default Developer Hub
    data. You can fork the red hat developer hub customization provider service repository
    from GitHub and modify it with your own data, if required. Deploy the red hat
    developer hub customization provider service and the Developer Hub Helm chart
    on the same cluster. You have installed the Red Hat Developer Hub using Helm chart.
    For more information, see Installing Red Hat Developer Hub on OpenShift Container
    Platform with the Helm chart. To use a separate service to provide the Home page
    data, complete the following steps: 1. In the Red Hat OpenShift Container Platform
    web console, click +Add > Import from Git. 2. Enter the URL of your Git repository
    into the Git Repo URL field. To use the red-hat-developer-hub-customization-provider
    service, add the URL for the red-hat-developer-hub-customization-provider repository'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:40.699160'
    uuid: ab6b11c3-01ac-403b-9ff5-825416a53929
  response: "To allow the homepage to fetch data from a hosted JSON file, you must\
    \ add a proxy configuration to your RHDH app-config.yaml file. The configuration\
    \ specifies the target, pathRewrite, and other settings. An example is as follows:\n\
    ```yaml\nproxy:\n  endpoints:\n    # customize your backstage instance\n    '/developer-hub':\n\
    \      target: https://raw.githubusercontent.com/ # For example, https://raw.githubusercontent.com/\n\
    \      pathRewrite:\n        '^/api/proxy/developer-hub$': <path-to-your>.json\
    \ # For example, /redhat-developer/rhdh/main/packages/app/public/homepage/data.json\n\
    \      changeOrigin: true\n      secure: true\n```"
  user_input: How is the proxy configured in the app-config.yaml file to fetch data
    from a hosted JSON file?
- context:
  - 'or your fork of the repository containing your customizations. 3. On the General
    tab, enter red-hat-developer-hub-customization-provider in the Name field and
    click Create. 4. On the Advanced Options tab, copy the value from Target Port.
    [NOTE] ---- Target Port automatically generates a Kubernetes or OpenShift Container
    Platform service to communicate with. ---- 5. Add the following code to the app-config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: ${HOMEPAGE_DATA_URL} 1 changeOrigin: true # Change
    to "false" in case of using self-hosted cluster with a self-signed certificate
    secure: true ``` http://<SERVICE_NAME>:8080, for example, http://rhdh customization
    provider:8080. [NOTE] ---- The red-hat-developer-hub-customization-provider service
    contains the 8080 port by default. If you are using a custom port, you can specify
    it with the ''PORT'' environmental variable in the app-config.yaml file. ----
    6. Replace the HOMEPAGE_DATA_URL by adding the URL to rhdh-secrets or by directly
    replacing it in your custom ConfigMap. 7. Delete the Developer Hub pod to ensure
    that the new configurations are loaded correctly. To view the service, go to the
    OpenShift Container Platform web console and click Networking > Service. [NOTE]
    ---- You can also view Service Resources in the Topology view. ---- * Ensure that
    the provided API URL for the Home page returns the data in JSON format as shown
    in the following example: ```json [ { "title": "Dropdown 1", "isExpanded": false,
    "links": [ { "iconUrl": "https://imagehost.com/image.png", "label": "Dropdown
    1 Item 1", "url": "https://example.com/" }, { "iconUrl": "https://imagehost2.org/icon.png",
    "label": "Dropdown 1 Item 2", "url": "" } ] }, { "title": "Dropdown 2", "isExpanded":
    true, "links": [ { "iconUrl": "http://imagehost3.edu/img.jpg", "label": "Dropdown
    2 Item 1", "url": "http://example.com" } ] } ] ``` [NOTE] ---- If the request
    call fails or is not configured, the Developer Hub instance falls back to the
    default local data. ---- * If the images or icons do not load, then allowlist
    them by adding your image or icon host URLs to the content security policy (csp)
    img-src in your custom ConfigMap as shown in the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: app-config.yaml data: app-config.yaml:
    | app: title: Red Hat Developer Hub backend: csp: connect-src: - "''self''" -
    ''http:'' - ''https:'' img-src: - "''self''" - ''data:'' - <image host url 1>
    - <image host url 2> - <image host url 3> # Other Configurations ``` # Customizing
    the RHDH Metadata card on the Settings page The Settings page in Red Hat Developer
    Hub contains a RHDH Metadata card. By default, the RHDH Metadata card shows the
    RHDH Version and Backstage Version of your Red Hat Developer Hub instance. When
    you click the Show more icon, the card expands to also show Upstream, Midstream,
    and Build Time information. You can override the default to show custom build
    information about your Red Hat Developer Hub instance in the card. You can customize
    the card title as well as the card contents. To customize the RHDH Metadata card,
    complete the following step: In your app config.yaml file, configure the buildinfo
    field. For example: ```yaml buildInfo: title: _<metadata_card_title>_ card: TechDocs
    builder: ''_<techdocs_builder>_'' Authentication provider: ''_<authentication_provider>_''
    RBAC: disabled full: true ``` where <metadata_card_title>:: Specifies the title
    that you want to display on the customized card. <techdocs_builder>:: Specifies
    whether to generate and publish the docs or to only fetch the docs when using
    the default build strategy. Possible values are local or external. If you want
    to generate and publish the docs, set the techdocs.builder field to local in your
    app-config.yaml file. If you only want to fetch the docs without generating and
    publishing them, set the techdocs.builder field to external. <authentication_provider>::
    Specifies the authentication provider that you want to use. Example values are
    GitHub or GitLab. full:: Specifies what information is shown on the customized
    card. Possible values are true or false. If set to true, only the information
    specified in this configuration is shown on the card. If set to false, the specified
    information is shown on the card along with the build versions. The default value
    is true. The Settings page displays a card with a custom title and custom build
    information about your Red Hat Developer Hub instance. # Localization in Red Hat
    Developer Hub ## Enabling the localization framework in Developer Hub Enabling
    localization enhances accessibility, improves the user experience for a global
    audience, and assists organizations in meeting language requirements in specific
    regions. The language settings of Red Hat Developer Hub (RHDH) use English by
    default. In RHDH 1.8, you can choose to use one of the following supported languages:
    English (en) French (fr) 1. To enable the localization framework in your RHDH
    application, add the i18n section to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml fragment with localization i18n fields ```yaml
    ... i18n: locales: # List of supported locales. Must include en, otherwise the
    translation framework will fail to load. - en - fr defaultLocale: en # Optional.
    Defaults to en if not specified. ... ``` ## Selecting the language for your Developer
    Hub instance You can choose to use one of the following supported languages: English
    (default) French You are logged in to the Developer Hub web console. You have
    enabled the localization framework in your RHDH instance. 1. From the Developer
    Hub web console, click the down arrow next to your profile name, then click Settings.
    2. From the Appearance panel, click the language dropdown to select your language
    of choice. ![customize language dropdown] ### Language persistence When you change
    the language in the UI, your preference is saved to storage. On next login or
    refresh, your chosen language setting is restored. Guest users cannot persist
    language preferences. Default language selection uses the following priority order:
    1. Browser language priority: The system first checks the user''s browser language
    preferences to provide a personalized experience. 2. Configuration priority: If
    no browser language matches the supported locales, the defaultLocale from the
    i18n configuration is used as a fallback. 3. Fallback priority: If neither browser
    preferences nor configuration provide a match, defaults to en. Red Hat Developer'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:31:47.971500'
    uuid: 7e830293-80d5-4070-a081-65db79264776
  response: To customize the RHDH Metadata card, you must configure the `buildInfo`
    field in your `app-config.yaml` file. This allows you to override the default
    card to show custom build information. The configurable fields include a `title`
    (`<metadata_card_title>`) for the card, a `TechDocs builder` (`<techdocs_builder>`)
    which can be set to `local` to generate and publish docs or `external` to only
    fetch them, and an `Authentication provider` (`<authentication_provider>`) with
    example values like GitHub or GitLab. Additionally, there is a `full` field, which,
    if set to `true` (the default), shows only the information specified in your configuration.
    If set to `false`, it shows your specified information along with the build versions.
  user_input: As a Platform Engineering Lead tasked with creating a unified and streamlined
    developer experience, what are the precise configuration steps within the app-config.yaml
    file for customizing the RHDH Metadata card on the Settings page to display our
    organization's specific build information, including the TechDocs builder strategy
    and authentication provider?
- context:
  - 'or your fork of the repository containing your customizations. 3. On the General
    tab, enter red-hat-developer-hub-customization-provider in the Name field and
    click Create. 4. On the Advanced Options tab, copy the value from Target Port.
    [NOTE] ---- Target Port automatically generates a Kubernetes or OpenShift Container
    Platform service to communicate with. ---- 5. Add the following code to the app-config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: ${HOMEPAGE_DATA_URL} 1 changeOrigin: true # Change
    to "false" in case of using self-hosted cluster with a self-signed certificate
    secure: true ``` http://<SERVICE_NAME>:8080, for example, http://rhdh customization
    provider:8080. [NOTE] ---- The red-hat-developer-hub-customization-provider service
    contains the 8080 port by default. If you are using a custom port, you can specify
    it with the ''PORT'' environmental variable in the app-config.yaml file. ----
    6. Replace the HOMEPAGE_DATA_URL by adding the URL to rhdh-secrets or by directly
    replacing it in your custom ConfigMap. 7. Delete the Developer Hub pod to ensure
    that the new configurations are loaded correctly. To view the service, go to the
    OpenShift Container Platform web console and click Networking > Service. [NOTE]
    ---- You can also view Service Resources in the Topology view. ---- * Ensure that
    the provided API URL for the Home page returns the data in JSON format as shown
    in the following example: ```json [ { "title": "Dropdown 1", "isExpanded": false,
    "links": [ { "iconUrl": "https://imagehost.com/image.png", "label": "Dropdown
    1 Item 1", "url": "https://example.com/" }, { "iconUrl": "https://imagehost2.org/icon.png",
    "label": "Dropdown 1 Item 2", "url": "" } ] }, { "title": "Dropdown 2", "isExpanded":
    true, "links": [ { "iconUrl": "http://imagehost3.edu/img.jpg", "label": "Dropdown
    2 Item 1", "url": "http://example.com" } ] } ] ``` [NOTE] ---- If the request
    call fails or is not configured, the Developer Hub instance falls back to the
    default local data. ---- * If the images or icons do not load, then allowlist
    them by adding your image or icon host URLs to the content security policy (csp)
    img-src in your custom ConfigMap as shown in the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: app-config.yaml data: app-config.yaml:
    | app: title: Red Hat Developer Hub backend: csp: connect-src: - "''self''" -
    ''http:'' - ''https:'' img-src: - "''self''" - ''data:'' - <image host url 1>
    - <image host url 2> - <image host url 3> # Other Configurations ``` # Customizing
    the RHDH Metadata card on the Settings page The Settings page in Red Hat Developer
    Hub contains a RHDH Metadata card. By default, the RHDH Metadata card shows the
    RHDH Version and Backstage Version of your Red Hat Developer Hub instance. When
    you click the Show more icon, the card expands to also show Upstream, Midstream,
    and Build Time information. You can override the default to show custom build
    information about your Red Hat Developer Hub instance in the card. You can customize
    the card title as well as the card contents. To customize the RHDH Metadata card,
    complete the following step: In your app config.yaml file, configure the buildinfo
    field. For example: ```yaml buildInfo: title: _<metadata_card_title>_ card: TechDocs
    builder: ''_<techdocs_builder>_'' Authentication provider: ''_<authentication_provider>_''
    RBAC: disabled full: true ``` where <metadata_card_title>:: Specifies the title
    that you want to display on the customized card. <techdocs_builder>:: Specifies
    whether to generate and publish the docs or to only fetch the docs when using
    the default build strategy. Possible values are local or external. If you want
    to generate and publish the docs, set the techdocs.builder field to local in your
    app-config.yaml file. If you only want to fetch the docs without generating and
    publishing them, set the techdocs.builder field to external. <authentication_provider>::
    Specifies the authentication provider that you want to use. Example values are
    GitHub or GitLab. full:: Specifies what information is shown on the customized
    card. Possible values are true or false. If set to true, only the information
    specified in this configuration is shown on the card. If set to false, the specified
    information is shown on the card along with the build versions. The default value
    is true. The Settings page displays a card with a custom title and custom build
    information about your Red Hat Developer Hub instance. # Localization in Red Hat
    Developer Hub ## Enabling the localization framework in Developer Hub Enabling
    localization enhances accessibility, improves the user experience for a global
    audience, and assists organizations in meeting language requirements in specific
    regions. The language settings of Red Hat Developer Hub (RHDH) use English by
    default. In RHDH 1.8, you can choose to use one of the following supported languages:
    English (en) French (fr) 1. To enable the localization framework in your RHDH
    application, add the i18n section to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml fragment with localization i18n fields ```yaml
    ... i18n: locales: # List of supported locales. Must include en, otherwise the
    translation framework will fail to load. - en - fr defaultLocale: en # Optional.
    Defaults to en if not specified. ... ``` ## Selecting the language for your Developer
    Hub instance You can choose to use one of the following supported languages: English
    (default) French You are logged in to the Developer Hub web console. You have
    enabled the localization framework in your RHDH instance. 1. From the Developer
    Hub web console, click the down arrow next to your profile name, then click Settings.
    2. From the Appearance panel, click the language dropdown to select your language
    of choice. ![customize language dropdown] ### Language persistence When you change
    the language in the UI, your preference is saved to storage. On next login or
    refresh, your chosen language setting is restored. Guest users cannot persist
    language preferences. Default language selection uses the following priority order:
    1. Browser language priority: The system first checks the user''s browser language
    preferences to provide a personalized experience. 2. Configuration priority: If
    no browser language matches the supported locales, the defaultLocale from the
    i18n configuration is used as a fallback. 3. Fallback priority: If neither browser
    preferences nor configuration provide a match, defaults to en. Red Hat Developer'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:31:54.475796'
    uuid: 75802a29-ac46-4d4e-a97e-78c7cd306127
  response: The Target Port automatically generates a Kubernetes or OpenShift Container
    Platform service to facilitate communication.
  user_input: What is the function of the Target Port in a Kubernetes environment?
- context:
  - 'or your fork of the repository containing your customizations. 3. On the General
    tab, enter red-hat-developer-hub-customization-provider in the Name field and
    click Create. 4. On the Advanced Options tab, copy the value from Target Port.
    [NOTE] ---- Target Port automatically generates a Kubernetes or OpenShift Container
    Platform service to communicate with. ---- 5. Add the following code to the app-config.yaml
    file: ```yaml proxy: endpoints: # Other Proxies # customize developer hub instance
    ''/developer-hub'': target: ${HOMEPAGE_DATA_URL} 1 changeOrigin: true # Change
    to "false" in case of using self-hosted cluster with a self-signed certificate
    secure: true ``` http://<SERVICE_NAME>:8080, for example, http://rhdh customization
    provider:8080. [NOTE] ---- The red-hat-developer-hub-customization-provider service
    contains the 8080 port by default. If you are using a custom port, you can specify
    it with the ''PORT'' environmental variable in the app-config.yaml file. ----
    6. Replace the HOMEPAGE_DATA_URL by adding the URL to rhdh-secrets or by directly
    replacing it in your custom ConfigMap. 7. Delete the Developer Hub pod to ensure
    that the new configurations are loaded correctly. To view the service, go to the
    OpenShift Container Platform web console and click Networking > Service. [NOTE]
    ---- You can also view Service Resources in the Topology view. ---- * Ensure that
    the provided API URL for the Home page returns the data in JSON format as shown
    in the following example: ```json [ { "title": "Dropdown 1", "isExpanded": false,
    "links": [ { "iconUrl": "https://imagehost.com/image.png", "label": "Dropdown
    1 Item 1", "url": "https://example.com/" }, { "iconUrl": "https://imagehost2.org/icon.png",
    "label": "Dropdown 1 Item 2", "url": "" } ] }, { "title": "Dropdown 2", "isExpanded":
    true, "links": [ { "iconUrl": "http://imagehost3.edu/img.jpg", "label": "Dropdown
    2 Item 1", "url": "http://example.com" } ] } ] ``` [NOTE] ---- If the request
    call fails or is not configured, the Developer Hub instance falls back to the
    default local data. ---- * If the images or icons do not load, then allowlist
    them by adding your image or icon host URLs to the content security policy (csp)
    img-src in your custom ConfigMap as shown in the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: app-config.yaml data: app-config.yaml:
    | app: title: Red Hat Developer Hub backend: csp: connect-src: - "''self''" -
    ''http:'' - ''https:'' img-src: - "''self''" - ''data:'' - <image host url 1>
    - <image host url 2> - <image host url 3> # Other Configurations ``` # Customizing
    the RHDH Metadata card on the Settings page The Settings page in Red Hat Developer
    Hub contains a RHDH Metadata card. By default, the RHDH Metadata card shows the
    RHDH Version and Backstage Version of your Red Hat Developer Hub instance. When
    you click the Show more icon, the card expands to also show Upstream, Midstream,
    and Build Time information. You can override the default to show custom build
    information about your Red Hat Developer Hub instance in the card. You can customize
    the card title as well as the card contents. To customize the RHDH Metadata card,
    complete the following step: In your app config.yaml file, configure the buildinfo
    field. For example: ```yaml buildInfo: title: _<metadata_card_title>_ card: TechDocs
    builder: ''_<techdocs_builder>_'' Authentication provider: ''_<authentication_provider>_''
    RBAC: disabled full: true ``` where <metadata_card_title>:: Specifies the title
    that you want to display on the customized card. <techdocs_builder>:: Specifies
    whether to generate and publish the docs or to only fetch the docs when using
    the default build strategy. Possible values are local or external. If you want
    to generate and publish the docs, set the techdocs.builder field to local in your
    app-config.yaml file. If you only want to fetch the docs without generating and
    publishing them, set the techdocs.builder field to external. <authentication_provider>::
    Specifies the authentication provider that you want to use. Example values are
    GitHub or GitLab. full:: Specifies what information is shown on the customized
    card. Possible values are true or false. If set to true, only the information
    specified in this configuration is shown on the card. If set to false, the specified
    information is shown on the card along with the build versions. The default value
    is true. The Settings page displays a card with a custom title and custom build
    information about your Red Hat Developer Hub instance. # Localization in Red Hat
    Developer Hub ## Enabling the localization framework in Developer Hub Enabling
    localization enhances accessibility, improves the user experience for a global
    audience, and assists organizations in meeting language requirements in specific
    regions. The language settings of Red Hat Developer Hub (RHDH) use English by
    default. In RHDH 1.8, you can choose to use one of the following supported languages:
    English (en) French (fr) 1. To enable the localization framework in your RHDH
    application, add the i18n section to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml fragment with localization i18n fields ```yaml
    ... i18n: locales: # List of supported locales. Must include en, otherwise the
    translation framework will fail to load. - en - fr defaultLocale: en # Optional.
    Defaults to en if not specified. ... ``` ## Selecting the language for your Developer
    Hub instance You can choose to use one of the following supported languages: English
    (default) French You are logged in to the Developer Hub web console. You have
    enabled the localization framework in your RHDH instance. 1. From the Developer
    Hub web console, click the down arrow next to your profile name, then click Settings.
    2. From the Appearance panel, click the language dropdown to select your language
    of choice. ![customize language dropdown] ### Language persistence When you change
    the language in the UI, your preference is saved to storage. On next login or
    refresh, your chosen language setting is restored. Guest users cannot persist
    language preferences. Default language selection uses the following priority order:
    1. Browser language priority: The system first checks the user''s browser language
    preferences to provide a personalized experience. 2. Configuration priority: If
    no browser language matches the supported locales, the defaultLocale from the
    i18n configuration is used as a fallback. 3. Fallback priority: If neither browser
    preferences nor configuration provide a match, defaults to en. Red Hat Developer'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:32:02.118571'
    uuid: e75b6809-db53-4f9b-ad6e-d1540f498c3f
  response: To customize the RHDH Metadata card on the Settings page in Red Hat Developer
    Hub, you must configure the `buildinfo` field in your `app-config.yaml` file.
    This allows you to override the default display of RHDH Version and Backstage
    Version. The configuration allows you to specify a custom title and define the
    card's contents. For example, you can set the `<metadata_card_title>`, specify
    the `<techdocs_builder>` as 'local' or 'external', define the `<authentication_provider>`
    like 'GitHub' or 'GitLab', and set the `full` field. The `full` field, when set
    to `true` (the default), shows only the information specified in your configuration;
    when set to `false`, it shows your specified information along with the build
    versions.
  user_input: What configuration is required to customize the RHDH Metadata card,
    including its title and content, on the Settings page of a Red Hat Developer Hub
    instance?
- context:
  - "Hub automatically saves and restores user language settings across browser sessions.\
    \ This feature is enabled by default and uses database storage. To opt-out and\
    \ use browser storage instead, add the following to your app-config.yaml configuration\
    \ file: ```yaml userSettings: persistence: browser ``` where: userSettings:persistence::\
    \ Enter browser to opt-out and use browser local storage. Optionally, set this\
    \ value to database to persist across browsers and devices. This is the default\
    \ setting and does not require this configuration to be set. ## Localization support\
    \ for plugins ### Overriding translations In RHDH 1.8, you can override plugin\
    \ translation strings without modifying the plugin source code. You have enabled\
    \ localization in your RHDH application. For an Operator installed RHDH instance,\
    \ you have installed the OpenShift CLI (oc). For more information about installing\
    \ oc, see Installing the OpenShift CLI. 1. Create a JSON file containing the translation\
    \ strings that you want to override, as shown in the following example: allTranslations.json\
    \ fragment with translation string overrides ```json { \"plugin.global-floating-action-button\"\
    : { \"en\": { \"fab.quay.label\": \"QUAY EN JSON\", \"fab.rbac.label\": \"RBAC\
    \ EN JSON\", \"fab.rbac.tooltip\": \"RBAC EN tooltip JSON\" }, \"fr\": { \"fab.quay.label\"\
    : \"QUAY French JSON\", \"fab.quay.tooltip\": \"QUAY french tooltip JSON\", \"\
    fab.rbac.label\": \"RBAC French JSON\", \"fab.rbac.tooltip\": \"RBAC french tooltip\
    \ JSON\" } }, \"plugin.global-header\": { \"en\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub EN JSON\" }, \"fr\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub French JSON\" } } } ``` 2. Log in to your cluster and create\
    \ a config map for your translations override strings: ```bash oc create configmap\
    \ all translations \\ from file=/<path to>/allTranslations.json ``` 3. Update\
    \ your deployment configuration based on your installation method: 1. For an Operator-installed\
    \ RHDH instance, update your Backstage custom resource (CR). For more information\
    \ about configuring a CR, see Using the Red Hat Developer Hub Operator to run\
    \ Developer Hub with your custom configuration. 1. In the spec.application.extraFiles\
    \ section, add the translations custom app configuration as shown in the following\
    \ example: Backstage custom resource fragment ```yaml apiVersion: rhdh.redhat.com/v1alpha3\
    \ kind: Backstage spec: application: extraFiles: mountPath: /opt/app root/src/translations\
    \ configMaps: name: all translations ``` 2. For a Helm-installed RHDH instance,\
    \ update your Developer Hub Backstage Helm chart to mount in the Developer Hub\
    \ filesystem your files from the all-translations config map: 1. In the Developer\
    \ Hub Helm chart, go to Root Schema \u2192 Backstage chart schema \u2192 Backstage\
    \ parameters \u2192 Backstage container additional volume mounts. 2. Select Add\
    \ Backstage container additional volume mounts and add the following values: mountPath::\
    \ /opt/app-root/src/translations name:: all-translations 3. Add the translations\
    \ to the Backstage container additional volumes in the Developer Hub Helm chart:\
    \ name:: all-translations configMap:: defaultMode:: 420 name:: all-translations\
    \ 4. Update the i18n section to your custom Developer Hub app-config.yaml configuration\
    \ file to include the following translation override file: app-config.yaml fragment\
    \ with localization i18n fields ```yaml i18n: locales: # List of supported locales.\
    \ Must include en, otherwise the translation framework will fail to load. - en\
    \ - fr defaultLocale: en # Optional. Defaults to en if not specified. overrides:\
    \ # List of JSON translation files applied in order (last file wins). Each file\
    \ may override/add translations for one or more plugins/locales - /opt/app-root/src/translations/all-translations.json\
    \ ``` customizing display Enabling floating button localization in Developer Hub\
    \ Enabling Quickstart localization in Developer Hub Enabling sidebar menu items\
    \ localization in Developer Hub ### Best practices for implementing localization\
    \ support for custom plugins in RHDH When you add localization support to your\
    \ RHDH plugins, the following best practices help ensure that you establish a\
    \ robust, type-safe, and future-proof localization workflow, separating the immutable\
    \ source text from the organized key structure, and ensuring reliable deployment\
    \ across all targeted languages: Do not modify original English strings:: This\
    \ preserves the source of truth for all translators, preventing unexpected changes\
    \ that would invalidate existing translations and ensuring consistency across\
    \ all versions. Use flat dot notation in translation files:: Flat dot notation,\
    \ for example page.title, follows the standard i18next library convention, which\
    \ optimizes runtime lookups and keeps the actual translation values concise and\
    \ easy to manage for translation services. Use nested objects in the reference\
    \ file for TypeScript support:: This allows the TypeScript compiler to enforce\
    \ structural type checking on your translation keys, catching errors during development\
    \ rather than at runtime. Test with mocks to ensure translations work correctly::\
    \ This isolates the translation logic, guaranteeing the correct keys are passed\
    \ and rendered without relying on a full environment setup or external translation\
    \ files during unit testing. Add all languages to your application configuration::\
    \ This ensures that the RHDH application initializes and loads all necessary language\
    \ resources at startup, making the locales immediately available for users to\
    \ select in the UI. ### Implementing localization support for your custom plugins\
    \ You can implement localization support in your custom RHDH plugins so that your\
    \ plugins are accessible to a diverse, international user base and follow recommended\
    \ best practices. 1. Create the following translation files in your plugin's src/translations/\
    \ directory: src/translations/ref.ts English reference ```json import { createTranslationRef\
    \ } from \"@backstage/core-plugin-api/alpha\"; export const myPluginMessages =\
    \ { page: { title: \"My Plugin\", subtitle: \"Plugin description\", }, common:\
    \ { exportCSV: \"Export CSV\", noResults: \"No results found\", }, table: { headers:\
    \ { name: \"Name\", count: \"Count\", }, }, }; export const myPluginTranslationRef\
    \ = createTranslationRef({ id: \"plugin.my-plugin\", messages: myPluginMessages,\
    \ }); ``` src/translations/de.ts German translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationDe = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mein Plugin\", \"\
    page.subtitle\": \"Plugin Beschreibung\", \"common.exportCSV\": \"CSV exportieren\"\
    , \"common.noResults\": \"Keine Ergebnisse gefunden\", \"table.headers.name\"\
    : \"Name\", \"table.headers.count\": \"Anzahl\", }, }); export default myPluginTranslationDe;\
    \ ``` src/translations/fr.ts French translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationFr = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mon Plugin\", \"\
    page.subtitle\": \"Description du plugin\", \"common.exportCSV\": \"Exporter CSV\"\
    , \"common.noResults\": \"Aucun r\xE9sultat trouv\xE9\", \"table.headers.name\"\
    : \"Nom\", \"table.headers.count\": \"Nombre\", }, }); export default myPluginTranslationFr;\
    \ ``` src/translations/index.ts Translation resource ```json import { createTranslationResource\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; export const myPluginTranslations = createTranslationResource({\
    \ ref: myPluginTranslationRef, translations: { de: () => import(\"./de\"), fr:\
    \ () => import(\"./fr\"), }, }); export { myPluginTranslationRef }; ``` 2. Create\
    \ translation hooks file, as follows: src/hooks/useTranslation.ts Translation\
    \ hooks ```json"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:32:13.160344'
    uuid: a5aa8830-497f-4258-a194-ce1bda233ca3
  response: To override plugin translation strings in RHDH, you must first create
    a JSON file containing the translation strings you want to override. Next, log
    in to your cluster and create a config map from that file using `oc create configmap
    all translations \ from file=/<path to>/allTranslations.json`. After that, you
    update your deployment configuration. For an Operator-installed instance, you
    update the Backstage custom resource (CR) by adding the config map under `spec.application.extraFiles`.
    For a Helm-installed instance, you update your Developer Hub Backstage Helm chart
    to mount the files from the config map. Finally, you update the `i18n` section
    in your `app-config.yaml` file to include the path to your translation override
    file under the `overrides` list.
  user_input: How do I overide the default translashuns in RHDH for my plugins?
- context:
  - "Hub automatically saves and restores user language settings across browser sessions.\
    \ This feature is enabled by default and uses database storage. To opt-out and\
    \ use browser storage instead, add the following to your app-config.yaml configuration\
    \ file: ```yaml userSettings: persistence: browser ``` where: userSettings:persistence::\
    \ Enter browser to opt-out and use browser local storage. Optionally, set this\
    \ value to database to persist across browsers and devices. This is the default\
    \ setting and does not require this configuration to be set. ## Localization support\
    \ for plugins ### Overriding translations In RHDH 1.8, you can override plugin\
    \ translation strings without modifying the plugin source code. You have enabled\
    \ localization in your RHDH application. For an Operator installed RHDH instance,\
    \ you have installed the OpenShift CLI (oc). For more information about installing\
    \ oc, see Installing the OpenShift CLI. 1. Create a JSON file containing the translation\
    \ strings that you want to override, as shown in the following example: allTranslations.json\
    \ fragment with translation string overrides ```json { \"plugin.global-floating-action-button\"\
    : { \"en\": { \"fab.quay.label\": \"QUAY EN JSON\", \"fab.rbac.label\": \"RBAC\
    \ EN JSON\", \"fab.rbac.tooltip\": \"RBAC EN tooltip JSON\" }, \"fr\": { \"fab.quay.label\"\
    : \"QUAY French JSON\", \"fab.quay.tooltip\": \"QUAY french tooltip JSON\", \"\
    fab.rbac.label\": \"RBAC French JSON\", \"fab.rbac.tooltip\": \"RBAC french tooltip\
    \ JSON\" } }, \"plugin.global-header\": { \"en\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub EN JSON\" }, \"fr\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub French JSON\" } } } ``` 2. Log in to your cluster and create\
    \ a config map for your translations override strings: ```bash oc create configmap\
    \ all translations \\ from file=/<path to>/allTranslations.json ``` 3. Update\
    \ your deployment configuration based on your installation method: 1. For an Operator-installed\
    \ RHDH instance, update your Backstage custom resource (CR). For more information\
    \ about configuring a CR, see Using the Red Hat Developer Hub Operator to run\
    \ Developer Hub with your custom configuration. 1. In the spec.application.extraFiles\
    \ section, add the translations custom app configuration as shown in the following\
    \ example: Backstage custom resource fragment ```yaml apiVersion: rhdh.redhat.com/v1alpha3\
    \ kind: Backstage spec: application: extraFiles: mountPath: /opt/app root/src/translations\
    \ configMaps: name: all translations ``` 2. For a Helm-installed RHDH instance,\
    \ update your Developer Hub Backstage Helm chart to mount in the Developer Hub\
    \ filesystem your files from the all-translations config map: 1. In the Developer\
    \ Hub Helm chart, go to Root Schema \u2192 Backstage chart schema \u2192 Backstage\
    \ parameters \u2192 Backstage container additional volume mounts. 2. Select Add\
    \ Backstage container additional volume mounts and add the following values: mountPath::\
    \ /opt/app-root/src/translations name:: all-translations 3. Add the translations\
    \ to the Backstage container additional volumes in the Developer Hub Helm chart:\
    \ name:: all-translations configMap:: defaultMode:: 420 name:: all-translations\
    \ 4. Update the i18n section to your custom Developer Hub app-config.yaml configuration\
    \ file to include the following translation override file: app-config.yaml fragment\
    \ with localization i18n fields ```yaml i18n: locales: # List of supported locales.\
    \ Must include en, otherwise the translation framework will fail to load. - en\
    \ - fr defaultLocale: en # Optional. Defaults to en if not specified. overrides:\
    \ # List of JSON translation files applied in order (last file wins). Each file\
    \ may override/add translations for one or more plugins/locales - /opt/app-root/src/translations/all-translations.json\
    \ ``` customizing display Enabling floating button localization in Developer Hub\
    \ Enabling Quickstart localization in Developer Hub Enabling sidebar menu items\
    \ localization in Developer Hub ### Best practices for implementing localization\
    \ support for custom plugins in RHDH When you add localization support to your\
    \ RHDH plugins, the following best practices help ensure that you establish a\
    \ robust, type-safe, and future-proof localization workflow, separating the immutable\
    \ source text from the organized key structure, and ensuring reliable deployment\
    \ across all targeted languages: Do not modify original English strings:: This\
    \ preserves the source of truth for all translators, preventing unexpected changes\
    \ that would invalidate existing translations and ensuring consistency across\
    \ all versions. Use flat dot notation in translation files:: Flat dot notation,\
    \ for example page.title, follows the standard i18next library convention, which\
    \ optimizes runtime lookups and keeps the actual translation values concise and\
    \ easy to manage for translation services. Use nested objects in the reference\
    \ file for TypeScript support:: This allows the TypeScript compiler to enforce\
    \ structural type checking on your translation keys, catching errors during development\
    \ rather than at runtime. Test with mocks to ensure translations work correctly::\
    \ This isolates the translation logic, guaranteeing the correct keys are passed\
    \ and rendered without relying on a full environment setup or external translation\
    \ files during unit testing. Add all languages to your application configuration::\
    \ This ensures that the RHDH application initializes and loads all necessary language\
    \ resources at startup, making the locales immediately available for users to\
    \ select in the UI. ### Implementing localization support for your custom plugins\
    \ You can implement localization support in your custom RHDH plugins so that your\
    \ plugins are accessible to a diverse, international user base and follow recommended\
    \ best practices. 1. Create the following translation files in your plugin's src/translations/\
    \ directory: src/translations/ref.ts English reference ```json import { createTranslationRef\
    \ } from \"@backstage/core-plugin-api/alpha\"; export const myPluginMessages =\
    \ { page: { title: \"My Plugin\", subtitle: \"Plugin description\", }, common:\
    \ { exportCSV: \"Export CSV\", noResults: \"No results found\", }, table: { headers:\
    \ { name: \"Name\", count: \"Count\", }, }, }; export const myPluginTranslationRef\
    \ = createTranslationRef({ id: \"plugin.my-plugin\", messages: myPluginMessages,\
    \ }); ``` src/translations/de.ts German translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationDe = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mein Plugin\", \"\
    page.subtitle\": \"Plugin Beschreibung\", \"common.exportCSV\": \"CSV exportieren\"\
    , \"common.noResults\": \"Keine Ergebnisse gefunden\", \"table.headers.name\"\
    : \"Name\", \"table.headers.count\": \"Anzahl\", }, }); export default myPluginTranslationDe;\
    \ ``` src/translations/fr.ts French translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationFr = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mon Plugin\", \"\
    page.subtitle\": \"Description du plugin\", \"common.exportCSV\": \"Exporter CSV\"\
    , \"common.noResults\": \"Aucun r\xE9sultat trouv\xE9\", \"table.headers.name\"\
    : \"Nom\", \"table.headers.count\": \"Nombre\", }, }); export default myPluginTranslationFr;\
    \ ``` src/translations/index.ts Translation resource ```json import { createTranslationResource\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; export const myPluginTranslations = createTranslationResource({\
    \ ref: myPluginTranslationRef, translations: { de: () => import(\"./de\"), fr:\
    \ () => import(\"./fr\"), }, }); export { myPluginTranslationRef }; ``` 2. Create\
    \ translation hooks file, as follows: src/hooks/useTranslation.ts Translation\
    \ hooks ```json"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:32:24.828710'
    uuid: 4fb3bec3-c98f-43d7-96e4-2bb64352b9e0
  response: 'In RHDH 1.8, you can override plugin translation strings without modifying
    the plugin source code. First, create a JSON file containing the translation strings
    you want to override. Then, log in to your cluster and create a config map for
    your translations using the command: `oc create configmap all translations \ from
    file=/<path to>/allTranslations.json`. Next, update your deployment configuration
    based on your installation method. For an Operator-installed instance, update
    your Backstage custom resource (CR) by adding the translations config map to the
    `spec.application.extraFiles` section. For a Helm-installed instance, update your
    Developer Hub Backstage Helm chart to mount the files from the config map. Finally,
    update the `i18n` section in your `app-config.yaml` configuration file to include
    the path to your translation override file, such as `/opt/app-root/src/translations/all-translations.json`,
    under the `overrides` key.'
  user_input: how to override plugin translations in RHDH
- context:
  - "Hub automatically saves and restores user language settings across browser sessions.\
    \ This feature is enabled by default and uses database storage. To opt-out and\
    \ use browser storage instead, add the following to your app-config.yaml configuration\
    \ file: ```yaml userSettings: persistence: browser ``` where: userSettings:persistence::\
    \ Enter browser to opt-out and use browser local storage. Optionally, set this\
    \ value to database to persist across browsers and devices. This is the default\
    \ setting and does not require this configuration to be set. ## Localization support\
    \ for plugins ### Overriding translations In RHDH 1.8, you can override plugin\
    \ translation strings without modifying the plugin source code. You have enabled\
    \ localization in your RHDH application. For an Operator installed RHDH instance,\
    \ you have installed the OpenShift CLI (oc). For more information about installing\
    \ oc, see Installing the OpenShift CLI. 1. Create a JSON file containing the translation\
    \ strings that you want to override, as shown in the following example: allTranslations.json\
    \ fragment with translation string overrides ```json { \"plugin.global-floating-action-button\"\
    : { \"en\": { \"fab.quay.label\": \"QUAY EN JSON\", \"fab.rbac.label\": \"RBAC\
    \ EN JSON\", \"fab.rbac.tooltip\": \"RBAC EN tooltip JSON\" }, \"fr\": { \"fab.quay.label\"\
    : \"QUAY French JSON\", \"fab.quay.tooltip\": \"QUAY french tooltip JSON\", \"\
    fab.rbac.label\": \"RBAC French JSON\", \"fab.rbac.tooltip\": \"RBAC french tooltip\
    \ JSON\" } }, \"plugin.global-header\": { \"en\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub EN JSON\" }, \"fr\": { \"applicationLauncher.developerHub\"\
    : \"Developer Hub French JSON\" } } } ``` 2. Log in to your cluster and create\
    \ a config map for your translations override strings: ```bash oc create configmap\
    \ all translations \\ from file=/<path to>/allTranslations.json ``` 3. Update\
    \ your deployment configuration based on your installation method: 1. For an Operator-installed\
    \ RHDH instance, update your Backstage custom resource (CR). For more information\
    \ about configuring a CR, see Using the Red Hat Developer Hub Operator to run\
    \ Developer Hub with your custom configuration. 1. In the spec.application.extraFiles\
    \ section, add the translations custom app configuration as shown in the following\
    \ example: Backstage custom resource fragment ```yaml apiVersion: rhdh.redhat.com/v1alpha3\
    \ kind: Backstage spec: application: extraFiles: mountPath: /opt/app root/src/translations\
    \ configMaps: name: all translations ``` 2. For a Helm-installed RHDH instance,\
    \ update your Developer Hub Backstage Helm chart to mount in the Developer Hub\
    \ filesystem your files from the all-translations config map: 1. In the Developer\
    \ Hub Helm chart, go to Root Schema \u2192 Backstage chart schema \u2192 Backstage\
    \ parameters \u2192 Backstage container additional volume mounts. 2. Select Add\
    \ Backstage container additional volume mounts and add the following values: mountPath::\
    \ /opt/app-root/src/translations name:: all-translations 3. Add the translations\
    \ to the Backstage container additional volumes in the Developer Hub Helm chart:\
    \ name:: all-translations configMap:: defaultMode:: 420 name:: all-translations\
    \ 4. Update the i18n section to your custom Developer Hub app-config.yaml configuration\
    \ file to include the following translation override file: app-config.yaml fragment\
    \ with localization i18n fields ```yaml i18n: locales: # List of supported locales.\
    \ Must include en, otherwise the translation framework will fail to load. - en\
    \ - fr defaultLocale: en # Optional. Defaults to en if not specified. overrides:\
    \ # List of JSON translation files applied in order (last file wins). Each file\
    \ may override/add translations for one or more plugins/locales - /opt/app-root/src/translations/all-translations.json\
    \ ``` customizing display Enabling floating button localization in Developer Hub\
    \ Enabling Quickstart localization in Developer Hub Enabling sidebar menu items\
    \ localization in Developer Hub ### Best practices for implementing localization\
    \ support for custom plugins in RHDH When you add localization support to your\
    \ RHDH plugins, the following best practices help ensure that you establish a\
    \ robust, type-safe, and future-proof localization workflow, separating the immutable\
    \ source text from the organized key structure, and ensuring reliable deployment\
    \ across all targeted languages: Do not modify original English strings:: This\
    \ preserves the source of truth for all translators, preventing unexpected changes\
    \ that would invalidate existing translations and ensuring consistency across\
    \ all versions. Use flat dot notation in translation files:: Flat dot notation,\
    \ for example page.title, follows the standard i18next library convention, which\
    \ optimizes runtime lookups and keeps the actual translation values concise and\
    \ easy to manage for translation services. Use nested objects in the reference\
    \ file for TypeScript support:: This allows the TypeScript compiler to enforce\
    \ structural type checking on your translation keys, catching errors during development\
    \ rather than at runtime. Test with mocks to ensure translations work correctly::\
    \ This isolates the translation logic, guaranteeing the correct keys are passed\
    \ and rendered without relying on a full environment setup or external translation\
    \ files during unit testing. Add all languages to your application configuration::\
    \ This ensures that the RHDH application initializes and loads all necessary language\
    \ resources at startup, making the locales immediately available for users to\
    \ select in the UI. ### Implementing localization support for your custom plugins\
    \ You can implement localization support in your custom RHDH plugins so that your\
    \ plugins are accessible to a diverse, international user base and follow recommended\
    \ best practices. 1. Create the following translation files in your plugin's src/translations/\
    \ directory: src/translations/ref.ts English reference ```json import { createTranslationRef\
    \ } from \"@backstage/core-plugin-api/alpha\"; export const myPluginMessages =\
    \ { page: { title: \"My Plugin\", subtitle: \"Plugin description\", }, common:\
    \ { exportCSV: \"Export CSV\", noResults: \"No results found\", }, table: { headers:\
    \ { name: \"Name\", count: \"Count\", }, }, }; export const myPluginTranslationRef\
    \ = createTranslationRef({ id: \"plugin.my-plugin\", messages: myPluginMessages,\
    \ }); ``` src/translations/de.ts German translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationDe = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mein Plugin\", \"\
    page.subtitle\": \"Plugin Beschreibung\", \"common.exportCSV\": \"CSV exportieren\"\
    , \"common.noResults\": \"Keine Ergebnisse gefunden\", \"table.headers.name\"\
    : \"Name\", \"table.headers.count\": \"Anzahl\", }, }); export default myPluginTranslationDe;\
    \ ``` src/translations/fr.ts French translation ```json import { createTranslationMessages\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; const myPluginTranslationFr = createTranslationMessages({\
    \ ref: myPluginTranslationRef, messages: { \"page.title\": \"Mon Plugin\", \"\
    page.subtitle\": \"Description du plugin\", \"common.exportCSV\": \"Exporter CSV\"\
    , \"common.noResults\": \"Aucun r\xE9sultat trouv\xE9\", \"table.headers.name\"\
    : \"Nom\", \"table.headers.count\": \"Nombre\", }, }); export default myPluginTranslationFr;\
    \ ``` src/translations/index.ts Translation resource ```json import { createTranslationResource\
    \ } from \"@backstage/core-plugin-api/alpha\"; import { myPluginTranslationRef\
    \ } from \"./ref\"; export const myPluginTranslations = createTranslationResource({\
    \ ref: myPluginTranslationRef, translations: { de: () => import(\"./de\"), fr:\
    \ () => import(\"./fr\"), }, }); export { myPluginTranslationRef }; ``` 2. Create\
    \ translation hooks file, as follows: src/hooks/useTranslation.ts Translation\
    \ hooks ```json"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:32:34.256070'
    uuid: e4614ff9-31da-4c36-acc2-31db16d503e0
  response: 'To override plugin translation strings, you first create a JSON file
    containing the strings you want to override, for which an example `allTranslations.json`
    fragment is provided. Next, you log in to your cluster and create a config map
    from your file using the command: `oc create configmap all translations \ from
    file=/<path to>/allTranslations.json`. After that, you update your deployment
    configuration based on your installation method (Operator or Helm). Finally, you
    update the `i18n` section in your `app-config.yaml` file to include the translation
    override file in the `overrides` list, for example: `- /opt/app-root/src/translations/all-translations.json`.'
  user_input: how do i overide plugin translations with a jason file?
- context:
  - 'props that depend on the component you use. ---- ## import { useTranslationRef
    } from "@backstage/core-plugin-api/alpha"; import { myPluginTranslationRef } from
    "../translations"; export const useTranslation = () => useTranslationRef(myPluginTranslationRef);
    ``` 3. Update your plugin components to replace hard-coded strings with translation
    calls as shown in the following example: Before (hardcoded): ```json const MyComponent
    = () => { return ( <div> <h1>My Plugin</h1> <button>Export CSV</button> </div>
    ); }; ``` After (translated): ```json import { useTranslation } from ''../hooks/useTranslation'';
    const MyComponent = () => { const { t } = useTranslation(); return ( <div> <h1>{t(''page.title'')}</h1>
    <button>{t(''common.exportCSV'')}</button> </div> ); }; ``` 4. (Optional) If your
    content contains variables, use interpolation: ```json // In your translation
    files ''table.pagination.topN'': ''Top {{count}} items'' // In your component
    const { t } = useTranslation(); const message = t(''table.pagination.topN'', {
    count: ''10'' }); ``` 5. (Optional) If your content contains dynamic translation
    keys (for example, from your plugin configuration): ```json // Configuration object
    with translation keys const CARD_CONFIGS = [ { id: ''overview'', titleKey: ''cards.overview.title''
    }, { id: ''details'', titleKey: ''cards.details.title'' }, { id: ''settings'',
    titleKey: ''cards.settings.title'' }, ]; // In your component const { t } = useTranslation();
    const CardComponent = ({ config }) => { return ( <div> <h2>{t(config.titleKey
    as any)}</h2> {/* Use ''as any'' for dynamic keys */} </div> ); }; ``` 6. Export
    the translation resources src/alpha.ts file fragment ```json // Export your plugin
    export { myPlugin } from "./plugin"; // Export translation resources for RHDH
    export { myPluginTranslations, myPluginTranslationRef } from "./translations";
    ``` 7. Update your dynamic plugins.default.yaml file, as follows: dynamic plugins.default.yaml
    file fragment ```json backstage community.plugin my plugin: translationResources:
    importName: myPluginTranslations ref: myPluginTranslationRef module: Alpha ```
    8. Update your package.json file as follows: package.json file fragment ```json
    "exports": { ".": "./src/index.ts", "./alpha": "./src/alpha.ts", "./package.json":
    "./package.json" }, "main": "src/index.ts", "types": "src/index.ts", "typesVersions":
    { " ": { "alpha": [ "src/alpha.ts" ], "package.json": [ "package.json" ] } } ```
    To verify your translations, create a test mock file. For example: ```json import
    { myPluginMessages } from "../translations/ref"; function flattenMessages(obj:
    any, prefix = ""): Record<string, string> { const flattened: Record<string, string>
    = {}; for (const key in obj) { if (obj.hasOwnProperty(key)) { const value = obj[key];
    const newKey = prefix ? `${prefix}.${key}` : key; if (typeof value === "object"
    && value !== null) { Object.assign(flattened, flattenMessages(value, newKey));
    } else { flattened[newKey] = value; } } } return flattened; } const flattenedMessages
    = flattenMessages(myPluginMessages); export const mockT = (key: string, params?:
    any) => { let message = flattenedMessages[key] || key; if (params) { for (const
    [paramKey, paramValue] of Object.entries(params)) { message = message.replace(
    new RegExp(`{{${paramKey}}}`, "g"), String(paramValue), ); } } return message;
    }; export const mockUseTranslation = () => ({ t: mockT }); ``` ```json import
    { mockUseTranslation } from "../test-utils/mockTranslations"; jest.mock("../hooks/useTranslation",
    () => ({ useTranslation: mockUseTranslation, })); // Your test code... ```'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:32:41.629106'
    uuid: d56ec45e-8ca2-4ad3-9f3a-46807814c54f
  response: 'You import `useTranslationRef` from "@backstage/core-plugin-api/alpha".
    This is then used to create a `useTranslation` hook by passing your plugin''s
    translation reference to it, as demonstrated in the code: `export const useTranslation
    = () => useTranslationRef(myPluginTranslationRef);`.'
  user_input: so how do i use the `@backstage/core-plugin-api/alpha` thing for my
    plugin translations? the guide show some code but what is the step?
- context:
  - 'props that depend on the component you use. ---- ## import { useTranslationRef
    } from "@backstage/core-plugin-api/alpha"; import { myPluginTranslationRef } from
    "../translations"; export const useTranslation = () => useTranslationRef(myPluginTranslationRef);
    ``` 3. Update your plugin components to replace hard-coded strings with translation
    calls as shown in the following example: Before (hardcoded): ```json const MyComponent
    = () => { return ( <div> <h1>My Plugin</h1> <button>Export CSV</button> </div>
    ); }; ``` After (translated): ```json import { useTranslation } from ''../hooks/useTranslation'';
    const MyComponent = () => { const { t } = useTranslation(); return ( <div> <h1>{t(''page.title'')}</h1>
    <button>{t(''common.exportCSV'')}</button> </div> ); }; ``` 4. (Optional) If your
    content contains variables, use interpolation: ```json // In your translation
    files ''table.pagination.topN'': ''Top {{count}} items'' // In your component
    const { t } = useTranslation(); const message = t(''table.pagination.topN'', {
    count: ''10'' }); ``` 5. (Optional) If your content contains dynamic translation
    keys (for example, from your plugin configuration): ```json // Configuration object
    with translation keys const CARD_CONFIGS = [ { id: ''overview'', titleKey: ''cards.overview.title''
    }, { id: ''details'', titleKey: ''cards.details.title'' }, { id: ''settings'',
    titleKey: ''cards.settings.title'' }, ]; // In your component const { t } = useTranslation();
    const CardComponent = ({ config }) => { return ( <div> <h2>{t(config.titleKey
    as any)}</h2> {/* Use ''as any'' for dynamic keys */} </div> ); }; ``` 6. Export
    the translation resources src/alpha.ts file fragment ```json // Export your plugin
    export { myPlugin } from "./plugin"; // Export translation resources for RHDH
    export { myPluginTranslations, myPluginTranslationRef } from "./translations";
    ``` 7. Update your dynamic plugins.default.yaml file, as follows: dynamic plugins.default.yaml
    file fragment ```json backstage community.plugin my plugin: translationResources:
    importName: myPluginTranslations ref: myPluginTranslationRef module: Alpha ```
    8. Update your package.json file as follows: package.json file fragment ```json
    "exports": { ".": "./src/index.ts", "./alpha": "./src/alpha.ts", "./package.json":
    "./package.json" }, "main": "src/index.ts", "types": "src/index.ts", "typesVersions":
    { " ": { "alpha": [ "src/alpha.ts" ], "package.json": [ "package.json" ] } } ```
    To verify your translations, create a test mock file. For example: ```json import
    { myPluginMessages } from "../translations/ref"; function flattenMessages(obj:
    any, prefix = ""): Record<string, string> { const flattened: Record<string, string>
    = {}; for (const key in obj) { if (obj.hasOwnProperty(key)) { const value = obj[key];
    const newKey = prefix ? `${prefix}.${key}` : key; if (typeof value === "object"
    && value !== null) { Object.assign(flattened, flattenMessages(value, newKey));
    } else { flattened[newKey] = value; } } } return flattened; } const flattenedMessages
    = flattenMessages(myPluginMessages); export const mockT = (key: string, params?:
    any) => { let message = flattenedMessages[key] || key; if (params) { for (const
    [paramKey, paramValue] of Object.entries(params)) { message = message.replace(
    new RegExp(`{{${paramKey}}}`, "g"), String(paramValue), ); } } return message;
    }; export const mockUseTranslation = () => ({ t: mockT }); ``` ```json import
    { mockUseTranslation } from "../test-utils/mockTranslations"; jest.mock("../hooks/useTranslation",
    () => ({ useTranslation: mockUseTranslation, })); // Your test code... ```'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:32:49.938484'
    uuid: 9949175c-4545-49f9-b369-ba24b18fa52e
  response: 'To export translation resources for RHDH, you must update the `src/alpha.ts`
    file to include the following export statement: `export { myPluginTranslations,
    myPluginTranslationRef } from "./translations";`.'
  user_input: What is the required step to export translation resources for RHDH?
- context:
  - 'props that depend on the component you use. ---- ## import { useTranslationRef
    } from "@backstage/core-plugin-api/alpha"; import { myPluginTranslationRef } from
    "../translations"; export const useTranslation = () => useTranslationRef(myPluginTranslationRef);
    ``` 3. Update your plugin components to replace hard-coded strings with translation
    calls as shown in the following example: Before (hardcoded): ```json const MyComponent
    = () => { return ( <div> <h1>My Plugin</h1> <button>Export CSV</button> </div>
    ); }; ``` After (translated): ```json import { useTranslation } from ''../hooks/useTranslation'';
    const MyComponent = () => { const { t } = useTranslation(); return ( <div> <h1>{t(''page.title'')}</h1>
    <button>{t(''common.exportCSV'')}</button> </div> ); }; ``` 4. (Optional) If your
    content contains variables, use interpolation: ```json // In your translation
    files ''table.pagination.topN'': ''Top {{count}} items'' // In your component
    const { t } = useTranslation(); const message = t(''table.pagination.topN'', {
    count: ''10'' }); ``` 5. (Optional) If your content contains dynamic translation
    keys (for example, from your plugin configuration): ```json // Configuration object
    with translation keys const CARD_CONFIGS = [ { id: ''overview'', titleKey: ''cards.overview.title''
    }, { id: ''details'', titleKey: ''cards.details.title'' }, { id: ''settings'',
    titleKey: ''cards.settings.title'' }, ]; // In your component const { t } = useTranslation();
    const CardComponent = ({ config }) => { return ( <div> <h2>{t(config.titleKey
    as any)}</h2> {/* Use ''as any'' for dynamic keys */} </div> ); }; ``` 6. Export
    the translation resources src/alpha.ts file fragment ```json // Export your plugin
    export { myPlugin } from "./plugin"; // Export translation resources for RHDH
    export { myPluginTranslations, myPluginTranslationRef } from "./translations";
    ``` 7. Update your dynamic plugins.default.yaml file, as follows: dynamic plugins.default.yaml
    file fragment ```json backstage community.plugin my plugin: translationResources:
    importName: myPluginTranslations ref: myPluginTranslationRef module: Alpha ```
    8. Update your package.json file as follows: package.json file fragment ```json
    "exports": { ".": "./src/index.ts", "./alpha": "./src/alpha.ts", "./package.json":
    "./package.json" }, "main": "src/index.ts", "types": "src/index.ts", "typesVersions":
    { " ": { "alpha": [ "src/alpha.ts" ], "package.json": [ "package.json" ] } } ```
    To verify your translations, create a test mock file. For example: ```json import
    { myPluginMessages } from "../translations/ref"; function flattenMessages(obj:
    any, prefix = ""): Record<string, string> { const flattened: Record<string, string>
    = {}; for (const key in obj) { if (obj.hasOwnProperty(key)) { const value = obj[key];
    const newKey = prefix ? `${prefix}.${key}` : key; if (typeof value === "object"
    && value !== null) { Object.assign(flattened, flattenMessages(value, newKey));
    } else { flattened[newKey] = value; } } } return flattened; } const flattenedMessages
    = flattenMessages(myPluginMessages); export const mockT = (key: string, params?:
    any) => { let message = flattenedMessages[key] || key; if (params) { for (const
    [paramKey, paramValue] of Object.entries(params)) { message = message.replace(
    new RegExp(`{{${paramKey}}}`, "g"), String(paramValue), ); } } return message;
    }; export const mockUseTranslation = () => ({ t: mockT }); ``` ```json import
    { mockUseTranslation } from "../test-utils/mockTranslations"; jest.mock("../hooks/useTranslation",
    () => ({ useTranslation: mockUseTranslation, })); // Your test code... ```'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:32:58.218352'
    uuid: e810d323-6202-4bdd-8502-034fef0ef3ad
  response: "To enable translation resources for a plugin, you must update your `dynamic\
    \ plugins.default.yaml` file by adding the following fragment: \n```json\nbackstage\
    \ community.plugin my plugin:\n  translationResources:\n    importName: myPluginTranslations\n\
    \    ref: myPluginTranslationRef\n    module: Alpha\n```"
  user_input: As a Platform Engineer integrating a new plugin, what specific configuration
    fragment is required within the `dynamic plugins.default.yaml` file to correctly
    enable the translation resources for the 'my plugin' community plugin so that
    it functions as intended within the Red Hat Developer Hub environment?
- context:
  - 'Installing dynamic plugins with the Red Hat Developer Hub Operator You can store
    the configuration for dynamic plugins in a ConfigMap object that your Backstage
    custom resource (CR) can reference. Dynamic plugins might require certain Kubernetes
    resources to be configured. These resources are referred to as plugin dependencies.
    For more information, see Dynamic plugins dependency management. In Red Hat Developer
    Hub (RHDH), you can automatically create these resources when the Backstage CR
    is applied to the cluster. [NOTE] ---- If the pluginConfig field references environment
    variables, you must define the variables in your <my_product_secrets> secret.
    ---- 1. From the OpenShift Container Platform web console, select the ConfigMaps
    tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap page, select the
    YAML view option in Configure via and edit the file, if needed. Example ConfigMap
    object using the GitHub dynamic plugin ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic-plugins-rhdh data: dynamic-plugins.yaml: | includes: -
    dynamic-plugins.default.yaml plugins: - package: ''./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic''
    disabled: false pluginConfig: catalog: providers: github: organization: "${GITHUB_ORG}"
    schedule: frequency: { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds:
    100 } ``` 4. Click Create. 5. Go to the Topology view. 6. Click on the overflow
    menu for the Red Hat Developer Hub instance that you want to use and select Edit
    Backstage to load the YAML view of the Red Hat Developer Hub instance. ![operator
    install 2] 7. Add the dynamicPluginsConfigMapName field to your Backstage CR.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: my rhdh spec: application: # ... dynamicPluginsConfigMapName: dynamic plugins
    rhdh # ... ``` 8. Click Save. 9. Navigate back to the Topology view and wait for
    the Red Hat Developer Hub pod to start. 10. Click the Open URL icon to start using
    the Red Hat Developer Hub platform with the new configuration changes. Ensure
    that the dynamic plugins configuration has been loaded, by appending /api/dynamic
    plugins info/loaded plugins to your Red Hat Developer Hub root URL and checking
    the list of plugins: Example list of plugins ```json [ { "name": "backstage plugin
    catalog backend module github dynamic", "version": "0.5.2", "platform": "node",
    "role": "backend plugin module" }, { "name": "backstage plugin techdocs", "version":
    "1.10.0", "role": "frontend plugin", "platform": "web" }, { "name": "backstage
    plugin techdocs backend dynamic", "version": "1.9.5", "platform": "node", "role":
    "backend plugin" }, ] ``` ### Dynamic plugins dependency management Dynamic plugins
    configured for the Backstage custom resource (CR) may require certain Kubernetes
    resources to be configured to make the plugin work. These resources are referred
    to as plugin dependencies. In Red Hat Developer Hub (RHDH), you can automatically
    create these resources when the Backstage CR is applied to the cluster. #### Cluster
    level plugin dependencies configuration You can configure plugin dependencies
    by including the required Kubernetes resources in the /config/profile/{PROFILE}/plugin-deps
    directory. You must add the required resources as Kubernetes manifests in YAML
    format in the plugin-deps directory. Example showing how to add example-dep1.yaml
    and example-dep2.yaml as plugin dependencies: ```terminal config/ profile/ rhdh/
    kustomization.yaml plugin deps/ example dep1.yaml example dep2.yaml ``` [NOTE]
    ---- * If a resource manifest does not specify a namespace, it will be created
    in the namespace of the Backstage CR. * Resources may contain {{backstage-name}}
    and {{backstage-ns}} placeholders, which will be replaced with the name and namespace
    of the Backstage CR, respectively. ---- The kustomization.yaml file must contain
    the following lines: ```yaml configMapGenerator: files: plugin deps/example dep1.yaml
    plugin deps/example dep2.yaml name: plugin deps ``` #### Plugin dependencies infrastructure
    To install infrastructural resources that are required by plugin dependencies,
    for example, other operators or custom resources (CR), you can include these in
    the /config/profile/{PROFILE}/plugin-infra directory. To create these infrastructural
    resources (along with the operator deployment), use the make plugin-infra command.
    [NOTE] ---- On a production cluster, use this command with caution as it might
    reconfigure cluster-scoped resources. ---- #### Plugin configuration You must
    reference the plugin dependenciesin the dependencies field of the plugin configuration
    when the Backstage CR is applied. The Operator creates the resources described
    in the files located in the plugin-deps directory. You can reference plugin dependencies
    in the dynamic-plugins ConfigMap which can either be part of the default profile
    configuration for all Backstage custom resources or part of the ConfigMap referenced
    in the Backstage CR. In Red Hat Developer Hub, you can include plugin dependencies
    in the dynamic plugin configuration. Each dependencies.ref value can either match
    the full file name or serve as a prefix for the file name. The operator will create
    the resources described in the files contained in the plugin-deps that start with
    the specified ref value or exactly match it Example showing how to add example-dep
    plugin dependency: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: default
    dynamic plugins data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: "path or url to example plugin" dependencies:
    ref: example dep ``` ### Installing dynamic plugins using the Helm chart You can
    deploy a Developer Hub instance by using a Helm chart, which is a flexible installation
    method. With the Helm chart, you can sideload dynamic plugins into your Developer
    Hub instance without having to recompile your code or rebuild the container. To
    install dynamic plugins in Developer Hub using Helm, add the following global.dynamic
    parameters in your Helm chart: plugins: the dynamic plugins list intended for
    installation. By default, the list is empty. You can populate the plugins list
    with the following fields: package: a package specification for the dynamic plugin
    package that you want to install. You can use a package for either a local or
    an external dynamic plugin installation. For a local installation, use a path
    to the local folder containing the dynamic plugin. For an external installation,
    use a package specification from a public NPM repository. integrity (required
    for external packages): an integrity checksum in the form of <alg> <digest> specific
    to the package. Supported algorithms include sha256, sha384 and sha512. pluginConfig:
    an optional plugin specific app config.yaml YAML fragment. See plugin configuration
    for more information. disabled: disables the dynamic plugin if set to true. Default:
    false. forceDownload:'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:08.812071'
    uuid: 17b4ec15-3145-43b9-89ba-26c1cfb4abf9
  response: To install dynamic plugins with the Red Hat Developer Hub Operator, you
    can store their configuration in a ConfigMap object that your Backstage custom
    resource (CR) can reference. After creating the ConfigMap, you must edit your
    Backstage CR and add the dynamicPluginsConfigMapName field to reference it. For
    plugin dependencies, which are required Kubernetes resources, Red Hat Developer
    Hub (RHDH) allows you to automatically create these when the Backstage CR is applied
    to the cluster. To do this, you configure the dependencies by including the required
    Kubernetes resources as YAML manifests in the /config/profile/{PROFILE}/plugin-deps
    directory. You must then reference these plugin dependencies in the dependencies
    field of the plugin configuration. The Operator will then create the resources
    described in the files located in the plugin-deps directory.
  user_input: How do I go about installing dynamic plugins with teh Red Hat Developer
    Hub Operator, specifically how do I store teh configuration for them in a ConfigMap
    and then how do I make sure teh plugin dependancies, like certain Kubernetes resorces,
    are automatically created when teh Backstage CR is applied to teh cluster?
- context:
  - 'Installing dynamic plugins with the Red Hat Developer Hub Operator You can store
    the configuration for dynamic plugins in a ConfigMap object that your Backstage
    custom resource (CR) can reference. Dynamic plugins might require certain Kubernetes
    resources to be configured. These resources are referred to as plugin dependencies.
    For more information, see Dynamic plugins dependency management. In Red Hat Developer
    Hub (RHDH), you can automatically create these resources when the Backstage CR
    is applied to the cluster. [NOTE] ---- If the pluginConfig field references environment
    variables, you must define the variables in your <my_product_secrets> secret.
    ---- 1. From the OpenShift Container Platform web console, select the ConfigMaps
    tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap page, select the
    YAML view option in Configure via and edit the file, if needed. Example ConfigMap
    object using the GitHub dynamic plugin ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic-plugins-rhdh data: dynamic-plugins.yaml: | includes: -
    dynamic-plugins.default.yaml plugins: - package: ''./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic''
    disabled: false pluginConfig: catalog: providers: github: organization: "${GITHUB_ORG}"
    schedule: frequency: { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds:
    100 } ``` 4. Click Create. 5. Go to the Topology view. 6. Click on the overflow
    menu for the Red Hat Developer Hub instance that you want to use and select Edit
    Backstage to load the YAML view of the Red Hat Developer Hub instance. ![operator
    install 2] 7. Add the dynamicPluginsConfigMapName field to your Backstage CR.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: my rhdh spec: application: # ... dynamicPluginsConfigMapName: dynamic plugins
    rhdh # ... ``` 8. Click Save. 9. Navigate back to the Topology view and wait for
    the Red Hat Developer Hub pod to start. 10. Click the Open URL icon to start using
    the Red Hat Developer Hub platform with the new configuration changes. Ensure
    that the dynamic plugins configuration has been loaded, by appending /api/dynamic
    plugins info/loaded plugins to your Red Hat Developer Hub root URL and checking
    the list of plugins: Example list of plugins ```json [ { "name": "backstage plugin
    catalog backend module github dynamic", "version": "0.5.2", "platform": "node",
    "role": "backend plugin module" }, { "name": "backstage plugin techdocs", "version":
    "1.10.0", "role": "frontend plugin", "platform": "web" }, { "name": "backstage
    plugin techdocs backend dynamic", "version": "1.9.5", "platform": "node", "role":
    "backend plugin" }, ] ``` ### Dynamic plugins dependency management Dynamic plugins
    configured for the Backstage custom resource (CR) may require certain Kubernetes
    resources to be configured to make the plugin work. These resources are referred
    to as plugin dependencies. In Red Hat Developer Hub (RHDH), you can automatically
    create these resources when the Backstage CR is applied to the cluster. #### Cluster
    level plugin dependencies configuration You can configure plugin dependencies
    by including the required Kubernetes resources in the /config/profile/{PROFILE}/plugin-deps
    directory. You must add the required resources as Kubernetes manifests in YAML
    format in the plugin-deps directory. Example showing how to add example-dep1.yaml
    and example-dep2.yaml as plugin dependencies: ```terminal config/ profile/ rhdh/
    kustomization.yaml plugin deps/ example dep1.yaml example dep2.yaml ``` [NOTE]
    ---- * If a resource manifest does not specify a namespace, it will be created
    in the namespace of the Backstage CR. * Resources may contain {{backstage-name}}
    and {{backstage-ns}} placeholders, which will be replaced with the name and namespace
    of the Backstage CR, respectively. ---- The kustomization.yaml file must contain
    the following lines: ```yaml configMapGenerator: files: plugin deps/example dep1.yaml
    plugin deps/example dep2.yaml name: plugin deps ``` #### Plugin dependencies infrastructure
    To install infrastructural resources that are required by plugin dependencies,
    for example, other operators or custom resources (CR), you can include these in
    the /config/profile/{PROFILE}/plugin-infra directory. To create these infrastructural
    resources (along with the operator deployment), use the make plugin-infra command.
    [NOTE] ---- On a production cluster, use this command with caution as it might
    reconfigure cluster-scoped resources. ---- #### Plugin configuration You must
    reference the plugin dependenciesin the dependencies field of the plugin configuration
    when the Backstage CR is applied. The Operator creates the resources described
    in the files located in the plugin-deps directory. You can reference plugin dependencies
    in the dynamic-plugins ConfigMap which can either be part of the default profile
    configuration for all Backstage custom resources or part of the ConfigMap referenced
    in the Backstage CR. In Red Hat Developer Hub, you can include plugin dependencies
    in the dynamic plugin configuration. Each dependencies.ref value can either match
    the full file name or serve as a prefix for the file name. The operator will create
    the resources described in the files contained in the plugin-deps that start with
    the specified ref value or exactly match it Example showing how to add example-dep
    plugin dependency: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: default
    dynamic plugins data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: "path or url to example plugin" dependencies:
    ref: example dep ``` ### Installing dynamic plugins using the Helm chart You can
    deploy a Developer Hub instance by using a Helm chart, which is a flexible installation
    method. With the Helm chart, you can sideload dynamic plugins into your Developer
    Hub instance without having to recompile your code or rebuild the container. To
    install dynamic plugins in Developer Hub using Helm, add the following global.dynamic
    parameters in your Helm chart: plugins: the dynamic plugins list intended for
    installation. By default, the list is empty. You can populate the plugins list
    with the following fields: package: a package specification for the dynamic plugin
    package that you want to install. You can use a package for either a local or
    an external dynamic plugin installation. For a local installation, use a path
    to the local folder containing the dynamic plugin. For an external installation,
    use a package specification from a public NPM repository. integrity (required
    for external packages): an integrity checksum in the form of <alg> <digest> specific
    to the package. Supported algorithms include sha256, sha384 and sha512. pluginConfig:
    an optional plugin specific app config.yaml YAML fragment. See plugin configuration
    for more information. disabled: disables the dynamic plugin if set to true. Default:
    false. forceDownload:'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:19.071121'
    uuid: 5ef32fb3-7728-4159-b671-2bdf7238e0f3
  response: 'To install dynamic plugins in Developer Hub using a Helm chart, you add
    global.dynamic parameters to your chart. Specifically, you populate the `plugins`
    list, which is empty by default, with the plugins you intend to install. The fields
    for the plugins list include: `package`, which specifies the plugin package from
    a local folder or a public NPM repository; `integrity`, a required checksum for
    external packages in the format `<alg> <digest>`; `pluginConfig`, an optional
    YAML fragment for plugin-specific configuration; and `disabled`, which, if set
    to true, disables the dynamic plugin.'
  user_input: How do I install dynamic plugins in Developer Hub using a Helm chart?
- context:
  - 'Installing dynamic plugins with the Red Hat Developer Hub Operator You can store
    the configuration for dynamic plugins in a ConfigMap object that your Backstage
    custom resource (CR) can reference. Dynamic plugins might require certain Kubernetes
    resources to be configured. These resources are referred to as plugin dependencies.
    For more information, see Dynamic plugins dependency management. In Red Hat Developer
    Hub (RHDH), you can automatically create these resources when the Backstage CR
    is applied to the cluster. [NOTE] ---- If the pluginConfig field references environment
    variables, you must define the variables in your <my_product_secrets> secret.
    ---- 1. From the OpenShift Container Platform web console, select the ConfigMaps
    tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap page, select the
    YAML view option in Configure via and edit the file, if needed. Example ConfigMap
    object using the GitHub dynamic plugin ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic-plugins-rhdh data: dynamic-plugins.yaml: | includes: -
    dynamic-plugins.default.yaml plugins: - package: ''./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic''
    disabled: false pluginConfig: catalog: providers: github: organization: "${GITHUB_ORG}"
    schedule: frequency: { minutes: 1 } timeout: { minutes: 1 } initialDelay: { seconds:
    100 } ``` 4. Click Create. 5. Go to the Topology view. 6. Click on the overflow
    menu for the Red Hat Developer Hub instance that you want to use and select Edit
    Backstage to load the YAML view of the Red Hat Developer Hub instance. ![operator
    install 2] 7. Add the dynamicPluginsConfigMapName field to your Backstage CR.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: my rhdh spec: application: # ... dynamicPluginsConfigMapName: dynamic plugins
    rhdh # ... ``` 8. Click Save. 9. Navigate back to the Topology view and wait for
    the Red Hat Developer Hub pod to start. 10. Click the Open URL icon to start using
    the Red Hat Developer Hub platform with the new configuration changes. Ensure
    that the dynamic plugins configuration has been loaded, by appending /api/dynamic
    plugins info/loaded plugins to your Red Hat Developer Hub root URL and checking
    the list of plugins: Example list of plugins ```json [ { "name": "backstage plugin
    catalog backend module github dynamic", "version": "0.5.2", "platform": "node",
    "role": "backend plugin module" }, { "name": "backstage plugin techdocs", "version":
    "1.10.0", "role": "frontend plugin", "platform": "web" }, { "name": "backstage
    plugin techdocs backend dynamic", "version": "1.9.5", "platform": "node", "role":
    "backend plugin" }, ] ``` ### Dynamic plugins dependency management Dynamic plugins
    configured for the Backstage custom resource (CR) may require certain Kubernetes
    resources to be configured to make the plugin work. These resources are referred
    to as plugin dependencies. In Red Hat Developer Hub (RHDH), you can automatically
    create these resources when the Backstage CR is applied to the cluster. #### Cluster
    level plugin dependencies configuration You can configure plugin dependencies
    by including the required Kubernetes resources in the /config/profile/{PROFILE}/plugin-deps
    directory. You must add the required resources as Kubernetes manifests in YAML
    format in the plugin-deps directory. Example showing how to add example-dep1.yaml
    and example-dep2.yaml as plugin dependencies: ```terminal config/ profile/ rhdh/
    kustomization.yaml plugin deps/ example dep1.yaml example dep2.yaml ``` [NOTE]
    ---- * If a resource manifest does not specify a namespace, it will be created
    in the namespace of the Backstage CR. * Resources may contain {{backstage-name}}
    and {{backstage-ns}} placeholders, which will be replaced with the name and namespace
    of the Backstage CR, respectively. ---- The kustomization.yaml file must contain
    the following lines: ```yaml configMapGenerator: files: plugin deps/example dep1.yaml
    plugin deps/example dep2.yaml name: plugin deps ``` #### Plugin dependencies infrastructure
    To install infrastructural resources that are required by plugin dependencies,
    for example, other operators or custom resources (CR), you can include these in
    the /config/profile/{PROFILE}/plugin-infra directory. To create these infrastructural
    resources (along with the operator deployment), use the make plugin-infra command.
    [NOTE] ---- On a production cluster, use this command with caution as it might
    reconfigure cluster-scoped resources. ---- #### Plugin configuration You must
    reference the plugin dependenciesin the dependencies field of the plugin configuration
    when the Backstage CR is applied. The Operator creates the resources described
    in the files located in the plugin-deps directory. You can reference plugin dependencies
    in the dynamic-plugins ConfigMap which can either be part of the default profile
    configuration for all Backstage custom resources or part of the ConfigMap referenced
    in the Backstage CR. In Red Hat Developer Hub, you can include plugin dependencies
    in the dynamic plugin configuration. Each dependencies.ref value can either match
    the full file name or serve as a prefix for the file name. The operator will create
    the resources described in the files contained in the plugin-deps that start with
    the specified ref value or exactly match it Example showing how to add example-dep
    plugin dependency: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: default
    dynamic plugins data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: "path or url to example plugin" dependencies:
    ref: example dep ``` ### Installing dynamic plugins using the Helm chart You can
    deploy a Developer Hub instance by using a Helm chart, which is a flexible installation
    method. With the Helm chart, you can sideload dynamic plugins into your Developer
    Hub instance without having to recompile your code or rebuild the container. To
    install dynamic plugins in Developer Hub using Helm, add the following global.dynamic
    parameters in your Helm chart: plugins: the dynamic plugins list intended for
    installation. By default, the list is empty. You can populate the plugins list
    with the following fields: package: a package specification for the dynamic plugin
    package that you want to install. You can use a package for either a local or
    an external dynamic plugin installation. For a local installation, use a path
    to the local folder containing the dynamic plugin. For an external installation,
    use a package specification from a public NPM repository. integrity (required
    for external packages): an integrity checksum in the form of <alg> <digest> specific
    to the package. Supported algorithms include sha256, sha384 and sha512. pluginConfig:
    an optional plugin specific app config.yaml YAML fragment. See plugin configuration
    for more information. disabled: disables the dynamic plugin if set to true. Default:
    false. forceDownload:'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:30.139322'
    uuid: 09b6cd8c-3b18-4f90-985d-53de0ca4b5a1
  response: You can store the configuration for dynamic plugins in a ConfigMap object,
    which your Backstage custom resource (CR) can then reference. To link them, you
    must add the `dynamicPluginsConfigMapName` field to your Backstage CR. Additionally,
    you can reference plugin dependencies in the `dynamic-plugins` ConfigMap. When
    the Backstage CR is applied, the Operator creates the resources that are described
    in the files located in the `plugin-deps` directory and are referenced in the
    ConfigMap.
  user_input: RHDH dynamic plugin configuration using ConfigMap
- context:
  - 'Set the value to true to force a reinstall of the plugin, bypassing the cache.
    The default value is false. pullPolicy: Similar to the forceDownload parameter
    and is consistent with other image container platforms. You can use one of the
    following values for this key: Always: This value compares the image digest in
    the remote registry and downloads the artifact if it has changed, even if the
    plugin was previously downloaded. IfNotPresent: This value downloads the artifact
    if it is not already present in the dynamic plugins root folder, without checking
    image digests. [NOTE] ---- The pullPolicy setting is also applied to the NPM downloading
    method, although Always will download the remote artifact without a digest check.
    The existing forceDownload option remains functional, however, the pullPolicy
    option takes precedence. The forceDownload option may be deprecated in a future
    Developer Hub release. ---- * includes: a list of YAML files utilizing the same
    syntax. [NOTE] ---- The plugins list in the includes file is merged with the plugins
    list in the main Helm values. If a plugin package is mentioned in both plugins
    lists, the plugins fields in the main Helm values override the plugins fields
    in the includes file. The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins preinstalled in Developer Hub,
    whether enabled or disabled by default. ---- #### Example Helm chart configurations
    for dynamic plugin installations The following examples demonstrate how to configure
    the Helm chart for specific types of dynamic plugin installations. ```yaml global:
    dynamic: plugins: - package: <alocal package-spec used by npm pack> - package:
    <external package-spec used by npm pack> integrity: sha512-<some hash> pluginConfig:
    ... ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.default.yaml> disabled:
    true ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ### Installing dynamic plugins in an air-gapped environment You can
    install external plugins in an air-gapped environment by setting up a custom NPM
    registry. You can configure the NPM registry URL and authentication information
    for dynamic plugin packages using a Helm chart. For dynamic plugin packages obtained
    through npm pack, you can use a .npmrc file. Using the Helm chart, add the .npmrc
    file to the NPM registry by creating a secret. For example: ```yaml apiVersion:
    v1 kind: Secret metadata: name: <release_name> dynamic plugins npmrc 1 type: Opaque
    stringData: .npmrc: | registry=<registry link> //<registry link>:_authToken=<auth
    token> ... ``` Replace <release_name> with your Helm release name. This name is
    a unique identifier for each chart installation in the Kubernetes cluster. # Custom
    plugins in Red Hat Developer Hub You can integrate custom dynamic plugins into
    Red Hat Developer Hub to enhance its functionality without modifying its source
    code or rebuilding it. To add these plugins, export them as derived packages.
    While exporting the plugin package, you must ensure that dependencies are correctly
    bundled or marked as shared, depending on their relationship to the Developer
    Hub environment. To integrate a custom plugin into Developer Hub: 1. First, obtain
    the plugin''s source code. 2. Export the plugin as a dynamic plugin package. See
    . 3. Package and publish the dynamic plugin. See . 4. Install the plugin in the
    Developer Hub environment. See . ### Exporting custom plugins in Red Hat Developer
    Hub To use plugins in Red Hat Developer Hub, you can export plugins as derived
    dynamic plugin packages. These packages contain the plugin code and dependencies,
    ready for dynamic plugin integration into Developer Hub. The @red hat developer
    hub/cli package is installed. Use the latest version (@latest tag) for compatibility
    with the most recent features and fixes. Node.js and NPM is installed and configured.
    The custom plugin is compatible with your Red Hat Developer Hub version. For more
    information, see Version compatibility matrix. The custom plugin must have a valid
    package.json file in its root directory, containing all required metadata and
    dependencies. Backend plugins:: To ensure compatibility with the dynamic plugin
    support and enable their use as dynamic plugins, existing backend plugins must
    be compatible with the new Backstage backend system. Additionally, these plugins
    must be rebuilt using a dedicated CLI command. The new Backstage backend system
    entry point (created using createBackendPlugin() or createBackendModule()) must
    be exported as the default export from either the main package or an alpha package
    (if the plugin instance support is still provided using alpha APIs). This doesn''t
    add any additional requirement on top of the standard plugin development guidelines
    of the plugin instance. The dynamic export mechanism identifies private dependencies
    and sets the bundleDependencies field in the package.json file. This export mechanism
    ensures that the dynamic plugin package is published as a self-contained package,
    with its private dependencies bundled in a private node_modules folder. Certain
    plugin dependencies require specific handling in the derived packages, such as:
    * Shared dependencies are provided by the RHDH application and listed as peerDependencies
    in package.json file, not bundled in the dynamic plugin package. For example,
    by default, all @backstage scoped packages are shared. You can use the --shared-package
    flag to specify shared dependencies, that are expected to be provided by Red Hat
    Developer Hub application and not bundled in the dynamic plugin package. To treat
    a @backstage package as private, use the negation prefix (!). For example, when
    a plugin depends on the package in @backstage that is not provided by the Red
    Hat Developer Hub application. * Embedded dependencies are bundled into the dynamic
    plugin package with their dependencies hoisted to the top level. By default, packages
    with -node or -common suffixes are embedded. You can use the --embed-package flag
    to specify additional embedded packages. For example, packages from the same workspace
    that do not follow the default naming convention. The following is an example
    of exporting a dynamic plugin with shared and embedded packages: Example dynamic
    plugin export with shared and embedded packages ```terminal npx @red hat'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:38.647614'
    uuid: 604c8ed0-64e4-474c-ac22-5268965c0d4a
  response: 'To integrate custom dynamic plugins into Red Hat Developer Hub and enhance
    its functionality without modifying its source code or rebuilding it, you must
    export them as derived packages. The integration process involves four steps:
    first, obtain the plugin''s source code; second, export the plugin as a dynamic
    plugin package; third, package and publish the dynamic plugin; and fourth, install
    the plugin in the Developer Hub environment.'
  user_input: What is the process for integrating custom plugins into Red Hat Developer
    Hub?
- context:
  - 'Set the value to true to force a reinstall of the plugin, bypassing the cache.
    The default value is false. pullPolicy: Similar to the forceDownload parameter
    and is consistent with other image container platforms. You can use one of the
    following values for this key: Always: This value compares the image digest in
    the remote registry and downloads the artifact if it has changed, even if the
    plugin was previously downloaded. IfNotPresent: This value downloads the artifact
    if it is not already present in the dynamic plugins root folder, without checking
    image digests. [NOTE] ---- The pullPolicy setting is also applied to the NPM downloading
    method, although Always will download the remote artifact without a digest check.
    The existing forceDownload option remains functional, however, the pullPolicy
    option takes precedence. The forceDownload option may be deprecated in a future
    Developer Hub release. ---- * includes: a list of YAML files utilizing the same
    syntax. [NOTE] ---- The plugins list in the includes file is merged with the plugins
    list in the main Helm values. If a plugin package is mentioned in both plugins
    lists, the plugins fields in the main Helm values override the plugins fields
    in the includes file. The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins preinstalled in Developer Hub,
    whether enabled or disabled by default. ---- #### Example Helm chart configurations
    for dynamic plugin installations The following examples demonstrate how to configure
    the Helm chart for specific types of dynamic plugin installations. ```yaml global:
    dynamic: plugins: - package: <alocal package-spec used by npm pack> - package:
    <external package-spec used by npm pack> integrity: sha512-<some hash> pluginConfig:
    ... ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.default.yaml> disabled:
    true ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ### Installing dynamic plugins in an air-gapped environment You can
    install external plugins in an air-gapped environment by setting up a custom NPM
    registry. You can configure the NPM registry URL and authentication information
    for dynamic plugin packages using a Helm chart. For dynamic plugin packages obtained
    through npm pack, you can use a .npmrc file. Using the Helm chart, add the .npmrc
    file to the NPM registry by creating a secret. For example: ```yaml apiVersion:
    v1 kind: Secret metadata: name: <release_name> dynamic plugins npmrc 1 type: Opaque
    stringData: .npmrc: | registry=<registry link> //<registry link>:_authToken=<auth
    token> ... ``` Replace <release_name> with your Helm release name. This name is
    a unique identifier for each chart installation in the Kubernetes cluster. # Custom
    plugins in Red Hat Developer Hub You can integrate custom dynamic plugins into
    Red Hat Developer Hub to enhance its functionality without modifying its source
    code or rebuilding it. To add these plugins, export them as derived packages.
    While exporting the plugin package, you must ensure that dependencies are correctly
    bundled or marked as shared, depending on their relationship to the Developer
    Hub environment. To integrate a custom plugin into Developer Hub: 1. First, obtain
    the plugin''s source code. 2. Export the plugin as a dynamic plugin package. See
    . 3. Package and publish the dynamic plugin. See . 4. Install the plugin in the
    Developer Hub environment. See . ### Exporting custom plugins in Red Hat Developer
    Hub To use plugins in Red Hat Developer Hub, you can export plugins as derived
    dynamic plugin packages. These packages contain the plugin code and dependencies,
    ready for dynamic plugin integration into Developer Hub. The @red hat developer
    hub/cli package is installed. Use the latest version (@latest tag) for compatibility
    with the most recent features and fixes. Node.js and NPM is installed and configured.
    The custom plugin is compatible with your Red Hat Developer Hub version. For more
    information, see Version compatibility matrix. The custom plugin must have a valid
    package.json file in its root directory, containing all required metadata and
    dependencies. Backend plugins:: To ensure compatibility with the dynamic plugin
    support and enable their use as dynamic plugins, existing backend plugins must
    be compatible with the new Backstage backend system. Additionally, these plugins
    must be rebuilt using a dedicated CLI command. The new Backstage backend system
    entry point (created using createBackendPlugin() or createBackendModule()) must
    be exported as the default export from either the main package or an alpha package
    (if the plugin instance support is still provided using alpha APIs). This doesn''t
    add any additional requirement on top of the standard plugin development guidelines
    of the plugin instance. The dynamic export mechanism identifies private dependencies
    and sets the bundleDependencies field in the package.json file. This export mechanism
    ensures that the dynamic plugin package is published as a self-contained package,
    with its private dependencies bundled in a private node_modules folder. Certain
    plugin dependencies require specific handling in the derived packages, such as:
    * Shared dependencies are provided by the RHDH application and listed as peerDependencies
    in package.json file, not bundled in the dynamic plugin package. For example,
    by default, all @backstage scoped packages are shared. You can use the --shared-package
    flag to specify shared dependencies, that are expected to be provided by Red Hat
    Developer Hub application and not bundled in the dynamic plugin package. To treat
    a @backstage package as private, use the negation prefix (!). For example, when
    a plugin depends on the package in @backstage that is not provided by the Red
    Hat Developer Hub application. * Embedded dependencies are bundled into the dynamic
    plugin package with their dependencies hoisted to the top level. By default, packages
    with -node or -common suffixes are embedded. You can use the --embed-package flag
    to specify additional embedded packages. For example, packages from the same workspace
    that do not follow the default naming convention. The following is an example
    of exporting a dynamic plugin with shared and embedded packages: Example dynamic
    plugin export with shared and embedded packages ```terminal npx @red hat'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:45.723486'
    uuid: 6dd7e5ee-e346-4daf-9a10-caa452d05535
  response: To ensure compatibility with the dynamic plugin support and enable their
    use as dynamic plugins, existing backend plugins must be compatible with the new
    Backstage backend system. Additionally, these plugins must be rebuilt using a
    dedicated CLI command. The new Backstage backend system entry point (created using
    createBackendPlugin() or createBackendModule()) must be exported as the default
    export from either the main package or an alpha package.
  user_input: i have some existing backend plugins and they dont work, so what do
    i need to do for make them compatible with the new Backstage backend system so
    they can be used as dynamic plugins, what are all the requirements?
- context:
  - 'Set the value to true to force a reinstall of the plugin, bypassing the cache.
    The default value is false. pullPolicy: Similar to the forceDownload parameter
    and is consistent with other image container platforms. You can use one of the
    following values for this key: Always: This value compares the image digest in
    the remote registry and downloads the artifact if it has changed, even if the
    plugin was previously downloaded. IfNotPresent: This value downloads the artifact
    if it is not already present in the dynamic plugins root folder, without checking
    image digests. [NOTE] ---- The pullPolicy setting is also applied to the NPM downloading
    method, although Always will download the remote artifact without a digest check.
    The existing forceDownload option remains functional, however, the pullPolicy
    option takes precedence. The forceDownload option may be deprecated in a future
    Developer Hub release. ---- * includes: a list of YAML files utilizing the same
    syntax. [NOTE] ---- The plugins list in the includes file is merged with the plugins
    list in the main Helm values. If a plugin package is mentioned in both plugins
    lists, the plugins fields in the main Helm values override the plugins fields
    in the includes file. The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins preinstalled in Developer Hub,
    whether enabled or disabled by default. ---- #### Example Helm chart configurations
    for dynamic plugin installations The following examples demonstrate how to configure
    the Helm chart for specific types of dynamic plugin installations. ```yaml global:
    dynamic: plugins: - package: <alocal package-spec used by npm pack> - package:
    <external package-spec used by npm pack> integrity: sha512-<some hash> pluginConfig:
    ... ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.default.yaml> disabled:
    true ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ```yaml global: dynamic: includes: - dynamic-plugins.default.yaml plugins:
    - package: <some imported plugins listed in dynamic-plugins.custom.yaml> disabled:
    false ``` ### Installing dynamic plugins in an air-gapped environment You can
    install external plugins in an air-gapped environment by setting up a custom NPM
    registry. You can configure the NPM registry URL and authentication information
    for dynamic plugin packages using a Helm chart. For dynamic plugin packages obtained
    through npm pack, you can use a .npmrc file. Using the Helm chart, add the .npmrc
    file to the NPM registry by creating a secret. For example: ```yaml apiVersion:
    v1 kind: Secret metadata: name: <release_name> dynamic plugins npmrc 1 type: Opaque
    stringData: .npmrc: | registry=<registry link> //<registry link>:_authToken=<auth
    token> ... ``` Replace <release_name> with your Helm release name. This name is
    a unique identifier for each chart installation in the Kubernetes cluster. # Custom
    plugins in Red Hat Developer Hub You can integrate custom dynamic plugins into
    Red Hat Developer Hub to enhance its functionality without modifying its source
    code or rebuilding it. To add these plugins, export them as derived packages.
    While exporting the plugin package, you must ensure that dependencies are correctly
    bundled or marked as shared, depending on their relationship to the Developer
    Hub environment. To integrate a custom plugin into Developer Hub: 1. First, obtain
    the plugin''s source code. 2. Export the plugin as a dynamic plugin package. See
    . 3. Package and publish the dynamic plugin. See . 4. Install the plugin in the
    Developer Hub environment. See . ### Exporting custom plugins in Red Hat Developer
    Hub To use plugins in Red Hat Developer Hub, you can export plugins as derived
    dynamic plugin packages. These packages contain the plugin code and dependencies,
    ready for dynamic plugin integration into Developer Hub. The @red hat developer
    hub/cli package is installed. Use the latest version (@latest tag) for compatibility
    with the most recent features and fixes. Node.js and NPM is installed and configured.
    The custom plugin is compatible with your Red Hat Developer Hub version. For more
    information, see Version compatibility matrix. The custom plugin must have a valid
    package.json file in its root directory, containing all required metadata and
    dependencies. Backend plugins:: To ensure compatibility with the dynamic plugin
    support and enable their use as dynamic plugins, existing backend plugins must
    be compatible with the new Backstage backend system. Additionally, these plugins
    must be rebuilt using a dedicated CLI command. The new Backstage backend system
    entry point (created using createBackendPlugin() or createBackendModule()) must
    be exported as the default export from either the main package or an alpha package
    (if the plugin instance support is still provided using alpha APIs). This doesn''t
    add any additional requirement on top of the standard plugin development guidelines
    of the plugin instance. The dynamic export mechanism identifies private dependencies
    and sets the bundleDependencies field in the package.json file. This export mechanism
    ensures that the dynamic plugin package is published as a self-contained package,
    with its private dependencies bundled in a private node_modules folder. Certain
    plugin dependencies require specific handling in the derived packages, such as:
    * Shared dependencies are provided by the RHDH application and listed as peerDependencies
    in package.json file, not bundled in the dynamic plugin package. For example,
    by default, all @backstage scoped packages are shared. You can use the --shared-package
    flag to specify shared dependencies, that are expected to be provided by Red Hat
    Developer Hub application and not bundled in the dynamic plugin package. To treat
    a @backstage package as private, use the negation prefix (!). For example, when
    a plugin depends on the package in @backstage that is not provided by the Red
    Hat Developer Hub application. * Embedded dependencies are bundled into the dynamic
    plugin package with their dependencies hoisted to the top level. By default, packages
    with -node or -common suffixes are embedded. You can use the --embed-package flag
    to specify additional embedded packages. For example, packages from the same workspace
    that do not follow the default naming convention. The following is an example
    of exporting a dynamic plugin with shared and embedded packages: Example dynamic
    plugin export with shared and embedded packages ```terminal npx @red hat'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:33:53.699704'
    uuid: e815f87c-6e3f-460c-bd76-fe2edf16a5d7
  response: 'To export custom plugins as derived dynamic plugin packages in Red Hat
    Developer Hub, the following requirements must be met: the @red hat developer
    hub/cli package must be installed, using the latest version for compatibility;
    Node.js and NPM must be installed and configured; the custom plugin must be compatible
    with your Red Hat Developer Hub version; and the custom plugin is required to
    have a valid package.json file in its root directory that contains all required
    metadata and dependencies.'
  user_input: What are the specific requirements, including Node.js and NPM, for exporting
    custom dynamic plugin packages in Red Hat Developer Hub?
- context:
  - '# Installing and viewing plugins in Red Hat Developer Hub # Installing dynamic
    plugins in Red Hat Developer Hub The dynamic plugin support is based on the backend
    plugin manager package, which is a service that scans a configured root directory
    (dynamicPlugins.rootDirectory in the app-config.yaml file) for dynamic plugin
    packages and loads them dynamically. You can use the dynamic plugins that come
    preinstalled with Red Hat Developer Hub or install external dynamic plugins from
    a public NPM registry. ###'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:02.433307'
    uuid: 8e864062-b4d7-4e84-b1e7-be4ef8dfb39c
  response: In Red Hat Developer Hub, dynamic plugin support is based on a backend
    plugin manager package. This service scans a configured root directory, specified
    as dynamicPlugins.rootDirectory in the app-config.yaml file, for dynamic plugin
    packages and loads them. You can use preinstalled dynamic plugins or install external
    ones from a public NPM registry.
  user_input: How do I instal plugns in Red Hat Developer Hub?
- context:
  - '# Installing and viewing plugins in Red Hat Developer Hub # Installing dynamic
    plugins in Red Hat Developer Hub The dynamic plugin support is based on the backend
    plugin manager package, which is a service that scans a configured root directory
    (dynamicPlugins.rootDirectory in the app-config.yaml file) for dynamic plugin
    packages and loads them dynamically. You can use the dynamic plugins that come
    preinstalled with Red Hat Developer Hub or install external dynamic plugins from
    a public NPM registry. ###'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:12.234332'
    uuid: 9fcec895-7ef9-4933-afb3-f933fa1ff5d8
  response: The dynamic plugin support is based on the backend plugin manager package,
    which is a service that scans a configured root directory, specified as dynamicPlugins.rootDirectory
    in the app-config.yaml file, for dynamic plugin packages and then loads them dynamically.
  user_input: ok so for our new platform with Red Hat Developer Hub, im trying to
    understand how the dynamic plugins work, like how does the hub even know where
    to find them and load them up, is there some service that just scans for them
    or do we have to point it somewhere in a config file for it to work?
- context:
  - '# Installing and viewing plugins in Red Hat Developer Hub # Installing dynamic
    plugins in Red Hat Developer Hub The dynamic plugin support is based on the backend
    plugin manager package, which is a service that scans a configured root directory
    (dynamicPlugins.rootDirectory in the app-config.yaml file) for dynamic plugin
    packages and loads them dynamically. You can use the dynamic plugins that come
    preinstalled with Red Hat Developer Hub or install external dynamic plugins from
    a public NPM registry. ###'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:21.612332'
    uuid: 64aea523-dcdc-448b-b2a7-ae2d15fb6184
  response: You can install external dynamic plugins from a public NPM registry. The
    dynamic plugin support is based on the backend plugin manager package, which is
    a service that scans a configured root directory (dynamicPlugins.rootDirectory
    in the app-config.yaml file) for dynamic plugin packages and loads them dynamically.
  user_input: Can you explane how I can instal the externel dynamic plugns that come
    from a publick NPM registry into our Red Hat Develper Hub instalation?
- context:
  - 'developer hub/cli@latest plugin export - shared package ''!/@backstage/plugin
    notifications/'' - embed package @backstage/plugin notifications backend ``` In
    the previous example: * @backstage/plugin-notifications package is treated as
    a private dependency and is bundled in the dynamic plugin package, despite being
    in the @backstage scope. * @backstage/plugin-notifications-backend package is
    marked as an embedded dependency and is bundled in the dynamic plugin package.
    Front-end plugins:: Front-end plugins can use scalprum for configuration, which
    the CLI can generate automatically during the export process. The generated default
    configuration is logged when running the following command: Example command to
    log the default configuration ```terminal npx @red hat developer hub/cli@latest
    plugin export ``` The following is an example of default scalprum configuration:
    Default scalprum configuration ```json "scalprum": { "name": "<package_name>",
    // The Webpack container name matches the NPM package name, with "@" replaced
    by "." and "/" removed. "exposedModules": { "PluginRoot": "./src/index.ts" //
    The default module name is "PluginRoot" and doesn''t need explicit specification
    in the app-config.yaml file. } } ``` You can add a scalprum section to the package.json
    file. For example: Example scalprum customization ```json "scalprum": { "name":
    "custom-package-name", "exposedModules": { "FooModuleName": "./src/foo.ts", "BarModuleName":
    "./src/bar.ts" // Define multiple modules here, with each exposed as a separate
    entry point in the Webpack container. } } ``` Dynamic plugins might need adjustments
    for Developer Hub needs, such as static JSX for mountpoints or dynamic routes.
    These changes are optional but might be incompatible with static plugins. To include
    static JSX, define an additional export and use it as the dynamic plugin''s importName.
    For example: Example static and dynamic plugin export ```tsx // For a static plugin
    export const EntityTechdocsContent = () => {...} // For a dynamic plugin export
    const DynamicEntityTechdocsContent = { element: EntityTechdocsContent, staticJSXContent:
    ( <TechDocsAddons> <ReportIssue /> </TechDocsAddons> ), }; ``` Use the plugin
    export command from the @red hat developer hub/cli package to export the plugin:
    ```terminal npx @red hat developer hub/cli@latest plugin export ``` Ensure that
    you execute the previous command in the root directory of the plugin''s JavaScript
    package (containing package.json file). The resulting derived package will be
    located in the dist-dynamic subfolder. The exported package name consists of the
    original plugin name with -dynamic appended. [WARNING] ---- The derived dynamic
    plugin JavaScript packages must not be published to the public NPM registry. For
    more appropriate packaging options, see . If you must publish to the NPM registry,
    use a private registry. ---- ## Packaging and publishing custom plugins as dynamic
    plugins After exporting a custom plugin, you can package the derived package into
    one of the following supported formats: Open Container Initiative (OCI) image
    (recommended) TGZ file JavaScript package [IMPORTANT] ---- Exported dynamic plugin
    packages must only be published to private NPM registries. ---- #### Creating
    an OCI image with dynamic packages You have installed podman or docker. You have
    exported a custom dynamic plugin package. For more information, see . 1. Navigate
    to the plugin''s root directory (not the dist-dynamic directory). 2. Run the following
    command to package the plugin into an OCI image: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/example/image:v0.0.1 ``` In the previous
    command, the --tag argument specifies the image name and tag. 3. Run one of the
    following commands to push the image to a registry: ```terminal podman push quay.io/example/image:v0.0.1
    ``` ```terminal docker push quay.io/example/image:v0.0.1 ``` The output of the
    package-dynamic-plugins command provides the plugin''s path for use in the dynamic-plugin-config.yaml
    file. #### Creating a TGZ file with dynamic packages You have exported a custom
    dynamic plugin package. For more information, see . 1. Navigate to the dist-dynamic
    directory. 2. Run the following command to create a tgz archive: ```terminal npm
    pack ``` You can obtain the integrity hash from the output of the npm pack command
    by using the --json flag as follows: ```terminal npm pack --json | head -n 10
    ``` 3. Host the archive on a web server accessible to your RHDH instance, and
    reference its URL in the dynamic-plugin-config.yaml file as follows: ```yaml plugins:
    - package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz integrity:
    sha512-<hash> ``` 4. Run the following command to package the plugins: ```terminal
    npm pack - pack destination ~/test/dynamic plugins root/ ``` [TIP] ---- To create
    a plugin registry using HTTP server on OpenShift Container Platform, run the following
    commands: ```terminal oc project my rhdh project oc new build httpd - name=plugin
    registry - binary oc start build plugin registry - from dir=dynamic plugins root
    - wait oc new app - image stream=plugin registry ``` ---- 5. Configure your RHDH
    to use plugins from the HTTP server by editing the dynamic-plugin-config.yaml
    file: ```yaml plugins: package: http://plugin registry:8080/backstage plugin myplugin
    1.9.6.tgz ``` #### Creating a JavaScript package with dynamic packages [WARNING]
    ---- The derived dynamic plugin JavaScript packages must not be published to the
    public NPM registry. If you must publish to the NPM registry, use a private registry.
    ---- You have exported a custom dynamic plugin package. For more information,
    see . 1. Navigate to the dist-dynamic directory. 2. Run the following command
    to publish the package to your private NPM registry: ```terminal npm publish -
    registry <npm_registry_url> ``` [TIP] ---- You can add the following to your package.json
    file before running the export command: ```json { "publishConfig": { "registry":
    "<npm_registry_url>" } } ``` If you modify publishConfig after exporting the dynamic
    plugin, re-run the plugin export command to ensure the correct configuration is
    included. ---- ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:30.852291'
    uuid: d793c143-64d8-4eb1-95b0-0ba307ea1083
  response: 'To push an OCI image to a registry, you can run the command: `podman
    push quay.io/example/image:v0.0.1`.'
  user_input: As a platform lead trying to document our new developer hub workflows,
    what is the exact comand I need to tell my team to use with podmen to push the
    OCI image for our custom dynamic plugins to the container registry?
- context:
  - 'developer hub/cli@latest plugin export - shared package ''!/@backstage/plugin
    notifications/'' - embed package @backstage/plugin notifications backend ``` In
    the previous example: * @backstage/plugin-notifications package is treated as
    a private dependency and is bundled in the dynamic plugin package, despite being
    in the @backstage scope. * @backstage/plugin-notifications-backend package is
    marked as an embedded dependency and is bundled in the dynamic plugin package.
    Front-end plugins:: Front-end plugins can use scalprum for configuration, which
    the CLI can generate automatically during the export process. The generated default
    configuration is logged when running the following command: Example command to
    log the default configuration ```terminal npx @red hat developer hub/cli@latest
    plugin export ``` The following is an example of default scalprum configuration:
    Default scalprum configuration ```json "scalprum": { "name": "<package_name>",
    // The Webpack container name matches the NPM package name, with "@" replaced
    by "." and "/" removed. "exposedModules": { "PluginRoot": "./src/index.ts" //
    The default module name is "PluginRoot" and doesn''t need explicit specification
    in the app-config.yaml file. } } ``` You can add a scalprum section to the package.json
    file. For example: Example scalprum customization ```json "scalprum": { "name":
    "custom-package-name", "exposedModules": { "FooModuleName": "./src/foo.ts", "BarModuleName":
    "./src/bar.ts" // Define multiple modules here, with each exposed as a separate
    entry point in the Webpack container. } } ``` Dynamic plugins might need adjustments
    for Developer Hub needs, such as static JSX for mountpoints or dynamic routes.
    These changes are optional but might be incompatible with static plugins. To include
    static JSX, define an additional export and use it as the dynamic plugin''s importName.
    For example: Example static and dynamic plugin export ```tsx // For a static plugin
    export const EntityTechdocsContent = () => {...} // For a dynamic plugin export
    const DynamicEntityTechdocsContent = { element: EntityTechdocsContent, staticJSXContent:
    ( <TechDocsAddons> <ReportIssue /> </TechDocsAddons> ), }; ``` Use the plugin
    export command from the @red hat developer hub/cli package to export the plugin:
    ```terminal npx @red hat developer hub/cli@latest plugin export ``` Ensure that
    you execute the previous command in the root directory of the plugin''s JavaScript
    package (containing package.json file). The resulting derived package will be
    located in the dist-dynamic subfolder. The exported package name consists of the
    original plugin name with -dynamic appended. [WARNING] ---- The derived dynamic
    plugin JavaScript packages must not be published to the public NPM registry. For
    more appropriate packaging options, see . If you must publish to the NPM registry,
    use a private registry. ---- ## Packaging and publishing custom plugins as dynamic
    plugins After exporting a custom plugin, you can package the derived package into
    one of the following supported formats: Open Container Initiative (OCI) image
    (recommended) TGZ file JavaScript package [IMPORTANT] ---- Exported dynamic plugin
    packages must only be published to private NPM registries. ---- #### Creating
    an OCI image with dynamic packages You have installed podman or docker. You have
    exported a custom dynamic plugin package. For more information, see . 1. Navigate
    to the plugin''s root directory (not the dist-dynamic directory). 2. Run the following
    command to package the plugin into an OCI image: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/example/image:v0.0.1 ``` In the previous
    command, the --tag argument specifies the image name and tag. 3. Run one of the
    following commands to push the image to a registry: ```terminal podman push quay.io/example/image:v0.0.1
    ``` ```terminal docker push quay.io/example/image:v0.0.1 ``` The output of the
    package-dynamic-plugins command provides the plugin''s path for use in the dynamic-plugin-config.yaml
    file. #### Creating a TGZ file with dynamic packages You have exported a custom
    dynamic plugin package. For more information, see . 1. Navigate to the dist-dynamic
    directory. 2. Run the following command to create a tgz archive: ```terminal npm
    pack ``` You can obtain the integrity hash from the output of the npm pack command
    by using the --json flag as follows: ```terminal npm pack --json | head -n 10
    ``` 3. Host the archive on a web server accessible to your RHDH instance, and
    reference its URL in the dynamic-plugin-config.yaml file as follows: ```yaml plugins:
    - package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz integrity:
    sha512-<hash> ``` 4. Run the following command to package the plugins: ```terminal
    npm pack - pack destination ~/test/dynamic plugins root/ ``` [TIP] ---- To create
    a plugin registry using HTTP server on OpenShift Container Platform, run the following
    commands: ```terminal oc project my rhdh project oc new build httpd - name=plugin
    registry - binary oc start build plugin registry - from dir=dynamic plugins root
    - wait oc new app - image stream=plugin registry ``` ---- 5. Configure your RHDH
    to use plugins from the HTTP server by editing the dynamic-plugin-config.yaml
    file: ```yaml plugins: package: http://plugin registry:8080/backstage plugin myplugin
    1.9.6.tgz ``` #### Creating a JavaScript package with dynamic packages [WARNING]
    ---- The derived dynamic plugin JavaScript packages must not be published to the
    public NPM registry. If you must publish to the NPM registry, use a private registry.
    ---- You have exported a custom dynamic plugin package. For more information,
    see . 1. Navigate to the dist-dynamic directory. 2. Run the following command
    to publish the package to your private NPM registry: ```terminal npm publish -
    registry <npm_registry_url> ``` [TIP] ---- You can add the following to your package.json
    file before running the export command: ```json { "publishConfig": { "registry":
    "<npm_registry_url>" } } ``` If you modify publishConfig after exporting the dynamic
    plugin, re-run the plugin export command to ensure the correct configuration is
    included. ---- ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:40.281136'
    uuid: c5c0a678-d689-4e5f-9394-68af8077a839
  response: 'To create a plugin registry using an HTTP server on OpenShift Container
    Platform, you should run the following commands: `oc project my rhdh project`,
    followed by `oc new build httpd - name=plugin registry - binary`, then `oc start
    build plugin registry - from dir=dynamic plugins root - wait`, and finally `oc
    new app - image stream=plugin registry`.'
  user_input: I'm tryin to figure out how to create a plugin registry for our RHDH
    instance, what are the specific comands I need to run on the OpenShift Container
    Platform to get an HTTP server goin for this purpose?
- context:
  - 'developer hub/cli@latest plugin export - shared package ''!/@backstage/plugin
    notifications/'' - embed package @backstage/plugin notifications backend ``` In
    the previous example: * @backstage/plugin-notifications package is treated as
    a private dependency and is bundled in the dynamic plugin package, despite being
    in the @backstage scope. * @backstage/plugin-notifications-backend package is
    marked as an embedded dependency and is bundled in the dynamic plugin package.
    Front-end plugins:: Front-end plugins can use scalprum for configuration, which
    the CLI can generate automatically during the export process. The generated default
    configuration is logged when running the following command: Example command to
    log the default configuration ```terminal npx @red hat developer hub/cli@latest
    plugin export ``` The following is an example of default scalprum configuration:
    Default scalprum configuration ```json "scalprum": { "name": "<package_name>",
    // The Webpack container name matches the NPM package name, with "@" replaced
    by "." and "/" removed. "exposedModules": { "PluginRoot": "./src/index.ts" //
    The default module name is "PluginRoot" and doesn''t need explicit specification
    in the app-config.yaml file. } } ``` You can add a scalprum section to the package.json
    file. For example: Example scalprum customization ```json "scalprum": { "name":
    "custom-package-name", "exposedModules": { "FooModuleName": "./src/foo.ts", "BarModuleName":
    "./src/bar.ts" // Define multiple modules here, with each exposed as a separate
    entry point in the Webpack container. } } ``` Dynamic plugins might need adjustments
    for Developer Hub needs, such as static JSX for mountpoints or dynamic routes.
    These changes are optional but might be incompatible with static plugins. To include
    static JSX, define an additional export and use it as the dynamic plugin''s importName.
    For example: Example static and dynamic plugin export ```tsx // For a static plugin
    export const EntityTechdocsContent = () => {...} // For a dynamic plugin export
    const DynamicEntityTechdocsContent = { element: EntityTechdocsContent, staticJSXContent:
    ( <TechDocsAddons> <ReportIssue /> </TechDocsAddons> ), }; ``` Use the plugin
    export command from the @red hat developer hub/cli package to export the plugin:
    ```terminal npx @red hat developer hub/cli@latest plugin export ``` Ensure that
    you execute the previous command in the root directory of the plugin''s JavaScript
    package (containing package.json file). The resulting derived package will be
    located in the dist-dynamic subfolder. The exported package name consists of the
    original plugin name with -dynamic appended. [WARNING] ---- The derived dynamic
    plugin JavaScript packages must not be published to the public NPM registry. For
    more appropriate packaging options, see . If you must publish to the NPM registry,
    use a private registry. ---- ## Packaging and publishing custom plugins as dynamic
    plugins After exporting a custom plugin, you can package the derived package into
    one of the following supported formats: Open Container Initiative (OCI) image
    (recommended) TGZ file JavaScript package [IMPORTANT] ---- Exported dynamic plugin
    packages must only be published to private NPM registries. ---- #### Creating
    an OCI image with dynamic packages You have installed podman or docker. You have
    exported a custom dynamic plugin package. For more information, see . 1. Navigate
    to the plugin''s root directory (not the dist-dynamic directory). 2. Run the following
    command to package the plugin into an OCI image: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/example/image:v0.0.1 ``` In the previous
    command, the --tag argument specifies the image name and tag. 3. Run one of the
    following commands to push the image to a registry: ```terminal podman push quay.io/example/image:v0.0.1
    ``` ```terminal docker push quay.io/example/image:v0.0.1 ``` The output of the
    package-dynamic-plugins command provides the plugin''s path for use in the dynamic-plugin-config.yaml
    file. #### Creating a TGZ file with dynamic packages You have exported a custom
    dynamic plugin package. For more information, see . 1. Navigate to the dist-dynamic
    directory. 2. Run the following command to create a tgz archive: ```terminal npm
    pack ``` You can obtain the integrity hash from the output of the npm pack command
    by using the --json flag as follows: ```terminal npm pack --json | head -n 10
    ``` 3. Host the archive on a web server accessible to your RHDH instance, and
    reference its URL in the dynamic-plugin-config.yaml file as follows: ```yaml plugins:
    - package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz integrity:
    sha512-<hash> ``` 4. Run the following command to package the plugins: ```terminal
    npm pack - pack destination ~/test/dynamic plugins root/ ``` [TIP] ---- To create
    a plugin registry using HTTP server on OpenShift Container Platform, run the following
    commands: ```terminal oc project my rhdh project oc new build httpd - name=plugin
    registry - binary oc start build plugin registry - from dir=dynamic plugins root
    - wait oc new app - image stream=plugin registry ``` ---- 5. Configure your RHDH
    to use plugins from the HTTP server by editing the dynamic-plugin-config.yaml
    file: ```yaml plugins: package: http://plugin registry:8080/backstage plugin myplugin
    1.9.6.tgz ``` #### Creating a JavaScript package with dynamic packages [WARNING]
    ---- The derived dynamic plugin JavaScript packages must not be published to the
    public NPM registry. If you must publish to the NPM registry, use a private registry.
    ---- You have exported a custom dynamic plugin package. For more information,
    see . 1. Navigate to the dist-dynamic directory. 2. Run the following command
    to publish the package to your private NPM registry: ```terminal npm publish -
    registry <npm_registry_url> ``` [TIP] ---- You can add the following to your package.json
    file before running the export command: ```json { "publishConfig": { "registry":
    "<npm_registry_url>" } } ``` If you modify publishConfig after exporting the dynamic
    plugin, re-run the plugin export command to ensure the correct configuration is
    included. ---- ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:48.142049'
    uuid: d51b412d-0431-4433-bcd8-238ecc15838f
  response: 'Front-end plugins can use scalprum for configuration. You can add a scalprum
    section to the package.json file. For example: "scalprum": { "name": "custom-package-name",
    "exposedModules": { "FooModuleName": "./src/foo.ts", "BarModuleName": "./src/bar.ts"
    } }'
  user_input: where do i configure scalpum?
- context:
  - 'Installing custom plugins in Red Hat Developer Hub You can install a custom plugins
    in Red Hat Developer Hub without rebuilding the RHDH application. The location
    of the dynamic-plugin-config.yaml file depends on the deployment method. For more
    details, refer to Installing dynamic plugins with the Red Hat Developer Hub Operator
    and Installing dynamic plugins using the Helm chart. Plugins are defined in the
    plugins array within the dynamic-plugin-config.yaml file. Each plugin is represented
    as an object with the following properties: package: The plugin''s package definition,
    which can be an OCI image, a TGZ file, a JavaScript package, or a directory path.
    disabled: A boolean value indicating whether the plugin is enabled or disabled.
    integrity: The integrity hash of the package, required for TGZ file and JavaScript
    packages. pluginConfig: The plugin''s configuration. For backend plugins, this
    is optional; for frontend plugins, it is required. The pluginConfig is a fragment
    of the app config.yaml file, and any added properties are merged with the RHDH
    app config.yaml file. [NOTE] ---- You can also load dynamic plugins from another
    directory, though this is intended for development or testing purposes and is
    not recommended for production, except for plugins included in the RHDH container
    image. For more information, see . ---- #### Loading a plugin packaged as an OCI
    image The custom plugin is packaged as a dynamic plugin in an OCI image. For more
    information about packaging a custom plugin, see . 1. To retrieve plugins from
    an authenticated registry, complete the following steps: 1. Log in to the container
    image registry. ```yaml podman login <registry> ``` 2. Verify the content of the
    auth.json file created after the login. ```yaml cat ${XDG_RUNTIME_DIR: ~/.config}/containers/auth.json
    ``` 3. Create a secret file using the following example: ```yaml oc create secret
    generic _<secret_name>_ --from-file=auth.json=${XDG_RUNTIME_DIR:-~/.config}/containers/auth.json
    1 ``` For an Operator based deployment, replace <secret_name> with dynamic plugins
    registry auth. For a Helm based deployment, replace <secret_name> with <Helm_release_name>_
    dynamic plugins registry auth. 2. Define the plugin with the oci:// prefix in
    the following format in dynamic plugins.yaml file: oci://<image_name>:<tag>!<plugin_name>
    ```yaml plugins: - disabled: false package: oci://quay.io/example/image:v0.0.1!backstage-plugin-myplugin
    ``` 3. To perform an integrity check, use the image digest in place of the tag
    in the dynamic-plugins.yaml file as shown in the following example: ```yaml plugins:
    - disabled: false package: oci://quay.io/example/image@sha256:28036abec4dffc714394e4ee433f16a59493db8017795049c831be41c02eb5dc!backstage-plugin-myplugin
    ``` 4. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a TGZ file The custom plugin is packaged as a dynamic plugin in a
    TGZ file. For more information about packaging a custom plugin, see . 1. Specify
    the archive URL and its integrity hash in the dynamic-plugins.yaml file using
    the following example: ```yaml plugins: - disabled: false package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 2. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a JavaScript package The custom plugin is packaged as a dynamic plugin
    in a JavaScript package. For more information about packaging a custom plugin,
    see . 1. Run the following command to obtain the integrity hash from the NPM registry:
    ```terminal npm view --registry <registry-link> <npm package>@<version> dist.integrity
    ``` 2. Specify the package name, version, and its integrity hash in the dynamic-plugins.yaml
    file as follows: ```yaml plugins: - disabled: false package: @example/backstage-plugin-myplugin@1.0.0
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 3. If you are using a custom NPM registry, create a .npmrc file with the registry
    URL and authentication details: ```text registry=<registry-link> //<registry-link>:_authToken=<auth-token>
    ``` 4. When using OpenShift Container Platform or Kubernetes: * Use the Helm chart
    to add the .npmrc file by creating a secret. For example: Example secret configuration
    ```yaml apiVersion: v1 kind: Secret metadata: name: <release_name> dynamic plugins
    npmrc 1 type: Opaque stringData: .npmrc: | registry=<registry link> //<registry
    link>:_authToken=<auth token> ``` Replace <release_name> with your Helm release
    name. This name is a unique identifier for each chart installation in the Kubernetes
    cluster. * For RHDH Helm chart, name the secret using the following format for
    automatic mounting: <release_name>-dynamic-plugins-npmrc 5. To apply the changes,
    restart the RHDH application. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:34:56.369478'
    uuid: 2c406cc3-a47b-4ce3-af42-4fe029994563
  response: 'You can install a custom plugin in Red Hat Developer Hub without rebuilding
    the RHDH application. Plugins are defined in the plugins array within the dynamic-plugin-config.yaml
    file, where each plugin is an object with the following properties: "package",
    which is the plugin''s package definition (can be an OCI image, a TGZ file, a
    JavaScript package, or a directory path); "disabled", a boolean value indicating
    if the plugin is enabled or disabled; "integrity", the integrity hash of the package,
    which is required for TGZ files and JavaScript packages; and "pluginConfig", the
    plugin''s configuration, which is optional for backend plugins but required for
    frontend plugins and is merged with the RHDH app config.yaml file.'
  user_input: I need to instal some custum plugns for our RHDH setup, but I dont want
    to rebuild the whole app. Can you explain what propertys I need to set in the
    dynamic-plugin-config.yaml file for each plugn, like the package defintion and
    the configurtion options?
- context:
  - 'Installing custom plugins in Red Hat Developer Hub You can install a custom plugins
    in Red Hat Developer Hub without rebuilding the RHDH application. The location
    of the dynamic-plugin-config.yaml file depends on the deployment method. For more
    details, refer to Installing dynamic plugins with the Red Hat Developer Hub Operator
    and Installing dynamic plugins using the Helm chart. Plugins are defined in the
    plugins array within the dynamic-plugin-config.yaml file. Each plugin is represented
    as an object with the following properties: package: The plugin''s package definition,
    which can be an OCI image, a TGZ file, a JavaScript package, or a directory path.
    disabled: A boolean value indicating whether the plugin is enabled or disabled.
    integrity: The integrity hash of the package, required for TGZ file and JavaScript
    packages. pluginConfig: The plugin''s configuration. For backend plugins, this
    is optional; for frontend plugins, it is required. The pluginConfig is a fragment
    of the app config.yaml file, and any added properties are merged with the RHDH
    app config.yaml file. [NOTE] ---- You can also load dynamic plugins from another
    directory, though this is intended for development or testing purposes and is
    not recommended for production, except for plugins included in the RHDH container
    image. For more information, see . ---- #### Loading a plugin packaged as an OCI
    image The custom plugin is packaged as a dynamic plugin in an OCI image. For more
    information about packaging a custom plugin, see . 1. To retrieve plugins from
    an authenticated registry, complete the following steps: 1. Log in to the container
    image registry. ```yaml podman login <registry> ``` 2. Verify the content of the
    auth.json file created after the login. ```yaml cat ${XDG_RUNTIME_DIR: ~/.config}/containers/auth.json
    ``` 3. Create a secret file using the following example: ```yaml oc create secret
    generic _<secret_name>_ --from-file=auth.json=${XDG_RUNTIME_DIR:-~/.config}/containers/auth.json
    1 ``` For an Operator based deployment, replace <secret_name> with dynamic plugins
    registry auth. For a Helm based deployment, replace <secret_name> with <Helm_release_name>_
    dynamic plugins registry auth. 2. Define the plugin with the oci:// prefix in
    the following format in dynamic plugins.yaml file: oci://<image_name>:<tag>!<plugin_name>
    ```yaml plugins: - disabled: false package: oci://quay.io/example/image:v0.0.1!backstage-plugin-myplugin
    ``` 3. To perform an integrity check, use the image digest in place of the tag
    in the dynamic-plugins.yaml file as shown in the following example: ```yaml plugins:
    - disabled: false package: oci://quay.io/example/image@sha256:28036abec4dffc714394e4ee433f16a59493db8017795049c831be41c02eb5dc!backstage-plugin-myplugin
    ``` 4. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a TGZ file The custom plugin is packaged as a dynamic plugin in a
    TGZ file. For more information about packaging a custom plugin, see . 1. Specify
    the archive URL and its integrity hash in the dynamic-plugins.yaml file using
    the following example: ```yaml plugins: - disabled: false package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 2. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a JavaScript package The custom plugin is packaged as a dynamic plugin
    in a JavaScript package. For more information about packaging a custom plugin,
    see . 1. Run the following command to obtain the integrity hash from the NPM registry:
    ```terminal npm view --registry <registry-link> <npm package>@<version> dist.integrity
    ``` 2. Specify the package name, version, and its integrity hash in the dynamic-plugins.yaml
    file as follows: ```yaml plugins: - disabled: false package: @example/backstage-plugin-myplugin@1.0.0
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 3. If you are using a custom NPM registry, create a .npmrc file with the registry
    URL and authentication details: ```text registry=<registry-link> //<registry-link>:_authToken=<auth-token>
    ``` 4. When using OpenShift Container Platform or Kubernetes: * Use the Helm chart
    to add the .npmrc file by creating a secret. For example: Example secret configuration
    ```yaml apiVersion: v1 kind: Secret metadata: name: <release_name> dynamic plugins
    npmrc 1 type: Opaque stringData: .npmrc: | registry=<registry link> //<registry
    link>:_authToken=<auth token> ``` Replace <release_name> with your Helm release
    name. This name is a unique identifier for each chart installation in the Kubernetes
    cluster. * For RHDH Helm chart, name the secret using the following format for
    automatic mounting: <release_name>-dynamic-plugins-npmrc 5. To apply the changes,
    restart the RHDH application. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:35:04.889468'
    uuid: 75ee021a-f4e3-43c9-bae7-6c76ae618d3b
  response: 'To load a custom plugin packaged as an OCI image, you must define it
    in the dynamic-plugins.yaml file. The plugin should be defined with the `oci://`
    prefix in the format `oci://<image_name>:<tag>!<plugin_name>`. An example configuration
    is: `plugins: - disabled: false package: oci://quay.io/example/image:v0.0.1!backstage-plugin-myplugin`.
    To perform an integrity check, you must use the image digest instead of the tag
    in the `package` definition. For instance: `plugins: - disabled: false package:
    oci://quay.io/example/image@sha256:28036abec4dffc714394e4ee433f16a59493db8017795049c831be41c02eb5dc!backstage-plugin-myplugin`.
    After applying these changes to the file, you must restart the RHDH application.'
  user_input: My team needs to standardize how we deploy plugins to Red Hat Developer
    Hub, so can you explain the propper proccedure for loading a custom plugin that
    is packaged as an OCI image, including the yaml format and how to do an integrity
    check?
- context:
  - 'Installing custom plugins in Red Hat Developer Hub You can install a custom plugins
    in Red Hat Developer Hub without rebuilding the RHDH application. The location
    of the dynamic-plugin-config.yaml file depends on the deployment method. For more
    details, refer to Installing dynamic plugins with the Red Hat Developer Hub Operator
    and Installing dynamic plugins using the Helm chart. Plugins are defined in the
    plugins array within the dynamic-plugin-config.yaml file. Each plugin is represented
    as an object with the following properties: package: The plugin''s package definition,
    which can be an OCI image, a TGZ file, a JavaScript package, or a directory path.
    disabled: A boolean value indicating whether the plugin is enabled or disabled.
    integrity: The integrity hash of the package, required for TGZ file and JavaScript
    packages. pluginConfig: The plugin''s configuration. For backend plugins, this
    is optional; for frontend plugins, it is required. The pluginConfig is a fragment
    of the app config.yaml file, and any added properties are merged with the RHDH
    app config.yaml file. [NOTE] ---- You can also load dynamic plugins from another
    directory, though this is intended for development or testing purposes and is
    not recommended for production, except for plugins included in the RHDH container
    image. For more information, see . ---- #### Loading a plugin packaged as an OCI
    image The custom plugin is packaged as a dynamic plugin in an OCI image. For more
    information about packaging a custom plugin, see . 1. To retrieve plugins from
    an authenticated registry, complete the following steps: 1. Log in to the container
    image registry. ```yaml podman login <registry> ``` 2. Verify the content of the
    auth.json file created after the login. ```yaml cat ${XDG_RUNTIME_DIR: ~/.config}/containers/auth.json
    ``` 3. Create a secret file using the following example: ```yaml oc create secret
    generic _<secret_name>_ --from-file=auth.json=${XDG_RUNTIME_DIR:-~/.config}/containers/auth.json
    1 ``` For an Operator based deployment, replace <secret_name> with dynamic plugins
    registry auth. For a Helm based deployment, replace <secret_name> with <Helm_release_name>_
    dynamic plugins registry auth. 2. Define the plugin with the oci:// prefix in
    the following format in dynamic plugins.yaml file: oci://<image_name>:<tag>!<plugin_name>
    ```yaml plugins: - disabled: false package: oci://quay.io/example/image:v0.0.1!backstage-plugin-myplugin
    ``` 3. To perform an integrity check, use the image digest in place of the tag
    in the dynamic-plugins.yaml file as shown in the following example: ```yaml plugins:
    - disabled: false package: oci://quay.io/example/image@sha256:28036abec4dffc714394e4ee433f16a59493db8017795049c831be41c02eb5dc!backstage-plugin-myplugin
    ``` 4. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a TGZ file The custom plugin is packaged as a dynamic plugin in a
    TGZ file. For more information about packaging a custom plugin, see . 1. Specify
    the archive URL and its integrity hash in the dynamic-plugins.yaml file using
    the following example: ```yaml plugins: - disabled: false package: https://example.com/backstage-plugin-myplugin-1.0.0.tgz
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 2. To apply the changes, restart the RHDH application. #### Loading a plugin
    packaged as a JavaScript package The custom plugin is packaged as a dynamic plugin
    in a JavaScript package. For more information about packaging a custom plugin,
    see . 1. Run the following command to obtain the integrity hash from the NPM registry:
    ```terminal npm view --registry <registry-link> <npm package>@<version> dist.integrity
    ``` 2. Specify the package name, version, and its integrity hash in the dynamic-plugins.yaml
    file as follows: ```yaml plugins: - disabled: false package: @example/backstage-plugin-myplugin@1.0.0
    integrity: sha512-9WlbgEdadJNeQxdn1973r5E4kNFvnT9GjLD627GWgrhCaxjCmxqdNW08cj+Bf47mwAtZMt1Ttyo+ZhDRDj9PoA==
    ``` 3. If you are using a custom NPM registry, create a .npmrc file with the registry
    URL and authentication details: ```text registry=<registry-link> //<registry-link>:_authToken=<auth-token>
    ``` 4. When using OpenShift Container Platform or Kubernetes: * Use the Helm chart
    to add the .npmrc file by creating a secret. For example: Example secret configuration
    ```yaml apiVersion: v1 kind: Secret metadata: name: <release_name> dynamic plugins
    npmrc 1 type: Opaque stringData: .npmrc: | registry=<registry link> //<registry
    link>:_authToken=<auth token> ``` Replace <release_name> with your Helm release
    name. This name is a unique identifier for each chart installation in the Kubernetes
    cluster. * For RHDH Helm chart, name the secret using the following format for
    automatic mounting: <release_name>-dynamic-plugins-npmrc 5. To apply the changes,
    restart the RHDH application. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:35:26.904855'
    uuid: baf80d10-26a4-4af7-9455-32af13539476
  response: To use a custom NPM registry, you must create a .npmrc file containing
    the registry URL and authentication details. When using OpenShift Container Platform,
    you add the .npmrc file by creating a secret with the Helm chart. For the RHDH
    Helm chart, the secret must be named in the format `<release_name>-dynamic-plugins-npmrc`
    for it to be automatically mounted.
  user_input: Howw do I cnfigure a custm NPM regstry with authenication for my dynamic
    plgins in RHDH on OpenShift?
- context:
  - "Example of installing a custom plugin in Red Hat Developer Hub This example demonstrates\
    \ how to package and install dynamic plugins using the Backstage Entity Feedback\
    \ community plugin that is not included in Red Hat Developer Hub pre-installed\
    \ dynamic plugins. You need to ensure that your custom plugin is built with a\
    \ compatible version of Backstage. In Developer Hub, click Settings. Your custom\
    \ plugin must be compatible with the Backstage Version (or the closest previous\
    \ version) that is displayed in the Metadata section of Red Hat Developer Hub.\
    \ For example, if you view the history of the backstage.json file for the Entity\
    \ Feedback plugin, the 1fc87de commit is closest previous version to Backstage\
    \ version of 1.39.1. backstage.json file history in Github ![custom limitations]\
    \ Your local environment meets the following requirements: Node.js: Version 22.x\
    \ Yarn: Version 4.x git CLI jq CLI: Command line JSON processor OpenShift CLI\
    \ (oc): The client for interacting with your OpenShift cluster. Container runtime:\
    \ Either podman or docker is required for packaging the plugin into an OCI image\
    \ and logging into registries. Container registry access: Access to an OCI compliant\
    \ container registry (such as the internal OpenShift registry or a public registry\
    \ like Quay.io). 1. Clone the source code for the Entity Feedback plugin, as follows:\
    \ ```terminal git clone https://github.com/backstage/community plugins.git cd\
    \ community plugins ``` 2. Prepare your environment to build the plugin by enabling\
    \ Yarn for your Node.js installation, as follows: ```terminal corepack enable\
    \ yarn ``` 3. Install the dependencies, compile the code, and build the plugins,\
    \ as follows: ```terminal cd workspaces/entity feedback yarn install yarn tsc\
    \ yarn build:all ``` [NOTE] ---- After this step, with upstream Backstage, you\
    \ publish the built plugins to a NPM or NPM-compatible registry. In this example,\
    \ as you are building this plugin to support it being loaded dynamically by Red\
    \ Hat Developer Hub, you can skip the npm publish step that publishes the plugin\
    \ to a NPM registry. Instead, you can package the plugin for dynamic loading and\
    \ publish it as a container image on Quay.io or your preferred container registry.\
    \ ---- 4. Prepare the Entity Feedback frontend plugin by using the Red Hat Developer\
    \ Hub CLI. The following command uses the plugin files in the dist folder that\
    \ was generated by the yarn build:all command, and creates a new dist-scalprum\
    \ folder that contains the necessary configuration and source files to enable\
    \ dynamic loading: ```terminal cd plugins/entity feedback npx @red hat developer\
    \ hub/cli@latest plugin export ``` When this command packages a frontend plugin,\
    \ it uses a default Scalprum configuration if one is not found. The Scalprum configuration\
    \ is used to specify the plugin entry point and exports, and then to build a dist-scalprum\
    \ folder that contains the dynamic plugin. The default Scalprum configuration\
    \ is shown below, however a scalprum key can be added to the package.json file\
    \ used by your plugin to set custom values, if necessary: ```json { \"name\":\
    \ \"backstage community.plugin entity feedback\", \"exposedModules\": { \"PluginRoot\"\
    : \"./src/index.ts\" } } ``` The following plugin-manifest.json file, which Red\
    \ Hat Developer Hub uses to load the plugin, is located in the dist-dynamic/dist-scalprum\
    \ folder: ```json { \"name\": \"backstage community.plugin entity feedback\",\
    \ \"version\": \"0.6.0\", \"extensions\": [], \"registrationMethod\": \"callback\"\
    , \"baseURL\": \"auto\", \"loadScripts\": [ \"backstage community.plugin entity\
    \ feedback.fd691533c03cb52c30ac.js\" ], \"buildHash\": \"fd691533c03cb52c30acbb5a80197c9d\"\
    \ } ``` 5. Package the plugin into a container image and publish it to Quay.io\
    \ or your preferred container registry: ```terminal export QUAY_USER=replace-with-your-username\
    \ export PLUGIN_NAME=entity-feedback-plugin export VERSION=$(cat package.json\
    \ | jq .version -r) npx @red hat developer hub/cli@latest plugin package \\ tag\
    \ quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman login quay.io podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` 6. Repeat the same steps for the backend plugin. Scalprum is not required\
    \ for backend plugins, and a dist-dynamic folder is generated instead of a dist-scalprum\
    \ folder: ```terminal cd ../entity feedback backend/ npx @red hat developer hub/cli@latest\
    \ plugin export export QUAY_USER=replace-with-your-username export PLUGIN_NAME=entity-feedback-plugin-backend\
    \ export VERSION=$(cat package.json | jq .version -r) npx @red hat developer hub/cli@latest\
    \ plugin package \\ tag quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` Those commands result in two container images being published to your container\
    \ registry. Container images published to Quay.io ![custom container images] ###\
    \ Adding a custom dynamic plugin to Red Hat Developer Hub 1. To add your custom\
    \ dynamic plugins to Red Hat Developer Hub. you must update the dynamic-plugins.yaml\
    \ file by using the following configuration that is generated from the npx @red-hat-developer-hub/cli@latest\
    \ plugin package command: ```yaml plugins: package: oci://quay.io/_<user_name>_/entity\
    \ feedback plugin:0.5.0!backstage community plugin entity feedback disabled: false\
    \ package: oci://quay.io/_<user_name>_/entity feedback plugin backend:0.6.0!backstage\
    \ community plugin entity feedback backend disabled: false ``` [NOTE] ---- Ensure\
    \ that your container images are publicly accessible, or that you have configured\
    \ a pull secret in your environment. A pull secret provides Red Hat Developer\
    \ Hub with credentials to authenticate pulling your plugin container images from\
    \ a container registry. ---- ### Displaying the frontend plugin 1. You need to\
    \ update the pluginConfig section of your dynamic-plugins.yaml file to specify\
    \ how the Entity Feedback should be added to the Red Hat Developer Hub UI. dynamic-plugins.yaml\
    \ file fragment ```yaml package: oci://quay.io/_<user_name>_/entity feedback plugin:0.5.0!backstage\
    \ community plugin entity feedback disabled: false pluginConfig: dynamicPlugins:\
    \ frontend: backstage community.plugin entity feedback: entityTabs: mountPoint:\
    \ entity.page.feedback path: /feedback title: Feedback mountPoints: config: layout:\
    \ gridColumn: 1 / 1 importName: StarredRatingButtons mountPoint: entity.page.feedback/cards\
    \ config: layout: gridColumn: 1 / 1 importName: EntityFeedbackResponseContent\
    \ mountPoint: entity.page.feedback/cards config: layout: gridColumnEnd: lg: span\
    \ 6 md: span 6 xs: span 6 importName: StarredRatingButtons mountPoint: entity.page.overview/cards\
    \ ``` where: backstage-community.plugin-entity-feedback:entityTabs:: Enter the\
    \ entityTabs array to define a new tab, named \u201CFeedback\u201D on the Entity\
    \ Overview screen in Red Hat Developer Hub. frontend:mountPoints:: This array\
    \ defines the following configurations to mount React components exposed by the\
    \ plugin: * The StarredRatingButtons component is added to the new Feedback tab\
    \ defined in entityTabs. * Similar to the StarredRatingButtons, the EntityFeedbackResponseContent\
    \ is mounted on the Feedback tab. * The StarredRatingButtons is added to the default\
    \ Overview tab for each entity. 2. To complete installing the Entity Feedback\
    \ plugins, you must redeploy your Red Hat Developer Hub instance. When your new\
    \ instance of Red Hat Developer Hub has started, you can check that your plugins\
    \ are installed and enabled by visiting the Administration"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:35:35.178119'
    uuid: d1f5006d-ba81-4bfe-9058-ae56d2b38656
  response: Before building, you should check the history of the backstage.json file
    for the plugin in Github to find the commit that is the closest previous version
    to your Backstage version. For example, the 1fc87de commit is the closest previous
    version to Backstage version 1.39.1. The first step to get the code is to clone
    the source for the Entity Feedback plugin by running the command `git clone https://github.com/backstage/community
    plugins.git`.
  user_input: So for this custom plugin thing, what is the first things I need to
    do with Github, like how do I get the code from there and what file history you
    said I should be looking at in Github before I start to build it?
- context:
  - "Example of installing a custom plugin in Red Hat Developer Hub This example demonstrates\
    \ how to package and install dynamic plugins using the Backstage Entity Feedback\
    \ community plugin that is not included in Red Hat Developer Hub pre-installed\
    \ dynamic plugins. You need to ensure that your custom plugin is built with a\
    \ compatible version of Backstage. In Developer Hub, click Settings. Your custom\
    \ plugin must be compatible with the Backstage Version (or the closest previous\
    \ version) that is displayed in the Metadata section of Red Hat Developer Hub.\
    \ For example, if you view the history of the backstage.json file for the Entity\
    \ Feedback plugin, the 1fc87de commit is closest previous version to Backstage\
    \ version of 1.39.1. backstage.json file history in Github ![custom limitations]\
    \ Your local environment meets the following requirements: Node.js: Version 22.x\
    \ Yarn: Version 4.x git CLI jq CLI: Command line JSON processor OpenShift CLI\
    \ (oc): The client for interacting with your OpenShift cluster. Container runtime:\
    \ Either podman or docker is required for packaging the plugin into an OCI image\
    \ and logging into registries. Container registry access: Access to an OCI compliant\
    \ container registry (such as the internal OpenShift registry or a public registry\
    \ like Quay.io). 1. Clone the source code for the Entity Feedback plugin, as follows:\
    \ ```terminal git clone https://github.com/backstage/community plugins.git cd\
    \ community plugins ``` 2. Prepare your environment to build the plugin by enabling\
    \ Yarn for your Node.js installation, as follows: ```terminal corepack enable\
    \ yarn ``` 3. Install the dependencies, compile the code, and build the plugins,\
    \ as follows: ```terminal cd workspaces/entity feedback yarn install yarn tsc\
    \ yarn build:all ``` [NOTE] ---- After this step, with upstream Backstage, you\
    \ publish the built plugins to a NPM or NPM-compatible registry. In this example,\
    \ as you are building this plugin to support it being loaded dynamically by Red\
    \ Hat Developer Hub, you can skip the npm publish step that publishes the plugin\
    \ to a NPM registry. Instead, you can package the plugin for dynamic loading and\
    \ publish it as a container image on Quay.io or your preferred container registry.\
    \ ---- 4. Prepare the Entity Feedback frontend plugin by using the Red Hat Developer\
    \ Hub CLI. The following command uses the plugin files in the dist folder that\
    \ was generated by the yarn build:all command, and creates a new dist-scalprum\
    \ folder that contains the necessary configuration and source files to enable\
    \ dynamic loading: ```terminal cd plugins/entity feedback npx @red hat developer\
    \ hub/cli@latest plugin export ``` When this command packages a frontend plugin,\
    \ it uses a default Scalprum configuration if one is not found. The Scalprum configuration\
    \ is used to specify the plugin entry point and exports, and then to build a dist-scalprum\
    \ folder that contains the dynamic plugin. The default Scalprum configuration\
    \ is shown below, however a scalprum key can be added to the package.json file\
    \ used by your plugin to set custom values, if necessary: ```json { \"name\":\
    \ \"backstage community.plugin entity feedback\", \"exposedModules\": { \"PluginRoot\"\
    : \"./src/index.ts\" } } ``` The following plugin-manifest.json file, which Red\
    \ Hat Developer Hub uses to load the plugin, is located in the dist-dynamic/dist-scalprum\
    \ folder: ```json { \"name\": \"backstage community.plugin entity feedback\",\
    \ \"version\": \"0.6.0\", \"extensions\": [], \"registrationMethod\": \"callback\"\
    , \"baseURL\": \"auto\", \"loadScripts\": [ \"backstage community.plugin entity\
    \ feedback.fd691533c03cb52c30ac.js\" ], \"buildHash\": \"fd691533c03cb52c30acbb5a80197c9d\"\
    \ } ``` 5. Package the plugin into a container image and publish it to Quay.io\
    \ or your preferred container registry: ```terminal export QUAY_USER=replace-with-your-username\
    \ export PLUGIN_NAME=entity-feedback-plugin export VERSION=$(cat package.json\
    \ | jq .version -r) npx @red hat developer hub/cli@latest plugin package \\ tag\
    \ quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman login quay.io podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` 6. Repeat the same steps for the backend plugin. Scalprum is not required\
    \ for backend plugins, and a dist-dynamic folder is generated instead of a dist-scalprum\
    \ folder: ```terminal cd ../entity feedback backend/ npx @red hat developer hub/cli@latest\
    \ plugin export export QUAY_USER=replace-with-your-username export PLUGIN_NAME=entity-feedback-plugin-backend\
    \ export VERSION=$(cat package.json | jq .version -r) npx @red hat developer hub/cli@latest\
    \ plugin package \\ tag quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` Those commands result in two container images being published to your container\
    \ registry. Container images published to Quay.io ![custom container images] ###\
    \ Adding a custom dynamic plugin to Red Hat Developer Hub 1. To add your custom\
    \ dynamic plugins to Red Hat Developer Hub. you must update the dynamic-plugins.yaml\
    \ file by using the following configuration that is generated from the npx @red-hat-developer-hub/cli@latest\
    \ plugin package command: ```yaml plugins: package: oci://quay.io/_<user_name>_/entity\
    \ feedback plugin:0.5.0!backstage community plugin entity feedback disabled: false\
    \ package: oci://quay.io/_<user_name>_/entity feedback plugin backend:0.6.0!backstage\
    \ community plugin entity feedback backend disabled: false ``` [NOTE] ---- Ensure\
    \ that your container images are publicly accessible, or that you have configured\
    \ a pull secret in your environment. A pull secret provides Red Hat Developer\
    \ Hub with credentials to authenticate pulling your plugin container images from\
    \ a container registry. ---- ### Displaying the frontend plugin 1. You need to\
    \ update the pluginConfig section of your dynamic-plugins.yaml file to specify\
    \ how the Entity Feedback should be added to the Red Hat Developer Hub UI. dynamic-plugins.yaml\
    \ file fragment ```yaml package: oci://quay.io/_<user_name>_/entity feedback plugin:0.5.0!backstage\
    \ community plugin entity feedback disabled: false pluginConfig: dynamicPlugins:\
    \ frontend: backstage community.plugin entity feedback: entityTabs: mountPoint:\
    \ entity.page.feedback path: /feedback title: Feedback mountPoints: config: layout:\
    \ gridColumn: 1 / 1 importName: StarredRatingButtons mountPoint: entity.page.feedback/cards\
    \ config: layout: gridColumn: 1 / 1 importName: EntityFeedbackResponseContent\
    \ mountPoint: entity.page.feedback/cards config: layout: gridColumnEnd: lg: span\
    \ 6 md: span 6 xs: span 6 importName: StarredRatingButtons mountPoint: entity.page.overview/cards\
    \ ``` where: backstage-community.plugin-entity-feedback:entityTabs:: Enter the\
    \ entityTabs array to define a new tab, named \u201CFeedback\u201D on the Entity\
    \ Overview screen in Red Hat Developer Hub. frontend:mountPoints:: This array\
    \ defines the following configurations to mount React components exposed by the\
    \ plugin: * The StarredRatingButtons component is added to the new Feedback tab\
    \ defined in entityTabs. * Similar to the StarredRatingButtons, the EntityFeedbackResponseContent\
    \ is mounted on the Feedback tab. * The StarredRatingButtons is added to the default\
    \ Overview tab for each entity. 2. To complete installing the Entity Feedback\
    \ plugins, you must redeploy your Red Hat Developer Hub instance. When your new\
    \ instance of Red Hat Developer Hub has started, you can check that your plugins\
    \ are installed and enabled by visiting the Administration"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:35:42.951116'
    uuid: 2bf78e49-5f25-4f19-a477-795e62bc2c5f
  response: You must ensure that your custom plugin is built with a compatible version
    of Backstage. The custom plugin must be compatible with the Backstage Version
    (or the closest previous version) that is displayed in the Metadata section of
    Red Hat Developer Hub. For example, the 1fc87de commit for the Entity Feedback
    plugin is the closest previous version to Backstage version 1.39.1.
  user_input: how backstage version affect custom plugin?
- context:
  - "Example of installing a custom plugin in Red Hat Developer Hub This example demonstrates\
    \ how to package and install dynamic plugins using the Backstage Entity Feedback\
    \ community plugin that is not included in Red Hat Developer Hub pre-installed\
    \ dynamic plugins. You need to ensure that your custom plugin is built with a\
    \ compatible version of Backstage. In Developer Hub, click Settings. Your custom\
    \ plugin must be compatible with the Backstage Version (or the closest previous\
    \ version) that is displayed in the Metadata section of Red Hat Developer Hub.\
    \ For example, if you view the history of the backstage.json file for the Entity\
    \ Feedback plugin, the 1fc87de commit is closest previous version to Backstage\
    \ version of 1.39.1. backstage.json file history in Github ![custom limitations]\
    \ Your local environment meets the following requirements: Node.js: Version 22.x\
    \ Yarn: Version 4.x git CLI jq CLI: Command line JSON processor OpenShift CLI\
    \ (oc): The client for interacting with your OpenShift cluster. Container runtime:\
    \ Either podman or docker is required for packaging the plugin into an OCI image\
    \ and logging into registries. Container registry access: Access to an OCI compliant\
    \ container registry (such as the internal OpenShift registry or a public registry\
    \ like Quay.io). 1. Clone the source code for the Entity Feedback plugin, as follows:\
    \ ```terminal git clone https://github.com/backstage/community plugins.git cd\
    \ community plugins ``` 2. Prepare your environment to build the plugin by enabling\
    \ Yarn for your Node.js installation, as follows: ```terminal corepack enable\
    \ yarn ``` 3. Install the dependencies, compile the code, and build the plugins,\
    \ as follows: ```terminal cd workspaces/entity feedback yarn install yarn tsc\
    \ yarn build:all ``` [NOTE] ---- After this step, with upstream Backstage, you\
    \ publish the built plugins to a NPM or NPM-compatible registry. In this example,\
    \ as you are building this plugin to support it being loaded dynamically by Red\
    \ Hat Developer Hub, you can skip the npm publish step that publishes the plugin\
    \ to a NPM registry. Instead, you can package the plugin for dynamic loading and\
    \ publish it as a container image on Quay.io or your preferred container registry.\
    \ ---- 4. Prepare the Entity Feedback frontend plugin by using the Red Hat Developer\
    \ Hub CLI. The following command uses the plugin files in the dist folder that\
    \ was generated by the yarn build:all command, and creates a new dist-scalprum\
    \ folder that contains the necessary configuration and source files to enable\
    \ dynamic loading: ```terminal cd plugins/entity feedback npx @red hat developer\
    \ hub/cli@latest plugin export ``` When this command packages a frontend plugin,\
    \ it uses a default Scalprum configuration if one is not found. The Scalprum configuration\
    \ is used to specify the plugin entry point and exports, and then to build a dist-scalprum\
    \ folder that contains the dynamic plugin. The default Scalprum configuration\
    \ is shown below, however a scalprum key can be added to the package.json file\
    \ used by your plugin to set custom values, if necessary: ```json { \"name\":\
    \ \"backstage community.plugin entity feedback\", \"exposedModules\": { \"PluginRoot\"\
    : \"./src/index.ts\" } } ``` The following plugin-manifest.json file, which Red\
    \ Hat Developer Hub uses to load the plugin, is located in the dist-dynamic/dist-scalprum\
    \ folder: ```json { \"name\": \"backstage community.plugin entity feedback\",\
    \ \"version\": \"0.6.0\", \"extensions\": [], \"registrationMethod\": \"callback\"\
    , \"baseURL\": \"auto\", \"loadScripts\": [ \"backstage community.plugin entity\
    \ feedback.fd691533c03cb52c30ac.js\" ], \"buildHash\": \"fd691533c03cb52c30acbb5a80197c9d\"\
    \ } ``` 5. Package the plugin into a container image and publish it to Quay.io\
    \ or your preferred container registry: ```terminal export QUAY_USER=replace-with-your-username\
    \ export PLUGIN_NAME=entity-feedback-plugin export VERSION=$(cat package.json\
    \ | jq .version -r) npx @red hat developer hub/cli@latest plugin package \\ tag\
    \ quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman login quay.io podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` 6. Repeat the same steps for the backend plugin. Scalprum is not required\
    \ for backend plugins, and a dist-dynamic folder is generated instead of a dist-scalprum\
    \ folder: ```terminal cd ../entity feedback backend/ npx @red hat developer hub/cli@latest\
    \ plugin export export QUAY_USER=replace-with-your-username export PLUGIN_NAME=entity-feedback-plugin-backend\
    \ export VERSION=$(cat package.json | jq .version -r) npx @red hat developer hub/cli@latest\
    \ plugin package \\ tag quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION podman push quay.io/$QUAY_USER/$PLUGIN_NAME:$VERSION\
    \ ``` Those commands result in two container images being published to your container\
    \ registry. Container images published to Quay.io ![custom container images] ###\
    \ Adding a custom dynamic plugin to Red Hat Developer Hub 1. To add your custom\
    \ dynamic plugins to Red Hat Developer Hub. you must update the dynamic-plugins.yaml\
    \ file by using the following configuration that is generated from the npx @red-hat-developer-hub/cli@latest\
    \ plugin package command: ```yaml plugins: package: oci://quay.io/_<user_name>_/entity\
    \ feedback plugin:0.5.0!backstage community plugin entity feedback disabled: false\
    \ package: oci://quay.io/_<user_name>_/entity feedback plugin backend:0.6.0!backstage\
    \ community plugin entity feedback backend disabled: false ``` [NOTE] ---- Ensure\
    \ that your container images are publicly accessible, or that you have configured\
    \ a pull secret in your environment. A pull secret provides Red Hat Developer\
    \ Hub with credentials to authenticate pulling your plugin container images from\
    \ a container registry. ---- ### Displaying the frontend plugin 1. You need to\
    \ update the pluginConfig section of your dynamic-plugins.yaml file to specify\
    \ how the Entity Feedback should be added to the Red Hat Developer Hub UI. dynamic-plugins.yaml\
    \ file fragment ```yaml package: oci://quay.io/_<user_name>_/entity feedback plugin:0.5.0!backstage\
    \ community plugin entity feedback disabled: false pluginConfig: dynamicPlugins:\
    \ frontend: backstage community.plugin entity feedback: entityTabs: mountPoint:\
    \ entity.page.feedback path: /feedback title: Feedback mountPoints: config: layout:\
    \ gridColumn: 1 / 1 importName: StarredRatingButtons mountPoint: entity.page.feedback/cards\
    \ config: layout: gridColumn: 1 / 1 importName: EntityFeedbackResponseContent\
    \ mountPoint: entity.page.feedback/cards config: layout: gridColumnEnd: lg: span\
    \ 6 md: span 6 xs: span 6 importName: StarredRatingButtons mountPoint: entity.page.overview/cards\
    \ ``` where: backstage-community.plugin-entity-feedback:entityTabs:: Enter the\
    \ entityTabs array to define a new tab, named \u201CFeedback\u201D on the Entity\
    \ Overview screen in Red Hat Developer Hub. frontend:mountPoints:: This array\
    \ defines the following configurations to mount React components exposed by the\
    \ plugin: * The StarredRatingButtons component is added to the new Feedback tab\
    \ defined in entityTabs. * Similar to the StarredRatingButtons, the EntityFeedbackResponseContent\
    \ is mounted on the Feedback tab. * The StarredRatingButtons is added to the default\
    \ Overview tab for each entity. 2. To complete installing the Entity Feedback\
    \ plugins, you must redeploy your Red Hat Developer Hub instance. When your new\
    \ instance of Red Hat Developer Hub has started, you can check that your plugins\
    \ are installed and enabled by visiting the Administration"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:35:50.495271'
    uuid: e9b448fe-57f6-4d37-a0fd-ca18e49db173
  response: To build a custom plugin for Red Hat Developer Hub, your local environment
    must have Node.js version 22.x. You also need to prepare your environment to build
    the plugin by enabling Yarn for your Node.js installation using the command `corepack
    enable yarn`.
  user_input: What are the local environment requirements for Node.js when building
    a custom plugin for Red Hat Developer Hub?
- context:
  - "> Extensions screen and searching for \u201Centity\u201D on the Installed tab.\
    \ ![custom extensions] When you click Catalog, you should see the new Feedback\
    \ tab, and the StarredRatingButtons displayed, as follows: ![custom entity view]\
    \ Selecting a low star rating prompts the user to provide feedback, as follows:\
    \ ![custom feedback overlay] [NOTE] ---- The user provided feedback is not saved\
    \ if you are logged in as the Guest user. ---- # Using the Dynamic Plugin Factory\
    \ to convert plugins into dynamic plugins You can automate the conversion and\
    \ packaging of standard Backstage plugins into RHDH dynamic plugins by using the\
    \ RHDH Dynamic Plugin Factory tool. [IMPORTANT] ---- The Dynamic Plugin Factory\
    \ is maintained as an open-source project by Red Hat, but is not supported or\
    \ subject to any service level agreement (SLA). ---- The core function of the\
    \ Dynamic Plugin Factory tool is to streamline the dynamic plugin build process,\
    \ offering the following capabilities: Source Code Handling:: Manages cloning,\
    \ checking out, and applying custom patches to the plugin source. Dependency Management::\
    \ Handles yarn installation and TypeScript compilation. Packaging:: Uses the RHDH\
    \ CLI to build, export, and package the final dynamic plugin. Deployment:: Offers\
    \ an option to push the resulting container image to registries like Quay or OpenShift.\
    \ The Dynamic Plugin Factory tool provides a simplified, reproducible method for\
    \ developers and platform engineers to create and test dynamic plugins using a\
    \ pre-configured dynamic plugin factory container and documentation, significantly\
    \ easing migration and testing. For more information, see RHDH Dynamic Plugin\
    \ Factory. # Enabling plugins added in the RHDH container image In the RHDH container\
    \ image, a set of dynamic plugins is preloaded to enhance functionality. However,\
    \ due to mandatory configuration requirements, most of the plugins are disabled.\
    \ You can enable and configure the plugins in the RHDH container image, including\
    \ how to manage the default configuration, set necessary environment variables,\
    \ and ensure the proper functionality of the plugins within your application.\
    \ You have access to the dynamic plugins.default.yaml file, which lists all preloaded\
    \ plugins and their default configuration. You have deployed the RHDH application,\
    \ and have access to the logs of the install dynamic plugins init container. You\
    \ have the necessary permissions to modify plugin configurations and access the\
    \ application environment. You have identified and set the required environment\
    \ variables referenced by the plugin's default configuration. These environment\
    \ variables must be defined in the Helm Chart or Operator configuration. 1. Start\
    \ your RHDH application and access the logs of the install-dynamic-plugins init\
    \ container within the RHDH pod. 2. Identify the Red Hat supported plugins that\
    \ are disabled by default. 3. Copy the package configuration from the dynamic-plugins.default.yaml\
    \ file. 4. Open the plugin configuration file and locate the plugin entry you\
    \ want to enable. The location of the plugin configuration file varies based on\
    \ the deployment method. For more details, see Installing and viewing plugins\
    \ in Red Hat Developer Hub. 5. Modify the disabled field to false and add the\
    \ package name as follows: ```yaml plugins: disabled: false package: ./dynamic\
    \ plugins/dist/backstage plugin catalog backend module github dynamic ``` For\
    \ more information about how to configure dynamic plugins in Developer Hub, see\
    \ Configuring dynamic plugins. 1. Restart the RHDH application and verify that\
    \ the plugin is successfully activated and configured. 2. Verify the application\
    \ logs for confirmation and ensure the plugin is functioning as expected. # Extensions\
    \ in Red Hat Developer Hub [IMPORTANT] ---- These features are for Technology\
    \ Preview only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ ---- Red Hat Developer Hub (RHDH) includes the Extensions feature which is preinstalled\
    \ and enabled by default. Extensions provides users with a centralized interface\
    \ to browse and manage available plugins You can use Extensions to discover plugins\
    \ that extend RHDH functionality, streamline development workflows, and improve\
    \ the developer experience. ## Viewing available plugins You can view plugins\
    \ available for your Red Hat Developer Hub application on the Extensions page.\
    \ 1. Open your Developer Hub application and click Administration > Extensions.\
    \ 2. Go to the Catalog tab to view a list of available plugins and related information.\
    \ ![Extensions Catalog] ## Viewing installed plugins Using the Dynamic Plugins\
    \ Info front-end plugin, you can view plugins that are currently installed in\
    \ your Red Hat Developer Hub application. This plugin is enabled by default. 1.\
    \ Open your Developer Hub application and click Administration > Extensions. 2.\
    \ Go to the Installed tab to view a list of installed plugins and related information.\
    \ ## Search and filter the plugins ### Search by plugin name You can use the search\
    \ bar in the header to filter the Extensions plugin cards by name. For example,\
    \ if you type \u201CA\u201D into the search bar, Extensions shows only the plugins\
    \ that contain the letter \u201CA\u201D in the Name field. ![Extensions catalog\
    \ with a Dynatrace search] Optionally, you can use the search bar in conjunction\
    \ with a filter to filter only plugins of the selected filter by name. For example,\
    \ you can apply the Category filter and then type a character into the search\
    \ bar to view only Openshift plugins that contain the typed character in the name.\
    \ The following filters are available: Category Author Support type ## Removing\
    \ Extensions The Extensions feature plugins are preinstalled in Red Hat Developer\
    \ Hub (RHDH) and enabled by default. If you want to remove Extensions from your\
    \ RHDH instance, you can disable the relevant plugins. 1. To disable the the Extensions\
    \ feature plugins, edit your dynamic-plugins.yaml with the following content.\
    \ dynamic-plugins.yaml fragment ```yaml plugins: package: ./dynamic plugins/dist/red\
    \ hat developer hub backstage plugin marketplace disabled: true package: ./dynamic\
    \ plugins/dist/red hat developer hub backstage plugin catalog backend module marketplace\
    \ dynamic disabled: true package: ./dynamic plugins/dist/red hat developer hub\
    \ backstage plugin marketplace backend dynamic disabled: true ```"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:36:00.570591'
    uuid: ee4366dd-b895-4cc4-8337-a06fbfc3b6e7
  response: 'To remove the Extensions feature, which is preinstalled and enabled by
    default in Red Hat Developer Hub (RHDH), you must disable the relevant plugins.
    This is accomplished by editing your dynamic-plugins.yaml file to include the
    following content, which disables three specific packages: `plugins: package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace disabled:
    true package: ./dynamic plugins/dist/red hat developer hub backstage plugin catalog
    backend module marketplace dynamic disabled: true package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin marketplace backend dynamic disabled: true`.'
  user_input: As a Platform Engineer responsible for our Red Hat Developer Hub instance,
    what is the specific procedure for removing the pre-installed and default-enabled
    Extensions feature, and which plugins must be configured to achieve this?
- context:
  - "> Extensions screen and searching for \u201Centity\u201D on the Installed tab.\
    \ ![custom extensions] When you click Catalog, you should see the new Feedback\
    \ tab, and the StarredRatingButtons displayed, as follows: ![custom entity view]\
    \ Selecting a low star rating prompts the user to provide feedback, as follows:\
    \ ![custom feedback overlay] [NOTE] ---- The user provided feedback is not saved\
    \ if you are logged in as the Guest user. ---- # Using the Dynamic Plugin Factory\
    \ to convert plugins into dynamic plugins You can automate the conversion and\
    \ packaging of standard Backstage plugins into RHDH dynamic plugins by using the\
    \ RHDH Dynamic Plugin Factory tool. [IMPORTANT] ---- The Dynamic Plugin Factory\
    \ is maintained as an open-source project by Red Hat, but is not supported or\
    \ subject to any service level agreement (SLA). ---- The core function of the\
    \ Dynamic Plugin Factory tool is to streamline the dynamic plugin build process,\
    \ offering the following capabilities: Source Code Handling:: Manages cloning,\
    \ checking out, and applying custom patches to the plugin source. Dependency Management::\
    \ Handles yarn installation and TypeScript compilation. Packaging:: Uses the RHDH\
    \ CLI to build, export, and package the final dynamic plugin. Deployment:: Offers\
    \ an option to push the resulting container image to registries like Quay or OpenShift.\
    \ The Dynamic Plugin Factory tool provides a simplified, reproducible method for\
    \ developers and platform engineers to create and test dynamic plugins using a\
    \ pre-configured dynamic plugin factory container and documentation, significantly\
    \ easing migration and testing. For more information, see RHDH Dynamic Plugin\
    \ Factory. # Enabling plugins added in the RHDH container image In the RHDH container\
    \ image, a set of dynamic plugins is preloaded to enhance functionality. However,\
    \ due to mandatory configuration requirements, most of the plugins are disabled.\
    \ You can enable and configure the plugins in the RHDH container image, including\
    \ how to manage the default configuration, set necessary environment variables,\
    \ and ensure the proper functionality of the plugins within your application.\
    \ You have access to the dynamic plugins.default.yaml file, which lists all preloaded\
    \ plugins and their default configuration. You have deployed the RHDH application,\
    \ and have access to the logs of the install dynamic plugins init container. You\
    \ have the necessary permissions to modify plugin configurations and access the\
    \ application environment. You have identified and set the required environment\
    \ variables referenced by the plugin's default configuration. These environment\
    \ variables must be defined in the Helm Chart or Operator configuration. 1. Start\
    \ your RHDH application and access the logs of the install-dynamic-plugins init\
    \ container within the RHDH pod. 2. Identify the Red Hat supported plugins that\
    \ are disabled by default. 3. Copy the package configuration from the dynamic-plugins.default.yaml\
    \ file. 4. Open the plugin configuration file and locate the plugin entry you\
    \ want to enable. The location of the plugin configuration file varies based on\
    \ the deployment method. For more details, see Installing and viewing plugins\
    \ in Red Hat Developer Hub. 5. Modify the disabled field to false and add the\
    \ package name as follows: ```yaml plugins: disabled: false package: ./dynamic\
    \ plugins/dist/backstage plugin catalog backend module github dynamic ``` For\
    \ more information about how to configure dynamic plugins in Developer Hub, see\
    \ Configuring dynamic plugins. 1. Restart the RHDH application and verify that\
    \ the plugin is successfully activated and configured. 2. Verify the application\
    \ logs for confirmation and ensure the plugin is functioning as expected. # Extensions\
    \ in Red Hat Developer Hub [IMPORTANT] ---- These features are for Technology\
    \ Preview only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ ---- Red Hat Developer Hub (RHDH) includes the Extensions feature which is preinstalled\
    \ and enabled by default. Extensions provides users with a centralized interface\
    \ to browse and manage available plugins You can use Extensions to discover plugins\
    \ that extend RHDH functionality, streamline development workflows, and improve\
    \ the developer experience. ## Viewing available plugins You can view plugins\
    \ available for your Red Hat Developer Hub application on the Extensions page.\
    \ 1. Open your Developer Hub application and click Administration > Extensions.\
    \ 2. Go to the Catalog tab to view a list of available plugins and related information.\
    \ ![Extensions Catalog] ## Viewing installed plugins Using the Dynamic Plugins\
    \ Info front-end plugin, you can view plugins that are currently installed in\
    \ your Red Hat Developer Hub application. This plugin is enabled by default. 1.\
    \ Open your Developer Hub application and click Administration > Extensions. 2.\
    \ Go to the Installed tab to view a list of installed plugins and related information.\
    \ ## Search and filter the plugins ### Search by plugin name You can use the search\
    \ bar in the header to filter the Extensions plugin cards by name. For example,\
    \ if you type \u201CA\u201D into the search bar, Extensions shows only the plugins\
    \ that contain the letter \u201CA\u201D in the Name field. ![Extensions catalog\
    \ with a Dynatrace search] Optionally, you can use the search bar in conjunction\
    \ with a filter to filter only plugins of the selected filter by name. For example,\
    \ you can apply the Category filter and then type a character into the search\
    \ bar to view only Openshift plugins that contain the typed character in the name.\
    \ The following filters are available: Category Author Support type ## Removing\
    \ Extensions The Extensions feature plugins are preinstalled in Red Hat Developer\
    \ Hub (RHDH) and enabled by default. If you want to remove Extensions from your\
    \ RHDH instance, you can disable the relevant plugins. 1. To disable the the Extensions\
    \ feature plugins, edit your dynamic-plugins.yaml with the following content.\
    \ dynamic-plugins.yaml fragment ```yaml plugins: package: ./dynamic plugins/dist/red\
    \ hat developer hub backstage plugin marketplace disabled: true package: ./dynamic\
    \ plugins/dist/red hat developer hub backstage plugin catalog backend module marketplace\
    \ dynamic disabled: true package: ./dynamic plugins/dist/red hat developer hub\
    \ backstage plugin marketplace backend dynamic disabled: true ```"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:36:08.728261'
    uuid: 88c86283-29e1-4a41-b643-d33d53276365
  response: The Dynamic Plugin Factory tool offers a deployment option to push the
    resulting container image to registries, including OpenShift.
  user_input: What deployment option does the Dynamic Plugin Factory provide for OpenShift?
- context:
  - "> Extensions screen and searching for \u201Centity\u201D on the Installed tab.\
    \ ![custom extensions] When you click Catalog, you should see the new Feedback\
    \ tab, and the StarredRatingButtons displayed, as follows: ![custom entity view]\
    \ Selecting a low star rating prompts the user to provide feedback, as follows:\
    \ ![custom feedback overlay] [NOTE] ---- The user provided feedback is not saved\
    \ if you are logged in as the Guest user. ---- # Using the Dynamic Plugin Factory\
    \ to convert plugins into dynamic plugins You can automate the conversion and\
    \ packaging of standard Backstage plugins into RHDH dynamic plugins by using the\
    \ RHDH Dynamic Plugin Factory tool. [IMPORTANT] ---- The Dynamic Plugin Factory\
    \ is maintained as an open-source project by Red Hat, but is not supported or\
    \ subject to any service level agreement (SLA). ---- The core function of the\
    \ Dynamic Plugin Factory tool is to streamline the dynamic plugin build process,\
    \ offering the following capabilities: Source Code Handling:: Manages cloning,\
    \ checking out, and applying custom patches to the plugin source. Dependency Management::\
    \ Handles yarn installation and TypeScript compilation. Packaging:: Uses the RHDH\
    \ CLI to build, export, and package the final dynamic plugin. Deployment:: Offers\
    \ an option to push the resulting container image to registries like Quay or OpenShift.\
    \ The Dynamic Plugin Factory tool provides a simplified, reproducible method for\
    \ developers and platform engineers to create and test dynamic plugins using a\
    \ pre-configured dynamic plugin factory container and documentation, significantly\
    \ easing migration and testing. For more information, see RHDH Dynamic Plugin\
    \ Factory. # Enabling plugins added in the RHDH container image In the RHDH container\
    \ image, a set of dynamic plugins is preloaded to enhance functionality. However,\
    \ due to mandatory configuration requirements, most of the plugins are disabled.\
    \ You can enable and configure the plugins in the RHDH container image, including\
    \ how to manage the default configuration, set necessary environment variables,\
    \ and ensure the proper functionality of the plugins within your application.\
    \ You have access to the dynamic plugins.default.yaml file, which lists all preloaded\
    \ plugins and their default configuration. You have deployed the RHDH application,\
    \ and have access to the logs of the install dynamic plugins init container. You\
    \ have the necessary permissions to modify plugin configurations and access the\
    \ application environment. You have identified and set the required environment\
    \ variables referenced by the plugin's default configuration. These environment\
    \ variables must be defined in the Helm Chart or Operator configuration. 1. Start\
    \ your RHDH application and access the logs of the install-dynamic-plugins init\
    \ container within the RHDH pod. 2. Identify the Red Hat supported plugins that\
    \ are disabled by default. 3. Copy the package configuration from the dynamic-plugins.default.yaml\
    \ file. 4. Open the plugin configuration file and locate the plugin entry you\
    \ want to enable. The location of the plugin configuration file varies based on\
    \ the deployment method. For more details, see Installing and viewing plugins\
    \ in Red Hat Developer Hub. 5. Modify the disabled field to false and add the\
    \ package name as follows: ```yaml plugins: disabled: false package: ./dynamic\
    \ plugins/dist/backstage plugin catalog backend module github dynamic ``` For\
    \ more information about how to configure dynamic plugins in Developer Hub, see\
    \ Configuring dynamic plugins. 1. Restart the RHDH application and verify that\
    \ the plugin is successfully activated and configured. 2. Verify the application\
    \ logs for confirmation and ensure the plugin is functioning as expected. # Extensions\
    \ in Red Hat Developer Hub [IMPORTANT] ---- These features are for Technology\
    \ Preview only. Technology Preview features are not supported with Red Hat production\
    \ service level agreements (SLAs), might not be functionally complete, and Red\
    \ Hat does not recommend using them for production. These features provide early\
    \ access to upcoming product features, enabling customers to test functionality\
    \ and provide feedback during the development process. For more information on\
    \ Red Hat Technology Preview features, see Technology Preview Features Scope.\
    \ ---- Red Hat Developer Hub (RHDH) includes the Extensions feature which is preinstalled\
    \ and enabled by default. Extensions provides users with a centralized interface\
    \ to browse and manage available plugins You can use Extensions to discover plugins\
    \ that extend RHDH functionality, streamline development workflows, and improve\
    \ the developer experience. ## Viewing available plugins You can view plugins\
    \ available for your Red Hat Developer Hub application on the Extensions page.\
    \ 1. Open your Developer Hub application and click Administration > Extensions.\
    \ 2. Go to the Catalog tab to view a list of available plugins and related information.\
    \ ![Extensions Catalog] ## Viewing installed plugins Using the Dynamic Plugins\
    \ Info front-end plugin, you can view plugins that are currently installed in\
    \ your Red Hat Developer Hub application. This plugin is enabled by default. 1.\
    \ Open your Developer Hub application and click Administration > Extensions. 2.\
    \ Go to the Installed tab to view a list of installed plugins and related information.\
    \ ## Search and filter the plugins ### Search by plugin name You can use the search\
    \ bar in the header to filter the Extensions plugin cards by name. For example,\
    \ if you type \u201CA\u201D into the search bar, Extensions shows only the plugins\
    \ that contain the letter \u201CA\u201D in the Name field. ![Extensions catalog\
    \ with a Dynatrace search] Optionally, you can use the search bar in conjunction\
    \ with a filter to filter only plugins of the selected filter by name. For example,\
    \ you can apply the Category filter and then type a character into the search\
    \ bar to view only Openshift plugins that contain the typed character in the name.\
    \ The following filters are available: Category Author Support type ## Removing\
    \ Extensions The Extensions feature plugins are preinstalled in Red Hat Developer\
    \ Hub (RHDH) and enabled by default. If you want to remove Extensions from your\
    \ RHDH instance, you can disable the relevant plugins. 1. To disable the the Extensions\
    \ feature plugins, edit your dynamic-plugins.yaml with the following content.\
    \ dynamic-plugins.yaml fragment ```yaml plugins: package: ./dynamic plugins/dist/red\
    \ hat developer hub backstage plugin marketplace disabled: true package: ./dynamic\
    \ plugins/dist/red hat developer hub backstage plugin catalog backend module marketplace\
    \ dynamic disabled: true package: ./dynamic plugins/dist/red hat developer hub\
    \ backstage plugin marketplace backend dynamic disabled: true ```"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:36:16.258161'
    uuid: e41ab558-130e-4d4f-ba29-55c62d67bf0e
  response: In Red Hat Developer Hub (RHDH), the Extensions feature is preinstalled
    and enabled by default. It provides users with a centralized interface to browse
    and manage available plugins. You can use Extensions to discover plugins that
    extend RHDH functionality, streamline development workflows, and improve the developer
    experience. However, these features are for Technology Preview only, are not supported
    with Red Hat production service level agreements (SLAs), might not be functionally
    complete, and Red Hat does not recommend using them for production.
  user_input: wat are extnsions in Develper Hub?
- context:
  - 'Managing plugins by using Extensions You can install and configure plugins by
    using Extensions. [WARNING] ---- Installation and configuration of plugins by
    using Extensions will only work in development environments. This feature is not
    supported in production environments. ---- In a production environment, users
    will be notified that plugin installation is not permitted. ![extensions restart
    plugin 1] In a development environment: Administrators can install a plugin using
    the default configuration preloaded in the editor, or modify the configuration
    before installing. Upon successful installation, users will be notified that a
    backend restart is required to complete the installation process. When a plugin
    is installed, administrators can access the Actions drop down in the side panel
    of the plugin. Available actions include: Editing the configuration used during
    installation Disabling or enabling the plugin After performing any of these actions,
    users will be notified that a backend restart is required for the changes to take
    effect. ### Configuring RBAC to manage Extensions You can add Extensions permissions
    by creating or updating and existing RBAC role. For more information about using
    RBAC to manage role-based controls, see Managing role-based access controls (RBAC)
    using the Red Hat Developer Hub Web UI. #### Creating a role in the Developer
    Hub UI to manage Extensions You have enabled RBAC, have a policy administrator
    role in Developer Hub, and have added plugins with permission. 1. Go to Administration
    at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying
    all the created roles in the Developer Hub. 2. Click Create to create a role.
    3. Enter the user name and description (optional) of role in the given fields
    and click Next. 4. In Add users and groups, select the user name, and click Next.
    5. In Add permission policies, select Extensions from the plugins dropdown. 6.
    Expand Extensions, select both the Create and Read permissions for the Extensions
    plugin and click Next. 7. Click Create to create the role. ![extensions rbac role
    create] After you refresh the RHDH application, when you select a plugin, the
    Actions drop-down is active. When you click the Actions drop-down, you can edit
    the the plugin configuration, and enable or disable the plugin. ### Configuring
    RHDH to install plugins by using Extensions When you install a plugin using Extensions
    UI, the configuration that you use is saved to a dynamic-plugins.extensions.yaml
    file within the dynamic-plugins-root persistent volume. This ensures the configuration
    is available when you restart the application, allowing you to edit or re-enable
    the plugin. You must create a persistent volume claim (PVC) to ensure that the
    cache persists when you restart the RHDH application. For more information about
    using the dynamic plugins cache, see Using the dynamic plugins cache. You have
    created a persistent volume claim (PVC) for the dynamic plugins cache with the
    name dynamic plugins root. You have installed Red Hat Developer Hub using the
    Helm chart or the Operator. You have installed the OpenShift CLI (oc). 1. Create
    the extensions configuration file and save it as dynamic-plugins.extensions.yaml.
    For example: ```yaml includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin marketplace: translationResources: importName: marketplaceTranslations
    ref: marketplaceTranslationRef module: Alpha appIcons: name: pluginsIcon importName:
    PluginsIcon dynamicRoutes: path: /extensions importName: DynamicMarketplacePluginRouter
    menuItem: icon: pluginsIcon text: Extensions textKey: menuItem.extensions menuItems:
    extensions: parent: default.admin package: ./dynamic plugins/dist/red hat developer
    hub backstage plugin marketplace backend dynamic disabled: false pluginConfig:
    extensions: installation: enabled: true saveToSingleFile: file: /opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` where: translationResources::
    Sets the extension point for localization. 2. Copy the file to your cluster by
    running the following commands: ```yaml oc get pods n <your namespace> oc cp ./dynamic
    plugins.extensions.yaml <your namespace>/<pod name>:/opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` 3. Update your RHDH application
    to use this file: 1. For operator-based installations: 1. Update your Backstage
    CR to update the NODE_ENV environment variable to development, as follows: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub namespace: rhdh spec: application: dynamicPluginsConfigMapName: dynamic plugins
    rhdh extraEnvs: envs: name: NODE_ENV value: "development" secrets: name: secrets
    rhdh extraFiles: mountPath: /opt/app root/src route: enabled: true database: enableLocalDb:
    true ``` 2. Update your dynamic-plugins-rhdh config map to include your extensions
    configuration file, as follows: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh namespace: rhdh data: dynamic plugins.yaml: | includes:
    dynamic plugins.default.yaml /dynamic plugins root/dynamic plugins.extensions.yaml
    plugins: [] ``` 2. For Helm chart installations: 1. Upgrade the Helm release to
    include your extensions configuration file and update the NODE_ENV environment
    variable to development: ```yaml global: auth: backend: enabled: true clusterRouterBase:
    apps.<clusterName>.com dynamic: includes: dynamic plugins.default.yaml /dynamic
    plugins root/dynamic plugins.extensions.yaml upstream: backstage: extraEnvVars:
    name: NODE_ENV value: development ``` 2. Click Upgrade Enable a plugin by using
    the Extensions UI, restart your RHDH application and refresh the UI to confirm
    that the plugin is enabled. ### Configuring RHDH Local to install plugins by using
    Extensions You can use RHDH Local to test installing plugins by using Extensions.
    You have installed RHDH Local. For more information about setting up RHDH Local,
    see Test locally with Red Hat Developer Hub. 1. Update your dynamic plugins.override.yaml
    file: ```yaml includes: dynamic plugins.default.yaml plugins: package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin marketplace disabled: false
    pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage plugin
    marketplace: translationResources: importName: marketplaceTranslations ref: marketplaceTranslationRef
    module: Alpha appIcons: name: pluginsIcon importName: PluginsIcon dynamicRoutes:
    path: /extensions importName: DynamicMarketplacePluginRouter menuItem: icon: pluginsIcon
    text: Extensions textKey: menuItem.extensions menuItems: extensions: parent: default.admin
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace
    backend dynamic disabled: false pluginConfig: extensions: installation: enabled:
    true saveToSingleFile: file: /opt/app root/src/configs/dynamic plugins/dynamic
    plugins.override.yaml ``` where: translationResources:: Sets the extension point
    for localization. 2. Update your compose.yaml file: ```yaml rhdh: container_name:
    rhdh environment: NODE_OPTIONS: "- inspect=0.0.0.0:9229" NODE_ENV: "development"
    ``` Enable a plugin by using the Extensions UI, restart your RHDH application
    and refresh the UI to confirm that the plugin is enabled. ### Installing plugins
    by using Extensions You can install and configure plugins by using Extensions.
    You have configured RHDH to allow plugins installation from'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:36:27.290480'
    uuid: 6e5b3b90-0417-4b62-9586-3f74a07c4043
  response: For operator-based installations, you must first update your Backstage
    CR to set the NODE_ENV environment variable to "development". Secondly, you need
    to update your dynamic-plugins-rhdh config map to include your extensions configuration
    file, specifically by adding `/dynamic-plugins-root/dynamic-plugins.extensions.yaml`
    to the `includes` section under `dynamic-plugins.yaml`.
  user_input: What are the configuration steps for an Operator-based RHDH installation
    to use Extensions?
- context:
  - 'Managing plugins by using Extensions You can install and configure plugins by
    using Extensions. [WARNING] ---- Installation and configuration of plugins by
    using Extensions will only work in development environments. This feature is not
    supported in production environments. ---- In a production environment, users
    will be notified that plugin installation is not permitted. ![extensions restart
    plugin 1] In a development environment: Administrators can install a plugin using
    the default configuration preloaded in the editor, or modify the configuration
    before installing. Upon successful installation, users will be notified that a
    backend restart is required to complete the installation process. When a plugin
    is installed, administrators can access the Actions drop down in the side panel
    of the plugin. Available actions include: Editing the configuration used during
    installation Disabling or enabling the plugin After performing any of these actions,
    users will be notified that a backend restart is required for the changes to take
    effect. ### Configuring RBAC to manage Extensions You can add Extensions permissions
    by creating or updating and existing RBAC role. For more information about using
    RBAC to manage role-based controls, see Managing role-based access controls (RBAC)
    using the Red Hat Developer Hub Web UI. #### Creating a role in the Developer
    Hub UI to manage Extensions You have enabled RBAC, have a policy administrator
    role in Developer Hub, and have added plugins with permission. 1. Go to Administration
    at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying
    all the created roles in the Developer Hub. 2. Click Create to create a role.
    3. Enter the user name and description (optional) of role in the given fields
    and click Next. 4. In Add users and groups, select the user name, and click Next.
    5. In Add permission policies, select Extensions from the plugins dropdown. 6.
    Expand Extensions, select both the Create and Read permissions for the Extensions
    plugin and click Next. 7. Click Create to create the role. ![extensions rbac role
    create] After you refresh the RHDH application, when you select a plugin, the
    Actions drop-down is active. When you click the Actions drop-down, you can edit
    the the plugin configuration, and enable or disable the plugin. ### Configuring
    RHDH to install plugins by using Extensions When you install a plugin using Extensions
    UI, the configuration that you use is saved to a dynamic-plugins.extensions.yaml
    file within the dynamic-plugins-root persistent volume. This ensures the configuration
    is available when you restart the application, allowing you to edit or re-enable
    the plugin. You must create a persistent volume claim (PVC) to ensure that the
    cache persists when you restart the RHDH application. For more information about
    using the dynamic plugins cache, see Using the dynamic plugins cache. You have
    created a persistent volume claim (PVC) for the dynamic plugins cache with the
    name dynamic plugins root. You have installed Red Hat Developer Hub using the
    Helm chart or the Operator. You have installed the OpenShift CLI (oc). 1. Create
    the extensions configuration file and save it as dynamic-plugins.extensions.yaml.
    For example: ```yaml includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin marketplace: translationResources: importName: marketplaceTranslations
    ref: marketplaceTranslationRef module: Alpha appIcons: name: pluginsIcon importName:
    PluginsIcon dynamicRoutes: path: /extensions importName: DynamicMarketplacePluginRouter
    menuItem: icon: pluginsIcon text: Extensions textKey: menuItem.extensions menuItems:
    extensions: parent: default.admin package: ./dynamic plugins/dist/red hat developer
    hub backstage plugin marketplace backend dynamic disabled: false pluginConfig:
    extensions: installation: enabled: true saveToSingleFile: file: /opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` where: translationResources::
    Sets the extension point for localization. 2. Copy the file to your cluster by
    running the following commands: ```yaml oc get pods n <your namespace> oc cp ./dynamic
    plugins.extensions.yaml <your namespace>/<pod name>:/opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` 3. Update your RHDH application
    to use this file: 1. For operator-based installations: 1. Update your Backstage
    CR to update the NODE_ENV environment variable to development, as follows: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub namespace: rhdh spec: application: dynamicPluginsConfigMapName: dynamic plugins
    rhdh extraEnvs: envs: name: NODE_ENV value: "development" secrets: name: secrets
    rhdh extraFiles: mountPath: /opt/app root/src route: enabled: true database: enableLocalDb:
    true ``` 2. Update your dynamic-plugins-rhdh config map to include your extensions
    configuration file, as follows: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh namespace: rhdh data: dynamic plugins.yaml: | includes:
    dynamic plugins.default.yaml /dynamic plugins root/dynamic plugins.extensions.yaml
    plugins: [] ``` 2. For Helm chart installations: 1. Upgrade the Helm release to
    include your extensions configuration file and update the NODE_ENV environment
    variable to development: ```yaml global: auth: backend: enabled: true clusterRouterBase:
    apps.<clusterName>.com dynamic: includes: dynamic plugins.default.yaml /dynamic
    plugins root/dynamic plugins.extensions.yaml upstream: backstage: extraEnvVars:
    name: NODE_ENV value: development ``` 2. Click Upgrade Enable a plugin by using
    the Extensions UI, restart your RHDH application and refresh the UI to confirm
    that the plugin is enabled. ### Configuring RHDH Local to install plugins by using
    Extensions You can use RHDH Local to test installing plugins by using Extensions.
    You have installed RHDH Local. For more information about setting up RHDH Local,
    see Test locally with Red Hat Developer Hub. 1. Update your dynamic plugins.override.yaml
    file: ```yaml includes: dynamic plugins.default.yaml plugins: package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin marketplace disabled: false
    pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage plugin
    marketplace: translationResources: importName: marketplaceTranslations ref: marketplaceTranslationRef
    module: Alpha appIcons: name: pluginsIcon importName: PluginsIcon dynamicRoutes:
    path: /extensions importName: DynamicMarketplacePluginRouter menuItem: icon: pluginsIcon
    text: Extensions textKey: menuItem.extensions menuItems: extensions: parent: default.admin
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace
    backend dynamic disabled: false pluginConfig: extensions: installation: enabled:
    true saveToSingleFile: file: /opt/app root/src/configs/dynamic plugins/dynamic
    plugins.override.yaml ``` where: translationResources:: Sets the extension point
    for localization. 2. Update your compose.yaml file: ```yaml rhdh: container_name:
    rhdh environment: NODE_OPTIONS: "- inspect=0.0.0.0:9229" NODE_ENV: "development"
    ``` Enable a plugin by using the Extensions UI, restart your RHDH application
    and refresh the UI to confirm that the plugin is enabled. ### Installing plugins
    by using Extensions You can install and configure plugins by using Extensions.
    You have configured RHDH to allow plugins installation from'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:36:54.539858'
    uuid: ad47caa8-e10d-439f-8bb9-d4fed99f916d
  response: For Helm chart installations, you must upgrade the Helm release to include
    your extensions configuration file and update the NODE_ENV environment variable
    to "development". The configuration should set "dynamic.includes" to include "dynamic-plugins.default.yaml"
    and "/dynamic-plugins-root/dynamic-plugins.extensions.yaml", and set "upstream.backstage.extraEnvVars"
    with the name NODE_ENV and value "development". After configuring, you click Upgrade.
  user_input: how do i setup extensins with Helmm?
- context:
  - 'Managing plugins by using Extensions You can install and configure plugins by
    using Extensions. [WARNING] ---- Installation and configuration of plugins by
    using Extensions will only work in development environments. This feature is not
    supported in production environments. ---- In a production environment, users
    will be notified that plugin installation is not permitted. ![extensions restart
    plugin 1] In a development environment: Administrators can install a plugin using
    the default configuration preloaded in the editor, or modify the configuration
    before installing. Upon successful installation, users will be notified that a
    backend restart is required to complete the installation process. When a plugin
    is installed, administrators can access the Actions drop down in the side panel
    of the plugin. Available actions include: Editing the configuration used during
    installation Disabling or enabling the plugin After performing any of these actions,
    users will be notified that a backend restart is required for the changes to take
    effect. ### Configuring RBAC to manage Extensions You can add Extensions permissions
    by creating or updating and existing RBAC role. For more information about using
    RBAC to manage role-based controls, see Managing role-based access controls (RBAC)
    using the Red Hat Developer Hub Web UI. #### Creating a role in the Developer
    Hub UI to manage Extensions You have enabled RBAC, have a policy administrator
    role in Developer Hub, and have added plugins with permission. 1. Go to Administration
    at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying
    all the created roles in the Developer Hub. 2. Click Create to create a role.
    3. Enter the user name and description (optional) of role in the given fields
    and click Next. 4. In Add users and groups, select the user name, and click Next.
    5. In Add permission policies, select Extensions from the plugins dropdown. 6.
    Expand Extensions, select both the Create and Read permissions for the Extensions
    plugin and click Next. 7. Click Create to create the role. ![extensions rbac role
    create] After you refresh the RHDH application, when you select a plugin, the
    Actions drop-down is active. When you click the Actions drop-down, you can edit
    the the plugin configuration, and enable or disable the plugin. ### Configuring
    RHDH to install plugins by using Extensions When you install a plugin using Extensions
    UI, the configuration that you use is saved to a dynamic-plugins.extensions.yaml
    file within the dynamic-plugins-root persistent volume. This ensures the configuration
    is available when you restart the application, allowing you to edit or re-enable
    the plugin. You must create a persistent volume claim (PVC) to ensure that the
    cache persists when you restart the RHDH application. For more information about
    using the dynamic plugins cache, see Using the dynamic plugins cache. You have
    created a persistent volume claim (PVC) for the dynamic plugins cache with the
    name dynamic plugins root. You have installed Red Hat Developer Hub using the
    Helm chart or the Operator. You have installed the OpenShift CLI (oc). 1. Create
    the extensions configuration file and save it as dynamic-plugins.extensions.yaml.
    For example: ```yaml includes: dynamic plugins.default.yaml plugins: package:
    ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin marketplace: translationResources: importName: marketplaceTranslations
    ref: marketplaceTranslationRef module: Alpha appIcons: name: pluginsIcon importName:
    PluginsIcon dynamicRoutes: path: /extensions importName: DynamicMarketplacePluginRouter
    menuItem: icon: pluginsIcon text: Extensions textKey: menuItem.extensions menuItems:
    extensions: parent: default.admin package: ./dynamic plugins/dist/red hat developer
    hub backstage plugin marketplace backend dynamic disabled: false pluginConfig:
    extensions: installation: enabled: true saveToSingleFile: file: /opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` where: translationResources::
    Sets the extension point for localization. 2. Copy the file to your cluster by
    running the following commands: ```yaml oc get pods n <your namespace> oc cp ./dynamic
    plugins.extensions.yaml <your namespace>/<pod name>:/opt/app root/src/dynamic
    plugins root/dynamic plugins.extensions.yaml ``` 3. Update your RHDH application
    to use this file: 1. For operator-based installations: 1. Update your Backstage
    CR to update the NODE_ENV environment variable to development, as follows: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub namespace: rhdh spec: application: dynamicPluginsConfigMapName: dynamic plugins
    rhdh extraEnvs: envs: name: NODE_ENV value: "development" secrets: name: secrets
    rhdh extraFiles: mountPath: /opt/app root/src route: enabled: true database: enableLocalDb:
    true ``` 2. Update your dynamic-plugins-rhdh config map to include your extensions
    configuration file, as follows: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh namespace: rhdh data: dynamic plugins.yaml: | includes:
    dynamic plugins.default.yaml /dynamic plugins root/dynamic plugins.extensions.yaml
    plugins: [] ``` 2. For Helm chart installations: 1. Upgrade the Helm release to
    include your extensions configuration file and update the NODE_ENV environment
    variable to development: ```yaml global: auth: backend: enabled: true clusterRouterBase:
    apps.<clusterName>.com dynamic: includes: dynamic plugins.default.yaml /dynamic
    plugins root/dynamic plugins.extensions.yaml upstream: backstage: extraEnvVars:
    name: NODE_ENV value: development ``` 2. Click Upgrade Enable a plugin by using
    the Extensions UI, restart your RHDH application and refresh the UI to confirm
    that the plugin is enabled. ### Configuring RHDH Local to install plugins by using
    Extensions You can use RHDH Local to test installing plugins by using Extensions.
    You have installed RHDH Local. For more information about setting up RHDH Local,
    see Test locally with Red Hat Developer Hub. 1. Update your dynamic plugins.override.yaml
    file: ```yaml includes: dynamic plugins.default.yaml plugins: package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin marketplace disabled: false
    pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage plugin
    marketplace: translationResources: importName: marketplaceTranslations ref: marketplaceTranslationRef
    module: Alpha appIcons: name: pluginsIcon importName: PluginsIcon dynamicRoutes:
    path: /extensions importName: DynamicMarketplacePluginRouter menuItem: icon: pluginsIcon
    text: Extensions textKey: menuItem.extensions menuItems: extensions: parent: default.admin
    package: ./dynamic plugins/dist/red hat developer hub backstage plugin marketplace
    backend dynamic disabled: false pluginConfig: extensions: installation: enabled:
    true saveToSingleFile: file: /opt/app root/src/configs/dynamic plugins/dynamic
    plugins.override.yaml ``` where: translationResources:: Sets the extension point
    for localization. 2. Update your compose.yaml file: ```yaml rhdh: container_name:
    rhdh environment: NODE_OPTIONS: "- inspect=0.0.0.0:9229" NODE_ENV: "development"
    ``` Enable a plugin by using the Extensions UI, restart your RHDH application
    and refresh the UI to confirm that the plugin is enabled. ### Installing plugins
    by using Extensions You can install and configure plugins by using Extensions.
    You have configured RHDH to allow plugins installation from'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:37:05.720434'
    uuid: 3a353cc0-8466-4592-aa9f-8772972cbf27
  response: When a plugin is installed using the Extensions UI, the configuration
    is saved to a dynamic-plugins.extensions.yaml file located within the dynamic-plugins-root
    persistent volume. A persistent volume claim (PVC) must be created to ensure that
    the cache persists when you restart the RHDH application. This persistence makes
    the configuration available after a restart, which in turn allows you to edit
    or re-enable the plugin.
  user_input: Considering the process for configuring Red Hat Developer Hub to install
    plugins using the Extensions UI, what is the explicit function of the persistent
    volume claim (PVC), and why is its creation a mandatory prerequisite for ensuring
    the persistence of plugin configurations across application restarts?
- context:
  - 'RHDH pod fails to start after enabling a plugin 1. Inspect your RHDH pod logs
    to identify if the plugin requires specific environment variables or additional
    configuration, for example: ```terminal Plugin ''<PLUGIN_NAME>'' threw an error
    during startup, waiting for X other plugins to finish before shutting down the
    process. Plugin ''<PLUGIN_NAME>'' startup failed; caused by Error: Missing required
    config value at ''<concretePluginRequiredVariable.name>'' in ''app-config.local.yaml''
    type="initialization" ``` 2. Verify the required configuration by inspecting dynamic-plugins.default.yaml
    file that lists the required environment variables for each plugin. The variables
    for each plugin are in the format of ${PLUGIN_VARIABLE_NAME} 3. If any required
    environment variables are missing, set the environment variables by using a secret.
    For example: ```yaml kind: Secret apiVersion: v1 metadata: name: rhdh secrets
    labels: backstage.io/kubernetes id: developer hub data: PLUGIN_VARIABLE_NAME:
    ''dummy value'' type: Opaque ``` 4. Mount the secret: 1. If RHDH is deployed by
    using the Operator, update your Backstage CR, as follows: ```yaml spec: application:
    extraEnvs: secrets: name: rhdh secrets ``` 2. If RHDH is deployed by using the
    Helm chart, in the upstream.backstage key in your Helm chart values, enter the
    name of the Developer Hub rhdh-secrets secret as the value for the extraEnvVarsSecrets
    field. For example: ```yaml upstream: backstage: extraEnvVarsSecrets: rhdh secrets
    ``` # Front end plugin wiring You can configure front-end plugins to customize
    icons, integrate components at mount points, and provide or replace utility APIs.
    ## Extending internal icon catalog You can use the internal catalog to fetch icons
    for configured routes with sidebar navigation menu entry. Add a custom icon to
    the internal icon catalog for use in the menu item of a plugin by using the appIcons
    configuration as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name appIcons: - name: fooIcon # The
    icon catalog name # (Optional): The set of assets to access within the plugin.
    If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The actual component name to be rendered as a standalone page. If
    not specified, the system uses the `default` export. importName: FooIcon ``` [NOTE]
    ---- The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in your plugin''s package.json. This ensures your dynamic plugin loads correctly
    during runtime. ---- ## Defining dynamic routes for new plugin pages 1. Define
    each route by specifying a unique path and, if needed, an importName if it is
    different from the default export. 2. Expose additional routes in a dynamic plugin
    by configuring dynamicRoutes as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name dynamicRoutes: # The unique path
    in the application. The path cannot override existing routes except the `/` home
    route. - path: /my-plugin # (Optional): The set of assets to access within the
    plugin. If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The component name as a standalone page. If not specified, the system
    uses the `default` export. importName: FooPluginPage # Allows you to extend the
    main sidebar navigation and point to a new route. menuItem: icon: fooIcon text:
    Foo Plugin Page enabled: false config: # (Optional): Passes `props` to a custom
    sidebar item props: ... ``` The menuItem accepts the following properties: * text:
    The label shown to the user. * icon: The Backstage system icon name. * enabled:
    Optional: Allows the user to remove a menuItem from the sidebar when it is set
    to false. * importName: Specifies the optional name of an exported SidebarItem
    component. To configure a custom SidebarItem to enhance experiences such as notification
    badges, ensure the component accepts the following properties: ```yaml export
    type MySidebarItemProps = { to: string; // supplied by the sidebar during rendering,
    this will be the path configured for the dynamicRoute }; ``` ```yaml # dynamic
    plugins config.yaml plugins: plugin: <plugin_path_or_url> disabled: false pluginConfig:
    dynamicPlugins: frontend: my dynamic plugin package name: dynamicRoutes: importName:
    CustomPage menuItem: config: props: text: Click Me! importName: SimpleSidebarItem
    path: /custom_page ``` ## Customizing menu items in the sidebar navigation You
    can customize the order and parent-child relationships of plugin menu items in
    the main sidebar navigation using the menu items configuration as shown in the
    following example: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name menuItems: # The unique name in the main sidebar navigation (for
    example, either a standalone menu item or a parent menu item) <menu_item_name>:
    # (Optional): The icon for the menu item, which refers to a Backstage system icon
    icon: fooIcon # (Optional): The display title of the menu item title: Foo Plugin
    Page # (Optional): The order in which menu items appear. The default priority
    is `0`. priority: 10 # (Optional): Defines the parent menu item to nest the current
    item under parent: favorites # (Optional): Allows you to remove a `menuItem` from
    the sidebar when it is set to `false` enabled: false ``` Handling Complex Paths:
    For simple paths like path: /my plugin, the menu_item_name should be my plugin.
    For complex paths like /metrics/users/info, the menu_item_name should represent
    the full path in dot notation (for example metrics.users.info). Ignore trailing
    and leading slashes in paths as follows: For path: /docs, the menu_item_name is
    docs. For path: /metrics/users, the menu_item_name is metrics.users. [NOTE] ----
    Red Hat Developer Hub supports up to 3 levels of nested menu items. ---- ## Binding
    to existing plugins You can bind to existing plugins and their routes, and declare
    new targets sourced from dynamic plugins as shown in the following routeBindings
    configuration: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name routeBindings: targets: # A new bind target # (Optional): Defaults
    to importName. Explicit name of the plugin that exposes the bind target. - name:
    barPlugin # (Required): Explicit import name that reference a BackstagePlugin<{}>
    implementation. importName: barPlugin # # (Optional): Same as key in `scalprum.exposedModules`
    key in'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:37:15.223346'
    uuid: 3ee682e6-153a-49ff-b36c-4a85addcf068
  response: To ensure that a dynamic plugin loads correctly during runtime, the package_name
    key under dynamicPlugins.frontend must match the scalprum.name value that is located
    in the plugin's package.json file.
  user_input: What is the specific requirement for the package_name key under dynamicPlugins.frontend
    and how does it relate to the scalprum.name value in a plugin's package.json to
    ensure a dynamic plugin loads correctly at runtime in Red Hat Developer Hub?
- context:
  - 'RHDH pod fails to start after enabling a plugin 1. Inspect your RHDH pod logs
    to identify if the plugin requires specific environment variables or additional
    configuration, for example: ```terminal Plugin ''<PLUGIN_NAME>'' threw an error
    during startup, waiting for X other plugins to finish before shutting down the
    process. Plugin ''<PLUGIN_NAME>'' startup failed; caused by Error: Missing required
    config value at ''<concretePluginRequiredVariable.name>'' in ''app-config.local.yaml''
    type="initialization" ``` 2. Verify the required configuration by inspecting dynamic-plugins.default.yaml
    file that lists the required environment variables for each plugin. The variables
    for each plugin are in the format of ${PLUGIN_VARIABLE_NAME} 3. If any required
    environment variables are missing, set the environment variables by using a secret.
    For example: ```yaml kind: Secret apiVersion: v1 metadata: name: rhdh secrets
    labels: backstage.io/kubernetes id: developer hub data: PLUGIN_VARIABLE_NAME:
    ''dummy value'' type: Opaque ``` 4. Mount the secret: 1. If RHDH is deployed by
    using the Operator, update your Backstage CR, as follows: ```yaml spec: application:
    extraEnvs: secrets: name: rhdh secrets ``` 2. If RHDH is deployed by using the
    Helm chart, in the upstream.backstage key in your Helm chart values, enter the
    name of the Developer Hub rhdh-secrets secret as the value for the extraEnvVarsSecrets
    field. For example: ```yaml upstream: backstage: extraEnvVarsSecrets: rhdh secrets
    ``` # Front end plugin wiring You can configure front-end plugins to customize
    icons, integrate components at mount points, and provide or replace utility APIs.
    ## Extending internal icon catalog You can use the internal catalog to fetch icons
    for configured routes with sidebar navigation menu entry. Add a custom icon to
    the internal icon catalog for use in the menu item of a plugin by using the appIcons
    configuration as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name appIcons: - name: fooIcon # The
    icon catalog name # (Optional): The set of assets to access within the plugin.
    If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The actual component name to be rendered as a standalone page. If
    not specified, the system uses the `default` export. importName: FooIcon ``` [NOTE]
    ---- The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in your plugin''s package.json. This ensures your dynamic plugin loads correctly
    during runtime. ---- ## Defining dynamic routes for new plugin pages 1. Define
    each route by specifying a unique path and, if needed, an importName if it is
    different from the default export. 2. Expose additional routes in a dynamic plugin
    by configuring dynamicRoutes as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name dynamicRoutes: # The unique path
    in the application. The path cannot override existing routes except the `/` home
    route. - path: /my-plugin # (Optional): The set of assets to access within the
    plugin. If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The component name as a standalone page. If not specified, the system
    uses the `default` export. importName: FooPluginPage # Allows you to extend the
    main sidebar navigation and point to a new route. menuItem: icon: fooIcon text:
    Foo Plugin Page enabled: false config: # (Optional): Passes `props` to a custom
    sidebar item props: ... ``` The menuItem accepts the following properties: * text:
    The label shown to the user. * icon: The Backstage system icon name. * enabled:
    Optional: Allows the user to remove a menuItem from the sidebar when it is set
    to false. * importName: Specifies the optional name of an exported SidebarItem
    component. To configure a custom SidebarItem to enhance experiences such as notification
    badges, ensure the component accepts the following properties: ```yaml export
    type MySidebarItemProps = { to: string; // supplied by the sidebar during rendering,
    this will be the path configured for the dynamicRoute }; ``` ```yaml # dynamic
    plugins config.yaml plugins: plugin: <plugin_path_or_url> disabled: false pluginConfig:
    dynamicPlugins: frontend: my dynamic plugin package name: dynamicRoutes: importName:
    CustomPage menuItem: config: props: text: Click Me! importName: SimpleSidebarItem
    path: /custom_page ``` ## Customizing menu items in the sidebar navigation You
    can customize the order and parent-child relationships of plugin menu items in
    the main sidebar navigation using the menu items configuration as shown in the
    following example: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name menuItems: # The unique name in the main sidebar navigation (for
    example, either a standalone menu item or a parent menu item) <menu_item_name>:
    # (Optional): The icon for the menu item, which refers to a Backstage system icon
    icon: fooIcon # (Optional): The display title of the menu item title: Foo Plugin
    Page # (Optional): The order in which menu items appear. The default priority
    is `0`. priority: 10 # (Optional): Defines the parent menu item to nest the current
    item under parent: favorites # (Optional): Allows you to remove a `menuItem` from
    the sidebar when it is set to `false` enabled: false ``` Handling Complex Paths:
    For simple paths like path: /my plugin, the menu_item_name should be my plugin.
    For complex paths like /metrics/users/info, the menu_item_name should represent
    the full path in dot notation (for example metrics.users.info). Ignore trailing
    and leading slashes in paths as follows: For path: /docs, the menu_item_name is
    docs. For path: /metrics/users, the menu_item_name is metrics.users. [NOTE] ----
    Red Hat Developer Hub supports up to 3 levels of nested menu items. ---- ## Binding
    to existing plugins You can bind to existing plugins and their routes, and declare
    new targets sourced from dynamic plugins as shown in the following routeBindings
    configuration: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name routeBindings: targets: # A new bind target # (Optional): Defaults
    to importName. Explicit name of the plugin that exposes the bind target. - name:
    barPlugin # (Required): Explicit import name that reference a BackstagePlugin<{}>
    implementation. importName: barPlugin # # (Optional): Same as key in `scalprum.exposedModules`
    key in'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:37:25.853583'
    uuid: 0d421105-edee-425b-852b-101a70afbe9f
  response: 'If RHDH is deployed using the Operator, you can mount a secret by updating
    your Backstage CR. You must add an `extraEnvs` configuration under `spec.application`,
    which includes a `secrets` block where you specify the name of the secret, for
    example: `name: rhdh secrets`.'
  user_input: What is the specific procedure for mounting a secret via the Backstage
    Custom Resource when Red Hat Developer Hub has been deployed using the Operator?
- context:
  - 'RHDH pod fails to start after enabling a plugin 1. Inspect your RHDH pod logs
    to identify if the plugin requires specific environment variables or additional
    configuration, for example: ```terminal Plugin ''<PLUGIN_NAME>'' threw an error
    during startup, waiting for X other plugins to finish before shutting down the
    process. Plugin ''<PLUGIN_NAME>'' startup failed; caused by Error: Missing required
    config value at ''<concretePluginRequiredVariable.name>'' in ''app-config.local.yaml''
    type="initialization" ``` 2. Verify the required configuration by inspecting dynamic-plugins.default.yaml
    file that lists the required environment variables for each plugin. The variables
    for each plugin are in the format of ${PLUGIN_VARIABLE_NAME} 3. If any required
    environment variables are missing, set the environment variables by using a secret.
    For example: ```yaml kind: Secret apiVersion: v1 metadata: name: rhdh secrets
    labels: backstage.io/kubernetes id: developer hub data: PLUGIN_VARIABLE_NAME:
    ''dummy value'' type: Opaque ``` 4. Mount the secret: 1. If RHDH is deployed by
    using the Operator, update your Backstage CR, as follows: ```yaml spec: application:
    extraEnvs: secrets: name: rhdh secrets ``` 2. If RHDH is deployed by using the
    Helm chart, in the upstream.backstage key in your Helm chart values, enter the
    name of the Developer Hub rhdh-secrets secret as the value for the extraEnvVarsSecrets
    field. For example: ```yaml upstream: backstage: extraEnvVarsSecrets: rhdh secrets
    ``` # Front end plugin wiring You can configure front-end plugins to customize
    icons, integrate components at mount points, and provide or replace utility APIs.
    ## Extending internal icon catalog You can use the internal catalog to fetch icons
    for configured routes with sidebar navigation menu entry. Add a custom icon to
    the internal icon catalog for use in the menu item of a plugin by using the appIcons
    configuration as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name appIcons: - name: fooIcon # The
    icon catalog name # (Optional): The set of assets to access within the plugin.
    If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The actual component name to be rendered as a standalone page. If
    not specified, the system uses the `default` export. importName: FooIcon ``` [NOTE]
    ---- The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in your plugin''s package.json. This ensures your dynamic plugin loads correctly
    during runtime. ---- ## Defining dynamic routes for new plugin pages 1. Define
    each route by specifying a unique path and, if needed, an importName if it is
    different from the default export. 2. Expose additional routes in a dynamic plugin
    by configuring dynamicRoutes as shown in the following example: ```yaml # dynamic-plugins-config.yaml
    plugins: - plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins:
    frontend: my-plugin: # The plugin package name dynamicRoutes: # The unique path
    in the application. The path cannot override existing routes except the `/` home
    route. - path: /my-plugin # (Optional): The set of assets to access within the
    plugin. If not specified, the system uses the `PluginRoot` module. module: CustomModule
    # (Optional): The component name as a standalone page. If not specified, the system
    uses the `default` export. importName: FooPluginPage # Allows you to extend the
    main sidebar navigation and point to a new route. menuItem: icon: fooIcon text:
    Foo Plugin Page enabled: false config: # (Optional): Passes `props` to a custom
    sidebar item props: ... ``` The menuItem accepts the following properties: * text:
    The label shown to the user. * icon: The Backstage system icon name. * enabled:
    Optional: Allows the user to remove a menuItem from the sidebar when it is set
    to false. * importName: Specifies the optional name of an exported SidebarItem
    component. To configure a custom SidebarItem to enhance experiences such as notification
    badges, ensure the component accepts the following properties: ```yaml export
    type MySidebarItemProps = { to: string; // supplied by the sidebar during rendering,
    this will be the path configured for the dynamicRoute }; ``` ```yaml # dynamic
    plugins config.yaml plugins: plugin: <plugin_path_or_url> disabled: false pluginConfig:
    dynamicPlugins: frontend: my dynamic plugin package name: dynamicRoutes: importName:
    CustomPage menuItem: config: props: text: Click Me! importName: SimpleSidebarItem
    path: /custom_page ``` ## Customizing menu items in the sidebar navigation You
    can customize the order and parent-child relationships of plugin menu items in
    the main sidebar navigation using the menu items configuration as shown in the
    following example: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name menuItems: # The unique name in the main sidebar navigation (for
    example, either a standalone menu item or a parent menu item) <menu_item_name>:
    # (Optional): The icon for the menu item, which refers to a Backstage system icon
    icon: fooIcon # (Optional): The display title of the menu item title: Foo Plugin
    Page # (Optional): The order in which menu items appear. The default priority
    is `0`. priority: 10 # (Optional): Defines the parent menu item to nest the current
    item under parent: favorites # (Optional): Allows you to remove a `menuItem` from
    the sidebar when it is set to `false` enabled: false ``` Handling Complex Paths:
    For simple paths like path: /my plugin, the menu_item_name should be my plugin.
    For complex paths like /metrics/users/info, the menu_item_name should represent
    the full path in dot notation (for example metrics.users.info). Ignore trailing
    and leading slashes in paths as follows: For path: /docs, the menu_item_name is
    docs. For path: /metrics/users, the menu_item_name is metrics.users. [NOTE] ----
    Red Hat Developer Hub supports up to 3 levels of nested menu items. ---- ## Binding
    to existing plugins You can bind to existing plugins and their routes, and declare
    new targets sourced from dynamic plugins as shown in the following routeBindings
    configuration: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name routeBindings: targets: # A new bind target # (Optional): Defaults
    to importName. Explicit name of the plugin that exposes the bind target. - name:
    barPlugin # (Required): Explicit import name that reference a BackstagePlugin<{}>
    implementation. importName: barPlugin # # (Optional): Same as key in `scalprum.exposedModules`
    key in'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:37:34.166776'
    uuid: 202de1a7-28cb-4ffc-aea7-9e466b520b00
  response: The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in your plugin's package.json. This ensures your dynamic plugin loads correctly
    during runtime.
  user_input: what does the scalphrum.name value have to match?
- context:
  - 'the `package.json` file of the plugin. module: CustomModule bindings: - bindTarget:
    "barPlugin.externalRoutes" # (Required): One of the supported or imported bind
    targets bindMap: # A required map of route bindings similar to `bind` function
    options headerLink: "fooPlugin.routes.root" ``` To configure routeBindings, complete
    the following steps: 1. Define new targets using routeBindings.targets. Set the
    required importName to a BackstagePlugin<{}> implementation. 2. Declare route
    bindings using the routeBindings.bindings field by setting bindTarget to the name
    of the target to bind to. This is a dynamic or static target, such as: * catalogPlugin.externalRoutes
    * catalogImportPlugin.externalRoutes * techdocsPlugin.externalRoutes * scaffolderPlugin.externalRoutes
    You can extend existing pages with additional content using mount points, which
    are predefined identifiers available throughout the application. ## Using mount
    points Mount points are defined identifiers available across Red Hat Developer
    Hub. You can use these points to extend existing pages with additional content.
    ### Customizing entity page You can extend catalog components and additional views.
    The available mount points include the following: [NOTE] ---- Mount points within
    catalog such as entity.page. are rendered as tabs and become visible only if at
    least one plugin contributes to them, or if they can render static content. ----
    Each entity.page. mount point contains the following variations: /context type
    that serves to create React contexts /cards type for regular React components
    The following is an example of the overall configuration structure of a mount
    point: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name mountPoints: # (Optional): Uses existing mount points - mountPoint:
    <mountPointName>/[cards|context] module: CustomModule importName: FooPluginPage
    config: # (Optional): Allows you to pass additional configuration to the component
    layout: {} # Used only in `/cards` type which renders visible content # Use only
    in `/cards` type which renders visible content. `if` is passed to `<EntitySwitch.Case
    if={<here>}`. if: allOf|anyOf|oneOf: - isMyPluginAvailable - isKind: component
    - isType: service - hasAnnotation: annotationKey props: {} # Useful when you are
    passing additional data to the component ``` The available conditions include:
    allOf: All conditions must be met anyOf: At least one condition must be met oneOf:
    Only one condition must be met Conditions are: isKind: Accepts a string or a list
    of string with entity kinds. For example isKind: component renders the component
    only for entity of kind: Component. isType: Accepts a string or a list of string
    with entity types. For example isType: service renders the component only for
    entities of spec.type: ''service''. hasAnnotation: Accepts a string or a list
    of string with annotation keys. For example hasAnnotation: my annotation renders
    the component only for entities that have defined metadata.annotations[''my annotation''].
    Condition imported from the module of the plugin: Must be function name exported
    from the same module within the plugin. For example isMyPluginAvailable renders
    the component only if isMyPluginAvailable function returns true. The function
    must have the following signature: (e: Entity) => boolean. The entity page supports
    adding more items to the context menu at the top right of the page. The exported
    component is a form of dialog wrapper component that accepts an open boolean property
    and an onClose event handler property as shown in the following example: ```yaml
    export type SimpleDialogProps = { open: boolean; onClose: () => void; }; ``` You
    can configure the context menu entry using the props configuration entry for the
    mount point. The title and icon properties sets the text and icon of the menu
    item. You can use any system icon or icon added through a dynamic plugin. The
    following is an example configuration: ```yaml # dynamic plugins config.yaml plugins:
    plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins: frontend:
    my dynamic plugin package: appIcons: name: dialogIcon importName: DialogIcon mountPoints:
    mountPoint: entity.context.menu importName: SimpleDialog config: props: title:
    Open Simple Dialog icon: dialogIcon ``` ### Adding application header You can
    customize global headers by specifying configurations in the app-config.yaml file
    as shown in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name mountPoints: - mountPoint: application/header
    # Adds the header as a global header importName: <header_component> # Specifies
    the component exported by the global header plugin config: position: above-main-content
    # Supported values: (`above-main-content`| above-sidebar`) ``` [NOTE] ---- To
    configure multiple global headers at different positions, add entries to the mountPoints
    field. ---- ### Adding application listeners You can add application listeners
    using the application/listener mount point as shown in the following example:
    ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name mountPoints: - mountPoint: application/listener importName: <exported listener
    component> ``` [NOTE] ---- You can configure multiple application listeners by
    adding entries to the mountPoints field. ---- ### Adding application providers
    You can add application providers using the application/provider mount point.
    You can use a mount point to configure a context provider as shown in the following
    example: ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The
    plugin package name dynamicRoutes: - path: /<route> importName: Component # The
    component to load on the route mountPoints: - mountPoint: application/provider
    importName: <exported provider component> ``` [NOTE] ---- 1. You can configure
    multiple application providers by adding entries to the mountPoints field. 2.
    The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in the package.json file of your plugin. This ensures your dynamic plugin
    loads correctly at runtime. ---- ## Customizing and extending entity tabs You
    can customize and extend the set of tabs using the entityTabs configuration as
    follows: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name entityTabs: # Specify a new tab - path: /new-path title: My New Tab
    mountPoint: entity.page.my-new-tab # Change an existing tab''s title or mount
    point - path: / title: General mountPoint: entity.page.overview # Specify the
    sub-path route in the catalog where this tab is available - path: "/pr" title:
    "Changed Pull/Merge Requests" # Specify the title you want to display priority:
    1 # The base mount point name available on the tab. This name expands to create
    two mount points per tab, with` /context` and with `/cards` mountPoint: "entity.page.pull-requests"
    - path: "/"'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:37:45.499010'
    uuid: b0dc8e73-6f36-4a68-82db-fb6fc29a03f7
  response: To ensure your dynamic plugin loads correctly at runtime, the package_name
    key under dynamicPlugins.frontend must match the scalprum.name value in the package.json
    file of your plugin.
  user_input: Why my dynamic plugin not loading, what does the package.json file have
    to do with the package_name key?
- context:
  - 'the `package.json` file of the plugin. module: CustomModule bindings: - bindTarget:
    "barPlugin.externalRoutes" # (Required): One of the supported or imported bind
    targets bindMap: # A required map of route bindings similar to `bind` function
    options headerLink: "fooPlugin.routes.root" ``` To configure routeBindings, complete
    the following steps: 1. Define new targets using routeBindings.targets. Set the
    required importName to a BackstagePlugin<{}> implementation. 2. Declare route
    bindings using the routeBindings.bindings field by setting bindTarget to the name
    of the target to bind to. This is a dynamic or static target, such as: * catalogPlugin.externalRoutes
    * catalogImportPlugin.externalRoutes * techdocsPlugin.externalRoutes * scaffolderPlugin.externalRoutes
    You can extend existing pages with additional content using mount points, which
    are predefined identifiers available throughout the application. ## Using mount
    points Mount points are defined identifiers available across Red Hat Developer
    Hub. You can use these points to extend existing pages with additional content.
    ### Customizing entity page You can extend catalog components and additional views.
    The available mount points include the following: [NOTE] ---- Mount points within
    catalog such as entity.page. are rendered as tabs and become visible only if at
    least one plugin contributes to them, or if they can render static content. ----
    Each entity.page. mount point contains the following variations: /context type
    that serves to create React contexts /cards type for regular React components
    The following is an example of the overall configuration structure of a mount
    point: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name mountPoints: # (Optional): Uses existing mount points - mountPoint:
    <mountPointName>/[cards|context] module: CustomModule importName: FooPluginPage
    config: # (Optional): Allows you to pass additional configuration to the component
    layout: {} # Used only in `/cards` type which renders visible content # Use only
    in `/cards` type which renders visible content. `if` is passed to `<EntitySwitch.Case
    if={<here>}`. if: allOf|anyOf|oneOf: - isMyPluginAvailable - isKind: component
    - isType: service - hasAnnotation: annotationKey props: {} # Useful when you are
    passing additional data to the component ``` The available conditions include:
    allOf: All conditions must be met anyOf: At least one condition must be met oneOf:
    Only one condition must be met Conditions are: isKind: Accepts a string or a list
    of string with entity kinds. For example isKind: component renders the component
    only for entity of kind: Component. isType: Accepts a string or a list of string
    with entity types. For example isType: service renders the component only for
    entities of spec.type: ''service''. hasAnnotation: Accepts a string or a list
    of string with annotation keys. For example hasAnnotation: my annotation renders
    the component only for entities that have defined metadata.annotations[''my annotation''].
    Condition imported from the module of the plugin: Must be function name exported
    from the same module within the plugin. For example isMyPluginAvailable renders
    the component only if isMyPluginAvailable function returns true. The function
    must have the following signature: (e: Entity) => boolean. The entity page supports
    adding more items to the context menu at the top right of the page. The exported
    component is a form of dialog wrapper component that accepts an open boolean property
    and an onClose event handler property as shown in the following example: ```yaml
    export type SimpleDialogProps = { open: boolean; onClose: () => void; }; ``` You
    can configure the context menu entry using the props configuration entry for the
    mount point. The title and icon properties sets the text and icon of the menu
    item. You can use any system icon or icon added through a dynamic plugin. The
    following is an example configuration: ```yaml # dynamic plugins config.yaml plugins:
    plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins: frontend:
    my dynamic plugin package: appIcons: name: dialogIcon importName: DialogIcon mountPoints:
    mountPoint: entity.context.menu importName: SimpleDialog config: props: title:
    Open Simple Dialog icon: dialogIcon ``` ### Adding application header You can
    customize global headers by specifying configurations in the app-config.yaml file
    as shown in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name mountPoints: - mountPoint: application/header
    # Adds the header as a global header importName: <header_component> # Specifies
    the component exported by the global header plugin config: position: above-main-content
    # Supported values: (`above-main-content`| above-sidebar`) ``` [NOTE] ---- To
    configure multiple global headers at different positions, add entries to the mountPoints
    field. ---- ### Adding application listeners You can add application listeners
    using the application/listener mount point as shown in the following example:
    ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name mountPoints: - mountPoint: application/listener importName: <exported listener
    component> ``` [NOTE] ---- You can configure multiple application listeners by
    adding entries to the mountPoints field. ---- ### Adding application providers
    You can add application providers using the application/provider mount point.
    You can use a mount point to configure a context provider as shown in the following
    example: ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The
    plugin package name dynamicRoutes: - path: /<route> importName: Component # The
    component to load on the route mountPoints: - mountPoint: application/provider
    importName: <exported provider component> ``` [NOTE] ---- 1. You can configure
    multiple application providers by adding entries to the mountPoints field. 2.
    The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in the package.json file of your plugin. This ensures your dynamic plugin
    loads correctly at runtime. ---- ## Customizing and extending entity tabs You
    can customize and extend the set of tabs using the entityTabs configuration as
    follows: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name entityTabs: # Specify a new tab - path: /new-path title: My New Tab
    mountPoint: entity.page.my-new-tab # Change an existing tab''s title or mount
    point - path: / title: General mountPoint: entity.page.overview # Specify the
    sub-path route in the catalog where this tab is available - path: "/pr" title:
    "Changed Pull/Merge Requests" # Specify the title you want to display priority:
    1 # The base mount point name available on the tab. This name expands to create
    two mount points per tab, with` /context` and with `/cards` mountPoint: "entity.page.pull-requests"
    - path: "/"'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:37:58.411087'
    uuid: 78039286-df91-4591-a1dd-74da61585304
  response: 'You can use mount points, which are defined identifiers available across
    Red Hat Developer Hub, to extend existing pages with additional content. To customize
    an entity page, you can use mount points like `entity.page.`, which are rendered
    as tabs and become visible if a plugin contributes to them. These mount points
    contain `/context` and `/cards` variations. The configuration is specified in
    a YAML file under the `mountPoints` key for a plugin. To control when the content
    renders, you can use the `if` key, which supports `allOf` (all conditions must
    be met), `anyOf` (at least one condition must be met), and `oneOf` (only one condition
    must be met). The specific conditions available include: `isKind`, which accepts
    entity kinds; `isType`, which accepts entity types; `hasAnnotation`, which accepts
    annotation keys; and a condition imported from the plugin''s module, which must
    be a function with the signature `(e: Entity) => boolean`.'
  user_input: How can I use mount points in Red Hat Developer Hub to extend an existing
    entity page with additional content, and what are the available conditions like
    `isKind` or `hasAnnotation` for controlling when that content is displayed?
- context:
  - 'the `package.json` file of the plugin. module: CustomModule bindings: - bindTarget:
    "barPlugin.externalRoutes" # (Required): One of the supported or imported bind
    targets bindMap: # A required map of route bindings similar to `bind` function
    options headerLink: "fooPlugin.routes.root" ``` To configure routeBindings, complete
    the following steps: 1. Define new targets using routeBindings.targets. Set the
    required importName to a BackstagePlugin<{}> implementation. 2. Declare route
    bindings using the routeBindings.bindings field by setting bindTarget to the name
    of the target to bind to. This is a dynamic or static target, such as: * catalogPlugin.externalRoutes
    * catalogImportPlugin.externalRoutes * techdocsPlugin.externalRoutes * scaffolderPlugin.externalRoutes
    You can extend existing pages with additional content using mount points, which
    are predefined identifiers available throughout the application. ## Using mount
    points Mount points are defined identifiers available across Red Hat Developer
    Hub. You can use these points to extend existing pages with additional content.
    ### Customizing entity page You can extend catalog components and additional views.
    The available mount points include the following: [NOTE] ---- Mount points within
    catalog such as entity.page. are rendered as tabs and become visible only if at
    least one plugin contributes to them, or if they can render static content. ----
    Each entity.page. mount point contains the following variations: /context type
    that serves to create React contexts /cards type for regular React components
    The following is an example of the overall configuration structure of a mount
    point: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name mountPoints: # (Optional): Uses existing mount points - mountPoint:
    <mountPointName>/[cards|context] module: CustomModule importName: FooPluginPage
    config: # (Optional): Allows you to pass additional configuration to the component
    layout: {} # Used only in `/cards` type which renders visible content # Use only
    in `/cards` type which renders visible content. `if` is passed to `<EntitySwitch.Case
    if={<here>}`. if: allOf|anyOf|oneOf: - isMyPluginAvailable - isKind: component
    - isType: service - hasAnnotation: annotationKey props: {} # Useful when you are
    passing additional data to the component ``` The available conditions include:
    allOf: All conditions must be met anyOf: At least one condition must be met oneOf:
    Only one condition must be met Conditions are: isKind: Accepts a string or a list
    of string with entity kinds. For example isKind: component renders the component
    only for entity of kind: Component. isType: Accepts a string or a list of string
    with entity types. For example isType: service renders the component only for
    entities of spec.type: ''service''. hasAnnotation: Accepts a string or a list
    of string with annotation keys. For example hasAnnotation: my annotation renders
    the component only for entities that have defined metadata.annotations[''my annotation''].
    Condition imported from the module of the plugin: Must be function name exported
    from the same module within the plugin. For example isMyPluginAvailable renders
    the component only if isMyPluginAvailable function returns true. The function
    must have the following signature: (e: Entity) => boolean. The entity page supports
    adding more items to the context menu at the top right of the page. The exported
    component is a form of dialog wrapper component that accepts an open boolean property
    and an onClose event handler property as shown in the following example: ```yaml
    export type SimpleDialogProps = { open: boolean; onClose: () => void; }; ``` You
    can configure the context menu entry using the props configuration entry for the
    mount point. The title and icon properties sets the text and icon of the menu
    item. You can use any system icon or icon added through a dynamic plugin. The
    following is an example configuration: ```yaml # dynamic plugins config.yaml plugins:
    plugin: <plugin_path_or_url> disabled: false pluginConfig: dynamicPlugins: frontend:
    my dynamic plugin package: appIcons: name: dialogIcon importName: DialogIcon mountPoints:
    mountPoint: entity.context.menu importName: SimpleDialog config: props: title:
    Open Simple Dialog icon: dialogIcon ``` ### Adding application header You can
    customize global headers by specifying configurations in the app-config.yaml file
    as shown in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name mountPoints: - mountPoint: application/header
    # Adds the header as a global header importName: <header_component> # Specifies
    the component exported by the global header plugin config: position: above-main-content
    # Supported values: (`above-main-content`| above-sidebar`) ``` [NOTE] ---- To
    configure multiple global headers at different positions, add entries to the mountPoints
    field. ---- ### Adding application listeners You can add application listeners
    using the application/listener mount point as shown in the following example:
    ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name mountPoints: - mountPoint: application/listener importName: <exported listener
    component> ``` [NOTE] ---- You can configure multiple application listeners by
    adding entries to the mountPoints field. ---- ### Adding application providers
    You can add application providers using the application/provider mount point.
    You can use a mount point to configure a context provider as shown in the following
    example: ```yaml # app-config.yaml dynamicPlugins: frontend: my-plugin: # The
    plugin package name dynamicRoutes: - path: /<route> importName: Component # The
    component to load on the route mountPoints: - mountPoint: application/provider
    importName: <exported provider component> ``` [NOTE] ---- 1. You can configure
    multiple application providers by adding entries to the mountPoints field. 2.
    The package_name key under dynamicPlugins.frontend must match the scalprum.name
    value in the package.json file of your plugin. This ensures your dynamic plugin
    loads correctly at runtime. ---- ## Customizing and extending entity tabs You
    can customize and extend the set of tabs using the entityTabs configuration as
    follows: ```yaml # dynamic-plugins-config.yaml plugins: - plugin: <plugin_path_or_url>
    disabled: false pluginConfig: dynamicPlugins: frontend: my-plugin: # The plugin
    package name entityTabs: # Specify a new tab - path: /new-path title: My New Tab
    mountPoint: entity.page.my-new-tab # Change an existing tab''s title or mount
    point - path: / title: General mountPoint: entity.page.overview # Specify the
    sub-path route in the catalog where this tab is available - path: "/pr" title:
    "Changed Pull/Merge Requests" # Specify the title you want to display priority:
    1 # The base mount point name available on the tab. This name expands to create
    two mount points per tab, with` /context` and with `/cards` mountPoint: "entity.page.pull-requests"
    - path: "/"'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:38:15.581109'
    uuid: 3fde958c-a837-4a62-bc92-70021560d5ef
  response: 'Mount points are defined identifiers available across Red Hat Developer
    Hub that you can use to extend existing pages with additional content. You can
    use them in several ways:


    *   **Customizing entity page**: You can extend catalog components and additional
    views. Mount points within the catalog, such as `entity.page.`, are rendered as
    tabs. The entity page also supports adding more items to the context menu at the
    top right of the page using the `entity.context.menu` mount point.

    *   **Adding application header**: You can customize global headers by specifying
    the `application/header` mount point in the `app-config.yaml` file.

    *   **Adding application listeners**: You can add application listeners by using
    the `application/listener` mount point.

    *   **Adding application providers**: You can add application providers, such
    as a context provider, using the `application/provider` mount point.'
  user_input: I'm trying to understand how we can use these mounte poynts to extend
    our Red Hat Developer Hub, so can you explane all the differnt places we can use
    them and what they do, like for the entity page, application headers, and other
    aplication-level stuff?
- context:
  - 'title: "Changed Overview" mountPoint: "entity.page.overview" # Specify the order
    of tabs. The tabs with higher priority values appear first priority: -6 ``` You
    can configure dynamic front-end plugins to target the mount points exposed by
    the entityTabs configuration. The following are the default catalog entity routes
    in the default order: [NOTE] ---- Mount points within Catalog such as `entity.page.*`
    are rendered as tabs and become visible only if at least one plugin contributes
    to them, or if they can render static content. ---- ## Using a custom SignInPage
    component In Red Hat Developer Hub (RHDH), the SignInPage component manages the
    authentication flow of the application. This component connects one or more authentication
    providers to the sign-in process. By default, Developer Hub uses a static SignInPage
    that supports all built-in authentication providers. When you configure a custom
    SignInPage: The system loads the specified importName component from your dynamic
    plugin. The component returns a configured SignInPage that connects the desired
    authentication provider factories. Only one signInPage is specified for the application
    at a time. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name
    signInPage: importName: CustomSignInPage ``` [NOTE] ---- The package_name specified
    under dynamicPlugins.frontend must match the scalprum.name value in the package.json
    file of your plugin to ensure the dynamic plugin loads correctly at runtime. The
    module field is optional and allows specifying which set of assets must be accessed
    within the dynamic plugin. By default, the system uses the PluginRoot module.
    ---- ## Providing custom Scaffolder field extensions The Scaffolder component
    in Red Hat Developer Hub (RHDH) enables users to create software components using
    templates through a guided wizard. You can extend the functionality of the Scaffolder
    by providing custom form fields as dynamic plugins using the scaffolderFieldExtensions
    configuration. Custom field extensions allow you to add specialized form fields
    that capture domain-specific data during the scaffolding process, such as environment
    selectors, input validations, or repository checks. When you configure custom
    scaffolder field extensions: The dynamic plugin exposes the field extension component
    using createScaffolderFieldExtension. Each field extension requires a unique importName
    for registration. You register multiple field extensions by listing each in the
    configuration. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name scaffolderFieldExtensions: - importName: MyNewFieldExtension # References
    the exported scaffolder field extension component from your plugin ``` [NOTE]
    ---- The module field is optional and specifies which set of assets to access
    within the plugin. By default, the system uses the PluginRoot module, consistent
    with the scalprum.exposedModules key in the package.json file of your package.
    ---- ## Providing additional utility APIs If a dynamic plugin exports the plugin
    object returned by createPlugin, it is supplied to the createApp API. All API
    factories exported by the plugin are automatically registered and available in
    the front-end application. You can add an entry to the dynamicPlugins.frontend
    configuration when a dynamic plugin contains only API factories as shown in the
    following example: ```yaml # app config.yaml dynamicPlugins: frontend: my dynamic
    plugin package with api factories: {} ``` However, when the dynamic plugin is
    not exporting the plugin object, explicitly configure each API factory that must
    be registered with the createApp API using the apiFactories configuration as shown
    in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name apiFactories: # (Optional): Specify the import
    name that references a `AnyApiFactory<{}>` implementation. (Defaults to `default`
    export) - importName: BarApi # (Optional): An argument which specifies the assets
    you want to access within the plugin. If not provided, the default module named
    `PluginRoot` is used module: CustomModule ``` The API factories initialized by
    the Developer Hub application shell are overridden by an API factory provided
    by a dynamic plugin by specifying the same API ref ID. A dynamic plugin can export
    AnyApiFactory<{}> to cater for some specific use case as shown in the following
    example: ```yaml export const customScmAuthApiFactory = createApiFactory({ api:
    scmAuthApiRef, deps: { githubAuthApi: githubAuthApiRef }, factory: ({ githubAuthApi
    }) => ScmAuth.merge( ScmAuth.forGithub(githubAuthApi, { host: "github.someinstance.com"
    }), ScmAuth.forGithub(githubAuthApi, { host: "github.someotherinstance.com", }),
    ), }); ``` The corresponding configuration which overrides the default ScmAuth
    API factory that Developer Hub defaults to is as shown in the following example:
    ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name apiFactories:
    - importName: customScmAuthApiFactory ``` ## Adding custom authentication provider
    settings You can install new authentication providers from a dynamic plugin that
    either adds additional configuration support for an existing provider or adds
    a new authentication provider. These providers are listed in the user settings
    section under the Authentication Providers tab. You can use the providerSettings
    configuration to add entries for an authentication provider from a dynamic plugin,
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name providerSettings: # The title for the authentication
    provider shown above the user''s profile image if available - title: My Custom
    Auth Provider # The description of the authentication provider description: Sign
    in using My Custom Auth Provider # The ID of the authentication provider as provided
    to the `createApiRef` API call. provider: core.auth.my-custom-auth-provider ```
    [NOTE] ---- provider looks up the corresponding API factory for the authentication
    provider to connect the provider''s Sign In/Sign Out button. ---- ## Providing
    custom TechDocs addons If a plugin provides multiple addons, each techdocsAddon
    entry specifies a unique importName corresponding to the addon. Front-end plugins
    exposes the TechDocs addon component using the techdocsAddons configuration as
    shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin: #
    The plugin package name techdocsAddons: - importName: ExampleAddon # The exported
    Addon component config: props: ... # (Optional): React props to pass to the addon
    ``` ## Customizing Red Hat Developer Hub theme You can customize Developer Hub
    themes from a dynamic plugin with various configurations as shown in the following
    example: ```yaml import { lightTheme } from ''./lightTheme''; import { darkTheme
    } from ''./darkTheme''; import { UnifiedThemeProvider } from ''@backstage/theme'';
    export const lightThemeProvider = ({ children }: { children: ReactNode }) => (
    <UnifiedThemeProvider theme={lightTheme} children={children} /> ); export const
    darkThemeProvider = ({ children }: { children: ReactNode }) => ('
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:38:26.646709'
    uuid: cfa36d18-3ea9-42ab-82eb-2095b89d2537
  response: 'In Red Hat Developer Hub (RHDH), you can extend the functionality of
    the Scaffolder component by providing custom form fields as dynamic plugins using
    the `scaffolderFieldExtensions` configuration. These custom extensions allow you
    to add specialized form fields for capturing domain-specific data like environment
    selectors, input validations, or repository checks. To configure them, the dynamic
    plugin must expose the field extension component using `createScaffolderFieldExtension`,
    and each extension needs a unique `importName` for registration. You can register
    multiple field extensions by listing each one in the configuration, as shown in
    the example: `dynamicPlugins: frontend: my-plugin: scaffolderFieldExtensions:
    - importName: MyNewFieldExtension`.'
  user_input: How do I provide custom field extensions for the Scaffolder component
    in Red Hat Developer Hub?
- context:
  - 'title: "Changed Overview" mountPoint: "entity.page.overview" # Specify the order
    of tabs. The tabs with higher priority values appear first priority: -6 ``` You
    can configure dynamic front-end plugins to target the mount points exposed by
    the entityTabs configuration. The following are the default catalog entity routes
    in the default order: [NOTE] ---- Mount points within Catalog such as `entity.page.*`
    are rendered as tabs and become visible only if at least one plugin contributes
    to them, or if they can render static content. ---- ## Using a custom SignInPage
    component In Red Hat Developer Hub (RHDH), the SignInPage component manages the
    authentication flow of the application. This component connects one or more authentication
    providers to the sign-in process. By default, Developer Hub uses a static SignInPage
    that supports all built-in authentication providers. When you configure a custom
    SignInPage: The system loads the specified importName component from your dynamic
    plugin. The component returns a configured SignInPage that connects the desired
    authentication provider factories. Only one signInPage is specified for the application
    at a time. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name
    signInPage: importName: CustomSignInPage ``` [NOTE] ---- The package_name specified
    under dynamicPlugins.frontend must match the scalprum.name value in the package.json
    file of your plugin to ensure the dynamic plugin loads correctly at runtime. The
    module field is optional and allows specifying which set of assets must be accessed
    within the dynamic plugin. By default, the system uses the PluginRoot module.
    ---- ## Providing custom Scaffolder field extensions The Scaffolder component
    in Red Hat Developer Hub (RHDH) enables users to create software components using
    templates through a guided wizard. You can extend the functionality of the Scaffolder
    by providing custom form fields as dynamic plugins using the scaffolderFieldExtensions
    configuration. Custom field extensions allow you to add specialized form fields
    that capture domain-specific data during the scaffolding process, such as environment
    selectors, input validations, or repository checks. When you configure custom
    scaffolder field extensions: The dynamic plugin exposes the field extension component
    using createScaffolderFieldExtension. Each field extension requires a unique importName
    for registration. You register multiple field extensions by listing each in the
    configuration. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name scaffolderFieldExtensions: - importName: MyNewFieldExtension # References
    the exported scaffolder field extension component from your plugin ``` [NOTE]
    ---- The module field is optional and specifies which set of assets to access
    within the plugin. By default, the system uses the PluginRoot module, consistent
    with the scalprum.exposedModules key in the package.json file of your package.
    ---- ## Providing additional utility APIs If a dynamic plugin exports the plugin
    object returned by createPlugin, it is supplied to the createApp API. All API
    factories exported by the plugin are automatically registered and available in
    the front-end application. You can add an entry to the dynamicPlugins.frontend
    configuration when a dynamic plugin contains only API factories as shown in the
    following example: ```yaml # app config.yaml dynamicPlugins: frontend: my dynamic
    plugin package with api factories: {} ``` However, when the dynamic plugin is
    not exporting the plugin object, explicitly configure each API factory that must
    be registered with the createApp API using the apiFactories configuration as shown
    in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name apiFactories: # (Optional): Specify the import
    name that references a `AnyApiFactory<{}>` implementation. (Defaults to `default`
    export) - importName: BarApi # (Optional): An argument which specifies the assets
    you want to access within the plugin. If not provided, the default module named
    `PluginRoot` is used module: CustomModule ``` The API factories initialized by
    the Developer Hub application shell are overridden by an API factory provided
    by a dynamic plugin by specifying the same API ref ID. A dynamic plugin can export
    AnyApiFactory<{}> to cater for some specific use case as shown in the following
    example: ```yaml export const customScmAuthApiFactory = createApiFactory({ api:
    scmAuthApiRef, deps: { githubAuthApi: githubAuthApiRef }, factory: ({ githubAuthApi
    }) => ScmAuth.merge( ScmAuth.forGithub(githubAuthApi, { host: "github.someinstance.com"
    }), ScmAuth.forGithub(githubAuthApi, { host: "github.someotherinstance.com", }),
    ), }); ``` The corresponding configuration which overrides the default ScmAuth
    API factory that Developer Hub defaults to is as shown in the following example:
    ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name apiFactories:
    - importName: customScmAuthApiFactory ``` ## Adding custom authentication provider
    settings You can install new authentication providers from a dynamic plugin that
    either adds additional configuration support for an existing provider or adds
    a new authentication provider. These providers are listed in the user settings
    section under the Authentication Providers tab. You can use the providerSettings
    configuration to add entries for an authentication provider from a dynamic plugin,
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name providerSettings: # The title for the authentication
    provider shown above the user''s profile image if available - title: My Custom
    Auth Provider # The description of the authentication provider description: Sign
    in using My Custom Auth Provider # The ID of the authentication provider as provided
    to the `createApiRef` API call. provider: core.auth.my-custom-auth-provider ```
    [NOTE] ---- provider looks up the corresponding API factory for the authentication
    provider to connect the provider''s Sign In/Sign Out button. ---- ## Providing
    custom TechDocs addons If a plugin provides multiple addons, each techdocsAddon
    entry specifies a unique importName corresponding to the addon. Front-end plugins
    exposes the TechDocs addon component using the techdocsAddons configuration as
    shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin: #
    The plugin package name techdocsAddons: - importName: ExampleAddon # The exported
    Addon component config: props: ... # (Optional): React props to pass to the addon
    ``` ## Customizing Red Hat Developer Hub theme You can customize Developer Hub
    themes from a dynamic plugin with various configurations as shown in the following
    example: ```yaml import { lightTheme } from ''./lightTheme''; import { darkTheme
    } from ''./darkTheme''; import { UnifiedThemeProvider } from ''@backstage/theme'';
    export const lightThemeProvider = ({ children }: { children: ReactNode }) => (
    <UnifiedThemeProvider theme={lightTheme} children={children} /> ); export const
    darkThemeProvider = ({ children }: { children: ReactNode }) => ('
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:38:35.824971'
    uuid: 3445da66-844f-4719-be72-899a9bb79cf4
  response: 'You can override the default ScmAuth API factory that Developer Hub defaults
    to by using a dynamic plugin. The configuration is as follows: `dynamicPlugins:
    frontend: my-plugin: # The plugin package name apiFactories: - importName: customScmAuthApiFactory`.'
  user_input: how do i overide the ScmAuth api?
- context:
  - 'title: "Changed Overview" mountPoint: "entity.page.overview" # Specify the order
    of tabs. The tabs with higher priority values appear first priority: -6 ``` You
    can configure dynamic front-end plugins to target the mount points exposed by
    the entityTabs configuration. The following are the default catalog entity routes
    in the default order: [NOTE] ---- Mount points within Catalog such as `entity.page.*`
    are rendered as tabs and become visible only if at least one plugin contributes
    to them, or if they can render static content. ---- ## Using a custom SignInPage
    component In Red Hat Developer Hub (RHDH), the SignInPage component manages the
    authentication flow of the application. This component connects one or more authentication
    providers to the sign-in process. By default, Developer Hub uses a static SignInPage
    that supports all built-in authentication providers. When you configure a custom
    SignInPage: The system loads the specified importName component from your dynamic
    plugin. The component returns a configured SignInPage that connects the desired
    authentication provider factories. Only one signInPage is specified for the application
    at a time. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name
    signInPage: importName: CustomSignInPage ``` [NOTE] ---- The package_name specified
    under dynamicPlugins.frontend must match the scalprum.name value in the package.json
    file of your plugin to ensure the dynamic plugin loads correctly at runtime. The
    module field is optional and allows specifying which set of assets must be accessed
    within the dynamic plugin. By default, the system uses the PluginRoot module.
    ---- ## Providing custom Scaffolder field extensions The Scaffolder component
    in Red Hat Developer Hub (RHDH) enables users to create software components using
    templates through a guided wizard. You can extend the functionality of the Scaffolder
    by providing custom form fields as dynamic plugins using the scaffolderFieldExtensions
    configuration. Custom field extensions allow you to add specialized form fields
    that capture domain-specific data during the scaffolding process, such as environment
    selectors, input validations, or repository checks. When you configure custom
    scaffolder field extensions: The dynamic plugin exposes the field extension component
    using createScaffolderFieldExtension. Each field extension requires a unique importName
    for registration. You register multiple field extensions by listing each in the
    configuration. ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package
    name scaffolderFieldExtensions: - importName: MyNewFieldExtension # References
    the exported scaffolder field extension component from your plugin ``` [NOTE]
    ---- The module field is optional and specifies which set of assets to access
    within the plugin. By default, the system uses the PluginRoot module, consistent
    with the scalprum.exposedModules key in the package.json file of your package.
    ---- ## Providing additional utility APIs If a dynamic plugin exports the plugin
    object returned by createPlugin, it is supplied to the createApp API. All API
    factories exported by the plugin are automatically registered and available in
    the front-end application. You can add an entry to the dynamicPlugins.frontend
    configuration when a dynamic plugin contains only API factories as shown in the
    following example: ```yaml # app config.yaml dynamicPlugins: frontend: my dynamic
    plugin package with api factories: {} ``` However, when the dynamic plugin is
    not exporting the plugin object, explicitly configure each API factory that must
    be registered with the createApp API using the apiFactories configuration as shown
    in the following example: ```yaml # app-config.yaml dynamicPlugins: frontend:
    my-plugin: # The plugin package name apiFactories: # (Optional): Specify the import
    name that references a `AnyApiFactory<{}>` implementation. (Defaults to `default`
    export) - importName: BarApi # (Optional): An argument which specifies the assets
    you want to access within the plugin. If not provided, the default module named
    `PluginRoot` is used module: CustomModule ``` The API factories initialized by
    the Developer Hub application shell are overridden by an API factory provided
    by a dynamic plugin by specifying the same API ref ID. A dynamic plugin can export
    AnyApiFactory<{}> to cater for some specific use case as shown in the following
    example: ```yaml export const customScmAuthApiFactory = createApiFactory({ api:
    scmAuthApiRef, deps: { githubAuthApi: githubAuthApiRef }, factory: ({ githubAuthApi
    }) => ScmAuth.merge( ScmAuth.forGithub(githubAuthApi, { host: "github.someinstance.com"
    }), ScmAuth.forGithub(githubAuthApi, { host: "github.someotherinstance.com", }),
    ), }); ``` The corresponding configuration which overrides the default ScmAuth
    API factory that Developer Hub defaults to is as shown in the following example:
    ```yaml dynamicPlugins: frontend: my-plugin: # The plugin package name apiFactories:
    - importName: customScmAuthApiFactory ``` ## Adding custom authentication provider
    settings You can install new authentication providers from a dynamic plugin that
    either adds additional configuration support for an existing provider or adds
    a new authentication provider. These providers are listed in the user settings
    section under the Authentication Providers tab. You can use the providerSettings
    configuration to add entries for an authentication provider from a dynamic plugin,
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name providerSettings: # The title for the authentication
    provider shown above the user''s profile image if available - title: My Custom
    Auth Provider # The description of the authentication provider description: Sign
    in using My Custom Auth Provider # The ID of the authentication provider as provided
    to the `createApiRef` API call. provider: core.auth.my-custom-auth-provider ```
    [NOTE] ---- provider looks up the corresponding API factory for the authentication
    provider to connect the provider''s Sign In/Sign Out button. ---- ## Providing
    custom TechDocs addons If a plugin provides multiple addons, each techdocsAddon
    entry specifies a unique importName corresponding to the addon. Front-end plugins
    exposes the TechDocs addon component using the techdocsAddons configuration as
    shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin: #
    The plugin package name techdocsAddons: - importName: ExampleAddon # The exported
    Addon component config: props: ... # (Optional): React props to pass to the addon
    ``` ## Customizing Red Hat Developer Hub theme You can customize Developer Hub
    themes from a dynamic plugin with various configurations as shown in the following
    example: ```yaml import { lightTheme } from ''./lightTheme''; import { darkTheme
    } from ''./darkTheme''; import { UnifiedThemeProvider } from ''@backstage/theme'';
    export const lightThemeProvider = ({ children }: { children: ReactNode }) => (
    <UnifiedThemeProvider theme={lightTheme} children={children} /> ); export const
    darkThemeProvider = ({ children }: { children: ReactNode }) => ('
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:38:47.282932'
    uuid: 63f04280-7c65-47d2-9814-e679edab6c00
  response: An API factory provided by a dynamic plugin can override the factories
    initialized by the Developer Hub application shell by specifying the same API
    ref ID. A dynamic plugin can export an `AnyApiFactory<{}>`, such as one created
    with `createApiFactory` for a specific use case. The corresponding configuration
    under `dynamicPlugins.frontend` must then list this factory in the `apiFactories`
    section, specifying its `importName`. For example, a `customScmAuthApiFactory`
    can be configured to override the default ScmAuth API factory.
  user_input: How can a dynamic plugin use `createApiFactory` to override a default
    API factory?
- context:
  - '[NOTE] ---- If you disable the Extensions feature plugins, the Catalog and Installed
    tabs will also be removed. You can still view installed plugins by clicking on
    Administration > Extensions. ---- ## Extensions. You have configured RBAC to allow
    the current user to manage plugin configuration. 1. Navigate to Extensions. 2.
    Select a plugin to install. 3. Click the Install button. ![extensions install
    plugin 1] The code editor is displayed which displays the plugin default configuration.
    4. Update the plugin configuration, if necessary. ![extensions install plugin
    2] 5. Click Install 6. To view the plugins that require a restart, click View
    plugins in the alert message. ![extensions install plugin 3] 7. Restart your RHDH
    application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Actions button is displayed.
    ### Enabling and disabling plugins by using Extensions You have configured RHDH
    to allow plugins installation from Extensions. You have configured RBAC to allow
    the current user to access to manage plugin configuration. 1. Navigate to Extensions.
    2. Select a plugin to enable or disable. 3. Click on the Enable/Disable slider.
    ![extensions enable plugin 1] 4. To view the plugins that require a restart, click
    View plugins in the alert message. ![extensions install plugin 3] 5. Restart your
    RHDH application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Enable/Disable slider is
    updated. # Troubleshooting plugins ## <UnifiedThemeProvider theme={darkTheme}
    children={children} /> ); ``` For more information about creating a custom theme,
    see creating a custom theme. You can declare the theme using the themes configuration
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name themes: # are `light` or `dark`. Using ''light'' overrides
    the app-provided light theme - id: light title: Light variant: light icon: someIconReference
    importName: lightThemeProvider # The theme name displayed to the user on the *Settings*
    page. Using ''dark'' overrides the app-provided dark theme - id: dark title: Dark
    variant: dark icon: someIconReference # A string reference to a system or app
    icon # The name of the exported theme provider function, the function signature
    should match `({ children }: { children: ReactNode }): React.JSX.Element` importName:
    darkThemeProvider ``` # Utilizing plugin indicators and support types in the Red
    Hat Developer Hub Understanding plugin indicators and support types is crucial
    for effectively utilizing the Red Hat Developer Hub. ## Navigating the plugin
    marketplace and filtering plugins using badges The plugin marketplace includes
    new indicators that enhance transparency. These changes provide clearer information
    about the status of each plugin, support level, and other relevant details, allowing
    you to make informed decisions when you select plugins. By understanding these
    visual cues and descriptive texts, you can quickly identify the maturity, support,
    and origin of each plugin. The marketplace employs the following badges and tags
    to provide quick visual cues: Certified Generally Available (GA) Community Plugin
    Tech Preview Dev Preview Custom Plugin [NOTE] ---- Hovering your mouse cursor
    over any badge or tag (such as GA or Certified) on either the plugin list or details
    page displays a helper text explanation clarifying its meaning and implications.
    Hovering over tags such as tech preview, or dev preview will display a helper
    text explanation clarifying its meaning and indicating if it is in a technical
    preview phase or a development preview phase. ---- The plugin details pages include
    the following fields for additional context: author, tags, category,publisher,
    and support provider. The update also changes the version text to Backstage compatibility
    version to offer more precise compatibility information. The following filter
    examples are available: To view only plugins that are Generally Available (GA),
    apply the GA filter. To find Certified plugins, apply the Certified in Support
    type filter. To explore plugins currently in Tech Preview, Dev Preview, or Community
    Plugin status, apply the corresponding filter. 1. Navigate to the main plugin
    list page within the Red Hat Developer Hub. 2. On the plugin list page, use the
    Support type filter to refine your plugin listings based on the plugin support
    status. You can use this filter to quickly narrow down options to plugins that
    meet your specific support requirements. 3. Click the entry of a plugin list page
    to view its details, which provide an in-depth view of its characteristics.'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T15:38:55.688589'
    uuid: d27cd049-057b-45ce-a066-908dd68b2ae3
  response: You must have configured RBAC to allow the current user to manage plugin
    configuration. For enabling and disabling plugins, you must also have configured
    RBAC to allow the current user to access to manage plugin configuration.
  user_input: what do i need rbac for with the plugins?
- context:
  - '[NOTE] ---- If you disable the Extensions feature plugins, the Catalog and Installed
    tabs will also be removed. You can still view installed plugins by clicking on
    Administration > Extensions. ---- ## Extensions. You have configured RBAC to allow
    the current user to manage plugin configuration. 1. Navigate to Extensions. 2.
    Select a plugin to install. 3. Click the Install button. ![extensions install
    plugin 1] The code editor is displayed which displays the plugin default configuration.
    4. Update the plugin configuration, if necessary. ![extensions install plugin
    2] 5. Click Install 6. To view the plugins that require a restart, click View
    plugins in the alert message. ![extensions install plugin 3] 7. Restart your RHDH
    application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Actions button is displayed.
    ### Enabling and disabling plugins by using Extensions You have configured RHDH
    to allow plugins installation from Extensions. You have configured RBAC to allow
    the current user to access to manage plugin configuration. 1. Navigate to Extensions.
    2. Select a plugin to enable or disable. 3. Click on the Enable/Disable slider.
    ![extensions enable plugin 1] 4. To view the plugins that require a restart, click
    View plugins in the alert message. ![extensions install plugin 3] 5. Restart your
    RHDH application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Enable/Disable slider is
    updated. # Troubleshooting plugins ## <UnifiedThemeProvider theme={darkTheme}
    children={children} /> ); ``` For more information about creating a custom theme,
    see creating a custom theme. You can declare the theme using the themes configuration
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name themes: # are `light` or `dark`. Using ''light'' overrides
    the app-provided light theme - id: light title: Light variant: light icon: someIconReference
    importName: lightThemeProvider # The theme name displayed to the user on the *Settings*
    page. Using ''dark'' overrides the app-provided dark theme - id: dark title: Dark
    variant: dark icon: someIconReference # A string reference to a system or app
    icon # The name of the exported theme provider function, the function signature
    should match `({ children }: { children: ReactNode }): React.JSX.Element` importName:
    darkThemeProvider ``` # Utilizing plugin indicators and support types in the Red
    Hat Developer Hub Understanding plugin indicators and support types is crucial
    for effectively utilizing the Red Hat Developer Hub. ## Navigating the plugin
    marketplace and filtering plugins using badges The plugin marketplace includes
    new indicators that enhance transparency. These changes provide clearer information
    about the status of each plugin, support level, and other relevant details, allowing
    you to make informed decisions when you select plugins. By understanding these
    visual cues and descriptive texts, you can quickly identify the maturity, support,
    and origin of each plugin. The marketplace employs the following badges and tags
    to provide quick visual cues: Certified Generally Available (GA) Community Plugin
    Tech Preview Dev Preview Custom Plugin [NOTE] ---- Hovering your mouse cursor
    over any badge or tag (such as GA or Certified) on either the plugin list or details
    page displays a helper text explanation clarifying its meaning and implications.
    Hovering over tags such as tech preview, or dev preview will display a helper
    text explanation clarifying its meaning and indicating if it is in a technical
    preview phase or a development preview phase. ---- The plugin details pages include
    the following fields for additional context: author, tags, category,publisher,
    and support provider. The update also changes the version text to Backstage compatibility
    version to offer more precise compatibility information. The following filter
    examples are available: To view only plugins that are Generally Available (GA),
    apply the GA filter. To find Certified plugins, apply the Certified in Support
    type filter. To explore plugins currently in Tech Preview, Dev Preview, or Community
    Plugin status, apply the corresponding filter. 1. Navigate to the main plugin
    list page within the Red Hat Developer Hub. 2. On the plugin list page, use the
    Support type filter to refine your plugin listings based on the plugin support
    status. You can use this filter to quickly narrow down options to plugins that
    meet your specific support requirements. 3. Click the entry of a plugin list page
    to view its details, which provide an in-depth view of its characteristics.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:39:02.901878'
    uuid: 036d7ac8-f969-49bc-b721-99fc7d481af5
  response: To filter plugins by their support status in the Red Hat Developer Hub,
    navigate to the main plugin list page and use the Support type filter to refine
    your plugin listings. This filter allows you to narrow down options to plugins
    that meet specific support requirements, such as applying the GA filter for Generally
    Available plugins or the Certified filter for Certified plugins.
  user_input: How can I filter plugins by their support status within the Red Hat
    Developer Hub?
- context:
  - '[NOTE] ---- If you disable the Extensions feature plugins, the Catalog and Installed
    tabs will also be removed. You can still view installed plugins by clicking on
    Administration > Extensions. ---- ## Extensions. You have configured RBAC to allow
    the current user to manage plugin configuration. 1. Navigate to Extensions. 2.
    Select a plugin to install. 3. Click the Install button. ![extensions install
    plugin 1] The code editor is displayed which displays the plugin default configuration.
    4. Update the plugin configuration, if necessary. ![extensions install plugin
    2] 5. Click Install 6. To view the plugins that require a restart, click View
    plugins in the alert message. ![extensions install plugin 3] 7. Restart your RHDH
    application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Actions button is displayed.
    ### Enabling and disabling plugins by using Extensions You have configured RHDH
    to allow plugins installation from Extensions. You have configured RBAC to allow
    the current user to access to manage plugin configuration. 1. Navigate to Extensions.
    2. Select a plugin to enable or disable. 3. Click on the Enable/Disable slider.
    ![extensions enable plugin 1] 4. To view the plugins that require a restart, click
    View plugins in the alert message. ![extensions install plugin 3] 5. Restart your
    RHDH application. 1. After you restart your RHDH application, navigate to Extensions.
    2. Select the plugin that you have installed. 3. The Enable/Disable slider is
    updated. # Troubleshooting plugins ## <UnifiedThemeProvider theme={darkTheme}
    children={children} /> ); ``` For more information about creating a custom theme,
    see creating a custom theme. You can declare the theme using the themes configuration
    as shown in the following example: ```yaml dynamicPlugins: frontend: my-plugin:
    # The plugin package name themes: # are `light` or `dark`. Using ''light'' overrides
    the app-provided light theme - id: light title: Light variant: light icon: someIconReference
    importName: lightThemeProvider # The theme name displayed to the user on the *Settings*
    page. Using ''dark'' overrides the app-provided dark theme - id: dark title: Dark
    variant: dark icon: someIconReference # A string reference to a system or app
    icon # The name of the exported theme provider function, the function signature
    should match `({ children }: { children: ReactNode }): React.JSX.Element` importName:
    darkThemeProvider ``` # Utilizing plugin indicators and support types in the Red
    Hat Developer Hub Understanding plugin indicators and support types is crucial
    for effectively utilizing the Red Hat Developer Hub. ## Navigating the plugin
    marketplace and filtering plugins using badges The plugin marketplace includes
    new indicators that enhance transparency. These changes provide clearer information
    about the status of each plugin, support level, and other relevant details, allowing
    you to make informed decisions when you select plugins. By understanding these
    visual cues and descriptive texts, you can quickly identify the maturity, support,
    and origin of each plugin. The marketplace employs the following badges and tags
    to provide quick visual cues: Certified Generally Available (GA) Community Plugin
    Tech Preview Dev Preview Custom Plugin [NOTE] ---- Hovering your mouse cursor
    over any badge or tag (such as GA or Certified) on either the plugin list or details
    page displays a helper text explanation clarifying its meaning and implications.
    Hovering over tags such as tech preview, or dev preview will display a helper
    text explanation clarifying its meaning and indicating if it is in a technical
    preview phase or a development preview phase. ---- The plugin details pages include
    the following fields for additional context: author, tags, category,publisher,
    and support provider. The update also changes the version text to Backstage compatibility
    version to offer more precise compatibility information. The following filter
    examples are available: To view only plugins that are Generally Available (GA),
    apply the GA filter. To find Certified plugins, apply the Certified in Support
    type filter. To explore plugins currently in Tech Preview, Dev Preview, or Community
    Plugin status, apply the corresponding filter. 1. Navigate to the main plugin
    list page within the Red Hat Developer Hub. 2. On the plugin list page, use the
    Support type filter to refine your plugin listings based on the plugin support
    status. You can use this filter to quickly narrow down options to plugins that
    meet your specific support requirements. 3. Click the entry of a plugin list page
    to view its details, which provide an in-depth view of its characteristics.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:39:10.116679'
    uuid: c0b91c58-39be-46b3-868a-2b98d06af589
  response: To explore plugins that are in Dev Preview, navigate to the main plugin
    list page within the Red Hat Developer Hub and apply the corresponding filter.
    You can use the Support type filter to refine your plugin listings. Hovering your
    mouse cursor over the dev preview tag will display a helper text explanation indicating
    that it is in a development preview phase.
  user_input: how do i find a dev prevew plugin?
- context:
  - '# Audit logs in Red Hat Developer Hub # Audit logs in Red Hat Developer Hub Audit
    logs are a chronological set of records documenting the user activities, system
    events, and data changes that affect your Red Hat Developer Hub users, administrators,
    or components. Administrators can view Developer Hub audit logs in the OpenShift
    Container Platform web console to monitor scaffolder events, changes to the RBAC
    system, and changes to the Catalog database. Audit logs include the following
    information: Name of the audited event Actor that triggered the audited event,
    for example, terminal, port, IP address, or hostname Event metadata, for example,
    date, time Event status, for example, success, failure Severity levels, for example,
    info, debug, warn, error You can use the information in the audit log to achieve
    the following goals: Enhance security:: Trace activities, including those initiated
    by automated systems and software templates, back to their source. Know when software
    templates are executed, and the details of application and component installations,
    updates, configuration changes, and removals. Automate compliance:: Use streamlined
    processes to view log data for specified points in time for auditing purposes
    or continuous compliance maintenance. Debug issues:: Use access records and activity
    details to fix issues with software templates or plugins. [NOTE] ---- Audit logs
    are not forwarded to the internal log store by default because this does not provide
    secure storage. You are responsible for ensuring that the system to which you
    forward audit logs is compliant with your organizational and governmental regulations,
    and is properly secured. ---- ## Configuring audit logs for Developer Hub on OpenShift
    Container Platform Use the OpenShift Container Platform web console to configure
    the following OpenShift Container Platform logging components to use audit logging
    for Developer Hub: Logging deployment:: Configure the logging environment, including
    both the CPU and memory limits for each logging component. Logging collector::
    Configure the spec.collection stanza in the ClusterLogging custom resource (CR)
    to use a supported modification to the log collector and collect logs from STDOUT.
    Log forwarding:: Send logs to specific endpoints inside and outside your OpenShift
    Container Platform cluster by specifying a combination of outputs and pipelines
    in a ClusterLogForwarder CR. Red Hat OpenShift Container Platform Configuring
    your Logging deployment Red Hat OpenShift Container Platform Configuring the logging
    collector Red Hat OpenShift Container Platform Enabling JSON log forwarding Red
    Hat OpenShift Container Platform Configuring log forwarding ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:39:17.306967'
    uuid: 286b16ac-9ffa-4f74-84e8-645b4f9c0398
  response: Administrators can view Developer Hub audit logs in the OpenShift Container
    Platform web console to monitor changes to the Catalog database.
  user_input: how do i see the changes what happen to the Catalog database?
- context:
  - '# Audit logs in Red Hat Developer Hub # Audit logs in Red Hat Developer Hub Audit
    logs are a chronological set of records documenting the user activities, system
    events, and data changes that affect your Red Hat Developer Hub users, administrators,
    or components. Administrators can view Developer Hub audit logs in the OpenShift
    Container Platform web console to monitor scaffolder events, changes to the RBAC
    system, and changes to the Catalog database. Audit logs include the following
    information: Name of the audited event Actor that triggered the audited event,
    for example, terminal, port, IP address, or hostname Event metadata, for example,
    date, time Event status, for example, success, failure Severity levels, for example,
    info, debug, warn, error You can use the information in the audit log to achieve
    the following goals: Enhance security:: Trace activities, including those initiated
    by automated systems and software templates, back to their source. Know when software
    templates are executed, and the details of application and component installations,
    updates, configuration changes, and removals. Automate compliance:: Use streamlined
    processes to view log data for specified points in time for auditing purposes
    or continuous compliance maintenance. Debug issues:: Use access records and activity
    details to fix issues with software templates or plugins. [NOTE] ---- Audit logs
    are not forwarded to the internal log store by default because this does not provide
    secure storage. You are responsible for ensuring that the system to which you
    forward audit logs is compliant with your organizational and governmental regulations,
    and is properly secured. ---- ## Configuring audit logs for Developer Hub on OpenShift
    Container Platform Use the OpenShift Container Platform web console to configure
    the following OpenShift Container Platform logging components to use audit logging
    for Developer Hub: Logging deployment:: Configure the logging environment, including
    both the CPU and memory limits for each logging component. Logging collector::
    Configure the spec.collection stanza in the ClusterLogging custom resource (CR)
    to use a supported modification to the log collector and collect logs from STDOUT.
    Log forwarding:: Send logs to specific endpoints inside and outside your OpenShift
    Container Platform cluster by specifying a combination of outputs and pipelines
    in a ClusterLogForwarder CR. Red Hat OpenShift Container Platform Configuring
    your Logging deployment Red Hat OpenShift Container Platform Configuring the logging
    collector Red Hat OpenShift Container Platform Enabling JSON log forwarding Red
    Hat OpenShift Container Platform Configuring log forwarding ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:39:37.867402'
    uuid: f8eef3b3-b1fd-4454-b9a4-c3ff358e06b3
  response: 'Audit logs in Red Hat Developer Hub are a chronological set of records
    that can be used to enhance security by tracing activities, including those from
    automated systems and software templates, back to their source. This allows you
    to know when software templates are executed and view details of application and
    component installations, updates, configuration changes, and removals. To automate
    compliance, you can use streamlined processes to view log data for specified points
    in time for auditing or continuous compliance maintenance. To enable this on OpenShift
    Container Platform, you must configure the following components: the Logging deployment
    to set up the logging environment''s CPU and memory limits; the Logging collector
    by configuring the spec.collection stanza in the ClusterLogging custom resource
    (CR) to collect logs from STDOUT; and Log forwarding, which uses a ClusterLogForwarder
    CR to send logs to specific endpoints. Please note that you are responsible for
    ensuring the system to which you forward audit logs is properly secured and compliant
    with regulations, as logs are not forwarded to the internal log store by default.'
  user_input: Given my responsibility for building a unified developer platform, could
    you please provide a comprehensive overview of how the audit logs in Red Hat Developer
    Hub can be utilized to enhance security and automate compliance, and what specific
    OpenShift Container Platform logging components must be configured to enable this
    functionality?
- context:
  - '# Audit logs in Red Hat Developer Hub # Audit logs in Red Hat Developer Hub Audit
    logs are a chronological set of records documenting the user activities, system
    events, and data changes that affect your Red Hat Developer Hub users, administrators,
    or components. Administrators can view Developer Hub audit logs in the OpenShift
    Container Platform web console to monitor scaffolder events, changes to the RBAC
    system, and changes to the Catalog database. Audit logs include the following
    information: Name of the audited event Actor that triggered the audited event,
    for example, terminal, port, IP address, or hostname Event metadata, for example,
    date, time Event status, for example, success, failure Severity levels, for example,
    info, debug, warn, error You can use the information in the audit log to achieve
    the following goals: Enhance security:: Trace activities, including those initiated
    by automated systems and software templates, back to their source. Know when software
    templates are executed, and the details of application and component installations,
    updates, configuration changes, and removals. Automate compliance:: Use streamlined
    processes to view log data for specified points in time for auditing purposes
    or continuous compliance maintenance. Debug issues:: Use access records and activity
    details to fix issues with software templates or plugins. [NOTE] ---- Audit logs
    are not forwarded to the internal log store by default because this does not provide
    secure storage. You are responsible for ensuring that the system to which you
    forward audit logs is compliant with your organizational and governmental regulations,
    and is properly secured. ---- ## Configuring audit logs for Developer Hub on OpenShift
    Container Platform Use the OpenShift Container Platform web console to configure
    the following OpenShift Container Platform logging components to use audit logging
    for Developer Hub: Logging deployment:: Configure the logging environment, including
    both the CPU and memory limits for each logging component. Logging collector::
    Configure the spec.collection stanza in the ClusterLogging custom resource (CR)
    to use a supported modification to the log collector and collect logs from STDOUT.
    Log forwarding:: Send logs to specific endpoints inside and outside your OpenShift
    Container Platform cluster by specifying a combination of outputs and pipelines
    in a ClusterLogForwarder CR. Red Hat OpenShift Container Platform Configuring
    your Logging deployment Red Hat OpenShift Container Platform Configuring the logging
    collector Red Hat OpenShift Container Platform Enabling JSON log forwarding Red
    Hat OpenShift Container Platform Configuring log forwarding ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:39:47.287963'
    uuid: a73e17db-a300-402e-9b69-b41fc58136e6
  response: You can send logs to specific endpoints inside and outside your OpenShift
    Container Platform cluster by specifying a combination of outputs and pipelines
    in a ClusterLogForwarder CR. This is part of configuring log forwarding, which
    is one of the OpenShift Container Platform logging components used for Developer
    Hub audit logging.
  user_input: How do I enable json log forwading?
- context:
  - 'Forwarding Red Hat Developer Hub audit logs to Splunk You can use the Red Hat
    OpenShift Logging (OpenShift Logging) Operator and a ClusterLogForwarder instance
    to capture the streamed audit logs from a Developer Hub instance and forward them
    to the HTTPS endpoint associated with your Splunk instance. You have a cluster
    running on a supported OpenShift Container Platform version. You have an account
    with cluster admin privileges. You have a Splunk Cloud account or Splunk Enterprise
    installation. 1. Log in to your OpenShift Container Platform cluster. 2. Install
    the OpenShift Logging Operator in the openshift-logging namespace and switch to
    the namespace: ```bash oc project openshift-logging ``` 3. Create a serviceAccount
    named log-collector and bind the collect-application-logs role to the serviceAccount
    : ```bash oc create sa log collector ``` ```bash oc create clusterrolebinding
    log-collector --clusterrole=collect-application-logs --serviceaccount=openshift-logging:log-collector
    ``` 4. Generate a hecToken in your Splunk instance. 5. Create a key/value secret
    in the openshift-logging namespace and verify the secret: ```bash oc -n openshift-logging
    create secret generic splunk-secret --from-literal=hecToken=<HEC_Token> ``` ```bash
    oc -n openshift-logging get secret/splunk-secret -o yaml ``` 6. Create a basic
    `ClusterLogForwarder`resource YAML file as follows: ```yaml apiVersion: logging.openshift.io/v1
    kind: ClusterLogForwarder metadata: name: instance namespace: openshift logging
    ``` For more information, see Creating a log forwarder. 7. Define the following
    ClusterLogForwarder configuration using OpenShift web console or OpenShift CLI:
    1. Specify the log-collector as serviceAccount in the YAML file: ```yaml serviceAccount:
    name: log-collector ``` 2. Configure inputs to specify the type and source of
    logs to forward. The following configuration enables the forwarder to capture
    logs from all applications in a provided namespace: ```yaml inputs: name: my app
    logs input type: application application: includes: namespace: my rhdh project
    containerLimit: maxRecordsPerSecond: 100 ``` For more information, see Forwarding
    application logs from specific pods. 3. Configure outputs to specify where the
    captured logs are sent. In this step, focus on the splunk type. You can either
    use tls.insecureSkipVerify option if the Splunk endpoint uses self-signed TLS
    certificates (not recommended) or provide the certificate chain using a Secret.
    ```yaml outputs: name: splunk receiver application type: splunk splunk: authentication:
    token: key: hecToken secretName: splunk secret index: main url: ''https://my splunk
    instance link'' rateLimit: maxRecordsPerSecond: 250 ``` For more information,
    see Forwarding logs to Splunk in OpenShift Container Platform documentation. 4.
    Optional: Filter logs to include only audit logs: ```yaml filters: name: audit
    logs only type: drop drop: test: field: .message notMatches: isAuditEvent ```
    For more information, see Filtering logs by content in OpenShift Container Platform
    documentation. 5. Configure pipelines to route logs from specific inputs to designated
    outputs. Use the names of the defined inputs and outputs to specify multiple inputRefs
    and outputRefs in each pipeline: ```yaml pipelines: - name: my-app-logs-pipeline
    detectMultilineErrors: true inputRefs: - my-app-logs-input outputRefs: - splunk-receiver-application
    filterRefs: - audit-logs-only ``` 8. Run the following command to apply the ClusterLogForwarder
    configuration: ```bash oc apply -f <ClusterLogForwarder-configuration.yaml> ```
    9. Optional: To reduce the risk of log loss, configure your ClusterLogForwarder
    pods using the following options: 1. Define the resource requests and limits for
    the log collector as follows: ```yaml collector: resources: requests: cpu: 250m
    memory: 64Mi ephemeral-storage: 250Mi limits: cpu: 500m memory: 128Mi ephemeral-storage:
    500Mi ``` 2. Define tuning options for log delivery, including delivery, compression,
    and RetryDuration. Tuning can be applied per output as needed. ```yaml tuning:
    delivery: AtLeastOnce 1 compression: none minRetryDuration: 1s maxRetryDuration:
    10s ``` AtLeastOnce delivery mode means that if the log forwarder crashes or is
    restarted, any logs that were read before the crash but not sent to their destination
    are re-sent. It is possible that some logs are duplicated after a crash. 1. Confirm
    that logs are being forwarded to your Splunk instance by viewing them in the Splunk
    dashboard. 2. Troubleshoot any issues using OpenShift Container Platform and Splunk
    logs as needed. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:39:59.423876'
    uuid: f7caed47-f84b-4605-9cba-be606fc52b26
  response: 'To forward Red Hat Developer Hub audit logs to Splunk, you must use the
    Red Hat OpenShift Logging Operator and a ClusterLogForwarder instance. The process
    requires creating a serviceAccount named "log-collector" with the "collect-application-logs"
    role and storing a Splunk HEC token in a secret. The ClusterLogForwarder configuration
    must then be defined with several key sections: "inputs" to specify the application
    logs to capture from the appropriate namespace, "outputs" of type "splunk" pointing
    to your Splunk URL and using the HEC token secret for authentication, and "pipelines"
    to connect the inputs to the outputs. An optional "filters" section can be added
    to the pipeline to ensure only audit logs are forwarded.'
  user_input: What are the essential components and configuration steps required to
    forward Red Hat Developer Hub audit logs to a Splunk instance using OpenShift
    Logging?
- context:
  - 'Forwarding Red Hat Developer Hub audit logs to Splunk You can use the Red Hat
    OpenShift Logging (OpenShift Logging) Operator and a ClusterLogForwarder instance
    to capture the streamed audit logs from a Developer Hub instance and forward them
    to the HTTPS endpoint associated with your Splunk instance. You have a cluster
    running on a supported OpenShift Container Platform version. You have an account
    with cluster admin privileges. You have a Splunk Cloud account or Splunk Enterprise
    installation. 1. Log in to your OpenShift Container Platform cluster. 2. Install
    the OpenShift Logging Operator in the openshift-logging namespace and switch to
    the namespace: ```bash oc project openshift-logging ``` 3. Create a serviceAccount
    named log-collector and bind the collect-application-logs role to the serviceAccount
    : ```bash oc create sa log collector ``` ```bash oc create clusterrolebinding
    log-collector --clusterrole=collect-application-logs --serviceaccount=openshift-logging:log-collector
    ``` 4. Generate a hecToken in your Splunk instance. 5. Create a key/value secret
    in the openshift-logging namespace and verify the secret: ```bash oc -n openshift-logging
    create secret generic splunk-secret --from-literal=hecToken=<HEC_Token> ``` ```bash
    oc -n openshift-logging get secret/splunk-secret -o yaml ``` 6. Create a basic
    `ClusterLogForwarder`resource YAML file as follows: ```yaml apiVersion: logging.openshift.io/v1
    kind: ClusterLogForwarder metadata: name: instance namespace: openshift logging
    ``` For more information, see Creating a log forwarder. 7. Define the following
    ClusterLogForwarder configuration using OpenShift web console or OpenShift CLI:
    1. Specify the log-collector as serviceAccount in the YAML file: ```yaml serviceAccount:
    name: log-collector ``` 2. Configure inputs to specify the type and source of
    logs to forward. The following configuration enables the forwarder to capture
    logs from all applications in a provided namespace: ```yaml inputs: name: my app
    logs input type: application application: includes: namespace: my rhdh project
    containerLimit: maxRecordsPerSecond: 100 ``` For more information, see Forwarding
    application logs from specific pods. 3. Configure outputs to specify where the
    captured logs are sent. In this step, focus on the splunk type. You can either
    use tls.insecureSkipVerify option if the Splunk endpoint uses self-signed TLS
    certificates (not recommended) or provide the certificate chain using a Secret.
    ```yaml outputs: name: splunk receiver application type: splunk splunk: authentication:
    token: key: hecToken secretName: splunk secret index: main url: ''https://my splunk
    instance link'' rateLimit: maxRecordsPerSecond: 250 ``` For more information,
    see Forwarding logs to Splunk in OpenShift Container Platform documentation. 4.
    Optional: Filter logs to include only audit logs: ```yaml filters: name: audit
    logs only type: drop drop: test: field: .message notMatches: isAuditEvent ```
    For more information, see Filtering logs by content in OpenShift Container Platform
    documentation. 5. Configure pipelines to route logs from specific inputs to designated
    outputs. Use the names of the defined inputs and outputs to specify multiple inputRefs
    and outputRefs in each pipeline: ```yaml pipelines: - name: my-app-logs-pipeline
    detectMultilineErrors: true inputRefs: - my-app-logs-input outputRefs: - splunk-receiver-application
    filterRefs: - audit-logs-only ``` 8. Run the following command to apply the ClusterLogForwarder
    configuration: ```bash oc apply -f <ClusterLogForwarder-configuration.yaml> ```
    9. Optional: To reduce the risk of log loss, configure your ClusterLogForwarder
    pods using the following options: 1. Define the resource requests and limits for
    the log collector as follows: ```yaml collector: resources: requests: cpu: 250m
    memory: 64Mi ephemeral-storage: 250Mi limits: cpu: 500m memory: 128Mi ephemeral-storage:
    500Mi ``` 2. Define tuning options for log delivery, including delivery, compression,
    and RetryDuration. Tuning can be applied per output as needed. ```yaml tuning:
    delivery: AtLeastOnce 1 compression: none minRetryDuration: 1s maxRetryDuration:
    10s ``` AtLeastOnce delivery mode means that if the log forwarder crashes or is
    restarted, any logs that were read before the crash but not sent to their destination
    are re-sent. It is possible that some logs are duplicated after a crash. 1. Confirm
    that logs are being forwarded to your Splunk instance by viewing them in the Splunk
    dashboard. 2. Troubleshoot any issues using OpenShift Container Platform and Splunk
    logs as needed. ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:40:10.532910'
    uuid: 39371ec3-ca31-49e0-960e-3e6d23153a81
  response: You can forward Red Hat Developer Hub audit logs to Splunk by using the
    Red Hat OpenShift Logging Operator and a ClusterLogForwarder instance. This combination
    allows you to capture the streamed audit logs from a Developer Hub instance and
    forward them to the HTTPS endpoint associated with your Splunk instance.
  user_input: How can I forward audit logs from Red Hat Developer Hub to Splunk?
- context:
  - 'Forwarding Red Hat Developer Hub audit logs to Splunk You can use the Red Hat
    OpenShift Logging (OpenShift Logging) Operator and a ClusterLogForwarder instance
    to capture the streamed audit logs from a Developer Hub instance and forward them
    to the HTTPS endpoint associated with your Splunk instance. You have a cluster
    running on a supported OpenShift Container Platform version. You have an account
    with cluster admin privileges. You have a Splunk Cloud account or Splunk Enterprise
    installation. 1. Log in to your OpenShift Container Platform cluster. 2. Install
    the OpenShift Logging Operator in the openshift-logging namespace and switch to
    the namespace: ```bash oc project openshift-logging ``` 3. Create a serviceAccount
    named log-collector and bind the collect-application-logs role to the serviceAccount
    : ```bash oc create sa log collector ``` ```bash oc create clusterrolebinding
    log-collector --clusterrole=collect-application-logs --serviceaccount=openshift-logging:log-collector
    ``` 4. Generate a hecToken in your Splunk instance. 5. Create a key/value secret
    in the openshift-logging namespace and verify the secret: ```bash oc -n openshift-logging
    create secret generic splunk-secret --from-literal=hecToken=<HEC_Token> ``` ```bash
    oc -n openshift-logging get secret/splunk-secret -o yaml ``` 6. Create a basic
    `ClusterLogForwarder`resource YAML file as follows: ```yaml apiVersion: logging.openshift.io/v1
    kind: ClusterLogForwarder metadata: name: instance namespace: openshift logging
    ``` For more information, see Creating a log forwarder. 7. Define the following
    ClusterLogForwarder configuration using OpenShift web console or OpenShift CLI:
    1. Specify the log-collector as serviceAccount in the YAML file: ```yaml serviceAccount:
    name: log-collector ``` 2. Configure inputs to specify the type and source of
    logs to forward. The following configuration enables the forwarder to capture
    logs from all applications in a provided namespace: ```yaml inputs: name: my app
    logs input type: application application: includes: namespace: my rhdh project
    containerLimit: maxRecordsPerSecond: 100 ``` For more information, see Forwarding
    application logs from specific pods. 3. Configure outputs to specify where the
    captured logs are sent. In this step, focus on the splunk type. You can either
    use tls.insecureSkipVerify option if the Splunk endpoint uses self-signed TLS
    certificates (not recommended) or provide the certificate chain using a Secret.
    ```yaml outputs: name: splunk receiver application type: splunk splunk: authentication:
    token: key: hecToken secretName: splunk secret index: main url: ''https://my splunk
    instance link'' rateLimit: maxRecordsPerSecond: 250 ``` For more information,
    see Forwarding logs to Splunk in OpenShift Container Platform documentation. 4.
    Optional: Filter logs to include only audit logs: ```yaml filters: name: audit
    logs only type: drop drop: test: field: .message notMatches: isAuditEvent ```
    For more information, see Filtering logs by content in OpenShift Container Platform
    documentation. 5. Configure pipelines to route logs from specific inputs to designated
    outputs. Use the names of the defined inputs and outputs to specify multiple inputRefs
    and outputRefs in each pipeline: ```yaml pipelines: - name: my-app-logs-pipeline
    detectMultilineErrors: true inputRefs: - my-app-logs-input outputRefs: - splunk-receiver-application
    filterRefs: - audit-logs-only ``` 8. Run the following command to apply the ClusterLogForwarder
    configuration: ```bash oc apply -f <ClusterLogForwarder-configuration.yaml> ```
    9. Optional: To reduce the risk of log loss, configure your ClusterLogForwarder
    pods using the following options: 1. Define the resource requests and limits for
    the log collector as follows: ```yaml collector: resources: requests: cpu: 250m
    memory: 64Mi ephemeral-storage: 250Mi limits: cpu: 500m memory: 128Mi ephemeral-storage:
    500Mi ``` 2. Define tuning options for log delivery, including delivery, compression,
    and RetryDuration. Tuning can be applied per output as needed. ```yaml tuning:
    delivery: AtLeastOnce 1 compression: none minRetryDuration: 1s maxRetryDuration:
    10s ``` AtLeastOnce delivery mode means that if the log forwarder crashes or is
    restarted, any logs that were read before the crash but not sent to their destination
    are re-sent. It is possible that some logs are duplicated after a crash. 1. Confirm
    that logs are being forwarded to your Splunk instance by viewing them in the Splunk
    dashboard. 2. Troubleshoot any issues using OpenShift Container Platform and Splunk
    logs as needed. ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:40:21.694726'
    uuid: bda68438-33b5-4581-b64d-e8d3392a5e7f
  response: 'To forward Red Hat Developer Hub audit logs to Splunk using OpenShift,
    you must first have a supported OpenShift Container Platform cluster with admin
    privileges and a Splunk instance. The process involves: 1. Installing the Red
    Hat OpenShift Logging Operator in the `openshift-logging` namespace. 2. Creating
    a serviceAccount named `log-collector` and binding the `collect-application-logs`
    cluster role to it. 3. Generating a hecToken in your Splunk instance and creating
    a secret named `splunk-secret` in the `openshift-logging` namespace with this
    token. 4. Creating a `ClusterLogForwarder` resource and configuring it by specifying
    the `log-collector` serviceAccount. 5. Configuring inputs to capture logs from
    the application namespace. 6. Configuring outputs of type `splunk`, providing
    the Splunk URL and the secret containing the hecToken. 7. Optionally, adding a
    filter of type `drop` to include only audit logs by matching for `isAuditEvent`
    in the message field. 8. Configuring pipelines to route logs from the defined
    inputs to the specified outputs, using the filter if created. 9. Applying the
    `ClusterLogForwarder` configuration file. Optionally, to reduce log loss, you
    can define resource requests and limits for the log collector and set tuning options
    for log delivery, such as `AtLeastOnce`.'
  user_input: What are the detailed steps to configure the OpenShift Logging Operator
    and a ClusterLogForwarder instance to capture and forward audit logs from a Developer
    Hub instance to a Splunk endpoint?
- context:
  - Viewing audit logs in Developer Hub Administrators can view, search, filter, and
    manage the log data from the Red Hat OpenShift Container Platform web console.
    You can filter audit logs from other log types by using the isAuditEvent field.
    You are logged in as an administrator in the OpenShift Container Platform web
    console. 1. From the Developer perspective of the OpenShift Container Platform
    web console, click the Topology tab. 2. From the Topology view, click the pod
    that you want to view audit log data for. 3. From the pod panel, click the Resources
    tab. 4. From the Pods section of the Resources tab, click View logs. 5. From the
    Logs view, enter isAuditEvent into the Search field to filter audit logs from
    other log types. You can use the arrows to browse the logs containing the isAuditEvent
    field. About Logging in Red Hat OpenShift Container Platform
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:40:31.519972'
    uuid: 897570ba-c989-434d-87ed-977e09f25c1c
  response: As an administrator in the OpenShift Container Platform web console, you
    can view audit logs in Developer Hub by first going to the Developer perspective
    and clicking the Topology tab. From the Topology view, select the pod you want
    to view logs for. In the pod panel, click the Resources tab, and from the Pods
    section, click 'View logs'. In the Logs view, you can filter for audit logs by
    entering 'isAuditEvent' into the Search field.
  user_input: how do i see audit logs in the Develper Hub?
- context:
  - Viewing audit logs in Developer Hub Administrators can view, search, filter, and
    manage the log data from the Red Hat OpenShift Container Platform web console.
    You can filter audit logs from other log types by using the isAuditEvent field.
    You are logged in as an administrator in the OpenShift Container Platform web
    console. 1. From the Developer perspective of the OpenShift Container Platform
    web console, click the Topology tab. 2. From the Topology view, click the pod
    that you want to view audit log data for. 3. From the pod panel, click the Resources
    tab. 4. From the Pods section of the Resources tab, click View logs. 5. From the
    Logs view, enter isAuditEvent into the Search field to filter audit logs from
    other log types. You can use the arrows to browse the logs containing the isAuditEvent
    field. About Logging in Red Hat OpenShift Container Platform
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:40:42.625307'
    uuid: 78bd0a2f-b564-4df7-86d8-c9875becccdd
  response: The isAuditEvent field is used to filter audit logs from other log types.
    In the Logs view of the OpenShift Container Platform web console, you can enter
    isAuditEvent into the Search field to filter the logs.
  user_input: isAuditEvent filter
- context:
  - Viewing audit logs in Developer Hub Administrators can view, search, filter, and
    manage the log data from the Red Hat OpenShift Container Platform web console.
    You can filter audit logs from other log types by using the isAuditEvent field.
    You are logged in as an administrator in the OpenShift Container Platform web
    console. 1. From the Developer perspective of the OpenShift Container Platform
    web console, click the Topology tab. 2. From the Topology view, click the pod
    that you want to view audit log data for. 3. From the pod panel, click the Resources
    tab. 4. From the Pods section of the Resources tab, click View logs. 5. From the
    Logs view, enter isAuditEvent into the Search field to filter audit logs from
    other log types. You can use the arrows to browse the logs containing the isAuditEvent
    field. About Logging in Red Hat OpenShift Container Platform
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:40:55.111340'
    uuid: aa45fda3-1756-4dfb-a774-b0565dfc36bd
  response: To view audit logs in Developer Hub, you must be logged in as an administrator
    in the OpenShift Container Platform web console. From the Developer perspective,
    click the Topology tab. In the Topology view, click the pod you want to view audit
    log data for. Then, from the pod panel, click the Resources tab. In the Pods section
    of the Resources tab, click 'View logs'. To filter the audit logs from other log
    types, enter 'isAuditEvent' into the Search field in the Logs view. You can then
    use the arrows to browse the logs that contain the isAuditEvent field.
  user_input: so i need to tell my team how to check the audit logs in the Developer
    Hub but i forget the exact steps, can you tell me what the whole process is from
    the openshift console, like where do they go after the topology view and how do
    they filter for just the audit logs and not all the other junk?
- context:
  - '# Monitoring and logging # Log Levels Logging is an essential part of monitoring
    and debugging software applications. It provides insight into how the application
    is functioning at runtime and can help you detect and diagnose issues. By adjusting
    the log level, you can control the amount and type of information displayed in
    the logs, ranging from highly detailed diagnostic output to the most critical
    errors. With this flexibility, you can customize logging output to match your
    current requirements, whether during development, testing, or production. You
    can choose from the following log levels, listed in order of decreasing verbosity:
    debug: Detailed information, typically useful only when troubleshooting. info:
    General information about the operation of the application. This is the default
    level. warn: Indicates potential issues or situations that might require attention.
    error: Indicates errors that have occurred but might not prevent the application
    from continuing. critical: Indicates critical errors that require immediate attention
    and are likely to prevent the application from functioning correctly. You can
    control the verbosity of the logging by setting the log level. The log level determines
    the minimum severity level of events displayed in the console. For example, if
    the log level is set to ''info'', events with a severity level of ''debug'' are
    ignored. To increase the log level, you can set the LOG_LEVEL environment variable
    to a higher severity level, such as ''warn'' or ''error''. However, increasing
    the log level might not result in more output if the existing code primarily emits
    logs at lower severity levels, for example, ''debug'' or ''info''. In such a case,
    adjust the logging statements within the code to use higher severity levels to
    see more output. No additional steps are required beyond setting the LOG_LEVEL
    environment variable, but its effectiveness depends on the existing logging statements
    in the code. # Enabling observability for Red Hat Developer Hub on OpenShift Container
    Platform In OpenShift Container Platform, metrics are exposed through an HTTP
    service endpoint under the /metrics canonical name. You can create a ServiceMonitor
    custom resource (CR) to scrape metrics from a service endpoint in a user-defined
    project. ## Enabling metrics monitoring in a Red Hat Developer Hub Operator installation
    on an OpenShift Container Platform cluster You can enable and view metrics for
    an Operator-installed Red Hat Developer Hub instance from the OpenShift Container
    Platform web console. Metrics are exposed through an HTTP service endpoint under
    the /metrics canonical name. By setting the spec.monitoring.enabled field to true
    in your Red Hat Developer Hub custom resource (CR), you instruct the Operator
    to automatically create and manage the necessary ServiceMonitor to scrape metrics
    from the service endpoint. Your OpenShift Container Platform cluster has monitoring
    for user defined projects enabled. You have installed Red Hat Developer Hub on
    OpenShift Container Platform using the Red Hat Developer Hub Operator. You have
    installed the OpenShift CLI (oc). 1. Use the OpenShift CLI (oc) to edit your existing
    Red Hat Developer Hub CR. ```bash oc edit Backstage <instance name> ``` 2. In
    the CR, locate the spec field and add the monitoring configuration block. ```yaml
    spec: monitoring: enabled: true ``` 3. Save the RHDH CR. The RHDH Operator detects
    the configuration and automatically creates the corresponding ServiceMonitor custom
    resource (CR). [NOTE] ---- The Operator automatically configures the ServiceMonitor
    with the correct labels (app.kubernetes.io/instance and app.kubernetes.io/name)
    that match your Backstage CR. The ServiceMonitor will be named metrics-<cr-name>.
    No additional label configuration is required. ---- 1. From the OpenShift Container
    Platform web console, select the Observe view. 2. Click the Metrics tab to view
    metrics for Red Hat Developer Hub pods. 3. From the OpenShift Container Platform
    web console, click Project > Services and verify the labels for backstage-developer-hub.
    ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:41:15.353337'
    uuid: f1f12bfa-fcf8-4279-96d5-724f9fcdb8f9
  response: To enable metrics monitoring for a Red Hat Developer Hub Operator installation,
    you must edit your existing Backstage custom resource (CR). Using the OpenShift
    CLI (oc), run the command `oc edit Backstage <instance name>`. In the CR, locate
    the `spec` field and add the monitoring configuration block, setting `enabled`
    to `true`. After saving the CR, the RHDH Operator will detect the configuration
    and automatically create the corresponding ServiceMonitor custom resource to scrape
    metrics from the service endpoint. The Operator automatically configures the ServiceMonitor
    with the correct labels and names it `metrics-<cr-name>`, so no additional label
    configuration is required.
  user_input: how to enable metrics monitoring for a Backstage instance on OpenShift
- context:
  - '# Monitoring and logging # Log Levels Logging is an essential part of monitoring
    and debugging software applications. It provides insight into how the application
    is functioning at runtime and can help you detect and diagnose issues. By adjusting
    the log level, you can control the amount and type of information displayed in
    the logs, ranging from highly detailed diagnostic output to the most critical
    errors. With this flexibility, you can customize logging output to match your
    current requirements, whether during development, testing, or production. You
    can choose from the following log levels, listed in order of decreasing verbosity:
    debug: Detailed information, typically useful only when troubleshooting. info:
    General information about the operation of the application. This is the default
    level. warn: Indicates potential issues or situations that might require attention.
    error: Indicates errors that have occurred but might not prevent the application
    from continuing. critical: Indicates critical errors that require immediate attention
    and are likely to prevent the application from functioning correctly. You can
    control the verbosity of the logging by setting the log level. The log level determines
    the minimum severity level of events displayed in the console. For example, if
    the log level is set to ''info'', events with a severity level of ''debug'' are
    ignored. To increase the log level, you can set the LOG_LEVEL environment variable
    to a higher severity level, such as ''warn'' or ''error''. However, increasing
    the log level might not result in more output if the existing code primarily emits
    logs at lower severity levels, for example, ''debug'' or ''info''. In such a case,
    adjust the logging statements within the code to use higher severity levels to
    see more output. No additional steps are required beyond setting the LOG_LEVEL
    environment variable, but its effectiveness depends on the existing logging statements
    in the code. # Enabling observability for Red Hat Developer Hub on OpenShift Container
    Platform In OpenShift Container Platform, metrics are exposed through an HTTP
    service endpoint under the /metrics canonical name. You can create a ServiceMonitor
    custom resource (CR) to scrape metrics from a service endpoint in a user-defined
    project. ## Enabling metrics monitoring in a Red Hat Developer Hub Operator installation
    on an OpenShift Container Platform cluster You can enable and view metrics for
    an Operator-installed Red Hat Developer Hub instance from the OpenShift Container
    Platform web console. Metrics are exposed through an HTTP service endpoint under
    the /metrics canonical name. By setting the spec.monitoring.enabled field to true
    in your Red Hat Developer Hub custom resource (CR), you instruct the Operator
    to automatically create and manage the necessary ServiceMonitor to scrape metrics
    from the service endpoint. Your OpenShift Container Platform cluster has monitoring
    for user defined projects enabled. You have installed Red Hat Developer Hub on
    OpenShift Container Platform using the Red Hat Developer Hub Operator. You have
    installed the OpenShift CLI (oc). 1. Use the OpenShift CLI (oc) to edit your existing
    Red Hat Developer Hub CR. ```bash oc edit Backstage <instance name> ``` 2. In
    the CR, locate the spec field and add the monitoring configuration block. ```yaml
    spec: monitoring: enabled: true ``` 3. Save the RHDH CR. The RHDH Operator detects
    the configuration and automatically creates the corresponding ServiceMonitor custom
    resource (CR). [NOTE] ---- The Operator automatically configures the ServiceMonitor
    with the correct labels (app.kubernetes.io/instance and app.kubernetes.io/name)
    that match your Backstage CR. The ServiceMonitor will be named metrics-<cr-name>.
    No additional label configuration is required. ---- 1. From the OpenShift Container
    Platform web console, select the Observe view. 2. Click the Metrics tab to view
    metrics for Red Hat Developer Hub pods. 3. From the OpenShift Container Platform
    web console, click Project > Services and verify the labels for backstage-developer-hub.
    ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:41:27.116858'
    uuid: 63dd8cc6-9e72-4f7f-ade2-35b073c56a31
  response: To enable metrics monitoring for an Operator-installed Red Hat Developer
    Hub instance, you must edit your existing Red Hat Developer Hub custom resource
    (CR) using the OpenShift CLI (oc). In the CR, locate the spec field and add the
    monitoring configuration block, setting `spec.monitoring.enabled` to `true`. After
    you save the CR, the RHDH Operator will detect the configuration and automatically
    create the corresponding ServiceMonitor custom resource to scrape metrics from
    the service endpoint.
  user_input: How do I enable metrics monitoring for my Operator-installed Red Hat
    Developer Hub instance on OpenShift?
- context:
  - '# Monitoring and logging # Log Levels Logging is an essential part of monitoring
    and debugging software applications. It provides insight into how the application
    is functioning at runtime and can help you detect and diagnose issues. By adjusting
    the log level, you can control the amount and type of information displayed in
    the logs, ranging from highly detailed diagnostic output to the most critical
    errors. With this flexibility, you can customize logging output to match your
    current requirements, whether during development, testing, or production. You
    can choose from the following log levels, listed in order of decreasing verbosity:
    debug: Detailed information, typically useful only when troubleshooting. info:
    General information about the operation of the application. This is the default
    level. warn: Indicates potential issues or situations that might require attention.
    error: Indicates errors that have occurred but might not prevent the application
    from continuing. critical: Indicates critical errors that require immediate attention
    and are likely to prevent the application from functioning correctly. You can
    control the verbosity of the logging by setting the log level. The log level determines
    the minimum severity level of events displayed in the console. For example, if
    the log level is set to ''info'', events with a severity level of ''debug'' are
    ignored. To increase the log level, you can set the LOG_LEVEL environment variable
    to a higher severity level, such as ''warn'' or ''error''. However, increasing
    the log level might not result in more output if the existing code primarily emits
    logs at lower severity levels, for example, ''debug'' or ''info''. In such a case,
    adjust the logging statements within the code to use higher severity levels to
    see more output. No additional steps are required beyond setting the LOG_LEVEL
    environment variable, but its effectiveness depends on the existing logging statements
    in the code. # Enabling observability for Red Hat Developer Hub on OpenShift Container
    Platform In OpenShift Container Platform, metrics are exposed through an HTTP
    service endpoint under the /metrics canonical name. You can create a ServiceMonitor
    custom resource (CR) to scrape metrics from a service endpoint in a user-defined
    project. ## Enabling metrics monitoring in a Red Hat Developer Hub Operator installation
    on an OpenShift Container Platform cluster You can enable and view metrics for
    an Operator-installed Red Hat Developer Hub instance from the OpenShift Container
    Platform web console. Metrics are exposed through an HTTP service endpoint under
    the /metrics canonical name. By setting the spec.monitoring.enabled field to true
    in your Red Hat Developer Hub custom resource (CR), you instruct the Operator
    to automatically create and manage the necessary ServiceMonitor to scrape metrics
    from the service endpoint. Your OpenShift Container Platform cluster has monitoring
    for user defined projects enabled. You have installed Red Hat Developer Hub on
    OpenShift Container Platform using the Red Hat Developer Hub Operator. You have
    installed the OpenShift CLI (oc). 1. Use the OpenShift CLI (oc) to edit your existing
    Red Hat Developer Hub CR. ```bash oc edit Backstage <instance name> ``` 2. In
    the CR, locate the spec field and add the monitoring configuration block. ```yaml
    spec: monitoring: enabled: true ``` 3. Save the RHDH CR. The RHDH Operator detects
    the configuration and automatically creates the corresponding ServiceMonitor custom
    resource (CR). [NOTE] ---- The Operator automatically configures the ServiceMonitor
    with the correct labels (app.kubernetes.io/instance and app.kubernetes.io/name)
    that match your Backstage CR. The ServiceMonitor will be named metrics-<cr-name>.
    No additional label configuration is required. ---- 1. From the OpenShift Container
    Platform web console, select the Observe view. 2. Click the Metrics tab to view
    metrics for Red Hat Developer Hub pods. 3. From the OpenShift Container Platform
    web console, click Project > Services and verify the labels for backstage-developer-hub.
    ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:41:37.671652'
    uuid: c20f56ad-268e-4512-865e-fbcd78c7dabd
  response: 'To enable metrics monitoring for an Operator-installed Red Hat Developer
    Hub instance, you set the `spec.monitoring.enabled` field to `true` in your Red
    Hat Developer Hub custom resource (CR). The steps are: 1. Use the OpenShift CLI
    (oc) to edit your CR with `oc edit Backstage <instance name>`. 2. In the CR, locate
    the `spec` field and add the monitoring configuration block: `spec: monitoring:
    enabled: true`. 3. Save the RHDH CR. After saving, the RHDH Operator detects the
    configuration and automatically creates the corresponding ServiceMonitor custom
    resource (CR). The Operator also automatically configures the ServiceMonitor with
    the correct labels that match your Backstage CR, and the ServiceMonitor will be
    named `metrics-<cr-name>`.'
  user_input: I'm trying to setup observability for our Red Hat Developer Hub instalation
    on OpenShift Container Platfrom, how can I enabel metrics monitering and what
    are the specific steps I need to take in the CR, and what does the Opertor do
    automatically after I make the changes?
- context:
  - 'Enabling metrics monitoring in a Helm chart installation on an OpenShift Container
    Platform cluster You can enable and view metrics for a Red Hat Developer Hub Helm
    deployment from the OpenShift Container Platform web console. Metrics monitoring
    is enabled through configuration during a chart upgrade. After the upgrade, the
    Helm release generates the necessary ServiceMonitor resource. Your OpenShift Container
    Platform cluster has monitoring for user defined projects enabled. You have installed
    Red Hat Developer Hub on OpenShift Container Platform using the Helm chart. 1.
    From the OpenShift Container Platform web console, select the Topology view. 2.
    Click the overflow menu of the Red Hat Developer Hub Helm chart, and select Upgrade.
    ![helm upgrade] 3. On the Upgrade Helm Release page, select the YAML view option
    in Configure via, then configure the metrics section in the YAML, as shown in
    the following example: ```yaml upstream: # ... metrics: serviceMonitor: enabled:
    true path: /metrics port: http metrics # ... ``` ![upgrade helm metrics] 4. Click
    Upgrade. 1. From the OpenShift Container Platform web console, select the Observe
    view. 2. Click the Metrics tab to view metrics for Red Hat Developer Hub pods.
    Configuring and using the monitoring stack in Red Hat OpenShift Container Platform
    # Monitoring and logging Red Hat Developer Hub on Amazon Web Services (AWS) You
    can configure Red Hat Developer Hub to use Amazon CloudWatch for real-time monitoring
    and Amazon Prometheus for comprehensive logging. This is convenient when hosting
    Developer Hub on Amazon Web Services (AWS) infrastructure. ## Monitoring with
    Amazon Prometheus You can configure Red Hat Developer Hub to use Amazon Prometheus
    for comprehensive logging. Amazon Prometheus extracts data from pods that have
    specific pod annotations. ### Prerequisites You configured Prometheus for your
    Elastic Kubernetes Service (EKS) clusters. You created an Amazon managed service
    for the Prometheus workspace. You configured Prometheus to import the Developer
    Hub metrics. You ingested Prometheus metrics into the created workspace. ### Configuring
    annotations for monitoring with Amazon Prometheus by using the Red Hat Developer
    Hub Operator To enable logging to Amazon Prometheus, you can configure the required
    pod annotations by using the Red Hat Developer Hub Operator. 1. As an administrator
    of the Red Hat Developer Hub Operator, edit the default configuration to add Prometheus
    annotations as follows: ``` # Update OPERATOR_NS accordingly $ OPERATOR_NS=rhdh-operator
    $ kubectl edit configmap backstage-default-config -n "${OPERATOR_NS}" ``` 2. Find
    the deployment.yaml key in the config map and add the annotations to the spec.template.metadata.annotations
    field as follows: ```yaml deployment.yaml: |- apiVersion: apps/v1 kind: Deployment
    # --- truncated --- spec: template: # --- truncated --- metadata: labels: rhdh.redhat.com/app:
    # placeholder for ''backstage-<cr-name>'' # --- truncated --- annotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' # --- truncated --- ``` 3. Save your changes. To verify if the scraping
    works: 1. Use kubectl to port-forward the Prometheus console to your local machine
    as follows: ``` $ kubectl - namespace=prometheus port forward deploy/prometheus
    server 9090 ``` 2. Open your web browser and navigate to http://localhost:9090
    to access the Prometheus console. 3. Monitor relevant metrics, such as process_cpu_user_seconds_total.
    ### Configuring annotations for monitoring with Amazon Prometheus by using the
    Red Hat Developer Hub Helm chart To enable logging to Amazon Prometheus, you can
    configure the required pod annotations by using the Red Hat Developer Hub Helm
    chart. To annotate the backstage pod for monitoring, update your values.yaml file
    as follows: ```yaml upstream: backstage: # -- TRUNCATED -- podAnnotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' ``` To verify if the scraping works: 1. Use kubectl to port-forward the
    Prometheus console to your local machine as follows: ```bash kubectl - namespace=prometheus
    port forward deploy/prometheus server 9090 ``` 2. Open your web browser and navigate
    to http://localhost:9090 to access the Prometheus console. 3. Monitor relevant
    metrics, such as process_cpu_user_seconds_total. ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:41:45.842219'
    uuid: f3d52eb6-07df-4efe-a5e9-96f62ad05f60
  response: 'To configure the required pod annotations for monitoring with Amazon
    Prometheus using the Red Hat Developer Hub Helm chart, you must update your values.yaml
    file. In the file, you need to add the following pod annotations under the `upstream.backstage`
    section: `prometheus.io/scrape: ''true''`, `prometheus.io/path: ''/metrics''`,
    `prometheus.io/port: ''9464''`, and `prometheus.io/scheme: ''http''`.'
  user_input: How do I configure Prometheus pod annotations for monitoring using the
    Red Hat Developer Hub Helm chart?
- context:
  - 'Enabling metrics monitoring in a Helm chart installation on an OpenShift Container
    Platform cluster You can enable and view metrics for a Red Hat Developer Hub Helm
    deployment from the OpenShift Container Platform web console. Metrics monitoring
    is enabled through configuration during a chart upgrade. After the upgrade, the
    Helm release generates the necessary ServiceMonitor resource. Your OpenShift Container
    Platform cluster has monitoring for user defined projects enabled. You have installed
    Red Hat Developer Hub on OpenShift Container Platform using the Helm chart. 1.
    From the OpenShift Container Platform web console, select the Topology view. 2.
    Click the overflow menu of the Red Hat Developer Hub Helm chart, and select Upgrade.
    ![helm upgrade] 3. On the Upgrade Helm Release page, select the YAML view option
    in Configure via, then configure the metrics section in the YAML, as shown in
    the following example: ```yaml upstream: # ... metrics: serviceMonitor: enabled:
    true path: /metrics port: http metrics # ... ``` ![upgrade helm metrics] 4. Click
    Upgrade. 1. From the OpenShift Container Platform web console, select the Observe
    view. 2. Click the Metrics tab to view metrics for Red Hat Developer Hub pods.
    Configuring and using the monitoring stack in Red Hat OpenShift Container Platform
    # Monitoring and logging Red Hat Developer Hub on Amazon Web Services (AWS) You
    can configure Red Hat Developer Hub to use Amazon CloudWatch for real-time monitoring
    and Amazon Prometheus for comprehensive logging. This is convenient when hosting
    Developer Hub on Amazon Web Services (AWS) infrastructure. ## Monitoring with
    Amazon Prometheus You can configure Red Hat Developer Hub to use Amazon Prometheus
    for comprehensive logging. Amazon Prometheus extracts data from pods that have
    specific pod annotations. ### Prerequisites You configured Prometheus for your
    Elastic Kubernetes Service (EKS) clusters. You created an Amazon managed service
    for the Prometheus workspace. You configured Prometheus to import the Developer
    Hub metrics. You ingested Prometheus metrics into the created workspace. ### Configuring
    annotations for monitoring with Amazon Prometheus by using the Red Hat Developer
    Hub Operator To enable logging to Amazon Prometheus, you can configure the required
    pod annotations by using the Red Hat Developer Hub Operator. 1. As an administrator
    of the Red Hat Developer Hub Operator, edit the default configuration to add Prometheus
    annotations as follows: ``` # Update OPERATOR_NS accordingly $ OPERATOR_NS=rhdh-operator
    $ kubectl edit configmap backstage-default-config -n "${OPERATOR_NS}" ``` 2. Find
    the deployment.yaml key in the config map and add the annotations to the spec.template.metadata.annotations
    field as follows: ```yaml deployment.yaml: |- apiVersion: apps/v1 kind: Deployment
    # --- truncated --- spec: template: # --- truncated --- metadata: labels: rhdh.redhat.com/app:
    # placeholder for ''backstage-<cr-name>'' # --- truncated --- annotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' # --- truncated --- ``` 3. Save your changes. To verify if the scraping
    works: 1. Use kubectl to port-forward the Prometheus console to your local machine
    as follows: ``` $ kubectl - namespace=prometheus port forward deploy/prometheus
    server 9090 ``` 2. Open your web browser and navigate to http://localhost:9090
    to access the Prometheus console. 3. Monitor relevant metrics, such as process_cpu_user_seconds_total.
    ### Configuring annotations for monitoring with Amazon Prometheus by using the
    Red Hat Developer Hub Helm chart To enable logging to Amazon Prometheus, you can
    configure the required pod annotations by using the Red Hat Developer Hub Helm
    chart. To annotate the backstage pod for monitoring, update your values.yaml file
    as follows: ```yaml upstream: backstage: # -- TRUNCATED -- podAnnotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' ``` To verify if the scraping works: 1. Use kubectl to port-forward the
    Prometheus console to your local machine as follows: ```bash kubectl - namespace=prometheus
    port forward deploy/prometheus server 9090 ``` 2. Open your web browser and navigate
    to http://localhost:9090 to access the Prometheus console. 3. Monitor relevant
    metrics, such as process_cpu_user_seconds_total. ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:41:57.998484'
    uuid: 0ce05abf-14cb-4486-ae86-0e553b257295
  response: 'When hosting Red Hat Developer Hub on Amazon Web Services (AWS), it can
    be configured to use Amazon Prometheus for comprehensive logging by adding specific
    pod annotations. This can be accomplished through two methods: by using the Red
    Hat Developer Hub Operator or by using the Red Hat Developer Hub Helm chart. With
    the Operator, you edit the `backstage-default-config` config map and add the annotations
    `prometheus.io/scrape: ''true''`, `prometheus.io/path: ''/metrics''`, `prometheus.io/port:
    ''9464''`, and `prometheus.io/scheme: ''http''` to the `spec.template.metadata.annotations`
    field within the `deployment.yaml` key. Alternatively, with the Helm chart, you
    update your `values.yaml` file to include these same annotations under the `upstream.backstage.podAnnotations`
    key.'
  user_input: What are the standardized procedures for configuring Red Hat Developer
    Hub for comprehensive logging with Amazon Prometheus when it is hosted on Amazon
    Web Services?
- context:
  - 'Enabling metrics monitoring in a Helm chart installation on an OpenShift Container
    Platform cluster You can enable and view metrics for a Red Hat Developer Hub Helm
    deployment from the OpenShift Container Platform web console. Metrics monitoring
    is enabled through configuration during a chart upgrade. After the upgrade, the
    Helm release generates the necessary ServiceMonitor resource. Your OpenShift Container
    Platform cluster has monitoring for user defined projects enabled. You have installed
    Red Hat Developer Hub on OpenShift Container Platform using the Helm chart. 1.
    From the OpenShift Container Platform web console, select the Topology view. 2.
    Click the overflow menu of the Red Hat Developer Hub Helm chart, and select Upgrade.
    ![helm upgrade] 3. On the Upgrade Helm Release page, select the YAML view option
    in Configure via, then configure the metrics section in the YAML, as shown in
    the following example: ```yaml upstream: # ... metrics: serviceMonitor: enabled:
    true path: /metrics port: http metrics # ... ``` ![upgrade helm metrics] 4. Click
    Upgrade. 1. From the OpenShift Container Platform web console, select the Observe
    view. 2. Click the Metrics tab to view metrics for Red Hat Developer Hub pods.
    Configuring and using the monitoring stack in Red Hat OpenShift Container Platform
    # Monitoring and logging Red Hat Developer Hub on Amazon Web Services (AWS) You
    can configure Red Hat Developer Hub to use Amazon CloudWatch for real-time monitoring
    and Amazon Prometheus for comprehensive logging. This is convenient when hosting
    Developer Hub on Amazon Web Services (AWS) infrastructure. ## Monitoring with
    Amazon Prometheus You can configure Red Hat Developer Hub to use Amazon Prometheus
    for comprehensive logging. Amazon Prometheus extracts data from pods that have
    specific pod annotations. ### Prerequisites You configured Prometheus for your
    Elastic Kubernetes Service (EKS) clusters. You created an Amazon managed service
    for the Prometheus workspace. You configured Prometheus to import the Developer
    Hub metrics. You ingested Prometheus metrics into the created workspace. ### Configuring
    annotations for monitoring with Amazon Prometheus by using the Red Hat Developer
    Hub Operator To enable logging to Amazon Prometheus, you can configure the required
    pod annotations by using the Red Hat Developer Hub Operator. 1. As an administrator
    of the Red Hat Developer Hub Operator, edit the default configuration to add Prometheus
    annotations as follows: ``` # Update OPERATOR_NS accordingly $ OPERATOR_NS=rhdh-operator
    $ kubectl edit configmap backstage-default-config -n "${OPERATOR_NS}" ``` 2. Find
    the deployment.yaml key in the config map and add the annotations to the spec.template.metadata.annotations
    field as follows: ```yaml deployment.yaml: |- apiVersion: apps/v1 kind: Deployment
    # --- truncated --- spec: template: # --- truncated --- metadata: labels: rhdh.redhat.com/app:
    # placeholder for ''backstage-<cr-name>'' # --- truncated --- annotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' # --- truncated --- ``` 3. Save your changes. To verify if the scraping
    works: 1. Use kubectl to port-forward the Prometheus console to your local machine
    as follows: ``` $ kubectl - namespace=prometheus port forward deploy/prometheus
    server 9090 ``` 2. Open your web browser and navigate to http://localhost:9090
    to access the Prometheus console. 3. Monitor relevant metrics, such as process_cpu_user_seconds_total.
    ### Configuring annotations for monitoring with Amazon Prometheus by using the
    Red Hat Developer Hub Helm chart To enable logging to Amazon Prometheus, you can
    configure the required pod annotations by using the Red Hat Developer Hub Helm
    chart. To annotate the backstage pod for monitoring, update your values.yaml file
    as follows: ```yaml upstream: backstage: # -- TRUNCATED -- podAnnotations: prometheus.io/scrape:
    ''true'' prometheus.io/path: ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme:
    ''http'' ``` To verify if the scraping works: 1. Use kubectl to port-forward the
    Prometheus console to your local machine as follows: ```bash kubectl - namespace=prometheus
    port forward deploy/prometheus server 9090 ``` 2. Open your web browser and navigate
    to http://localhost:9090 to access the Prometheus console. 3. Monitor relevant
    metrics, such as process_cpu_user_seconds_total. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:42:09.624838'
    uuid: 150e4549-20a0-4cae-b112-d46f685ac8f6
  response: To enable metrics monitoring in a Red Hat Developer Hub Helm chart installation
    on an OpenShift Container Platform cluster, you first go to the OpenShift Container
    Platform web console and select the Topology view. From there, click the overflow
    menu of the Red Hat Developer Hub Helm chart and select Upgrade. On the Upgrade
    Helm Release page, select the YAML view option and configure the metrics section
    in the YAML by setting `serviceMonitor.enabled` to `true`, `path` to `/metrics`,
    and `port` to `http metrics`. After you click Upgrade, the Helm release generates
    the necessary ServiceMonitor resource, and you can view the metrics by selecting
    the Observe view and clicking the Metrics tab.
  user_input: how i turn on metrics for helm chart?
- context:
  - 'Logging with Amazon CloudWatch Logging within the Red Hat Developer Hub relies
    on the Winston library. ### Configuring the application log level by using the
    Red Hat Developer Hub Operator You can configure the application log level by
    using the Red Hat Developer Hub Operator. Modify the logging level by including
    the environment variable LOG_LEVEL in your custom resource as follows: ```yaml
    spec: # Other fields omitted application: extraEnvs: envs: name: LOG_LEVEL value:
    debug ``` ### Configuring the application log level by using the Red Hat Developer
    Hub Helm chart You can configure the application log level by using the Red Hat
    Developer Hub Helm chart. Modify the logging level by adding the environment variable
    LOG_LEVEL to your Helm chart values.yaml file: ```yaml upstream: backstage: #
    -- Truncated -- extraEnvVars: name: LOG_LEVEL value: debug ``` ### Retrieving
    logs from Amazon CloudWatch CloudWatch Container Insights is used to capture logs
    and metrics for Amazon Elastic Kubernetes Service. For more information, see Logging
    for Amazon Elastic Kubernetes Service documentation. To capture the logs and metrics,
    install the Amazon CloudWatch Observability EKS add on in your cluster. Following
    the setup of Container Insights, you can access container logs using Logs Insights
    or Live Tail views. CloudWatch names the log group where all container logs are
    consolidated in the following manner: ``` /aws/containerinsights/<cluster_name>/application
    ``` To retrieve logs from the Developer Hub instance, run a query such as: ```sql
    fields @timestamp, @message, kubernetes.container_name | filter kubernetes.container_name
    in ["install-dynamic-plugins", "backstage-backend"] ``` # Monitoring and logging
    with Azure Kubernetes Services (AKS) in Red Hat Developer Hub Monitoring and logging
    are integral aspects of managing and maintaining Azure Kubernetes Services (AKS)
    in Red Hat Developer Hub. With features like Managed Prometheus Monitoring and
    Azure Monitor integration, administrators can efficiently monitor resource utilization,
    diagnose issues, and ensure the reliability of their containerized workloads.
    ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:42:19.833594'
    uuid: b1385c42-1474-4480-9fe1-44a2f85f404a
  response: Monitoring and logging are integral aspects of managing and maintaining
    Azure Kubernetes Services (AKS) in Red Hat Developer Hub. With features like Managed
    Prometheus Monitoring and Azure Monitor integration, administrators can efficiently
    monitor resource utilization, diagnose issues, and ensure the reliability of their
    containerized workloads.
  user_input: how do i monitor my azure kubernets services?
- context:
  - 'Logging with Amazon CloudWatch Logging within the Red Hat Developer Hub relies
    on the Winston library. ### Configuring the application log level by using the
    Red Hat Developer Hub Operator You can configure the application log level by
    using the Red Hat Developer Hub Operator. Modify the logging level by including
    the environment variable LOG_LEVEL in your custom resource as follows: ```yaml
    spec: # Other fields omitted application: extraEnvs: envs: name: LOG_LEVEL value:
    debug ``` ### Configuring the application log level by using the Red Hat Developer
    Hub Helm chart You can configure the application log level by using the Red Hat
    Developer Hub Helm chart. Modify the logging level by adding the environment variable
    LOG_LEVEL to your Helm chart values.yaml file: ```yaml upstream: backstage: #
    -- Truncated -- extraEnvVars: name: LOG_LEVEL value: debug ``` ### Retrieving
    logs from Amazon CloudWatch CloudWatch Container Insights is used to capture logs
    and metrics for Amazon Elastic Kubernetes Service. For more information, see Logging
    for Amazon Elastic Kubernetes Service documentation. To capture the logs and metrics,
    install the Amazon CloudWatch Observability EKS add on in your cluster. Following
    the setup of Container Insights, you can access container logs using Logs Insights
    or Live Tail views. CloudWatch names the log group where all container logs are
    consolidated in the following manner: ``` /aws/containerinsights/<cluster_name>/application
    ``` To retrieve logs from the Developer Hub instance, run a query such as: ```sql
    fields @timestamp, @message, kubernetes.container_name | filter kubernetes.container_name
    in ["install-dynamic-plugins", "backstage-backend"] ``` # Monitoring and logging
    with Azure Kubernetes Services (AKS) in Red Hat Developer Hub Monitoring and logging
    are integral aspects of managing and maintaining Azure Kubernetes Services (AKS)
    in Red Hat Developer Hub. With features like Managed Prometheus Monitoring and
    Azure Monitor integration, administrators can efficiently monitor resource utilization,
    diagnose issues, and ensure the reliability of their containerized workloads.
    ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:42:29.697728'
    uuid: 9bcbb65d-4808-4b0b-b892-9da5a8b93706
  response: 'CloudWatch Container Insights is used to capture logs and metrics for
    Amazon Elastic Kubernetes Service. To do this, you must install the Amazon CloudWatch
    Observability EKS add on in your cluster. After the setup is complete, you can
    access container logs using Logs Insights or Live Tail views. All container logs
    are consolidated in a log group named with the format `/aws/containerinsights/<cluster_name>/application`.
    To retrieve logs specifically from the Developer Hub instance, you can run a query
    such as: `fields @timestamp, @message, kubernetes.container_name | filter kubernetes.container_name
    in ["install-dynamic-plugins", "backstage-backend"]`.'
  user_input: How do we use Cloudwathc Contaner Insites to get logs and metrics from
    our Amazon Elastic Kubernets Servic?
- context:
  - 'Logging with Amazon CloudWatch Logging within the Red Hat Developer Hub relies
    on the Winston library. ### Configuring the application log level by using the
    Red Hat Developer Hub Operator You can configure the application log level by
    using the Red Hat Developer Hub Operator. Modify the logging level by including
    the environment variable LOG_LEVEL in your custom resource as follows: ```yaml
    spec: # Other fields omitted application: extraEnvs: envs: name: LOG_LEVEL value:
    debug ``` ### Configuring the application log level by using the Red Hat Developer
    Hub Helm chart You can configure the application log level by using the Red Hat
    Developer Hub Helm chart. Modify the logging level by adding the environment variable
    LOG_LEVEL to your Helm chart values.yaml file: ```yaml upstream: backstage: #
    -- Truncated -- extraEnvVars: name: LOG_LEVEL value: debug ``` ### Retrieving
    logs from Amazon CloudWatch CloudWatch Container Insights is used to capture logs
    and metrics for Amazon Elastic Kubernetes Service. For more information, see Logging
    for Amazon Elastic Kubernetes Service documentation. To capture the logs and metrics,
    install the Amazon CloudWatch Observability EKS add on in your cluster. Following
    the setup of Container Insights, you can access container logs using Logs Insights
    or Live Tail views. CloudWatch names the log group where all container logs are
    consolidated in the following manner: ``` /aws/containerinsights/<cluster_name>/application
    ``` To retrieve logs from the Developer Hub instance, run a query such as: ```sql
    fields @timestamp, @message, kubernetes.container_name | filter kubernetes.container_name
    in ["install-dynamic-plugins", "backstage-backend"] ``` # Monitoring and logging
    with Azure Kubernetes Services (AKS) in Red Hat Developer Hub Monitoring and logging
    are integral aspects of managing and maintaining Azure Kubernetes Services (AKS)
    in Red Hat Developer Hub. With features like Managed Prometheus Monitoring and
    Azure Monitor integration, administrators can efficiently monitor resource utilization,
    diagnose issues, and ensure the reliability of their containerized workloads.
    ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:42:38.091451'
    uuid: 482c7879-61c4-451a-8f10-3a83537ee6bf
  response: Logging within the Red Hat Developer Hub relies on the Winston library.
  user_input: The logging in Red Hat Developer Hub, it use the Winston library, what
    is this library for?
- context:
  - 'Enabling Azure Monitor metrics To enable managed Prometheus monitoring, use the
    -enable-azure-monitor-metrics option within either the az aks create or az aks
    update command, depending on whether you&#8217;re creating a new cluster or updating
    an existing one, such as: ```bash az aks create/update - resource group <your
    ResourceGroup> - name <your Cluster> - enable azure monitor metrics ``` The previous
    command installs the metrics add-on, which gathers Prometheus metrics. Using the
    previous command, you can enable monitoring of Azure resources through both native
    Azure Monitor metrics. You can also view the results in the portal under Monitoring
    -> Insights. For more information, see Monitor Azure resources with Azure Monitor.
    Furthermore, metrics from both the Managed Prometheus service and Azure Monitor
    can be accessed through Azure Managed Grafana service. For more information, see
    Link a Grafana workspace section. By default, Prometheus uses the minimum ingesting
    profile, which optimizes ingestion volume and sets default configurations for
    scrape frequency, targets, and metrics collected. The default settings can be
    customized through custom configuration. Azure offers various methods, including
    using different ConfigMaps, to provide scrape configuration and other metric add-on
    settings. For more information about default configuration, see Default Prometheus
    metrics configuration in Azure Monitor and Customize scraping of Prometheus metrics
    in Azure Monitor managed service for Prometheus documentation. ## Configuring
    annotations for monitoring You can configure the annotations for monitoring Red
    Hat Developer Hub specific metrics in both Helm deployment and Operator-backed
    deployment. Helm deployment:: To annotate the backstage pod for monitoring, update
    your values.yaml file as follows: ```yaml upstream: backstage: # --- TRUNCATED
    --- podAnnotations: prometheus.io/scrape: ''true'' prometheus.io/path: ''/metrics''
    prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' ``` Operator-backed
    deployment:: 1. As an administrator of the operator, edit the default configuration
    to add Prometheus annotations as follows: ```bash # Update OPERATOR_NS accordingly
    OPERATOR_NS=rhdh operator kubectl edit configmap backstage default config n "${OPERATOR_NS}"
    ``` 2. Find the deployment.yaml key in the ConfigMap and add the annotations to
    the spec.template.metadata.annotations field as follows: ```yaml deployment.yaml:
    |- apiVersion: apps/v1 kind: Deployment # --- truncated --- spec: template: #
    --- truncated --- metadata: labels: rhdh.redhat.com/app: # placeholder for ''backstage-<cr-name>''
    # --- truncated --- annotations: prometheus.io/scrape: ''true'' prometheus.io/path:
    ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' # ---
    truncated --- ``` 3. Save your changes. To verify if the scraping works, navigate
    to the corresponding Azure Monitor Workspace and view the metrics under Monitoring
    -> Metrics. ## Viewing logs with Azure Kubernetes Service (AKS) You can access
    live data logs generated by Kubernetes objects and collect log data in Container
    Insights within AKS. You have deployed Developer Hub on AKS. For more information,
    see Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service. View
    live logs from your Developer Hub instance:: 1. Navigate to the Azure Portal.
    2. Search for the resource group <your-ResourceGroup> and locate your AKS cluster
    <your-Cluster>. 3. Select Kubernetes resources -> Workloads from the menu. 4.
    Select the <your-rhdh-cr>-developer-hub (in case of Helm Chart installation) or
    <your-rhdh-cr>-backstage (in case of Operator-backed installation) deployment.
    5. Click Live Logs in the left menu. 6. Select the pod. [NOTE] ---- There must
    be only single pod. ---- Live log data is collected and displayed. View real-time
    log data from the Container Engine:: 1. Navigate to the Azure Portal. 2. Search
    for the resource group <your-ResourceGroup> and locate your AKS cluster <your-Cluster>.
    3. Select Monitoring -> Insights from the menu. 4. Go to the Containers tab. 5.
    Find the backend-backstage container and click it to view real-time log data as
    it''s generated by the Container Engine.'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:42:47.101498'
    uuid: 3d7e9cef-132a-43ff-a021-4fcd425b3eb3
  response: To enable managed Prometheus monitoring, you must use the "-enable-azure-monitor-metrics"
    option with either the "az aks create" or "az aks update" command, depending on
    whether you are creating a new cluster or updating an existing one. This command
    installs the metrics add-on, which gathers Prometheus metrics and enables monitoring
    of Azure resources through native Azure Monitor metrics. The results can be viewed
    in the portal under Monitoring -> Insights, and metrics from both the Managed
    Prometheus service and Azure Monitor can be accessed through the Azure Managed
    Grafana service.
  user_input: How do I enable Azure Monitor metrics to collect Prometheus data from
    my AKS cluster?
- context:
  - 'Enabling Azure Monitor metrics To enable managed Prometheus monitoring, use the
    -enable-azure-monitor-metrics option within either the az aks create or az aks
    update command, depending on whether you&#8217;re creating a new cluster or updating
    an existing one, such as: ```bash az aks create/update - resource group <your
    ResourceGroup> - name <your Cluster> - enable azure monitor metrics ``` The previous
    command installs the metrics add-on, which gathers Prometheus metrics. Using the
    previous command, you can enable monitoring of Azure resources through both native
    Azure Monitor metrics. You can also view the results in the portal under Monitoring
    -> Insights. For more information, see Monitor Azure resources with Azure Monitor.
    Furthermore, metrics from both the Managed Prometheus service and Azure Monitor
    can be accessed through Azure Managed Grafana service. For more information, see
    Link a Grafana workspace section. By default, Prometheus uses the minimum ingesting
    profile, which optimizes ingestion volume and sets default configurations for
    scrape frequency, targets, and metrics collected. The default settings can be
    customized through custom configuration. Azure offers various methods, including
    using different ConfigMaps, to provide scrape configuration and other metric add-on
    settings. For more information about default configuration, see Default Prometheus
    metrics configuration in Azure Monitor and Customize scraping of Prometheus metrics
    in Azure Monitor managed service for Prometheus documentation. ## Configuring
    annotations for monitoring You can configure the annotations for monitoring Red
    Hat Developer Hub specific metrics in both Helm deployment and Operator-backed
    deployment. Helm deployment:: To annotate the backstage pod for monitoring, update
    your values.yaml file as follows: ```yaml upstream: backstage: # --- TRUNCATED
    --- podAnnotations: prometheus.io/scrape: ''true'' prometheus.io/path: ''/metrics''
    prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' ``` Operator-backed
    deployment:: 1. As an administrator of the operator, edit the default configuration
    to add Prometheus annotations as follows: ```bash # Update OPERATOR_NS accordingly
    OPERATOR_NS=rhdh operator kubectl edit configmap backstage default config n "${OPERATOR_NS}"
    ``` 2. Find the deployment.yaml key in the ConfigMap and add the annotations to
    the spec.template.metadata.annotations field as follows: ```yaml deployment.yaml:
    |- apiVersion: apps/v1 kind: Deployment # --- truncated --- spec: template: #
    --- truncated --- metadata: labels: rhdh.redhat.com/app: # placeholder for ''backstage-<cr-name>''
    # --- truncated --- annotations: prometheus.io/scrape: ''true'' prometheus.io/path:
    ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' # ---
    truncated --- ``` 3. Save your changes. To verify if the scraping works, navigate
    to the corresponding Azure Monitor Workspace and view the metrics under Monitoring
    -> Metrics. ## Viewing logs with Azure Kubernetes Service (AKS) You can access
    live data logs generated by Kubernetes objects and collect log data in Container
    Insights within AKS. You have deployed Developer Hub on AKS. For more information,
    see Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service. View
    live logs from your Developer Hub instance:: 1. Navigate to the Azure Portal.
    2. Search for the resource group <your-ResourceGroup> and locate your AKS cluster
    <your-Cluster>. 3. Select Kubernetes resources -> Workloads from the menu. 4.
    Select the <your-rhdh-cr>-developer-hub (in case of Helm Chart installation) or
    <your-rhdh-cr>-backstage (in case of Operator-backed installation) deployment.
    5. Click Live Logs in the left menu. 6. Select the pod. [NOTE] ---- There must
    be only single pod. ---- Live log data is collected and displayed. View real-time
    log data from the Container Engine:: 1. Navigate to the Azure Portal. 2. Search
    for the resource group <your-ResourceGroup> and locate your AKS cluster <your-Cluster>.
    3. Select Monitoring -> Insights from the menu. 4. Go to the Containers tab. 5.
    Find the backend-backstage container and click it to view real-time log data as
    it''s generated by the Container Engine.'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:42:56.628697'
    uuid: cb44875a-05e1-4388-9bad-72dfec235f02
  response: To enable managed Prometheus monitoring on Azure Kubernetes Service, you
    must use the `-enable-azure-monitor-metrics` option with either the `az aks create`
    or `az aks update` command. This command installs the metrics add-on, which gathers
    Prometheus metrics and enables monitoring of Azure resources through native Azure
    Monitor metrics. The results can be viewed in the portal under Monitoring -> Insights,
    and metrics can be accessed through the Azure Managed Grafana service. To view
    logs, you can access live data logs generated by Kubernetes objects. To view live
    logs from your Developer Hub instance, navigate to the Azure Portal, locate your
    AKS cluster within its resource group, and select Kubernetes resources -> Workloads.
    From there, select the appropriate deployment (`<your-rhdh-cr>-developer-hub`
    for Helm Chart or `<your-rhdh-cr>-backstage` for Operator-backed installation),
    click "Live Logs", and select the pod. Alternatively, to view real-time log data
    from the Container Engine, navigate to your AKS cluster in the Azure Portal, select
    Monitoring -> Insights, go to the Containers tab, and click on the `backend-backstage`
    container.
  user_input: Could you provide a detailed breakdown of the procedures for enabling
    Azure Monitor metrics and subsequently viewing the live logs for a Red Hat Developer
    Hub instance that has been deployed on Azure Kubernetes Service?
- context:
  - 'Enabling Azure Monitor metrics To enable managed Prometheus monitoring, use the
    -enable-azure-monitor-metrics option within either the az aks create or az aks
    update command, depending on whether you&#8217;re creating a new cluster or updating
    an existing one, such as: ```bash az aks create/update - resource group <your
    ResourceGroup> - name <your Cluster> - enable azure monitor metrics ``` The previous
    command installs the metrics add-on, which gathers Prometheus metrics. Using the
    previous command, you can enable monitoring of Azure resources through both native
    Azure Monitor metrics. You can also view the results in the portal under Monitoring
    -> Insights. For more information, see Monitor Azure resources with Azure Monitor.
    Furthermore, metrics from both the Managed Prometheus service and Azure Monitor
    can be accessed through Azure Managed Grafana service. For more information, see
    Link a Grafana workspace section. By default, Prometheus uses the minimum ingesting
    profile, which optimizes ingestion volume and sets default configurations for
    scrape frequency, targets, and metrics collected. The default settings can be
    customized through custom configuration. Azure offers various methods, including
    using different ConfigMaps, to provide scrape configuration and other metric add-on
    settings. For more information about default configuration, see Default Prometheus
    metrics configuration in Azure Monitor and Customize scraping of Prometheus metrics
    in Azure Monitor managed service for Prometheus documentation. ## Configuring
    annotations for monitoring You can configure the annotations for monitoring Red
    Hat Developer Hub specific metrics in both Helm deployment and Operator-backed
    deployment. Helm deployment:: To annotate the backstage pod for monitoring, update
    your values.yaml file as follows: ```yaml upstream: backstage: # --- TRUNCATED
    --- podAnnotations: prometheus.io/scrape: ''true'' prometheus.io/path: ''/metrics''
    prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' ``` Operator-backed
    deployment:: 1. As an administrator of the operator, edit the default configuration
    to add Prometheus annotations as follows: ```bash # Update OPERATOR_NS accordingly
    OPERATOR_NS=rhdh operator kubectl edit configmap backstage default config n "${OPERATOR_NS}"
    ``` 2. Find the deployment.yaml key in the ConfigMap and add the annotations to
    the spec.template.metadata.annotations field as follows: ```yaml deployment.yaml:
    |- apiVersion: apps/v1 kind: Deployment # --- truncated --- spec: template: #
    --- truncated --- metadata: labels: rhdh.redhat.com/app: # placeholder for ''backstage-<cr-name>''
    # --- truncated --- annotations: prometheus.io/scrape: ''true'' prometheus.io/path:
    ''/metrics'' prometheus.io/port: ''9464'' prometheus.io/scheme: ''http'' # ---
    truncated --- ``` 3. Save your changes. To verify if the scraping works, navigate
    to the corresponding Azure Monitor Workspace and view the metrics under Monitoring
    -> Metrics. ## Viewing logs with Azure Kubernetes Service (AKS) You can access
    live data logs generated by Kubernetes objects and collect log data in Container
    Insights within AKS. You have deployed Developer Hub on AKS. For more information,
    see Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service. View
    live logs from your Developer Hub instance:: 1. Navigate to the Azure Portal.
    2. Search for the resource group <your-ResourceGroup> and locate your AKS cluster
    <your-Cluster>. 3. Select Kubernetes resources -> Workloads from the menu. 4.
    Select the <your-rhdh-cr>-developer-hub (in case of Helm Chart installation) or
    <your-rhdh-cr>-backstage (in case of Operator-backed installation) deployment.
    5. Click Live Logs in the left menu. 6. Select the pod. [NOTE] ---- There must
    be only single pod. ---- Live log data is collected and displayed. View real-time
    log data from the Container Engine:: 1. Navigate to the Azure Portal. 2. Search
    for the resource group <your-ResourceGroup> and locate your AKS cluster <your-Cluster>.
    3. Select Monitoring -> Insights from the menu. 4. Go to the Containers tab. 5.
    Find the backend-backstage container and click it to view real-time log data as
    it''s generated by the Container Engine.'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:43:04.081103'
    uuid: 153b119e-ff03-48aa-8211-1535435a164d
  response: To view live logs from a Kubernetes object, you first navigate to the
    Azure Portal, search for your resource group, and locate your AKS cluster. From
    the menu, select Kubernetes resources -> Workloads. Next, select the deployment,
    which will be `<your-rhdh-cr>-developer-hub` for a Helm Chart installation or
    `<your-rhdh-cr>-backstage` for an Operator-backed installation. Click Live Logs
    in the left menu and then select the pod. The live log data will then be collected
    and displayed.
  user_input: howw can i see the live loggs from a Kubernets object for my Developer
    Hub instance?
- context:
  - '# About Red Hat Developer Hub Red Hat Developer Hub (RHDH) is an enterprise-grade
    internal developer portal (IDP) that helps simplify and accelerates software delivery.
    It provides a customizable web-based interface that centralizes access to key
    development resources, including source code repositories, CI and CD pipelines,
    APIs, documentation, and runtime environments. Red Hat Developer Hub is designed
    for cloud-native environments, including supported Kubernetes platforms, Red Hat
    OpenShift Container Platform, and hybrid infrastructure. By consolidating tools
    and standardizing development workflows, it helps teams deliver software faster
    with more consistency. Designed for enterprise-scale software teams, RHDH helps
    developers focus on building software rather than managing tools. Developers can
    onboard quickly, create environments, and integrate with existing systems. With
    enterprise-grade security, role-based access control, and 24x7 support, teams
    stay productive while meeting compliance and reliability standards. #'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T15:43:11.576750'
    uuid: 07a24870-8129-4669-bd41-0851f758e450
  response: Red Hat Developer Hub provides a customizable web-based interface that
    centralizes access to key development resources, including CI and CD pipelines.
  user_input: What access does Red Hat Developer Hub provide for CI?
- context:
  - '# About Red Hat Developer Hub Red Hat Developer Hub (RHDH) is an enterprise-grade
    internal developer portal (IDP) that helps simplify and accelerates software delivery.
    It provides a customizable web-based interface that centralizes access to key
    development resources, including source code repositories, CI and CD pipelines,
    APIs, documentation, and runtime environments. Red Hat Developer Hub is designed
    for cloud-native environments, including supported Kubernetes platforms, Red Hat
    OpenShift Container Platform, and hybrid infrastructure. By consolidating tools
    and standardizing development workflows, it helps teams deliver software faster
    with more consistency. Designed for enterprise-scale software teams, RHDH helps
    developers focus on building software rather than managing tools. Developers can
    onboard quickly, create environments, and integrate with existing systems. With
    enterprise-grade security, role-based access control, and 24x7 support, teams
    stay productive while meeting compliance and reliability standards. #'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T15:43:19.563320'
    uuid: e296a9e0-fed3-4dce-b0fd-60a460875e46
  response: Red Hat Developer Hub (RHDH) is an enterprise-grade internal developer
    portal that helps simplify and accelerate software delivery. It achieves this
    by providing a customizable web-based interface that centralizes access to key
    development resources such as source code repositories, CI and CD pipelines, APIs,
    documentation, and runtime environments. By consolidating tools and standardizing
    development workflows, RHDH helps teams deliver software faster with more consistency,
    allowing developers to focus on building software rather than managing tools.
  user_input: How does RHDH help to simplyfy and accelarate our software delivry process
    for our teams?
- context:
  - '# About Red Hat Developer Hub Red Hat Developer Hub (RHDH) is an enterprise-grade
    internal developer portal (IDP) that helps simplify and accelerates software delivery.
    It provides a customizable web-based interface that centralizes access to key
    development resources, including source code repositories, CI and CD pipelines,
    APIs, documentation, and runtime environments. Red Hat Developer Hub is designed
    for cloud-native environments, including supported Kubernetes platforms, Red Hat
    OpenShift Container Platform, and hybrid infrastructure. By consolidating tools
    and standardizing development workflows, it helps teams deliver software faster
    with more consistency. Designed for enterprise-scale software teams, RHDH helps
    developers focus on building software rather than managing tools. Developers can
    onboard quickly, create environments, and integrate with existing systems. With
    enterprise-grade security, role-based access control, and 24x7 support, teams
    stay productive while meeting compliance and reliability standards. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:43:37.589391'
    uuid: 3b68b50f-d4e3-4292-872f-7143029854c7
  response: Red Hat Developer Hub (RHDH) is an enterprise-grade internal developer
    portal (IDP) designed to simplify and accelerate software delivery. It offers
    a customizable web-based interface that centralizes access to development resources
    like source code repositories, CI and CD pipelines, APIs, documentation, and runtime
    environments. It is designed for cloud-native environments, including supported
    Kubernetes platforms, Red Hat OpenShift Container Platform, and hybrid infrastructure,
    helping teams deliver software faster and with more consistency by consolidating
    tools and standardizing workflows.
  user_input: what is Red Hat Developer Hub
- context:
  - 'Understanding internal developer platforms An internal developer platform (IDP)
    is a curated set of tools and services that supports developer self-service. Instead
    of navigating multiple systems, developers use a unified interface to provision
    environments, deploy code, and access APIs. Why IDPs matter:: IDPs address the
    challenges of modern software delivery by enabling self-service, enforcing standards,
    and improving the developer experience. For organizations:: * Scalability: RHDH
    enables consistent developer onboarding and application delivery across growing
    teams and environments. * Security: Role-based access control (RBAC) and integration
    with enterprise systems ensure access is managed securely and in line with compliance
    requirements. * Operational efficiency: By removing manual handoffs and centralizing
    key development workflows, RHDH improves time to value and increases return on
    engineering investment. For platform engineers:: * Curated platforms: Platform
    teams can design reusable templates and integrations aligned with organizational
    policies and developer needs. * Central configuration: Infrastructure and policies
    are defined as code and centrally managed, reducing drift and maintenance overhead.
    * Governance at scale: Policies and best practices are embedded into developer
    workflows using automation and templates, without adding friction to the process.
    For developers:: * Faster onboarding: Developers can use learning paths, software
    templates, and software catalog to deploy compliant services within minutes, without
    depending on other teams for setup. * Reduced cognitive load: Developers can find
    tools, documentation, and deployment environments in one place, eliminating the
    need to switch between systems or manage disconnected resources. * Self-service
    workflows: Developers can create applications or environments on demand, without
    raising tickets or waiting for approvals. * Built-in standards: Developers can
    use preconfigured templates that enforce secure, compliant workflows without requiring
    manual setup. * Cross-team visibility: Developers can discover shared service
    catalogs and documentation to improve reuse and reduce duplication. * Higher productivity:
    Developers can spend more time building features and less time configuring infrastructure
    or resolving toolchain inconsistencies. Centralized dashboard:: Access development
    tools, CI/CD pipelines, APIs, monitoring tools, and documentation from a single
    interface. Integrate with systems like Git, Red Hat OpenShift Container Platform,
    Kubernetes, and JIRA. Learning paths:: Guide developers through structured tutorials
    and onboarding steps. Help teams upskill with internal and Red Hat training resources
    in one place. Plugins and integrations:: Extend RHDH with verified plugins that
    add new functionality without downtime. Dynamically integrate with supported tools
    such as Tekton for pipelines, GitOps for deployment automation, Nexus Repository
    for artifact storage, and JFrog Artifactory. RHDH also supports connecting to
    Red Hat OpenShift Container Platform, CI/CD systems, and security scanners through
    Red Hat-curated extensions. Role-Based Access Control (RBAC):: Manage user access
    with robust security permissions tailored to organizational needs. Software catalog::
    Search, view, and manage services, APIs, and libraries from a central inventory.
    Track ownership, metadata, and component health in one place. Software templates::
    Accelerate project setup using preconfigured templates for CI/CD, runtime, and
    security. Standardize implementation while enabling developer autonomy. Tech docs::
    Create, store, and view technical documentation alongside code. Make content searchable,
    consistently formatted, and accessible through the portal. Scalability:: Support
    growing teams and applications while maintaining access to the same tools and
    services. Configuring templates TechDocs for Red Hat Developer Hub Customizing
    the Learning Paths in Red Hat Developer Hub Introduction to plugins'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T15:43:47.398180'
    uuid: 29675688-bbdf-4576-a709-be5e5d4d5cfa
  response: Red Hat Developer Hub (RHDH) features a centralized dashboard that can
    integrate with systems like Git. Additionally, RHDH can be extended with plugins
    to dynamically integrate with supported tools such as GitOps for deployment automation.
  user_input: Red Hat Developer Hub Git integration
- context:
  - 'Understanding internal developer platforms An internal developer platform (IDP)
    is a curated set of tools and services that supports developer self-service. Instead
    of navigating multiple systems, developers use a unified interface to provision
    environments, deploy code, and access APIs. Why IDPs matter:: IDPs address the
    challenges of modern software delivery by enabling self-service, enforcing standards,
    and improving the developer experience. For organizations:: * Scalability: RHDH
    enables consistent developer onboarding and application delivery across growing
    teams and environments. * Security: Role-based access control (RBAC) and integration
    with enterprise systems ensure access is managed securely and in line with compliance
    requirements. * Operational efficiency: By removing manual handoffs and centralizing
    key development workflows, RHDH improves time to value and increases return on
    engineering investment. For platform engineers:: * Curated platforms: Platform
    teams can design reusable templates and integrations aligned with organizational
    policies and developer needs. * Central configuration: Infrastructure and policies
    are defined as code and centrally managed, reducing drift and maintenance overhead.
    * Governance at scale: Policies and best practices are embedded into developer
    workflows using automation and templates, without adding friction to the process.
    For developers:: * Faster onboarding: Developers can use learning paths, software
    templates, and software catalog to deploy compliant services within minutes, without
    depending on other teams for setup. * Reduced cognitive load: Developers can find
    tools, documentation, and deployment environments in one place, eliminating the
    need to switch between systems or manage disconnected resources. * Self-service
    workflows: Developers can create applications or environments on demand, without
    raising tickets or waiting for approvals. * Built-in standards: Developers can
    use preconfigured templates that enforce secure, compliant workflows without requiring
    manual setup. * Cross-team visibility: Developers can discover shared service
    catalogs and documentation to improve reuse and reduce duplication. * Higher productivity:
    Developers can spend more time building features and less time configuring infrastructure
    or resolving toolchain inconsistencies. Centralized dashboard:: Access development
    tools, CI/CD pipelines, APIs, monitoring tools, and documentation from a single
    interface. Integrate with systems like Git, Red Hat OpenShift Container Platform,
    Kubernetes, and JIRA. Learning paths:: Guide developers through structured tutorials
    and onboarding steps. Help teams upskill with internal and Red Hat training resources
    in one place. Plugins and integrations:: Extend RHDH with verified plugins that
    add new functionality without downtime. Dynamically integrate with supported tools
    such as Tekton for pipelines, GitOps for deployment automation, Nexus Repository
    for artifact storage, and JFrog Artifactory. RHDH also supports connecting to
    Red Hat OpenShift Container Platform, CI/CD systems, and security scanners through
    Red Hat-curated extensions. Role-Based Access Control (RBAC):: Manage user access
    with robust security permissions tailored to organizational needs. Software catalog::
    Search, view, and manage services, APIs, and libraries from a central inventory.
    Track ownership, metadata, and component health in one place. Software templates::
    Accelerate project setup using preconfigured templates for CI/CD, runtime, and
    security. Standardize implementation while enabling developer autonomy. Tech docs::
    Create, store, and view technical documentation alongside code. Make content searchable,
    consistently formatted, and accessible through the portal. Scalability:: Support
    growing teams and applications while maintaining access to the same tools and
    services. Configuring templates TechDocs for Red Hat Developer Hub Customizing
    the Learning Paths in Red Hat Developer Hub Introduction to plugins'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:43:58.498242'
    uuid: 83daa76c-de50-4610-9cfb-be0f3dbdc53f
  response: For platform engineers, an internal developer platform allows them to
    design reusable templates and integrations aligned with organizational policies
    and developer needs through curated platforms. It provides central configuration
    where infrastructure and policies are defined as code and centrally managed, which
    reduces drift and maintenance overhead. It also enables governance at scale by
    embedding policies and best practices into developer workflows using automation
    and templates, without adding friction to the process.
  user_input: Internal developer platform benefits for platform engineers
- context:
  - 'Understanding internal developer platforms An internal developer platform (IDP)
    is a curated set of tools and services that supports developer self-service. Instead
    of navigating multiple systems, developers use a unified interface to provision
    environments, deploy code, and access APIs. Why IDPs matter:: IDPs address the
    challenges of modern software delivery by enabling self-service, enforcing standards,
    and improving the developer experience. For organizations:: * Scalability: RHDH
    enables consistent developer onboarding and application delivery across growing
    teams and environments. * Security: Role-based access control (RBAC) and integration
    with enterprise systems ensure access is managed securely and in line with compliance
    requirements. * Operational efficiency: By removing manual handoffs and centralizing
    key development workflows, RHDH improves time to value and increases return on
    engineering investment. For platform engineers:: * Curated platforms: Platform
    teams can design reusable templates and integrations aligned with organizational
    policies and developer needs. * Central configuration: Infrastructure and policies
    are defined as code and centrally managed, reducing drift and maintenance overhead.
    * Governance at scale: Policies and best practices are embedded into developer
    workflows using automation and templates, without adding friction to the process.
    For developers:: * Faster onboarding: Developers can use learning paths, software
    templates, and software catalog to deploy compliant services within minutes, without
    depending on other teams for setup. * Reduced cognitive load: Developers can find
    tools, documentation, and deployment environments in one place, eliminating the
    need to switch between systems or manage disconnected resources. * Self-service
    workflows: Developers can create applications or environments on demand, without
    raising tickets or waiting for approvals. * Built-in standards: Developers can
    use preconfigured templates that enforce secure, compliant workflows without requiring
    manual setup. * Cross-team visibility: Developers can discover shared service
    catalogs and documentation to improve reuse and reduce duplication. * Higher productivity:
    Developers can spend more time building features and less time configuring infrastructure
    or resolving toolchain inconsistencies. Centralized dashboard:: Access development
    tools, CI/CD pipelines, APIs, monitoring tools, and documentation from a single
    interface. Integrate with systems like Git, Red Hat OpenShift Container Platform,
    Kubernetes, and JIRA. Learning paths:: Guide developers through structured tutorials
    and onboarding steps. Help teams upskill with internal and Red Hat training resources
    in one place. Plugins and integrations:: Extend RHDH with verified plugins that
    add new functionality without downtime. Dynamically integrate with supported tools
    such as Tekton for pipelines, GitOps for deployment automation, Nexus Repository
    for artifact storage, and JFrog Artifactory. RHDH also supports connecting to
    Red Hat OpenShift Container Platform, CI/CD systems, and security scanners through
    Red Hat-curated extensions. Role-Based Access Control (RBAC):: Manage user access
    with robust security permissions tailored to organizational needs. Software catalog::
    Search, view, and manage services, APIs, and libraries from a central inventory.
    Track ownership, metadata, and component health in one place. Software templates::
    Accelerate project setup using preconfigured templates for CI/CD, runtime, and
    security. Standardize implementation while enabling developer autonomy. Tech docs::
    Create, store, and view technical documentation alongside code. Make content searchable,
    consistently formatted, and accessible through the portal. Scalability:: Support
    growing teams and applications while maintaining access to the same tools and
    services. Configuring templates TechDocs for Red Hat Developer Hub Customizing
    the Learning Paths in Red Hat Developer Hub Introduction to plugins'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:44:15.054847'
    uuid: 454bd4ac-db8f-401f-89f0-97c648be9a1a
  response: For platform engineers, an internal developer platform allows them to
    design curated platforms with reusable templates and integrations that are aligned
    with organizational policies and developer needs. It also facilitates central
    configuration, where infrastructure and policies are defined as code and managed
    centrally, which reduces drift and maintenance overhead. Finally, it enables governance
    at scale by embedding policies and best practices into developer workflows through
    automation and templates, without adding friction to the process.
  user_input: From a platform engineer's perspective, what are the key advantages
    of implementing an internal developer platform?
- context:
  - "Integrations in Red Hat Developer Hub Authentication in Red Hat Developer Hub\
    \ # Integrations in Red Hat Developer Hub Red Hat Developer Hub integrates seamlessly\
    \ with Red Hat OpenShift Container Platform and other tools, enabling comprehensive\
    \ development and deployment workflows across enterprise. ## Integration with\
    \ Red Hat OpenShift Container Platform Red Hat Developer Hub is fully integrated\
    \ with Red Hat OpenShift Container Platform, offering: Operators to manage application\
    \ lifecycle. Access to advanced OpenShift capabilities such as service mesh, serverless\
    \ functions, GitOps, and distributed tracing. Pipelines and GitOps plugins for\
    \ streamlined cloud native workflows. ## Integration with Red Hat Advanced Developer\
    \ Suite - secure supply chain Red Hat Advanced Developer Suite - secure supply\
    \ chain (RHADS - ssc) enhances Red Hat Developer Hub by providing secure CI/CD\
    \ capabilities that integrate security measures into every stage of the development\
    \ process. While Red Hat Developer Hub focuses on the inner loop (code, build,\
    \ and test), RHADS - ssc manages the outer loop, automating: Code scanning Image\
    \ building Vulnerability detection Deployment RHADS - ssc includes tools like\
    \ Red Hat Trusted Artifact Signer (TAS) for code integrity, Red Hat Trusted Profile\
    \ Analyzer (TPA) for automated Software build of Materials (SBOM) creation, and\
    \ Red Hat Advanced Cluster Security (ACS) for vulnerability scanning. ## Extending\
    \ Backstage with Red Hat Developer Hub Red Hat Developer Hub which is a fully\
    \ supported, enterprise-grade productized version of upstream Backstage extends\
    \ the upstream project by adding: Enhanced search capabilities that aggregate\
    \ data from CI/CD pipelines, cloud providers, source control, and more. A centralized\
    \ software catalog for locating applications, APIs, and resources. Automation\
    \ through open source plugins that expand Backstage\u2019s core functionality.\
    \ Simplified technical documentation using Markdown and GitHub, with integrated\
    \ search for easy navigation. # Supported platforms You can find the supported\
    \ platforms and life cycle dates for both current and past versions of Red Hat\
    \ Developer Hub on the Life Cycle page. Life Cycle page # Sizing requirements\
    \ for Red Hat Developer Hub Learn about sizing requirements for Red Hat Developer\
    \ Hub. Table 1 lists the sizing requirements for installing and running Red Hat\
    \ Developer Hub, including Developer Hub application, database components, and\
    \ Operator. Table 2 lists recommended sizing requirements for external PostgreSQL\
    \ deployment based on the deployment scale. # Red Hat Developer Hub support If\
    \ you experience difficulty with a procedure described in this documentation,\
    \ visit the Red Hat Customer Portal. You can use the Red Hat Customer Portal for\
    \ the following purposes: To search or browse through the Red Hat Knowledgebase\
    \ of technical support articles about Red Hat products. To create a support case\
    \ for Red Hat Global Support Services (GSS), select Red Hat Developer Hub as the\
    \ product and select the appropriate product version. Red Hat Customer Portal\
    \ Create a support case for Red Hat Global Support Services (GSS) Red Hat Developer\
    \ Hub Life Cycle Installing Red Hat Developer Hub on Amazon Elastic Kubernetes\
    \ Service Installing Red Hat Developer Hub on Google Cloud on Google Cloud Installing\
    \ Red Hat Developer Hub on Google Kubernetes Engine Installing Red Hat Developer\
    \ Hub on Microsoft Azure Kubernetes Service Installing Red Hat Developer Hub on\
    \ OpenShift Container Platform"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:44:28.106373'
    uuid: 6b23cac9-cb0d-42de-87a1-facb0fb202bc
  response: If you experience difficulty with a procedure described in the documentation,
    you should visit the Red Hat Customer Portal. To create a support case for Red
    Hat Global Support Services (GSS), you need to select Red Hat Developer Hub as
    the product and then select the appropriate product version. The portal can also
    be used to search or browse through the Red Hat Knowledgebase of technical support
    articles.
  user_input: I'm having truble with a procedure in the documentation, what is the
    proccess for creating a support case with Red Hat Globl Support Servises (GSS)
    for my Red Hat Developer Hub instalation?
- context:
  - "Integrations in Red Hat Developer Hub Authentication in Red Hat Developer Hub\
    \ # Integrations in Red Hat Developer Hub Red Hat Developer Hub integrates seamlessly\
    \ with Red Hat OpenShift Container Platform and other tools, enabling comprehensive\
    \ development and deployment workflows across enterprise. ## Integration with\
    \ Red Hat OpenShift Container Platform Red Hat Developer Hub is fully integrated\
    \ with Red Hat OpenShift Container Platform, offering: Operators to manage application\
    \ lifecycle. Access to advanced OpenShift capabilities such as service mesh, serverless\
    \ functions, GitOps, and distributed tracing. Pipelines and GitOps plugins for\
    \ streamlined cloud native workflows. ## Integration with Red Hat Advanced Developer\
    \ Suite - secure supply chain Red Hat Advanced Developer Suite - secure supply\
    \ chain (RHADS - ssc) enhances Red Hat Developer Hub by providing secure CI/CD\
    \ capabilities that integrate security measures into every stage of the development\
    \ process. While Red Hat Developer Hub focuses on the inner loop (code, build,\
    \ and test), RHADS - ssc manages the outer loop, automating: Code scanning Image\
    \ building Vulnerability detection Deployment RHADS - ssc includes tools like\
    \ Red Hat Trusted Artifact Signer (TAS) for code integrity, Red Hat Trusted Profile\
    \ Analyzer (TPA) for automated Software build of Materials (SBOM) creation, and\
    \ Red Hat Advanced Cluster Security (ACS) for vulnerability scanning. ## Extending\
    \ Backstage with Red Hat Developer Hub Red Hat Developer Hub which is a fully\
    \ supported, enterprise-grade productized version of upstream Backstage extends\
    \ the upstream project by adding: Enhanced search capabilities that aggregate\
    \ data from CI/CD pipelines, cloud providers, source control, and more. A centralized\
    \ software catalog for locating applications, APIs, and resources. Automation\
    \ through open source plugins that expand Backstage\u2019s core functionality.\
    \ Simplified technical documentation using Markdown and GitHub, with integrated\
    \ search for easy navigation. # Supported platforms You can find the supported\
    \ platforms and life cycle dates for both current and past versions of Red Hat\
    \ Developer Hub on the Life Cycle page. Life Cycle page # Sizing requirements\
    \ for Red Hat Developer Hub Learn about sizing requirements for Red Hat Developer\
    \ Hub. Table 1 lists the sizing requirements for installing and running Red Hat\
    \ Developer Hub, including Developer Hub application, database components, and\
    \ Operator. Table 2 lists recommended sizing requirements for external PostgreSQL\
    \ deployment based on the deployment scale. # Red Hat Developer Hub support If\
    \ you experience difficulty with a procedure described in this documentation,\
    \ visit the Red Hat Customer Portal. You can use the Red Hat Customer Portal for\
    \ the following purposes: To search or browse through the Red Hat Knowledgebase\
    \ of technical support articles about Red Hat products. To create a support case\
    \ for Red Hat Global Support Services (GSS), select Red Hat Developer Hub as the\
    \ product and select the appropriate product version. Red Hat Customer Portal\
    \ Create a support case for Red Hat Global Support Services (GSS) Red Hat Developer\
    \ Hub Life Cycle Installing Red Hat Developer Hub on Amazon Elastic Kubernetes\
    \ Service Installing Red Hat Developer Hub on Google Cloud on Google Cloud Installing\
    \ Red Hat Developer Hub on Google Kubernetes Engine Installing Red Hat Developer\
    \ Hub on Microsoft Azure Kubernetes Service Installing Red Hat Developer Hub on\
    \ OpenShift Container Platform"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:44:46.934736'
    uuid: 3235b8d5-2dc5-4e24-8271-a65fdc191a1e
  response: If you experience difficulty with a procedure described in the documentation,
    you can visit the Red Hat Customer Portal. You can use the Red Hat Customer Portal
    to search or browse through the Red Hat Knowledgebase of technical support articles
    about Red Hat products. You can also use it to create a support case for Red Hat
    Global Support Services (GSS), by selecting Red Hat Developer Hub as the product
    and selecting the appropriate product version.
  user_input: So my team is having some difficulty with a procedure in the docs for
    the developer hub, what is the things we can do with the Red Hat Customer Portal,
    like what is its purpose for us when we need help with this stuff?
- context:
  - "Integrations in Red Hat Developer Hub Authentication in Red Hat Developer Hub\
    \ # Integrations in Red Hat Developer Hub Red Hat Developer Hub integrates seamlessly\
    \ with Red Hat OpenShift Container Platform and other tools, enabling comprehensive\
    \ development and deployment workflows across enterprise. ## Integration with\
    \ Red Hat OpenShift Container Platform Red Hat Developer Hub is fully integrated\
    \ with Red Hat OpenShift Container Platform, offering: Operators to manage application\
    \ lifecycle. Access to advanced OpenShift capabilities such as service mesh, serverless\
    \ functions, GitOps, and distributed tracing. Pipelines and GitOps plugins for\
    \ streamlined cloud native workflows. ## Integration with Red Hat Advanced Developer\
    \ Suite - secure supply chain Red Hat Advanced Developer Suite - secure supply\
    \ chain (RHADS - ssc) enhances Red Hat Developer Hub by providing secure CI/CD\
    \ capabilities that integrate security measures into every stage of the development\
    \ process. While Red Hat Developer Hub focuses on the inner loop (code, build,\
    \ and test), RHADS - ssc manages the outer loop, automating: Code scanning Image\
    \ building Vulnerability detection Deployment RHADS - ssc includes tools like\
    \ Red Hat Trusted Artifact Signer (TAS) for code integrity, Red Hat Trusted Profile\
    \ Analyzer (TPA) for automated Software build of Materials (SBOM) creation, and\
    \ Red Hat Advanced Cluster Security (ACS) for vulnerability scanning. ## Extending\
    \ Backstage with Red Hat Developer Hub Red Hat Developer Hub which is a fully\
    \ supported, enterprise-grade productized version of upstream Backstage extends\
    \ the upstream project by adding: Enhanced search capabilities that aggregate\
    \ data from CI/CD pipelines, cloud providers, source control, and more. A centralized\
    \ software catalog for locating applications, APIs, and resources. Automation\
    \ through open source plugins that expand Backstage\u2019s core functionality.\
    \ Simplified technical documentation using Markdown and GitHub, with integrated\
    \ search for easy navigation. # Supported platforms You can find the supported\
    \ platforms and life cycle dates for both current and past versions of Red Hat\
    \ Developer Hub on the Life Cycle page. Life Cycle page # Sizing requirements\
    \ for Red Hat Developer Hub Learn about sizing requirements for Red Hat Developer\
    \ Hub. Table 1 lists the sizing requirements for installing and running Red Hat\
    \ Developer Hub, including Developer Hub application, database components, and\
    \ Operator. Table 2 lists recommended sizing requirements for external PostgreSQL\
    \ deployment based on the deployment scale. # Red Hat Developer Hub support If\
    \ you experience difficulty with a procedure described in this documentation,\
    \ visit the Red Hat Customer Portal. You can use the Red Hat Customer Portal for\
    \ the following purposes: To search or browse through the Red Hat Knowledgebase\
    \ of technical support articles about Red Hat products. To create a support case\
    \ for Red Hat Global Support Services (GSS), select Red Hat Developer Hub as the\
    \ product and select the appropriate product version. Red Hat Customer Portal\
    \ Create a support case for Red Hat Global Support Services (GSS) Red Hat Developer\
    \ Hub Life Cycle Installing Red Hat Developer Hub on Amazon Elastic Kubernetes\
    \ Service Installing Red Hat Developer Hub on Google Cloud on Google Cloud Installing\
    \ Red Hat Developer Hub on Google Kubernetes Engine Installing Red Hat Developer\
    \ Hub on Microsoft Azure Kubernetes Service Installing Red Hat Developer Hub on\
    \ OpenShift Container Platform"
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T15:44:59.336382'
    uuid: c3d42b08-4d8f-4acb-8ace-c98fbf51ee87
  response: Red Hat Developer Hub is fully integrated with Red Hat OpenShift Container
    Platform, providing Operators to manage the application lifecycle, access to advanced
    OpenShift capabilities such as service mesh, serverless functions, GitOps, and
    distributed tracing, and includes Pipelines and GitOps plugins for streamlined
    cloud native workflows. Furthermore, it integrates with the Red Hat Advanced Developer
    Suite - secure supply chain (RHADS - ssc), which enhances Red Hat Developer Hub
    by providing secure CI/CD capabilities. While Red Hat Developer Hub focuses on
    the inner loop (code, build, and test), RHADS - ssc manages the outer loop by
    automating code scanning, image building, vulnerability detection, and deployment
    using tools like Red Hat Trusted Artifact Signer (TAS), Red Hat Trusted Profile
    Analyzer (TPA), and Red Hat Advanced Cluster Security (ACS).
  user_input: As a Platform Engineer responsible for our OpenShift environment, could
    you please provide a detailed explanation of how Red Hat Developer Hub integrates
    with both Red Hat OpenShift Container Platform and the Red Hat Advanced Developer
    Suite - secure supply chain to facilitate comprehensive development and deployment
    workflows?
- context:
  - '# Setting up and configuring your first Red Hat Developer Hub instance Prepare
    your IT infrastructure including Red Hat OpenShift Container Platform and required
    external components, and run your first Red Hat Developer Hub (RHDH) instance
    in production. # Checklist to run your first Red Hat Developer Hub (RHDH) instance
    in production. With the default configuration, Developer Hub runs with a minimal
    feature set that does not require secure connection to external services such
    as an identity provider, a Git provider, and external PostgreSQL and Redis databases.
    Using critical features therefore requires following additional configuration:
    For resiliency:: * Use an external PostgreSQL database. * Enable high-availability.
    For performance:: * Enable assets caching to an external Redis database. For security::
    * Use secure connections to your external services. * Provision users and enable
    authentication. * Enable role-based access control, and configure the permission
    policy by using the Web UI. For adapting to your environment:: * Enable GitHub
    repository discovery. * Customize Developer Hub appearance with your logo. #'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:45:10.080193'
    uuid: d62834b8-0294-453c-b31a-f6d7f96530f5
  response: To adapt Red Hat Developer Hub to your environment, you must enable GitHub
    repository discovery. A production instance with critical features also requires
    using secure connections to external services, such as a Git provider.
  user_input: What configuration is required to adapt Red Hat Developer Hub for an
    environment that utilizes a Git provider like GitHub?
- context:
  - '# Setting up and configuring your first Red Hat Developer Hub instance Prepare
    your IT infrastructure including Red Hat OpenShift Container Platform and required
    external components, and run your first Red Hat Developer Hub (RHDH) instance
    in production. # Checklist to run your first Red Hat Developer Hub (RHDH) instance
    in production. With the default configuration, Developer Hub runs with a minimal
    feature set that does not require secure connection to external services such
    as an identity provider, a Git provider, and external PostgreSQL and Redis databases.
    Using critical features therefore requires following additional configuration:
    For resiliency:: * Use an external PostgreSQL database. * Enable high-availability.
    For performance:: * Enable assets caching to an external Redis database. For security::
    * Use secure connections to your external services. * Provision users and enable
    authentication. * Enable role-based access control, and configure the permission
    policy by using the Web UI. For adapting to your environment:: * Enable GitHub
    repository discovery. * Customize Developer Hub appearance with your logo. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:45:20.045864'
    uuid: 996f927a-338c-4a8e-896f-501cea4e39ca
  response: According to the checklist for running your first Red Hat Developer Hub
    instance in production, you should use an external PostgreSQL database for resiliency.
  user_input: I'm looking at this checklist for getting Red Hat Developer Hub ready
    for production and it say i need to use a external PostgreSQL database, what is
    the reason for this requirement? why do i need to do that?
- context:
  - '# Setting up and configuring your first Red Hat Developer Hub instance Prepare
    your IT infrastructure including Red Hat OpenShift Container Platform and required
    external components, and run your first Red Hat Developer Hub (RHDH) instance
    in production. # Checklist to run your first Red Hat Developer Hub (RHDH) instance
    in production. With the default configuration, Developer Hub runs with a minimal
    feature set that does not require secure connection to external services such
    as an identity provider, a Git provider, and external PostgreSQL and Redis databases.
    Using critical features therefore requires following additional configuration:
    For resiliency:: * Use an external PostgreSQL database. * Enable high-availability.
    For performance:: * Enable assets caching to an external Redis database. For security::
    * Use secure connections to your external services. * Provision users and enable
    authentication. * Enable role-based access control, and configure the permission
    policy by using the Web UI. For adapting to your environment:: * Enable GitHub
    repository discovery. * Customize Developer Hub appearance with your logo. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:45:30.329397'
    uuid: c0c2d736-97e4-418d-9cb6-aa9dc7001e58
  response: According to the checklist for running a Red Hat Developer Hub instance
    in production, using an external PostgreSQL database is recommended for resiliency.
  user_input: For what specific purpose does the production checklist for Red Hat
    Developer Hub recommend using an external PostgreSQL database?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:45:37.771189'
    uuid: c9129761-5c5f-42a6-a163-56b8aaa061d1
  response: You have installed Red Hat OpenShift Container Platform 4.16 to 4.19.
  user_input: what versions of Red Hat OpenShift Container Platform is needed for
    install the Red Hat Developer Hub Operator?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:45:45.040850'
    uuid: 398186dc-8487-4831-80fd-8add3ef35d0c
  response: You must have installed Red Hat OpenShift Container Platform 4.16 to 4.19.
  user_input: what versions for Red Hat OpenShift Container Platform do i need to
    have before i can install the operator?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:45:53.268735'
    uuid: 0dd4f374-8441-445e-8432-a0f328b9080f
  response: 'As an administrator logged into the OpenShift Container Platform web
    console, you can install the Red Hat Developer Hub Operator by following these
    steps: In the navigation menu, click Operators > OperatorHub. Use the filter box
    to enter "Developer Hub" and click the Red Hat Developer Hub Operator card, then
    click Install. On the Install Operator page, you must select an update channel,
    a version, the installation mode, and an installed namespace. For the update approval
    method, you can select either "Automatic", where the Operator updates without
    manual confirmation, or "Manual", which requires an administrator to approve the
    update. Finally, click Install. The operator is ready for use when a dialog box
    displays the message "Installed operator: ready for use".'
  user_input: Wht are the steps to instal the Red Hat Developer Hub Operator?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration. 5. From the Update
    channel drop-down menu, select the update channel that you want to use, for example,
    fast or fast-1.8. [IMPORTANT] ---- The `fast channel includes all of the updates
    available for a particular version. Any update might introduce unexpected changes
    in your Red Hat Developer Hub deployment. Check the release notes for details
    about any potentially breaking changes. The fast-1.8 channel only provides z-stream
    updates, for example, updating from version 1.8.1 to 1.8.2. If you want to update
    the Red Hat Developer Hub y-version in the future, for example, updating from
    1.8 to 1.9, you must switch to the fast-1.9 channel manually. ---- 6. From the
    Version drop-down menu, select the version of the Red Hat Developer Hub Operator
    that you want to install. The default version is the latest version available
    in the selected channel. 7. Select the Operator Installation mode. [NOTE] ----
    The All namespaces on the cluster (default) option is selected by default. The
    Specific namespace on the cluster option is not currently supported. ---- 8. In
    the Installed Namespace field, do one of the following actions: * Select Operator
    recommended Namespace to create and use the rhdh-operator namespace. This option
    is selected by default. * Select Select a Namespace to use an alternative namespace.
    * From the Select Project drop-down menu, do one of the following actions: * Select
    an existing project. * Select Create Project to create a new project for the Operator.
    * On the Create Project dialog, enter text into the required fields and click
    Create. [IMPORTANT] ---- For enhanced security, better control over the Operator
    lifecycle, and preventing potential privilege escalation, install the Red Hat
    Developer Hub Operator in a dedicated default rhdh-operator namespace. You can
    restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. # Preparing
    your external services Red Hat Developer Hub relies on external services. Prepare
    the following required external services: PostgreSQL database:: Developer Hub
    stores data in a PostgreSQL database. Use an external database for resiliency
    and include it in your disaster recovery plan. Redis cache:: For efficiency, Developer
    Hub caches plugin and Techdocs assets when your provide a Redis cache server.
    GitHub API access:: Provide credentials to a GitHub app to enable access to the
    GitHub API for repository discovery. Connection to your identity provider:: Provide
    credentials to your identity provider to enable user provisioning and authentication.
    Get your external PostgreSQL database connection strings and certificates. postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: For security, use TLS certificates to secure the connection
    to the database. 1. Get your Redis cache server connection string, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. 2. Create a GitHub
    App to allow Developer Hub to access the GitHub API for repository. Opt for a
    GitHub App instead of an OAuth app to use fine grained permissions, gain more
    control over which repositories the application can access, and use short lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating with
    rhdh <GUID>. Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read only
    Commit statuses:: Read only Reading organization data:: Members:: Read only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:46:06.382620'
    uuid: ebb11f38-44ef-47ba-938f-38ea374b416f
  response: To enable repository discovery, Red Hat Developer Hub requires credentials
    for a GitHub app to access the GitHub API. It is recommended to use a GitHub App
    instead of an OAuth app to benefit from fine-grained permissions, greater control
    over repository access, and short-lived tokens. When registering the app, you
    must provide a unique name, set the 'Homepage URL' to your Developer Hub URL,
    and the 'Authorization callback URL' to your Developer Hub authentication backend
    URL. The 'Webhook' should be cleared as "Active". App permissions should be adapted
    to your needs; for reading software components, 'Contents' and 'Commit statuses'
    must be set to 'Read only', and for reading organization data, 'Members' must
    be 'Read only'. If the same app is used for software templates, additional permissions
    for 'Administration', 'Contents', 'Pull requests', 'Issues', and 'Workflows' will
    require 'Read & write' access.
  user_input: What are the specific requirements and recommended configurations for
    integrating GitHub with Red Hat Developer Hub to enable repository discovery?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration. 5. From the Update
    channel drop-down menu, select the update channel that you want to use, for example,
    fast or fast-1.8. [IMPORTANT] ---- The `fast channel includes all of the updates
    available for a particular version. Any update might introduce unexpected changes
    in your Red Hat Developer Hub deployment. Check the release notes for details
    about any potentially breaking changes. The fast-1.8 channel only provides z-stream
    updates, for example, updating from version 1.8.1 to 1.8.2. If you want to update
    the Red Hat Developer Hub y-version in the future, for example, updating from
    1.8 to 1.9, you must switch to the fast-1.9 channel manually. ---- 6. From the
    Version drop-down menu, select the version of the Red Hat Developer Hub Operator
    that you want to install. The default version is the latest version available
    in the selected channel. 7. Select the Operator Installation mode. [NOTE] ----
    The All namespaces on the cluster (default) option is selected by default. The
    Specific namespace on the cluster option is not currently supported. ---- 8. In
    the Installed Namespace field, do one of the following actions: * Select Operator
    recommended Namespace to create and use the rhdh-operator namespace. This option
    is selected by default. * Select Select a Namespace to use an alternative namespace.
    * From the Select Project drop-down menu, do one of the following actions: * Select
    an existing project. * Select Create Project to create a new project for the Operator.
    * On the Create Project dialog, enter text into the required fields and click
    Create. [IMPORTANT] ---- For enhanced security, better control over the Operator
    lifecycle, and preventing potential privilege escalation, install the Red Hat
    Developer Hub Operator in a dedicated default rhdh-operator namespace. You can
    restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. # Preparing
    your external services Red Hat Developer Hub relies on external services. Prepare
    the following required external services: PostgreSQL database:: Developer Hub
    stores data in a PostgreSQL database. Use an external database for resiliency
    and include it in your disaster recovery plan. Redis cache:: For efficiency, Developer
    Hub caches plugin and Techdocs assets when your provide a Redis cache server.
    GitHub API access:: Provide credentials to a GitHub app to enable access to the
    GitHub API for repository discovery. Connection to your identity provider:: Provide
    credentials to your identity provider to enable user provisioning and authentication.
    Get your external PostgreSQL database connection strings and certificates. postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: For security, use TLS certificates to secure the connection
    to the database. 1. Get your Redis cache server connection string, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. 2. Create a GitHub
    App to allow Developer Hub to access the GitHub API for repository. Opt for a
    GitHub App instead of an OAuth app to use fine grained permissions, gain more
    control over which repositories the application can access, and use short lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating with
    rhdh <GUID>. Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read only
    Commit statuses:: Read only Reading organization data:: Members:: Read only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:46:14.679695'
    uuid: 1dae768c-b31c-4c8f-be14-965239477245
  response: For efficiency, Developer Hub caches plugin and Techdocs assets when you
    provide a Redis cache server.
  user_input: why we need redis cache for the techdocs assets, how it make more efficient?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration. 5. From the Update
    channel drop-down menu, select the update channel that you want to use, for example,
    fast or fast-1.8. [IMPORTANT] ---- The `fast channel includes all of the updates
    available for a particular version. Any update might introduce unexpected changes
    in your Red Hat Developer Hub deployment. Check the release notes for details
    about any potentially breaking changes. The fast-1.8 channel only provides z-stream
    updates, for example, updating from version 1.8.1 to 1.8.2. If you want to update
    the Red Hat Developer Hub y-version in the future, for example, updating from
    1.8 to 1.9, you must switch to the fast-1.9 channel manually. ---- 6. From the
    Version drop-down menu, select the version of the Red Hat Developer Hub Operator
    that you want to install. The default version is the latest version available
    in the selected channel. 7. Select the Operator Installation mode. [NOTE] ----
    The All namespaces on the cluster (default) option is selected by default. The
    Specific namespace on the cluster option is not currently supported. ---- 8. In
    the Installed Namespace field, do one of the following actions: * Select Operator
    recommended Namespace to create and use the rhdh-operator namespace. This option
    is selected by default. * Select Select a Namespace to use an alternative namespace.
    * From the Select Project drop-down menu, do one of the following actions: * Select
    an existing project. * Select Create Project to create a new project for the Operator.
    * On the Create Project dialog, enter text into the required fields and click
    Create. [IMPORTANT] ---- For enhanced security, better control over the Operator
    lifecycle, and preventing potential privilege escalation, install the Red Hat
    Developer Hub Operator in a dedicated default rhdh-operator namespace. You can
    restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. # Preparing
    your external services Red Hat Developer Hub relies on external services. Prepare
    the following required external services: PostgreSQL database:: Developer Hub
    stores data in a PostgreSQL database. Use an external database for resiliency
    and include it in your disaster recovery plan. Redis cache:: For efficiency, Developer
    Hub caches plugin and Techdocs assets when your provide a Redis cache server.
    GitHub API access:: Provide credentials to a GitHub app to enable access to the
    GitHub API for repository discovery. Connection to your identity provider:: Provide
    credentials to your identity provider to enable user provisioning and authentication.
    Get your external PostgreSQL database connection strings and certificates. postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: For security, use TLS certificates to secure the connection
    to the database. 1. Get your Redis cache server connection string, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. 2. Create a GitHub
    App to allow Developer Hub to access the GitHub API for repository. Opt for a
    GitHub App instead of an OAuth app to use fine grained permissions, gain more
    control over which repositories the application can access, and use short lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating with
    rhdh <GUID>. Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read only
    Commit statuses:: Read only Reading organization data:: Members:: Read only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:46:24.660431'
    uuid: 37e2c751-620a-4c2a-b856-1343f3ba5ffa
  response: For efficiency, Red Hat Developer Hub uses a Redis cache server to cache
    plugin and Techdocs assets.
  user_input: I'm trying to get our Red Hat Develper Hub instance running on OpenShift,
    and the docs mention I need to prepair a Redis cache, what is the purpuse of this
    Redis service and what does it cache for the platform?
- context:
  - 'Repository Variables) Secrets:: Read & write (if templates include GitHub Action
    Repository Secrets) Environments:: Read & write (if templates include GitHub Environments)
    Organization permissions:: Members:: Read only Where can this GitHub App be installed?::
    Select Only on this account. 1. In the General > Clients secrets section, click
    Generate a new client secret. 2. In the General > Private keys section, click
    Generate a private key. 3. In the Install App tab, choose an account to install
    your GitHub App on. 4. Save the following values for the next step: App ID Client
    ID Client secret Private key # Provisioning your custom Red Hat Developer Hub
    configuration To configure Red Hat Developer Hub, provision your custom Red Hat
    Developer Hub config maps and secrets to {platform-long} before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the {platform cli link}, you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. You have the connection
    string to an active Redis server, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. See . You have
    an external PostgreSQL database, with the following details. See See . postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: TLS certificates to secure the connection to the database.
    You have a GitHub App enabling access to the GitHub API for repository discovery,
    with the following details. See . GITHUB_INTEGRATION_APP_ID:: Your GitHub integration
    App ID. GITHUB_INTEGRATION_CLIENT_ID:: Your GitHub integration App client ID.
    GITHUB_INTEGRATION_CLIENT_SECRET:: Your GitHub integration App client secret.
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE:: Your GitHub integration App private key.
    1. For security, store your secrets as environment variables values in an OpenShift
    Container Platform secret, rather than in clear text in your configuration files.
    Collect all your secrets in the secrets.txt file, with one secret per line in
    KEY=value form. 1. Enter your custom logo. ``` BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,<base64_full_logo_data>"
    BASE64_EMBEDDED_ICON_LOGO="data:image/svg+xml;base64,<base64_icon_logo_data>"
    ``` BASE64_EMBEDDED_FULL_LOGO:: Enter your logo for the expanded (pinned) sidebar
    as a base64 encoded SVG image. To encode your logo in base64, run: ``` $ base64
    i logo.svg ``` BASE64_EMBEDDED_ICON_LOGO:: Enter your logo for the collapsed (unpinned)
    sidebar as a base64 encoded SVG image. 2. Enter the connection string to your
    Redis server that caches plugin assets. ``` REDIS_CONNECTION=rediss://user:pass@cache.example.com:6379
    ``` 3. Enter your GitHub integration credentials: ``` GITHUB_INTEGRATION_APP_ID=_<Enter_the_saved_App_ID>
    GITHUB_INTEGRATION_CLIENT_ID=<Enter_the_saved_Client_ID> GITHUB_INTEGRATION_CLIENT_SECRET=<Enter_the_saved_Client_Secret>
    GITHUB_INTEGRATION_HOST_DOMAIN=github.com GITHUB_INTEGRATION_ORGANIZATION=<Enter_your_github_organization_name>
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE= <Enter_the_saved_Private_key> ``` 4. Enter
    your PosgreSQL database secrets: ``` POSTGRES_PASSWORD: <postgres password> POSTGRES_PORT:
    "<postgres port>" POSTGRES_USER: <postgres username> POSTGRES_HOST: <postgres
    host> PGSSLMODE: verify full NODE_EXTRA_CA_CERTS: /opt/app root/src/postgres crt.pem
    ``` 5. Enter your authentication secrets. 2. Author your custom app-config.yaml
    file. This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your {platform} cluster. 1. Create the <my-rhdh-project> {namespace}
    aimed at containing your Developer Hub instance. ```terminal $ oc create namespace
    my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. 4. Provision your PosgreSQL TLS certificates to the my-rhdh-database-secrets
    secret in the <my-rhdh-project> project. ```terminal $ oc create secret generic
    my-rhdh-secrets --from-file=postgres-ca.pem --from-file=postgres-crt.pem --from-file=postgres-key.key
    --namespace=my-rhdh-project ``` # Enabling authentication in Red Hat Developer
    Hub (with mandatory steps only) ## Understanding authentication and user provisioning
    Learn about the authentication process from creating user and group entities in
    the software catalog to user sign-in, and how authentication and catalog plugins
    enable each step. Understanding this process is essential for successfully configuring
    your Developer Hub instance, securing access through authorization, and enabling
    features that rely on synchronized user and group data. To fully enable catalog
    features, provision user and group data from the Identity Provider to the Developer
    Hub software catalog. Catalog provider plugins'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:46:37.473970'
    uuid: f3c11b25-9992-4748-a71b-19d833ab259b
  response: You need to author a custom `dynamic-plugins.yaml` file to enable plugins.
    By default, Developer Hub enables a minimal plugin set and disables plugins that
    require configuration or secrets. For example, the GitHub repository discovery
    plugin and the Role-based access control (RBAC) plugin are disabled by default
    and can be enabled using this file. After creating the file, you must provision
    it to the `dynamic-plugins-rhdh` config map in your project.
  user_input: Why do I need to author a custum `dynamic-plugins.yaml` file, what does
    it do for my Developer Hub instalation?
- context:
  - 'Repository Variables) Secrets:: Read & write (if templates include GitHub Action
    Repository Secrets) Environments:: Read & write (if templates include GitHub Environments)
    Organization permissions:: Members:: Read only Where can this GitHub App be installed?::
    Select Only on this account. 1. In the General > Clients secrets section, click
    Generate a new client secret. 2. In the General > Private keys section, click
    Generate a private key. 3. In the Install App tab, choose an account to install
    your GitHub App on. 4. Save the following values for the next step: App ID Client
    ID Client secret Private key # Provisioning your custom Red Hat Developer Hub
    configuration To configure Red Hat Developer Hub, provision your custom Red Hat
    Developer Hub config maps and secrets to {platform-long} before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the {platform cli link}, you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. You have the connection
    string to an active Redis server, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. See . You have
    an external PostgreSQL database, with the following details. See See . postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: TLS certificates to secure the connection to the database.
    You have a GitHub App enabling access to the GitHub API for repository discovery,
    with the following details. See . GITHUB_INTEGRATION_APP_ID:: Your GitHub integration
    App ID. GITHUB_INTEGRATION_CLIENT_ID:: Your GitHub integration App client ID.
    GITHUB_INTEGRATION_CLIENT_SECRET:: Your GitHub integration App client secret.
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE:: Your GitHub integration App private key.
    1. For security, store your secrets as environment variables values in an OpenShift
    Container Platform secret, rather than in clear text in your configuration files.
    Collect all your secrets in the secrets.txt file, with one secret per line in
    KEY=value form. 1. Enter your custom logo. ``` BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,<base64_full_logo_data>"
    BASE64_EMBEDDED_ICON_LOGO="data:image/svg+xml;base64,<base64_icon_logo_data>"
    ``` BASE64_EMBEDDED_FULL_LOGO:: Enter your logo for the expanded (pinned) sidebar
    as a base64 encoded SVG image. To encode your logo in base64, run: ``` $ base64
    i logo.svg ``` BASE64_EMBEDDED_ICON_LOGO:: Enter your logo for the collapsed (unpinned)
    sidebar as a base64 encoded SVG image. 2. Enter the connection string to your
    Redis server that caches plugin assets. ``` REDIS_CONNECTION=rediss://user:pass@cache.example.com:6379
    ``` 3. Enter your GitHub integration credentials: ``` GITHUB_INTEGRATION_APP_ID=_<Enter_the_saved_App_ID>
    GITHUB_INTEGRATION_CLIENT_ID=<Enter_the_saved_Client_ID> GITHUB_INTEGRATION_CLIENT_SECRET=<Enter_the_saved_Client_Secret>
    GITHUB_INTEGRATION_HOST_DOMAIN=github.com GITHUB_INTEGRATION_ORGANIZATION=<Enter_your_github_organization_name>
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE= <Enter_the_saved_Private_key> ``` 4. Enter
    your PosgreSQL database secrets: ``` POSTGRES_PASSWORD: <postgres password> POSTGRES_PORT:
    "<postgres port>" POSTGRES_USER: <postgres username> POSTGRES_HOST: <postgres
    host> PGSSLMODE: verify full NODE_EXTRA_CA_CERTS: /opt/app root/src/postgres crt.pem
    ``` 5. Enter your authentication secrets. 2. Author your custom app-config.yaml
    file. This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your {platform} cluster. 1. Create the <my-rhdh-project> {namespace}
    aimed at containing your Developer Hub instance. ```terminal $ oc create namespace
    my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. 4. Provision your PosgreSQL TLS certificates to the my-rhdh-database-secrets
    secret in the <my-rhdh-project> project. ```terminal $ oc create secret generic
    my-rhdh-secrets --from-file=postgres-ca.pem --from-file=postgres-crt.pem --from-file=postgres-key.key
    --namespace=my-rhdh-project ``` # Enabling authentication in Red Hat Developer
    Hub (with mandatory steps only) ## Understanding authentication and user provisioning
    Learn about the authentication process from creating user and group entities in
    the software catalog to user sign-in, and how authentication and catalog plugins
    enable each step. Understanding this process is essential for successfully configuring
    your Developer Hub instance, securing access through authorization, and enabling
    features that rely on synchronized user and group data. To fully enable catalog
    features, provision user and group data from the Identity Provider to the Developer
    Hub software catalog. Catalog provider plugins'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:46:47.718274'
    uuid: c3ac05a6-ee9b-4078-bc43-233aa24c1a37
  response: You need to author a custom dynamic-plugins.yaml file to enable plugins.
    By default, Developer Hub enables a minimal plugin set, and disables plugins that
    require configuration or secrets, such as the GitHub repository discovery plugin
    and the Role-based access control (RBAC) plugin. You can enable the GitHub repository
    discovery and the RBAC features using the dynamic-plugins.yaml file.
  user_input: I am trying to setup the developer hub and the doc say I need to make
    a custom dynamic-plugins.yaml file, but why is that? what does this file do and
    why are some plugins disabled by default that I have to enable with it?
- context:
  - 'Repository Variables) Secrets:: Read & write (if templates include GitHub Action
    Repository Secrets) Environments:: Read & write (if templates include GitHub Environments)
    Organization permissions:: Members:: Read only Where can this GitHub App be installed?::
    Select Only on this account. 1. In the General > Clients secrets section, click
    Generate a new client secret. 2. In the General > Private keys section, click
    Generate a private key. 3. In the Install App tab, choose an account to install
    your GitHub App on. 4. Save the following values for the next step: App ID Client
    ID Client secret Private key # Provisioning your custom Red Hat Developer Hub
    configuration To configure Red Hat Developer Hub, provision your custom Red Hat
    Developer Hub config maps and secrets to {platform-long} before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the {platform cli link}, you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. You have the connection
    string to an active Redis server, such as rediss://user:pass@cache.example.com:6379.
    For security, consider using a rediss secure server connection. See . You have
    an external PostgreSQL database, with the following details. See See . postgres
    host:: Your PostgreSQL instance Domain Name System (DNS) or IP address. postgres
    port:: Your PostgreSQL instance port number, such as 5432. postres username::
    The user name to connect to your PostgreSQL instance. postgres password:: The
    password to connect to your PostgreSQL instance. postgres ca.pem, postgres key.key,
    postgres crt.pem:: TLS certificates to secure the connection to the database.
    You have a GitHub App enabling access to the GitHub API for repository discovery,
    with the following details. See . GITHUB_INTEGRATION_APP_ID:: Your GitHub integration
    App ID. GITHUB_INTEGRATION_CLIENT_ID:: Your GitHub integration App client ID.
    GITHUB_INTEGRATION_CLIENT_SECRET:: Your GitHub integration App client secret.
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE:: Your GitHub integration App private key.
    1. For security, store your secrets as environment variables values in an OpenShift
    Container Platform secret, rather than in clear text in your configuration files.
    Collect all your secrets in the secrets.txt file, with one secret per line in
    KEY=value form. 1. Enter your custom logo. ``` BASE64_EMBEDDED_FULL_LOGO="data:image/svg+xml;base64,<base64_full_logo_data>"
    BASE64_EMBEDDED_ICON_LOGO="data:image/svg+xml;base64,<base64_icon_logo_data>"
    ``` BASE64_EMBEDDED_FULL_LOGO:: Enter your logo for the expanded (pinned) sidebar
    as a base64 encoded SVG image. To encode your logo in base64, run: ``` $ base64
    i logo.svg ``` BASE64_EMBEDDED_ICON_LOGO:: Enter your logo for the collapsed (unpinned)
    sidebar as a base64 encoded SVG image. 2. Enter the connection string to your
    Redis server that caches plugin assets. ``` REDIS_CONNECTION=rediss://user:pass@cache.example.com:6379
    ``` 3. Enter your GitHub integration credentials: ``` GITHUB_INTEGRATION_APP_ID=_<Enter_the_saved_App_ID>
    GITHUB_INTEGRATION_CLIENT_ID=<Enter_the_saved_Client_ID> GITHUB_INTEGRATION_CLIENT_SECRET=<Enter_the_saved_Client_Secret>
    GITHUB_INTEGRATION_HOST_DOMAIN=github.com GITHUB_INTEGRATION_ORGANIZATION=<Enter_your_github_organization_name>
    GITHUB_INTEGRATION_PRIVATE_KEY_FILE= <Enter_the_saved_Private_key> ``` 4. Enter
    your PosgreSQL database secrets: ``` POSTGRES_PASSWORD: <postgres password> POSTGRES_PORT:
    "<postgres port>" POSTGRES_USER: <postgres username> POSTGRES_HOST: <postgres
    host> PGSSLMODE: verify full NODE_EXTRA_CA_CERTS: /opt/app root/src/postgres crt.pem
    ``` 5. Enter your authentication secrets. 2. Author your custom app-config.yaml
    file. This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your {platform} cluster. 1. Create the <my-rhdh-project> {namespace}
    aimed at containing your Developer Hub instance. ```terminal $ oc create namespace
    my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. 4. Provision your PosgreSQL TLS certificates to the my-rhdh-database-secrets
    secret in the <my-rhdh-project> project. ```terminal $ oc create secret generic
    my-rhdh-secrets --from-file=postgres-ca.pem --from-file=postgres-crt.pem --from-file=postgres-key.key
    --namespace=my-rhdh-project ``` # Enabling authentication in Red Hat Developer
    Hub (with mandatory steps only) ## Understanding authentication and user provisioning
    Learn about the authentication process from creating user and group entities in
    the software catalog to user sign-in, and how authentication and catalog plugins
    enable each step. Understanding this process is essential for successfully configuring
    your Developer Hub instance, securing access through authorization, and enabling
    features that rely on synchronized user and group data. To fully enable catalog
    features, provision user and group data from the Identity Provider to the Developer
    Hub software catalog. Catalog provider plugins'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:46:57.222037'
    uuid: ff03974b-e782-4e3a-b854-e3aa7bf19e70
  response: 'For a GitHub App enabling access to the GitHub API for repository discovery,
    you need the following details: your GitHub integration App ID (GITHUB_INTEGRATION_APP_ID),
    your GitHub integration App client ID (GITHUB_INTEGRATION_CLIENT_ID), your GitHub
    integration App client secret (GITHUB_INTEGRATION_CLIENT_SECRET), and your GitHub
    integration App private key (GITHUB_INTEGRATION_PRIVATE_KEY_FILE).'
  user_input: what github integration secrets i need?
- context:
  - 'handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- ## Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ### Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ### Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:47:10.382394'
    uuid: ef6bf02f-bba4-402e-8359-9dc036df6d6c
  response: 'For trial or non-production environments installed by using the Red Hat
    Developer Hub Operator, you can enable guest access to skip configuring authentication
    and authorization. First, you must have added a custom Developer Hub application
    configuration and have enough permissions to change it. Then, add the following
    content to the app config.yaml file: `auth: environment: development providers:
    guest: dangerouslyAllowOutsideDevelopment: true`. After that, go to the Developer
    Hub login page and click Enter in the Guest tile to log in with the Guest user
    account. In the Developer Hub Settings page, your profile name will be Guest,
    and you can use Developer Hub features.'
  user_input: how do i enabel gest login on a Red Hat Developer Hub Operater install?
- context:
  - 'handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- ## Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ### Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ### Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:47:21.794083'
    uuid: 86d3b149-1bb4-4d98-a1f9-1e52b5c019e2
  response: 'To enable guest access for a trial or non-production environment installed
    with the Red Hat Developer Hub Operator, you must add the following content to
    the app-config.yaml file: `auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true`. After applying this configuration, go to the Developer Hub login page and
    click ''Enter'' in the Guest tile to log in. In the Developer Hub Settings page,
    your profile name will be ''Guest'', and you can then use the platform''s features.'
  user_input: For a trial environment, what is the specific configuration and procedure
    to enable guest user authentication on an instance installed using the Red Hat
    Developer Hub Operator?
- context:
  - 'handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- ## Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ### Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ### Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:47:34.031266'
    uuid: 5a01a24b-d873-4394-8b7c-80e174ddabe3
  response: "The Developer Hub authentication plugin is configured in your app-config.yaml\
    \ file. For trial or non-production environments, you can enable guest access\
    \ to skip configuring authentication and authorization. For an Operator-based\
    \ installation, add the following content to the app config.yaml file: ```yaml\n\
    auth:\n  environment: development\n  providers:\n    guest:\n      dangerouslyAllowOutsideDevelopment:\
    \ true\n```. For a Helm-based installation, add the following content to your\
    \ Red Hat Developer Hub Helm Chart: ```yaml\nupstream:\n  backstage:\n    appConfig:\n\
    \      app:\n        baseUrl: 'https://{{ include \\\"janus idp.hostname\\\" .\
    \ }}'\n      auth:\n        environment: development\n        providers:\n   \
    \       guest:\n            dangerouslyAllowOutsideDevelopment: true\n```."
  user_input: Developer Hub guest access app-config.yaml
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK) Authenticate
    users with Red Hat Build of Keycloak (RHBK), by provisioning the users and groups
    from RHBK to the Developer Hub software catalog, and configuring the OpenID Connect
    (OIDC) authentication provider in Red Hat Developer Hub. You added a custom Developer
    Hub application configuration, and have enough permissions to change it. You have
    enough permissions in RHSSO to create and manage a realm and a client. [TIP] ----
    Alternatively, ask your RHBK administrator to prepare in RHBK the required realm
    and client. ---- 1. Register your Developer Hub app in RHBK: 1. Use an existing
    realm, or create a realm, with a distinctive Name such as <my_realm>. Save the
    value for the next step: * RHBK realm base URL, such as: <your_rhbk_URL>/realms/<your_realm>.
    2. To register your Developer Hub in RHBK, in the created realm, secure the first
    application, with: 1. Client ID: A distinctive client ID, such as <RHDH>. 2. Valid
    redirect URIs: Set to the OIDC handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame.
    3. Go to the Credentials tab and copy the Client secret. 4. Save the values for
    the next step: * Client ID * Client Secret 3. To prepare for the verification
    steps, in the same realm, get the credential information for an existing user
    or create a user. Save the user credential information for the verification steps.
    2. Add your RHSSO credentials to Developer Hub, by adding the following key/value
    pairs to your Developer Hub secrets. You can use these secrets in the Developer
    Hub configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. Optional: To configure optional fields, see Configuring Red
    Hat Developer Hub. 5. Enable the RHBK authentication provider, by adding the OIDC
    provider section in your app-config.yaml file: ```yaml auth: environment: production
    providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID}
    clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt: auto signInPage: oidc ``` environment:
    production:: Mark the environment as production to hide the Guest login in the
    Developer Hub home page. metadataUrl, clientId, clientSecret:: Configure the OIDC
    provider with your secrets. prompt:: Enter auto to allow the identity provider
    to automatically determine whether to prompt for credentials or bypass the login
    redirect if an active RHSSO session exists. The identity provider defaults to
    none, which assumes that you are already logged in. Sign-in requests without an
    active session are rejected. signInPage:: Enter oidc to enable the OIDC provider
    as default sign-in provider. Optional: To configure optional fields, see Configuring
    Red Hat Developer Hub. 1. To verify user and group provisioning, check the console
    logs. Successful synchronization example: ``` 2025-06-27T16:02:34.647Z catalog
    info Read 5 Keycloak users and 3 Keycloak groups in 0.4 seconds. Committing...
    class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ## Enabling user authentication with GitHub Authenticate users with GitHub
    by provisioning the users and groups from GitHub to the Developer Hub software
    catalog, and configuring the GitHub authentication provider in Red Hat Developer
    Hub. You have enough permissions in GitHub to create and manage a GitHub App.
    [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough permissions to change it. 1. Allow Developer Hub to authenticate
    with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub App instead of
    an OAuth app to use fine-grained permissions, use short-lived tokens, scale with
    the number of installations by avoiding rate limits, and have a more transparent
    integration by avoiding to request user input. ---- 1. Register a GitHub App with
    the following configuration: GitHub App name:: Enter a unique name identifying
    your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage URL:: Enter
    your Developer Hub URL: https://<my_developer_hub_domain>. Authorization callback
    URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:47:46.453231'
    uuid: 77e6d2d8-1b33-4749-b4bf-5fe81a51500d
  response: 'To add your RHSSO credentials to Red Hat Developer Hub, you must add
    the following key/value pairs to your Developer Hub secrets: KEYCLOAK_CLIENT_ID,
    where you enter the saved Client ID; KEYCLOAK_CLIENT_SECRET, where you enter the
    saved Client Secret; KEYCLOAK_BASE_URL, where you enter the saved RHBK realm base
    URL; KEYCLOAK_REALM, where you enter the realm name to provision users; and KEYCLOAK_LOGIN_REALM,
    where you enter the realm name to authenticate users.'
  user_input: how do i make Red Hat Developer Hub use keycloak for auth, what secrets
    i need to add for it?
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK) Authenticate
    users with Red Hat Build of Keycloak (RHBK), by provisioning the users and groups
    from RHBK to the Developer Hub software catalog, and configuring the OpenID Connect
    (OIDC) authentication provider in Red Hat Developer Hub. You added a custom Developer
    Hub application configuration, and have enough permissions to change it. You have
    enough permissions in RHSSO to create and manage a realm and a client. [TIP] ----
    Alternatively, ask your RHBK administrator to prepare in RHBK the required realm
    and client. ---- 1. Register your Developer Hub app in RHBK: 1. Use an existing
    realm, or create a realm, with a distinctive Name such as <my_realm>. Save the
    value for the next step: * RHBK realm base URL, such as: <your_rhbk_URL>/realms/<your_realm>.
    2. To register your Developer Hub in RHBK, in the created realm, secure the first
    application, with: 1. Client ID: A distinctive client ID, such as <RHDH>. 2. Valid
    redirect URIs: Set to the OIDC handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame.
    3. Go to the Credentials tab and copy the Client secret. 4. Save the values for
    the next step: * Client ID * Client Secret 3. To prepare for the verification
    steps, in the same realm, get the credential information for an existing user
    or create a user. Save the user credential information for the verification steps.
    2. Add your RHSSO credentials to Developer Hub, by adding the following key/value
    pairs to your Developer Hub secrets. You can use these secrets in the Developer
    Hub configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. Optional: To configure optional fields, see Configuring Red
    Hat Developer Hub. 5. Enable the RHBK authentication provider, by adding the OIDC
    provider section in your app-config.yaml file: ```yaml auth: environment: production
    providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID}
    clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt: auto signInPage: oidc ``` environment:
    production:: Mark the environment as production to hide the Guest login in the
    Developer Hub home page. metadataUrl, clientId, clientSecret:: Configure the OIDC
    provider with your secrets. prompt:: Enter auto to allow the identity provider
    to automatically determine whether to prompt for credentials or bypass the login
    redirect if an active RHSSO session exists. The identity provider defaults to
    none, which assumes that you are already logged in. Sign-in requests without an
    active session are rejected. signInPage:: Enter oidc to enable the OIDC provider
    as default sign-in provider. Optional: To configure optional fields, see Configuring
    Red Hat Developer Hub. 1. To verify user and group provisioning, check the console
    logs. Successful synchronization example: ``` 2025-06-27T16:02:34.647Z catalog
    info Read 5 Keycloak users and 3 Keycloak groups in 0.4 seconds. Committing...
    class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ## Enabling user authentication with GitHub Authenticate users with GitHub
    by provisioning the users and groups from GitHub to the Developer Hub software
    catalog, and configuring the GitHub authentication provider in Red Hat Developer
    Hub. You have enough permissions in GitHub to create and manage a GitHub App.
    [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough permissions to change it. 1. Allow Developer Hub to authenticate
    with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub App instead of
    an OAuth app to use fine-grained permissions, use short-lived tokens, scale with
    the number of installations by avoiding rate limits, and have a more transparent
    integration by avoiding to request user input. ---- 1. Register a GitHub App with
    the following configuration: GitHub App name:: Enter a unique name identifying
    your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage URL:: Enter
    your Developer Hub URL: https://<my_developer_hub_domain>. Authorization callback
    URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:47:57.579740'
    uuid: 7d83ddb8-b5c3-4f3b-abfc-f4f4bfec7401
  response: To enable user authentication with Red Hat Build of Keycloak (RHBK), you
    must first register your Developer Hub app in RHBK. This involves using or creating
    a realm, securing the application with a Client ID and a 'Valid redirect URIs'
    set to your OIDC handler URL (https://<my_developer_hub_domain>/api/auth/oidc/handler/frame),
    and copying the Client secret. Next, you add these credentials to Developer Hub
    secrets by creating key/value pairs for KEYCLOAK_CLIENT_ID, KEYCLOAK_CLIENT_SECRET,
    KEYCLOAK_BASE_URL, KEYCLOAK_REALM, and KEYCLOAK_LOGIN_REALM. After that, you enable
    the Keycloak catalog provider plugin in your dynamic-plugins.yaml file. To enable
    user and group provisioning, you add the 'catalog.providers.keycloakOrg' section
    to your app-config.yaml file, configuring it with the secrets you created. Finally,
    you enable the RHBK authentication provider by adding the OIDC provider section
    in your app-config.yaml file, also configuring it with your secrets for metadataUrl,
    clientId, and clientSecret.
  user_input: Im trying to get our Develper Hub instance to use our existing Red Hat
    Build of Keycloak (RHBK) for authenication. Can you walk me thru the entire proces?
    I need to know what to do in RHBK itself, what secrets I need to create for Developer
    Hub, and what changes I need to make to the config files like `app-config.yaml`
    to get user provsioning working?
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK) Authenticate
    users with Red Hat Build of Keycloak (RHBK), by provisioning the users and groups
    from RHBK to the Developer Hub software catalog, and configuring the OpenID Connect
    (OIDC) authentication provider in Red Hat Developer Hub. You added a custom Developer
    Hub application configuration, and have enough permissions to change it. You have
    enough permissions in RHSSO to create and manage a realm and a client. [TIP] ----
    Alternatively, ask your RHBK administrator to prepare in RHBK the required realm
    and client. ---- 1. Register your Developer Hub app in RHBK: 1. Use an existing
    realm, or create a realm, with a distinctive Name such as <my_realm>. Save the
    value for the next step: * RHBK realm base URL, such as: <your_rhbk_URL>/realms/<your_realm>.
    2. To register your Developer Hub in RHBK, in the created realm, secure the first
    application, with: 1. Client ID: A distinctive client ID, such as <RHDH>. 2. Valid
    redirect URIs: Set to the OIDC handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame.
    3. Go to the Credentials tab and copy the Client secret. 4. Save the values for
    the next step: * Client ID * Client Secret 3. To prepare for the verification
    steps, in the same realm, get the credential information for an existing user
    or create a user. Save the user credential information for the verification steps.
    2. Add your RHSSO credentials to Developer Hub, by adding the following key/value
    pairs to your Developer Hub secrets. You can use these secrets in the Developer
    Hub configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. Optional: To configure optional fields, see Configuring Red
    Hat Developer Hub. 5. Enable the RHBK authentication provider, by adding the OIDC
    provider section in your app-config.yaml file: ```yaml auth: environment: production
    providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID}
    clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt: auto signInPage: oidc ``` environment:
    production:: Mark the environment as production to hide the Guest login in the
    Developer Hub home page. metadataUrl, clientId, clientSecret:: Configure the OIDC
    provider with your secrets. prompt:: Enter auto to allow the identity provider
    to automatically determine whether to prompt for credentials or bypass the login
    redirect if an active RHSSO session exists. The identity provider defaults to
    none, which assumes that you are already logged in. Sign-in requests without an
    active session are rejected. signInPage:: Enter oidc to enable the OIDC provider
    as default sign-in provider. Optional: To configure optional fields, see Configuring
    Red Hat Developer Hub. 1. To verify user and group provisioning, check the console
    logs. Successful synchronization example: ``` 2025-06-27T16:02:34.647Z catalog
    info Read 5 Keycloak users and 3 Keycloak groups in 0.4 seconds. Committing...
    class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ## Enabling user authentication with GitHub Authenticate users with GitHub
    by provisioning the users and groups from GitHub to the Developer Hub software
    catalog, and configuring the GitHub authentication provider in Red Hat Developer
    Hub. You have enough permissions in GitHub to create and manage a GitHub App.
    [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough permissions to change it. 1. Allow Developer Hub to authenticate
    with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub App instead of
    an OAuth app to use fine-grained permissions, use short-lived tokens, scale with
    the number of installations by avoiding rate limits, and have a more transparent
    integration by avoiding to request user input. ---- 1. Register a GitHub App with
    the following configuration: GitHub App name:: Enter a unique name identifying
    your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage URL:: Enter
    your Developer Hub URL: https://<my_developer_hub_domain>. Authorization callback
    URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:48:07.821166'
    uuid: 5d536ead-ac8a-487f-b955-b25b34b9bce5
  response: You should use a GitHub App instead of an OAuth app to use fine-grained
    permissions, use short-lived tokens, scale with the number of installations by
    avoiding rate limits, and have a more transparent integration by avoiding to request
    user input.
  user_input: why not use oauth app for github?
- context:
  - 'groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module github org dynamic'' disabled:
    false ``` 4. Enable provisioning GitHub users and groups to the Developer Hub
    software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. 1. Verify user and group
    provisioning by checking the console logs. Successful synchronization example:
    ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with Microsoft
    Azure Authenticate users with Microsoft Azure by provisioning the users and groups
    from Azure to the Developer Hub software catalog, and configuring the Azure authentication
    provider in Red Hat Developer Hub. You have the permission to register an application
    in Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the
    required Azure application. ---- * You added a custom Developer Hub application
    configuration, and have enough permissions to change it. * Your Developer Hub
    backend can access the following hosts: login.microsoftonline.com:: The Microsoft
    Azure authorization server, which enables the authentication flow. graph.microsoft.com::
    The server for retrieving organization data, including user and group data, to
    import into the Developer Hub catalog. 1. Register your Developer Hub app in Azure,
    by using the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2.
    Optional: If you have access to multiple tenants, use the Settings icon in the
    top menu to switch to the tenant in which you want to register the application
    from the Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. Enable Azure authentication,
    by adding'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:48:18.630671'
    uuid: 397b691f-7554-4475-b5ec-4692b7b0d9bd
  response: To authenticate users with Microsoft Azure, you must provision users and
    groups from Azure to the Developer Hub software catalog and configure the Azure
    authentication provider. First, register your Developer Hub app in Azure through
    the Microsoft Entra admin center, specifying a name, setting "Supported account
    types" to "Accounts in this organizational directory only", and providing a Redirect
    URI for the backend. Next, on the API permissions page, add Microsoft Graph permissions.
    For Application Permissions, add `GroupMember.Read.All` and `User.Read.All` to
    enable provisioning. For Delegated Permissions, add `User.Read`, `email`, `offline_access`,
    `openid`, and `profile` to enable user authentication. Then, create a new client
    secret and save the Directory (tenant) ID, Application (client) ID, and the secret.
    Add these credentials to your Developer Hub secrets as `MICROSOFT_TENANT_ID`,
    `MICROSOFT_CLIENT_ID`, and `MICROSOFT_CLIENT_SECRET`. After that, enable the Microsoft
    Graph catalog provider plugin in your `dynamic-plugins.yaml` file. Finally, enable
    provisioning by adding the Microsoft Graph catalog provider section to your `app-config.yaml`
    file, configuring the target, tenantId, clientId, clientSecret, and schedule.
  user_input: how i can make Red Hat Developer Hub work with azure users for login?
- context:
  - 'groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module github org dynamic'' disabled:
    false ``` 4. Enable provisioning GitHub users and groups to the Developer Hub
    software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. 1. Verify user and group
    provisioning by checking the console logs. Successful synchronization example:
    ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with Microsoft
    Azure Authenticate users with Microsoft Azure by provisioning the users and groups
    from Azure to the Developer Hub software catalog, and configuring the Azure authentication
    provider in Red Hat Developer Hub. You have the permission to register an application
    in Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the
    required Azure application. ---- * You added a custom Developer Hub application
    configuration, and have enough permissions to change it. * Your Developer Hub
    backend can access the following hosts: login.microsoftonline.com:: The Microsoft
    Azure authorization server, which enables the authentication flow. graph.microsoft.com::
    The server for retrieving organization data, including user and group data, to
    import into the Developer Hub catalog. 1. Register your Developer Hub app in Azure,
    by using the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2.
    Optional: If you have access to multiple tenants, use the Settings icon in the
    top menu to switch to the tenant in which you want to register the application
    from the Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. Enable Azure authentication,
    by adding'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:48:34.488229'
    uuid: 4d244cbd-8b69-4d7e-a91a-e5c71a94a7c9
  response: 'To authenticate users with Microsoft Azure, you must first register your
    Developer Hub app in the Azure portal. In the Microsoft Entra admin center, create
    a ''New registration'' with ''Accounts in this organizational directory only''
    and a Redirect URI set to ''https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame''.
    On the API permissions page, you need to add permissions for Microsoft Graph.
    For Application Permissions, add ''GroupMember.Read.All'' and ''User.Read.All''.
    For Delegated Permissions, add ''User.Read'', ''email'', ''offline_access'', ''openid'',
    and ''profile''. Next, create a ''New client secret'' and save the ''Directory
    (tenant) ID'', ''Application (client) ID'', and ''Application (client) Secret
    ID''. These credentials must be added to your Developer Hub secrets as ''MICROSOFT_TENANT_ID'',
    ''MICROSOFT_CLIENT_ID'', and ''MICROSOFT_CLIENT_SECRET''. You also need to enable
    the Microsoft Graph catalog provider plugin in your ''dynamic-plugins.yaml'' file.
    Finally, to enable provisioning, you must add the Microsoft Graph catalog provider
    section to your ''app-config.yaml'' file with the following configuration: ```yaml
    catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ```'
  user_input: What are all the stepps I need to take to integrate Microsft Azure for
    user authenication in our Developer Hub, specificaly what permisions do I need
    to set in the Azure portal and what do I need to configure in the app-config.yaml
    file?
- context:
  - 'groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module github org dynamic'' disabled:
    false ``` 4. Enable provisioning GitHub users and groups to the Developer Hub
    software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. 1. Verify user and group
    provisioning by checking the console logs. Successful synchronization example:
    ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with Microsoft
    Azure Authenticate users with Microsoft Azure by provisioning the users and groups
    from Azure to the Developer Hub software catalog, and configuring the Azure authentication
    provider in Red Hat Developer Hub. You have the permission to register an application
    in Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the
    required Azure application. ---- * You added a custom Developer Hub application
    configuration, and have enough permissions to change it. * Your Developer Hub
    backend can access the following hosts: login.microsoftonline.com:: The Microsoft
    Azure authorization server, which enables the authentication flow. graph.microsoft.com::
    The server for retrieving organization data, including user and group data, to
    import into the Developer Hub catalog. 1. Register your Developer Hub app in Azure,
    by using the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2.
    Optional: If you have access to multiple tenants, use the Settings icon in the
    top menu to switch to the tenant in which you want to register the application
    from the Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. Optional: To configure
    optional fields, see Configuring Red Hat Developer Hub. Enable Azure authentication,
    by adding'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:48:45.449618'
    uuid: 56b90716-0fe1-4fe5-b7c7-319f0049db36
  response: To enable the GitHub authentication provider, you must add the GitHub
    authentication provider section to your app-config.yaml file. In this configuration,
    set the `environment` to `production` to disable the Guest login option in the
    Developer Hub login page. You also need to provide the configured secret variable
    names for the `clientId` (${GITHUB_CLIENT_ID}) and `clientSecret` (${GITHUB_CLIENT_SECRET}).
    Finally, set the `signInPage` to `github` to enable the GitHub provider as your
    Developer Hub sign-in provider.
  user_input: how to configure GitHub authentication in Developer Hub
- context:
  - 'the Microsoft authentication provider to your app-config.yaml file content: ```yaml
    auth: environment: production providers: microsoft: production: clientId: ${MICROSOFT_CLIENT_ID}
    clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID} signInPage:
    microsoft ``` environment:: Enter production to disable the Guest login option
    in the Developer Hub login page. clientId:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured secret variable
    name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to set the Azure provider
    as your Developer Hub sign-in provider. Optional: To configure optional fields,
    see Configuring Red Hat Developer Hub. 1. To verify user and group provisioning,
    check the console logs for MicrosoftGraphOrgEntityProvider events. Successful
    synchronization example: ``` 2025-06-23T13:37:55.804Z catalog info Read 9 msgraph
    users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Using the Red Hat Developer Hub Operator to run Developer
    Hub with your custom configuration Use the Developer Hub Operator to run Red Hat
    Developer Hub with your custom configuration by creating your Backstage custom
    resource (CR) that can perform the following actions: Mount files provisioned
    in your custom config maps. Inject environment variables provisioned in your custom
    secrets. By using the OpenShift CLI (oc), you have access, with developer permissions,
    to the OpenShift Container Platform cluster aimed at containing your Developer
    Hub instance. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml file
    to use your custom config maps and secrets. my-rhdh-custom-resource.yaml custom
    resource example with dynamic plugins and RBAC policies config maps, and external
    PostgreSQL database secrets. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: <my rhdh custom resource> spec: application: appConfig:
    mountPath: /opt/app root/src configMaps: name: my rhdh app config name: rbac policies
    dynamicPluginsConfigMapName: dynamic plugins rhdh extraEnvs: envs: name: HTTP_PROXY
    value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' secrets: name: my rhdh secrets
    extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh database certificates
    secrets key: postgres crt.pem, postgres ca.pem, postgres key.key replicas: 2 database:
    enableLocalDb: false ``` application:: appConfig:: Register your my-rhdh-app-config
    and rbac-policies config maps. dynamicPluginsConfigMapName:: Register your dynamic-plugins-rhdh
    config map. extraEnvs:: env:: Enter your proxy environment variables. secrets::
    Register your <my_product_secrets> and my-rhdh-database-secrets secrets. extraFiles::
    secrets:: Register the postgres-crt.pem, postgres-ca.pem, and postgres-key.key
    files contained in the my-rhdh-database-certificates-secrets secret. replicas::
    Enable high availability (HA) by increasing the replicas count to a value higher
    or equal to 2. database:: enableLocalDb:: Use your external PostgreSQL database
    rather than the internal PostgreSQL database. 2. Apply your Backstage CR to start
    or update your Developer Hub instance. ```terminal $ oc apply - filename=my rhdh
    custom resource.yaml - namespace=my rhdh project ``` # Customizing the theme mode
    for your Developer Hub instance You can choose one of the following theme modes
    for your Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub,
    theme configurations are used to change the look and feel of different UI components.
    So, you might notice changes in different UI components, such as buttons, tabs,
    sidebars, cards, and tables along with some changes in background color and font
    used on the RHDH pages. ---- The default theme mode is Auto, which automatically
    sets the light or dark theme based on your system preferences. You are logged
    in to the Developer Hub web console. 1. From the Developer Hub web console, click
    Settings. 2. From the Appearance panel, click Light, Dark, or Auto to change the
    theme mode. ![custom theme mode 1] #'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:48:56.228901'
    uuid: c8c178b0-ce20-4c19-ba4b-d02244a9745f
  response: You can use the Developer Hub Operator to run Red Hat Developer Hub with
    a custom configuration by creating a Backstage custom resource (CR). This CR can
    perform actions such as mounting files provisioned in your custom config maps
    and injecting environment variables from your custom secrets. After authoring
    the Backstage CR in a YAML file, you apply it using the OpenShift CLI (`oc apply
    -f <filename>`) to start or update your Developer Hub instance with the custom
    settings.
  user_input: how to use a Backstage custom resource to apply custom configurations
    in Red Hat Developer Hub
- context:
  - 'the Microsoft authentication provider to your app-config.yaml file content: ```yaml
    auth: environment: production providers: microsoft: production: clientId: ${MICROSOFT_CLIENT_ID}
    clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID} signInPage:
    microsoft ``` environment:: Enter production to disable the Guest login option
    in the Developer Hub login page. clientId:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured secret variable
    name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to set the Azure provider
    as your Developer Hub sign-in provider. Optional: To configure optional fields,
    see Configuring Red Hat Developer Hub. 1. To verify user and group provisioning,
    check the console logs for MicrosoftGraphOrgEntityProvider events. Successful
    synchronization example: ``` 2025-06-23T13:37:55.804Z catalog info Read 9 msgraph
    users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Using the Red Hat Developer Hub Operator to run Developer
    Hub with your custom configuration Use the Developer Hub Operator to run Red Hat
    Developer Hub with your custom configuration by creating your Backstage custom
    resource (CR) that can perform the following actions: Mount files provisioned
    in your custom config maps. Inject environment variables provisioned in your custom
    secrets. By using the OpenShift CLI (oc), you have access, with developer permissions,
    to the OpenShift Container Platform cluster aimed at containing your Developer
    Hub instance. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml file
    to use your custom config maps and secrets. my-rhdh-custom-resource.yaml custom
    resource example with dynamic plugins and RBAC policies config maps, and external
    PostgreSQL database secrets. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: <my rhdh custom resource> spec: application: appConfig:
    mountPath: /opt/app root/src configMaps: name: my rhdh app config name: rbac policies
    dynamicPluginsConfigMapName: dynamic plugins rhdh extraEnvs: envs: name: HTTP_PROXY
    value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' secrets: name: my rhdh secrets
    extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh database certificates
    secrets key: postgres crt.pem, postgres ca.pem, postgres key.key replicas: 2 database:
    enableLocalDb: false ``` application:: appConfig:: Register your my-rhdh-app-config
    and rbac-policies config maps. dynamicPluginsConfigMapName:: Register your dynamic-plugins-rhdh
    config map. extraEnvs:: env:: Enter your proxy environment variables. secrets::
    Register your <my_product_secrets> and my-rhdh-database-secrets secrets. extraFiles::
    secrets:: Register the postgres-crt.pem, postgres-ca.pem, and postgres-key.key
    files contained in the my-rhdh-database-certificates-secrets secret. replicas::
    Enable high availability (HA) by increasing the replicas count to a value higher
    or equal to 2. database:: enableLocalDb:: Use your external PostgreSQL database
    rather than the internal PostgreSQL database. 2. Apply your Backstage CR to start
    or update your Developer Hub instance. ```terminal $ oc apply - filename=my rhdh
    custom resource.yaml - namespace=my rhdh project ``` # Customizing the theme mode
    for your Developer Hub instance You can choose one of the following theme modes
    for your Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub,
    theme configurations are used to change the look and feel of different UI components.
    So, you might notice changes in different UI components, such as buttons, tabs,
    sidebars, cards, and tables along with some changes in background color and font
    used on the RHDH pages. ---- The default theme mode is Auto, which automatically
    sets the light or dark theme based on your system preferences. You are logged
    in to the Developer Hub web console. 1. From the Developer Hub web console, click
    Settings. 2. From the Appearance panel, click Light, Dark, or Auto to change the
    theme mode. ![custom theme mode 1] #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:49:09.008587'
    uuid: f0df5544-9966-45fb-9226-297290917a2f
  response: 'By using the OpenShift CLI (oc), you have access, with developer permissions,
    to the OpenShift Container Platform cluster aimed at containing your Developer
    Hub instance. You can use it to apply your Backstage CR to start or update your
    Developer Hub instance with a command like: $ oc apply - filename=my rhdh custom
    resource.yaml - namespace=my rhdh project.'
  user_input: wat is the OpenShift CLI ussed for?
- context:
  - 'the Microsoft authentication provider to your app-config.yaml file content: ```yaml
    auth: environment: production providers: microsoft: production: clientId: ${MICROSOFT_CLIENT_ID}
    clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID} signInPage:
    microsoft ``` environment:: Enter production to disable the Guest login option
    in the Developer Hub login page. clientId:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured secret variable
    name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured secret variable
    name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to set the Azure provider
    as your Developer Hub sign-in provider. Optional: To configure optional fields,
    see Configuring Red Hat Developer Hub. 1. To verify user and group provisioning,
    check the console logs for MicrosoftGraphOrgEntityProvider events. Successful
    synchronization example: ``` 2025-06-23T13:37:55.804Z catalog info Read 9 msgraph
    users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Using the Red Hat Developer Hub Operator to run Developer
    Hub with your custom configuration Use the Developer Hub Operator to run Red Hat
    Developer Hub with your custom configuration by creating your Backstage custom
    resource (CR) that can perform the following actions: Mount files provisioned
    in your custom config maps. Inject environment variables provisioned in your custom
    secrets. By using the OpenShift CLI (oc), you have access, with developer permissions,
    to the OpenShift Container Platform cluster aimed at containing your Developer
    Hub instance. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml file
    to use your custom config maps and secrets. my-rhdh-custom-resource.yaml custom
    resource example with dynamic plugins and RBAC policies config maps, and external
    PostgreSQL database secrets. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: <my rhdh custom resource> spec: application: appConfig:
    mountPath: /opt/app root/src configMaps: name: my rhdh app config name: rbac policies
    dynamicPluginsConfigMapName: dynamic plugins rhdh extraEnvs: envs: name: HTTP_PROXY
    value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' secrets: name: my rhdh secrets
    extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh database certificates
    secrets key: postgres crt.pem, postgres ca.pem, postgres key.key replicas: 2 database:
    enableLocalDb: false ``` application:: appConfig:: Register your my-rhdh-app-config
    and rbac-policies config maps. dynamicPluginsConfigMapName:: Register your dynamic-plugins-rhdh
    config map. extraEnvs:: env:: Enter your proxy environment variables. secrets::
    Register your <my_product_secrets> and my-rhdh-database-secrets secrets. extraFiles::
    secrets:: Register the postgres-crt.pem, postgres-ca.pem, and postgres-key.key
    files contained in the my-rhdh-database-certificates-secrets secret. replicas::
    Enable high availability (HA) by increasing the replicas count to a value higher
    or equal to 2. database:: enableLocalDb:: Use your external PostgreSQL database
    rather than the internal PostgreSQL database. 2. Apply your Backstage CR to start
    or update your Developer Hub instance. ```terminal $ oc apply - filename=my rhdh
    custom resource.yaml - namespace=my rhdh project ``` # Customizing the theme mode
    for your Developer Hub instance You can choose one of the following theme modes
    for your Developer Hub instance: Light Dark Auto [NOTE] ---- In Developer Hub,
    theme configurations are used to change the look and feel of different UI components.
    So, you might notice changes in different UI components, such as buttons, tabs,
    sidebars, cards, and tables along with some changes in background color and font
    used on the RHDH pages. ---- The default theme mode is Auto, which automatically
    sets the light or dark theme based on your system preferences. You are logged
    in to the Developer Hub web console. 1. From the Developer Hub web console, click
    Settings. 2. From the Appearance panel, click Light, Dark, or Auto to change the
    theme mode. ![custom theme mode 1] #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:49:22.291710'
    uuid: 69c0d29b-d9ef-4f16-81e7-b8a3a9944972
  response: 'By using the OpenShift CLI (oc), you have access to the OpenShift Container
    Platform cluster to apply your Backstage CR, which will start or update your Developer
    Hub instance. You can do this with the command: `$ oc apply - filename=my rhdh
    custom resource.yaml - namespace=my rhdh project`.'
  user_input: how i use openshift cli for this?
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE."
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T15:49:32.402507'
    uuid: e892f83a-e576-4fee-a06e-d6fda79fc104
  response: The policies generated from a ConfigMap file cannot be edited or deleted
    using the Developer Hub Web UI.
  user_input: Developer Hub UI edit policy from ConfigMap
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE."
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T15:49:38.470903'
    uuid: 878f11ac-60fb-49e3-8d54-66194eb99085
  response: 'To delete a role in the Red Hat Developer Hub using the Web UI, you must
    have enabled RBAC and have a policy administrator role in Developer Hub. The role
    you wish to delete must have been created in the Developer Hub. Note that policies
    generated from a policy.csv or ConfigMap file cannot be deleted using the Developer
    Hub Web UI. The steps are as follows: 1. Go to Administration at the bottom of
    the sidebar in the Developer Hub, which will display the RBAC tab with all created
    roles. 2. Optionally, you can click any role to view its information on the OVERVIEW
    page. 3. Select the delete icon from the Actions column for the specific role
    you want to remove. A "Delete this role?" pop-up will appear. 4. Click DELETE.'
  user_input: how do i delte a role in Red Hat Developer Hub?
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE."
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T15:49:46.904603'
    uuid: e6fbcda2-6f74-44e3-9afe-1e01a6aba8d2
  response: 'Policy administrators can use the Developer Hub web interface (Web UI)
    to create, modify, and delete roles. To create a role, you must have RBAC enabled,
    a policy administrator role, and have added plugins with permission. The steps
    are: go to Administration, click CREATE, enter a name and description, add users
    and groups, select a Plugin and Permission, set the Policy, review the information,
    and click CREATE. To edit a role, you must have the same prerequisites and the
    role must have been created in the Developer Hub. The steps are: go to Administration,
    select the edit icon for the role, edit the details, and click SAVE. To delete
    a role, with the same prerequisites, you go to Administration, select the delete
    icon for the role, and click DELETE on the pop-up. However, it is important to
    note that policies generated from a policy.csv or ConfigMap file cannot be edited
    or deleted using the Developer Hub Web UI.'
  user_input: so how do i manage roles in the Developer Hub for my teams, like i need
    to know how you make a new role and then how to change one thats already there
    or even get rid of one we dont need no more, is it all just done in the web ui
    or what?
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Container Platform You can install
    Red Hat Developer Hub on OpenShift Container Platform by using one of the following
    installers: The Red Hat Developer Hub Operator:: * Ready for immediate use in
    OpenShift Container Platform after an administrator installs it with OperatorHub
    * Uses Operator Lifecycle Management (OLM) to manage automated subscription updates
    on OpenShift Container Platform * Requires preinstallation of Operator Lifecycle
    Management (OLM) to manage automated subscription updates on Kubernetes The Red
    Hat Developer Hub Helm chart:: * Ready for immediate use in both OpenShift Container
    Platform and Kubernetes * Requires manual installation and management [IMPORTANT]
    ---- You must set the baseUrl in app-config.yaml to match the external URL of
    your Developer Hub instance (for example, https://rhdh.example.com). This value
    is required for the Red Hat Developer Hub to function correctly. If it is not
    set, frontend and backend services cannot communicate properly, and features may
    not work as expected. ---- Use the installation method that best meets your needs
    and preferences. * Choosing an installation method: Helm Charts vs. Operators
    * Working with Operators * Working with Helm charts # Installing Red Hat Developer
    Hub on OpenShift Container Platform with the Operator You can install Red Hat
    Developer Hub on OpenShift Container Platform by using the Red Hat Developer Hub
    Operator in the OpenShift Container Platform console. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:49:54.651516'
    uuid: 65a25515-ed3d-4a5e-a934-008f811a6c1d
  response: The Red Hat Developer Hub Helm chart is ready for immediate use in both
    OpenShift Container Platform and Kubernetes, but it requires manual installation
    and management. For the installation to function correctly, you must set the baseUrl
    in app-config.yaml to match the external URL of your Developer Hub instance, as
    this is required for frontend and backend services to communicate properly.
  user_input: Red Hat Developer Hub install with Helm
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Container Platform You can install
    Red Hat Developer Hub on OpenShift Container Platform by using one of the following
    installers: The Red Hat Developer Hub Operator:: * Ready for immediate use in
    OpenShift Container Platform after an administrator installs it with OperatorHub
    * Uses Operator Lifecycle Management (OLM) to manage automated subscription updates
    on OpenShift Container Platform * Requires preinstallation of Operator Lifecycle
    Management (OLM) to manage automated subscription updates on Kubernetes The Red
    Hat Developer Hub Helm chart:: * Ready for immediate use in both OpenShift Container
    Platform and Kubernetes * Requires manual installation and management [IMPORTANT]
    ---- You must set the baseUrl in app-config.yaml to match the external URL of
    your Developer Hub instance (for example, https://rhdh.example.com). This value
    is required for the Red Hat Developer Hub to function correctly. If it is not
    set, frontend and backend services cannot communicate properly, and features may
    not work as expected. ---- Use the installation method that best meets your needs
    and preferences. * Choosing an installation method: Helm Charts vs. Operators
    * Working with Operators * Working with Helm charts # Installing Red Hat Developer
    Hub on OpenShift Container Platform with the Operator You can install Red Hat
    Developer Hub on OpenShift Container Platform by using the Red Hat Developer Hub
    Operator in the OpenShift Container Platform console. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:50:06.932603'
    uuid: 3675251e-3cf5-4c93-961b-35dbf5f09c92
  response: The Red Hat Developer Hub Helm chart is ready for immediate use in both
    OpenShift Container Platform and Kubernetes, but it requires manual installation
    and management. Additionally, you must set the baseUrl in app-config.yaml to match
    the external URL of your Developer Hub instance. This value is required for the
    Red Hat Developer Hub to function correctly, as without it, frontend and backend
    services cannot communicate properly.
  user_input: what are the specific requirements and management implications for installing
    Red Hat Developer Hub on OpenShift Container Platform using the Helm chart method
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Container Platform You can install
    Red Hat Developer Hub on OpenShift Container Platform by using one of the following
    installers: The Red Hat Developer Hub Operator:: * Ready for immediate use in
    OpenShift Container Platform after an administrator installs it with OperatorHub
    * Uses Operator Lifecycle Management (OLM) to manage automated subscription updates
    on OpenShift Container Platform * Requires preinstallation of Operator Lifecycle
    Management (OLM) to manage automated subscription updates on Kubernetes The Red
    Hat Developer Hub Helm chart:: * Ready for immediate use in both OpenShift Container
    Platform and Kubernetes * Requires manual installation and management [IMPORTANT]
    ---- You must set the baseUrl in app-config.yaml to match the external URL of
    your Developer Hub instance (for example, https://rhdh.example.com). This value
    is required for the Red Hat Developer Hub to function correctly. If it is not
    set, frontend and backend services cannot communicate properly, and features may
    not work as expected. ---- Use the installation method that best meets your needs
    and preferences. * Choosing an installation method: Helm Charts vs. Operators
    * Working with Operators * Working with Helm charts # Installing Red Hat Developer
    Hub on OpenShift Container Platform with the Operator You can install Red Hat
    Developer Hub on OpenShift Container Platform by using the Red Hat Developer Hub
    Operator in the OpenShift Container Platform console. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:50:14.623712'
    uuid: 59500393-5aae-43ea-af87-bc61452f6347
  response: 'You can install Red Hat Developer Hub on OpenShift Container Platform
    using one of two installers: the Red Hat Developer Hub Operator or the Red Hat
    Developer Hub Helm chart. The Operator is ready for immediate use after an administrator
    installs it with OperatorHub and uses Operator Lifecycle Management (OLM) for
    automated updates. The Helm chart is also ready for immediate use but requires
    manual installation and management.'
  user_input: What are the installation options for Red Hat Developer Hub on OpenShift
    Container Platform?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:50:23.704504'
    uuid: 021a983c-477a-472d-8700-d68dedfa8ac4
  response: Before installing the Red Hat Developer Hub Operator, you must be logged
    in as an administrator on the OpenShift Container Platform web console. You need
    to have configured the appropriate roles and permissions within your project to
    create or access an application. Additionally, you must have installed Red Hat
    OpenShift Container Platform version 4.16 to 4.19 and ensured your system meets
    the minimum sizing requirements.
  user_input: What are the prerequisites for installing the Red Hat Developer Hub
    Operator on Red Hat OpenShift Container Platform?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:50:32.118249'
    uuid: fc090004-31f5-4cfa-808d-e6f434dec601
  response: The recommended namespace for the installation is the "rhdh-operator"
    namespace, which is the default option. It is important to install the Red Hat
    Developer Hub Operator in a dedicated default namespace for enhanced security,
    better control over the Operator lifecycle, and to prevent potential privilege
    escalation. Using a dedicated namespace allows you to restrict other users' access
    to the Operator resources. Furthermore, if the Red Hat Developer Hub Operator
    shares a namespace with other Operators, it will also share the same update policy,
    which prevents the customization of its update policy.
  user_input: What is the reccomended namesapce for installing the Red Hat Developer
    Hub Operator and why is it important?
- context:
  - 'Installing the Red Hat Developer Hub Operator As an administrator, you can install
    the Red Hat Developer Hub Operator. Authorized users can use the Operator to install
    Red Hat Developer Hub on Red Hat OpenShift Container Platform (OpenShift Container
    Platform) and supported Kubernetes platforms. For more information on supported
    platforms and versions, see the Red Hat Developer Hub Life Cycle page. Containers
    are available for the following CPU architectures: AMD64 and Intel 64 (x86_64)
    You are logged in as an administrator on the OpenShift Container Platform web
    console. You have configured the appropriate roles and permissions within your
    project to create or access an application. For more information, see the Red
    Hat OpenShift Container Platform documentation on Building applications. You have
    installed Red Hat OpenShift Container Platform 4.16 to 4.19. Make sure that your
    system meets the minimum sizing requirements. See Sizing requirements for Red
    Hat Developer Hub. 1. In the navigation menu of the OpenShift Container Platform
    console, click Operators > OperatorHub. 2. In the Filter by keyword box, enter
    Developer Hub and click the Red Hat Developer Hub Operator card. 3. On the Red
    Hat Developer Hub Operator page, read the information about the Operator and click
    Install to open the Install Operator page. 4. After the Operator is successfully
    installed, provision your custom configuration: Before you create a Developer
    Hub instance, you must create the required config map and Secret resources in
    your project. These include the baseUrl and service-to-service authentication
    secrets. For detailed steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 5. From the Update channel drop-down menu, select the update channel
    that you want to use, for example, fast or fast-1.8. [IMPORTANT] ---- The `fast
    channel includes all of the updates available for a particular version. Any update
    might introduce unexpected changes in your Red Hat Developer Hub deployment. Check
    the release notes for details about any potentially breaking changes. The fast-1.8
    channel only provides z-stream updates, for example, updating from version 1.8.1
    to 1.8.2. If you want to update the Red Hat Developer Hub y-version in the future,
    for example, updating from 1.8 to 1.9, you must switch to the fast-1.9 channel
    manually. ---- 6. From the Version drop-down menu, select the version of the Red
    Hat Developer Hub Operator that you want to install. The default version is the
    latest version available in the selected channel. 7. Select the Operator Installation
    mode. [NOTE] ---- The All namespaces on the cluster (default) option is selected
    by default. The Specific namespace on the cluster option is not currently supported.
    ---- 8. In the Installed Namespace field, do one of the following actions: * Select
    Operator recommended Namespace to create and use the rhdh-operator namespace.
    This option is selected by default. * Select Select a Namespace to use an alternative
    namespace. * From the Select Project drop-down menu, do one of the following actions:
    * Select an existing project. * Select Create Project to create a new project
    for the Operator. * On the Create Project dialog, enter text into the required
    fields and click Create. [IMPORTANT] ---- For enhanced security, better control
    over the Operator lifecycle, and preventing potential privilege escalation, install
    the Red Hat Developer Hub Operator in a dedicated default rhdh-operator namespace.
    You can restrict other users'' access to the Operator resources through role bindings
    or cluster role bindings. You can also install the Operator in another namespace
    by creating the necessary resources, such as an Operator group. For more information,
    see Installing global Operators in custom namespaces. However, if the Red Hat
    Developer Hub Operator shares a namespace with other Operators, then it shares
    the same update policy as well, preventing the customization of the update policy.
    For example, if one Operator is set to manual updates, the Red Hat Developer Hub
    Operator update policy is also set to manual. For more information, see Colocation
    of Operators in a namespace. ---- 9. Select the Update approval method for the
    Operator. * If you select the Automatic option, the Operator is updated without
    requiring manual confirmation. * If you select the Manual option, a notification
    opens when a new update is released in the update channel. The update must be
    manually approved by an administrator before installation can begin. 10. Click
    Install. [NOTE] ---- If you selected a Manual approval strategy, the upgrade status
    of the subscription remains Upgrading until you review and approve the install
    plan. After you click Approve on the Install Plan page, the subscription upgrade
    status changes to Up to date. If you selected an Automatic approval strategy,
    the upgrade status should resolve to Up to date without intervention. ---- Immediately
    after the Operator is installed, the dialog box on the OperatorHub page displays
    the Installed operator: ready for use message. From the dialog box, do one of
    the following actions: Click View Operator to open the Operator details page for
    the Red Hat Developer Hub Operator. Click View all installed operators to open
    the Installed Operators page. From the list of installed Operators, locate the
    Red Hat Developer Hub Operator name and details. Click Red Hat Developer Hub Operator
    to open the Operator details page for the Red Hat Developer Hub Operator. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:50:40.393978'
    uuid: c2ae2e7a-79d9-4b02-b692-e3b383874005
  response: Before installing the Red Hat Developer Hub Operator, you must have installed
    Red Hat OpenShift Container Platform 4.16 to 4.19. You need to be logged in as
    an administrator on the OpenShift Container Platform web console and have configured
    the appropriate roles and permissions within your project to create or access
    an application. Additionally, you must make sure that your system meets the minimum
    sizing requirements. The available containers are for AMD64 and Intel 64 (x86_64)
    CPU architectures.
  user_input: I'm looking at this guide for the Developer Hub Operator, and I'm trying
    to figure out what all the things is I need to have ready before I start, like
    what versions of Red Hat OpenShift Container Platform is supported and do I need
    to be logged in as some special user or something?
- context:
  - 'Deploying Red Hat Developer Hub on OpenShift Container Platform with the Operator
    As a developer, you can deploy a Red Hat Developer Hub instance on OpenShift Container
    Platform by using the Developer Catalog in the Red Hat OpenShift Container Platform
    web console. This deployment method uses the Red Hat Developer Hub Operator. You
    have set the baseUrl in your app config.yaml to match the external URL of your
    Developer Hub instance. Without it, frontend and backend services cannot communicate,
    and features might not work as expected. An OpenShift Container Platform administrator
    has installed the Red Hat Developer Hub Operator. You have provisioned your custom
    config maps and secrets in your <my rhdh project> project. You have authored your
    Backstage custom resource. 1. In the OpenShift Container Platform web console,
    select your <{my_product_namespace}> project, then click Add. 2. From the Developer
    Catalog panel, click Operator Backed. 3. In the Filter by keyword box, enter Developer
    Hub and click the Red Hat Developer Hub card. 4. Provision your custom configuration
    using the following template: ```yaml apiVersion: v1 kind: ConfigMap metadata:
    name: app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer
    Hub baseUrl: https://__&lt;my_developer_hub_domain&gt;__ backend: auth: externalAccess:
    - type: legacy options: subject: legacy-default-config secret: "${BACKEND_SECRET}"
    baseUrl: https://__&lt;my_developer_hub_domain&gt;__ cors: origin: https://__&lt;my_developer_hub_domain&gt;__
    ``` Use a config map named app-config-rhdh to provide your app-config.yaml file,
    and a Secret for service-to-service authentication (such as BACKEND_SECRET). To
    create and apply these configuration resources, follow the steps in Provisioning
    your custom Red Hat Developer Hub configuration for the full procedure. [NOTE]
    ---- The app-config-rhdh config map must include your customized app-config.yaml
    file. This config map is mounted into the Developer Hub container at runtime.
    ---- 5. Create a secret named my-rhdh-secrets and add a key named BACKEND_SECRET
    with a Base64-encoded string as value, as shown in the following example: ```yaml
    apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets stringData: # TODO:
    Add the necessary auth secrets for service-to-service auth setup BACKEND_SECRET:
    "xxx" # Replace with your Base64-encoded secret ``` [NOTE] ---- Ensure that your
    secret includes BACKEND_SECRET, used for service-to-service authentication. For
    structure and provisioning steps, see Provisioning your custom Red Hat Developer
    Hub configuration. ---- 6. Click Create. 7. Add your Backstage custom resource
    content. 8. On the Create Backstage page, click Create. After the pods are ready,
    you can access the Red Hat Developer Hub platform by opening the URL. 1. Confirm
    that the pods are ready by clicking the pod in the Topology view and confirming
    the Status in the Details panel. The pod status is Active when the pod is ready.
    2. From the Topology view, click the Open URL icon on the Developer Hub pod. ![operator
    install 1] OpenShift Container Platform Building applications overview # Installing
    Red Hat Developer Hub on OpenShift Container Platform with the Helm chart You
    can install Red Hat Developer Hub on OpenShift Container Platform by using the
    Helm chart with one of the following methods: The OpenShift Container Platform
    console The Helm CLI ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:50:50.839690'
    uuid: 9709317d-fa6d-467a-b582-11c340acebda
  response: To provide your app-config.yaml file, you use a config map named app-config-rhdh.
    This config map must include your customized app-config.yaml file and is mounted
    into the Developer Hub container at runtime.
  user_input: How is the app-config.yaml file provided when deploying Red Hat Developer
    Hub?
- context:
  - 'Deploying Red Hat Developer Hub on OpenShift Container Platform with the Operator
    As a developer, you can deploy a Red Hat Developer Hub instance on OpenShift Container
    Platform by using the Developer Catalog in the Red Hat OpenShift Container Platform
    web console. This deployment method uses the Red Hat Developer Hub Operator. You
    have set the baseUrl in your app config.yaml to match the external URL of your
    Developer Hub instance. Without it, frontend and backend services cannot communicate,
    and features might not work as expected. An OpenShift Container Platform administrator
    has installed the Red Hat Developer Hub Operator. You have provisioned your custom
    config maps and secrets in your <my rhdh project> project. You have authored your
    Backstage custom resource. 1. In the OpenShift Container Platform web console,
    select your <{my_product_namespace}> project, then click Add. 2. From the Developer
    Catalog panel, click Operator Backed. 3. In the Filter by keyword box, enter Developer
    Hub and click the Red Hat Developer Hub card. 4. Provision your custom configuration
    using the following template: ```yaml apiVersion: v1 kind: ConfigMap metadata:
    name: app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer
    Hub baseUrl: https://__&lt;my_developer_hub_domain&gt;__ backend: auth: externalAccess:
    - type: legacy options: subject: legacy-default-config secret: "${BACKEND_SECRET}"
    baseUrl: https://__&lt;my_developer_hub_domain&gt;__ cors: origin: https://__&lt;my_developer_hub_domain&gt;__
    ``` Use a config map named app-config-rhdh to provide your app-config.yaml file,
    and a Secret for service-to-service authentication (such as BACKEND_SECRET). To
    create and apply these configuration resources, follow the steps in Provisioning
    your custom Red Hat Developer Hub configuration for the full procedure. [NOTE]
    ---- The app-config-rhdh config map must include your customized app-config.yaml
    file. This config map is mounted into the Developer Hub container at runtime.
    ---- 5. Create a secret named my-rhdh-secrets and add a key named BACKEND_SECRET
    with a Base64-encoded string as value, as shown in the following example: ```yaml
    apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets stringData: # TODO:
    Add the necessary auth secrets for service-to-service auth setup BACKEND_SECRET:
    "xxx" # Replace with your Base64-encoded secret ``` [NOTE] ---- Ensure that your
    secret includes BACKEND_SECRET, used for service-to-service authentication. For
    structure and provisioning steps, see Provisioning your custom Red Hat Developer
    Hub configuration. ---- 6. Click Create. 7. Add your Backstage custom resource
    content. 8. On the Create Backstage page, click Create. After the pods are ready,
    you can access the Red Hat Developer Hub platform by opening the URL. 1. Confirm
    that the pods are ready by clicking the pod in the Topology view and confirming
    the Status in the Details panel. The pod status is Active when the pod is ready.
    2. From the Topology view, click the Open URL icon on the Developer Hub pod. ![operator
    install 1] OpenShift Container Platform Building applications overview # Installing
    Red Hat Developer Hub on OpenShift Container Platform with the Helm chart You
    can install Red Hat Developer Hub on OpenShift Container Platform by using the
    Helm chart with one of the following methods: The OpenShift Container Platform
    console The Helm CLI ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:51:01.158282'
    uuid: a701735b-bd99-4ab2-af32-21f5318e25a7
  response: 'When deploying Red Hat Developer Hub on OpenShift Container Platform
    with the Operator, a `ConfigMap` named `app-config-rhdh` is used to provide your
    customized `app-config.yaml` file. This `ConfigMap` must be provisioned in your
    project and is mounted into the Developer Hub container at runtime. The provided
    template for this configuration resource specifies `apiVersion: v1`, `kind: ConfigMap`,
    and `metadata: { name: app-config-rhdh }`. The `data` field within the `ConfigMap`
    contains the `"app-config.yaml"` file, which includes settings for `app.title`,
    `app.baseUrl`, and `backend` configurations such as `cors.origin` and the `baseUrl`
    for the backend service.'
  user_input: From a platform engineering perspective focused on standardizing deployment
    processes, could you elaborate on the specific role and required configuration
    of the `ConfigMap` named `app-config-rhdh` when deploying a Red Hat Developer
    Hub instance on OpenShift Container Platform using the Operator?
- context:
  - 'Deploying Red Hat Developer Hub on OpenShift Container Platform with the Operator
    As a developer, you can deploy a Red Hat Developer Hub instance on OpenShift Container
    Platform by using the Developer Catalog in the Red Hat OpenShift Container Platform
    web console. This deployment method uses the Red Hat Developer Hub Operator. You
    have set the baseUrl in your app config.yaml to match the external URL of your
    Developer Hub instance. Without it, frontend and backend services cannot communicate,
    and features might not work as expected. An OpenShift Container Platform administrator
    has installed the Red Hat Developer Hub Operator. You have provisioned your custom
    config maps and secrets in your <my rhdh project> project. You have authored your
    Backstage custom resource. 1. In the OpenShift Container Platform web console,
    select your <{my_product_namespace}> project, then click Add. 2. From the Developer
    Catalog panel, click Operator Backed. 3. In the Filter by keyword box, enter Developer
    Hub and click the Red Hat Developer Hub card. 4. Provision your custom configuration
    using the following template: ```yaml apiVersion: v1 kind: ConfigMap metadata:
    name: app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer
    Hub baseUrl: https://__&lt;my_developer_hub_domain&gt;__ backend: auth: externalAccess:
    - type: legacy options: subject: legacy-default-config secret: "${BACKEND_SECRET}"
    baseUrl: https://__&lt;my_developer_hub_domain&gt;__ cors: origin: https://__&lt;my_developer_hub_domain&gt;__
    ``` Use a config map named app-config-rhdh to provide your app-config.yaml file,
    and a Secret for service-to-service authentication (such as BACKEND_SECRET). To
    create and apply these configuration resources, follow the steps in Provisioning
    your custom Red Hat Developer Hub configuration for the full procedure. [NOTE]
    ---- The app-config-rhdh config map must include your customized app-config.yaml
    file. This config map is mounted into the Developer Hub container at runtime.
    ---- 5. Create a secret named my-rhdh-secrets and add a key named BACKEND_SECRET
    with a Base64-encoded string as value, as shown in the following example: ```yaml
    apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets stringData: # TODO:
    Add the necessary auth secrets for service-to-service auth setup BACKEND_SECRET:
    "xxx" # Replace with your Base64-encoded secret ``` [NOTE] ---- Ensure that your
    secret includes BACKEND_SECRET, used for service-to-service authentication. For
    structure and provisioning steps, see Provisioning your custom Red Hat Developer
    Hub configuration. ---- 6. Click Create. 7. Add your Backstage custom resource
    content. 8. On the Create Backstage page, click Create. After the pods are ready,
    you can access the Red Hat Developer Hub platform by opening the URL. 1. Confirm
    that the pods are ready by clicking the pod in the Topology view and confirming
    the Status in the Details panel. The pod status is Active when the pod is ready.
    2. From the Topology view, click the Open URL icon on the Developer Hub pod. ![operator
    install 1] OpenShift Container Platform Building applications overview # Installing
    Red Hat Developer Hub on OpenShift Container Platform with the Helm chart You
    can install Red Hat Developer Hub on OpenShift Container Platform by using the
    Helm chart with one of the following methods: The OpenShift Container Platform
    console The Helm CLI ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:51:11.119872'
    uuid: d16f41c3-af31-424c-9d4b-f6a429f740bc
  response: To deploy a Red Hat Developer Hub instance on OpenShift Container Platform,
    you can use the Developer Catalog in the web console. First, select your project
    and click Add. From the Developer Catalog panel, click Operator Backed, then use
    the filter to find and click the Red Hat Developer Hub card. You must provision
    a custom configuration using a config map named app-config-rhdh for your app-config.yaml
    file and create a secret named my-rhdh-secrets with a BACKEND_SECRET key for service-to-service
    authentication. After clicking Create, add your Backstage custom resource content
    and click Create on the Create Backstage page. You can access the platform via
    its URL once the pods are ready, which can be confirmed in the Topology view.
  user_input: What is the procedure for deploying a Red Hat Developer Hub instance
    on OpenShift Container Platform using the Developer Catalog in the web console?
- context:
  - 'Deploying Developer Hub from the OpenShift Container Platform web console with
    the Helm Chart You can use a Helm chart to install Developer Hub on the Red Hat
    OpenShift Container Platform web console. Helm is a package manager on OpenShift
    Container Platform that provides the following features: Applies regular application
    updates using custom hooks Manages the installation of complex applications Provides
    charts that you can host on public and private servers Supports rolling back to
    previous application versions The Red Hat Developer Hub Helm chart is available
    in the Helm catalog on OpenShift Dedicated and OpenShift Container Platform. You
    are logged in to your OpenShift Container Platform account. A user with the OpenShift
    Container Platform admin role has configured the appropriate roles and permissions
    within your project to create an application. For more information about OpenShift
    Container Platform roles, see Using RBAC to define and apply permissions. You
    have created a project in OpenShift Container Platform. For more information about
    creating a project in OpenShift Container Platform, see Red Hat OpenShift Container
    Platform documentation. Make sure that your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective
    on the Developer Hub web console, click +Add. 2. From the Developer Catalog panel,
    click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub and click
    the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub page, click
    Create. 5. From your cluster, copy the OpenShift Container Platform router host
    (for example: apps.<clusterName>.com). 6. Select the radio button to configure
    the Developer Hub instance with either the form view or YAML view. The Form view
    is selected by default. * Using Form view 1. To configure the instance with the
    Form view, go to Root Schema -> global -> Enable service authentication within
    Backstage instance and paste your OpenShift Container Platform router host into
    the field on the form. * Using YAML view 1. To configure the instance with the
    YAML view, paste your OpenShift Container Platform router hostname in the global.clusterRouterBase
    parameter value as shown in the following example: ```yaml global: auth: backend:
    enabled: true clusterRouterBase: apps.<clusterName>.com ``` 7. Edit the other
    values if needed. [NOTE] ---- The information about the host is copied and can
    be accessed by the Developer Hub backend. When an OpenShift Container Platform
    route is generated automatically, the host value for the route is inferred and
    the same host information is sent to the Developer Hub. Also, if the Developer
    Hub is present on a custom domain by setting the host manually using values, the
    custom host takes precedence. ---- 8. Click Create and wait for the database and
    Developer Hub to start. 9. Click the Open URL icon to start using the Developer
    Hub platform. ![rhdh helm install] [NOTE] ---- Your developer-hub pod might be
    in a CrashLoopBackOff state if the Developer Hub container cannot access the configuration
    files. This error is indicated by the following log: ```log Loaded config from
    app-config-from-configmap.yaml, env ... 2023-07-24T19:44:46.223Z auth info Configuring
    "database" as KeyStore provider type=plugin Backend failed to start up Error:
    Missing required config value at ''backend.database.client'' ``` To resolve the
    error, verify the configuration files. ---- ## Deploying Developer Hub on OpenShift
    Container Platform with the Helm CLI You can use the Helm CLI to install Red Hat
    Developer Hub on Red Hat OpenShift Container Platform. You have installed the
    OpenShift CLI (oc) on your workstation. You are logged in to your OpenShift Container
    Platform account. A user with the OpenShift Container Platform admin role has
    configured the appropriate roles and permissions within your project to create
    an application. For more information about OpenShift Container Platform roles,
    see Using RBAC to define and apply permissions. You have created a project in
    OpenShift Container Platform. For more information about creating a project in
    OpenShift Container Platform, see Red Hat OpenShift Container Platform documentation.
    You have installed the Helm CLI tool. 1. Create and activate the <my-rhdh-project>
    OpenShift Container Platform project: ``` NAMESPACE=<rhdh> oc new-project ${NAMESPACE}
    || oc project ${NAMESPACE} ``` 2. Install the Red Hat Developer Hub Helm chart:
    ``` helm upgrade redhat developer hub i https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` 3. Configure your
    Developer Hub Helm chart instance with the Developer Hub database password and
    router base URL values from your OpenShift Container Platform cluster: ``` PASSWORD=$(oc
    get secret redhat developer hub postgresql o jsonpath="{.data.password}" | base64
    d) CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/^[^.] \.//'') helm upgrade redhat developer hub i "https://github.com/openshift
    helm charts/charts/releases/download/redhat redhat developer hub 1.8.0/redhat
    developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 4. Display the running Developer
    Hub instance URL: ``` echo "https://redhat developer hub $NAMESPACE.$CLUSTER_ROUTER_BASE"
    ``` Open the running Developer Hub instance URL in your browser to use Developer
    Hub. Installing Helm'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:51:17.566988'
    uuid: b8f89c9d-8b62-4247-bae3-845bfdab5d46
  response: You can deploy Developer Hub on Red Hat OpenShift Container Platform using
    a Helm chart from the web console, or you can use the Helm CLI to install it.
  user_input: how i deploy developer hub on openshift?
- context:
  - 'Deploying Developer Hub from the OpenShift Container Platform web console with
    the Helm Chart You can use a Helm chart to install Developer Hub on the Red Hat
    OpenShift Container Platform web console. Helm is a package manager on OpenShift
    Container Platform that provides the following features: Applies regular application
    updates using custom hooks Manages the installation of complex applications Provides
    charts that you can host on public and private servers Supports rolling back to
    previous application versions The Red Hat Developer Hub Helm chart is available
    in the Helm catalog on OpenShift Dedicated and OpenShift Container Platform. You
    are logged in to your OpenShift Container Platform account. A user with the OpenShift
    Container Platform admin role has configured the appropriate roles and permissions
    within your project to create an application. For more information about OpenShift
    Container Platform roles, see Using RBAC to define and apply permissions. You
    have created a project in OpenShift Container Platform. For more information about
    creating a project in OpenShift Container Platform, see Red Hat OpenShift Container
    Platform documentation. Make sure that your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective
    on the Developer Hub web console, click +Add. 2. From the Developer Catalog panel,
    click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub and click
    the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub page, click
    Create. 5. From your cluster, copy the OpenShift Container Platform router host
    (for example: apps.<clusterName>.com). 6. Select the radio button to configure
    the Developer Hub instance with either the form view or YAML view. The Form view
    is selected by default. * Using Form view 1. To configure the instance with the
    Form view, go to Root Schema -> global -> Enable service authentication within
    Backstage instance and paste your OpenShift Container Platform router host into
    the field on the form. * Using YAML view 1. To configure the instance with the
    YAML view, paste your OpenShift Container Platform router hostname in the global.clusterRouterBase
    parameter value as shown in the following example: ```yaml global: auth: backend:
    enabled: true clusterRouterBase: apps.<clusterName>.com ``` 7. Edit the other
    values if needed. [NOTE] ---- The information about the host is copied and can
    be accessed by the Developer Hub backend. When an OpenShift Container Platform
    route is generated automatically, the host value for the route is inferred and
    the same host information is sent to the Developer Hub. Also, if the Developer
    Hub is present on a custom domain by setting the host manually using values, the
    custom host takes precedence. ---- 8. Click Create and wait for the database and
    Developer Hub to start. 9. Click the Open URL icon to start using the Developer
    Hub platform. ![rhdh helm install] [NOTE] ---- Your developer-hub pod might be
    in a CrashLoopBackOff state if the Developer Hub container cannot access the configuration
    files. This error is indicated by the following log: ```log Loaded config from
    app-config-from-configmap.yaml, env ... 2023-07-24T19:44:46.223Z auth info Configuring
    "database" as KeyStore provider type=plugin Backend failed to start up Error:
    Missing required config value at ''backend.database.client'' ``` To resolve the
    error, verify the configuration files. ---- ## Deploying Developer Hub on OpenShift
    Container Platform with the Helm CLI You can use the Helm CLI to install Red Hat
    Developer Hub on Red Hat OpenShift Container Platform. You have installed the
    OpenShift CLI (oc) on your workstation. You are logged in to your OpenShift Container
    Platform account. A user with the OpenShift Container Platform admin role has
    configured the appropriate roles and permissions within your project to create
    an application. For more information about OpenShift Container Platform roles,
    see Using RBAC to define and apply permissions. You have created a project in
    OpenShift Container Platform. For more information about creating a project in
    OpenShift Container Platform, see Red Hat OpenShift Container Platform documentation.
    You have installed the Helm CLI tool. 1. Create and activate the <my-rhdh-project>
    OpenShift Container Platform project: ``` NAMESPACE=<rhdh> oc new-project ${NAMESPACE}
    || oc project ${NAMESPACE} ``` 2. Install the Red Hat Developer Hub Helm chart:
    ``` helm upgrade redhat developer hub i https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` 3. Configure your
    Developer Hub Helm chart instance with the Developer Hub database password and
    router base URL values from your OpenShift Container Platform cluster: ``` PASSWORD=$(oc
    get secret redhat developer hub postgresql o jsonpath="{.data.password}" | base64
    d) CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/^[^.] \.//'') helm upgrade redhat developer hub i "https://github.com/openshift
    helm charts/charts/releases/download/redhat redhat developer hub 1.8.0/redhat
    developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 4. Display the running Developer
    Hub instance URL: ``` echo "https://redhat developer hub $NAMESPACE.$CLUSTER_ROUTER_BASE"
    ``` Open the running Developer Hub instance URL in your browser to use Developer
    Hub. Installing Helm'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:51:26.578696'
    uuid: 9bdbfa58-c2e7-4acd-9443-cfcc10c48b35
  response: 'To deploy Developer Hub from the OpenShift Container Platform web console
    with a Helm Chart, you must first meet several prerequisites: you must be logged
    into your OpenShift Container Platform account, an admin must have configured
    the appropriate roles and permissions in your project, you must have created a
    project, and your system must meet minimum sizing requirements. The deployment
    process is as follows: 1. From the Developer perspective, click "+Add". 2. In
    the Developer Catalog panel, select "Helm Chart". 3. Search for "Developer Hub"
    and click the "Red Hat Developer Hub" card. 4. Click "Create". 5. Copy your OpenShift
    Container Platform router host. 6. Choose to configure the instance using either
    the Form view or YAML view. For the Form view, paste the router host under Root
    Schema -> global -> Enable service authentication within Backstage instance. For
    the YAML view, paste the router hostname in the `global.clusterRouterBase` parameter
    value. 7. Edit other values as needed. 8. Click "Create" and wait for the database
    and Developer Hub to start. 9. Finally, click the "Open URL" icon to begin using
    the platform.'
  user_input: What are the detailed steps and prerequisites for deploying Red Hat
    Developer Hub on OpenShift Container Platform using the web console and a Helm
    chart?
- context:
  - 'Deploying Developer Hub from the OpenShift Container Platform web console with
    the Helm Chart You can use a Helm chart to install Developer Hub on the Red Hat
    OpenShift Container Platform web console. Helm is a package manager on OpenShift
    Container Platform that provides the following features: Applies regular application
    updates using custom hooks Manages the installation of complex applications Provides
    charts that you can host on public and private servers Supports rolling back to
    previous application versions The Red Hat Developer Hub Helm chart is available
    in the Helm catalog on OpenShift Dedicated and OpenShift Container Platform. You
    are logged in to your OpenShift Container Platform account. A user with the OpenShift
    Container Platform admin role has configured the appropriate roles and permissions
    within your project to create an application. For more information about OpenShift
    Container Platform roles, see Using RBAC to define and apply permissions. You
    have created a project in OpenShift Container Platform. For more information about
    creating a project in OpenShift Container Platform, see Red Hat OpenShift Container
    Platform documentation. Make sure that your system meets the minimum sizing requirements.
    See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective
    on the Developer Hub web console, click +Add. 2. From the Developer Catalog panel,
    click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub and click
    the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub page, click
    Create. 5. From your cluster, copy the OpenShift Container Platform router host
    (for example: apps.<clusterName>.com). 6. Select the radio button to configure
    the Developer Hub instance with either the form view or YAML view. The Form view
    is selected by default. * Using Form view 1. To configure the instance with the
    Form view, go to Root Schema -> global -> Enable service authentication within
    Backstage instance and paste your OpenShift Container Platform router host into
    the field on the form. * Using YAML view 1. To configure the instance with the
    YAML view, paste your OpenShift Container Platform router hostname in the global.clusterRouterBase
    parameter value as shown in the following example: ```yaml global: auth: backend:
    enabled: true clusterRouterBase: apps.<clusterName>.com ``` 7. Edit the other
    values if needed. [NOTE] ---- The information about the host is copied and can
    be accessed by the Developer Hub backend. When an OpenShift Container Platform
    route is generated automatically, the host value for the route is inferred and
    the same host information is sent to the Developer Hub. Also, if the Developer
    Hub is present on a custom domain by setting the host manually using values, the
    custom host takes precedence. ---- 8. Click Create and wait for the database and
    Developer Hub to start. 9. Click the Open URL icon to start using the Developer
    Hub platform. ![rhdh helm install] [NOTE] ---- Your developer-hub pod might be
    in a CrashLoopBackOff state if the Developer Hub container cannot access the configuration
    files. This error is indicated by the following log: ```log Loaded config from
    app-config-from-configmap.yaml, env ... 2023-07-24T19:44:46.223Z auth info Configuring
    "database" as KeyStore provider type=plugin Backend failed to start up Error:
    Missing required config value at ''backend.database.client'' ``` To resolve the
    error, verify the configuration files. ---- ## Deploying Developer Hub on OpenShift
    Container Platform with the Helm CLI You can use the Helm CLI to install Red Hat
    Developer Hub on Red Hat OpenShift Container Platform. You have installed the
    OpenShift CLI (oc) on your workstation. You are logged in to your OpenShift Container
    Platform account. A user with the OpenShift Container Platform admin role has
    configured the appropriate roles and permissions within your project to create
    an application. For more information about OpenShift Container Platform roles,
    see Using RBAC to define and apply permissions. You have created a project in
    OpenShift Container Platform. For more information about creating a project in
    OpenShift Container Platform, see Red Hat OpenShift Container Platform documentation.
    You have installed the Helm CLI tool. 1. Create and activate the <my-rhdh-project>
    OpenShift Container Platform project: ``` NAMESPACE=<rhdh> oc new-project ${NAMESPACE}
    || oc project ${NAMESPACE} ``` 2. Install the Red Hat Developer Hub Helm chart:
    ``` helm upgrade redhat developer hub i https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` 3. Configure your
    Developer Hub Helm chart instance with the Developer Hub database password and
    router base URL values from your OpenShift Container Platform cluster: ``` PASSWORD=$(oc
    get secret redhat developer hub postgresql o jsonpath="{.data.password}" | base64
    d) CLUSTER_ROUTER_BASE=$(oc get route console n openshift console o=jsonpath=''{.spec.host}''
    | sed ''s/^[^.] \.//'') helm upgrade redhat developer hub i "https://github.com/openshift
    helm charts/charts/releases/download/redhat redhat developer hub 1.8.0/redhat
    developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 4. Display the running Developer
    Hub instance URL: ``` echo "https://redhat developer hub $NAMESPACE.$CLUSTER_ROUTER_BASE"
    ``` Open the running Developer Hub instance URL in your browser to use Developer
    Hub. Installing Helm'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:51:34.502419'
    uuid: 27b9a839-5042-47fd-91de-434142d7ff32
  response: 'To deploy Red Hat Developer Hub on OpenShift Container Platform with
    the Helm CLI, you must first meet several prerequisites: you have installed the
    OpenShift CLI (oc) on your workstation, you are logged in to your OpenShift Container
    Platform account, a user with the admin role has configured the appropriate permissions,
    you have created a project in OpenShift Container Platform, and you have installed
    the Helm CLI tool. The procedure is as follows: 1. Create and activate the OpenShift
    Container Platform project with the command: `NAMESPACE=<rhdh> oc new-project
    ${NAMESPACE} || oc project ${NAMESPACE}`. 2. Install the Red Hat Developer Hub
    Helm chart using: `helm upgrade redhat developer hub i https://github.com/openshift
    helm charts/charts/releases/download/redhat redhat developer hub 1.8.0/redhat
    developer hub 1.8.0.tgz`. 3. Configure the instance with the database password
    and router base URL from your cluster by running: `PASSWORD=$(oc get secret redhat
    developer hub postgresql o jsonpath=\"{.data.password}\" | base64 d) CLUSTER_ROUTER_BASE=$(oc
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/^[^.]
    \\.//'') helm upgrade redhat developer hub i \"https://github.com/openshift helm
    charts/charts/releases/download/redhat redhat developer hub 1.8.0/redhat developer
    hub 1.8.0.tgz\" \\ set global.clusterRouterBase=\"$CLUSTER_ROUTER_BASE\" \\ set
    global.postgresql.auth.password=\"$PASSWORD\"`. 4. Finally, display the running
    Developer Hub instance URL with the command: `echo \"https://redhat developer
    hub $NAMESPACE.$CLUSTER_ROUTER_BASE\"`. You can then open this URL in your browser
    to use Developer Hub.'
  user_input: As a Platform Engineer, what are the specific prerequisites and the
    complete, step-by-step procedure for deploying Red Hat Developer Hub on OpenShift
    Container Platform using the Helm CLI, including the necessary commands to configure
    and display the instance URL?
- context:
  - '# Adoption Insights in Red Hat Developer Hub # Adoption Insights The Red Hat
    Developer Hub instance includes the Adoption Insights plugin preinstalled and
    enabled by default. As organizations generate an increasing number of data events,
    there is a growing need for detailed insights into the adoption and engagement
    metrics of the internal developer portal. These insights help platform engineers
    make data-driven decisions to improve its performance, usability, and translate
    them into actionable insights. You can use Adoption Insights in Red Hat Developer
    Hub to visualize key metrics and trends to get information about the usage of
    Developer Hub in your organization. The information provided by Adoption Insights
    in Developer Hub helps you pinpoint areas of improvement, highlights popular features,
    and evaluates progress toward adoption goals. You can also monitor user growth
    against licensed users and identify trends over time. The Adoption Insights dashboard
    in Developer Hub includes the following cards: Active users Total number of users
    Top catalog entities Top 3 templates Top 3 techdocs Top 3 plugins Portal searches
    ![adoption insights] ## Configuring the Adoption Insights plugin in Red Hat Developer
    Hub The Adoption Insights plugin is preinstalled and enabled on a Developer Hub
    instance by default. You can disable or enable the Adoption Insights plugin and
    change other parameters, by configuring the app-config ConfigMap, which is created
    by the Red Hat Developer Hub Helm chart or Operator. [IMPORTANT] ---- If you used
    the Developer Preview of the Adoption Insights plugin and configured the feature
    manually, you must remove those earlier configuration changes as they are no longer
    required. In your dynamic plugins ConfigMap, for example: dynamic-plugins-rhdh.yaml,
    update the package-disabled value of the plugin to false as shown in the following
    example: ```yaml plugins: package: ./dynamic plugins/dist/backstage community
    plugin analytics provider segment disabled: false ``` ---- ## Customizing the
    Adoption Insights plugin in Red Hat Developer Hub You can customize the Adoption
    Insights plugin to suit your needs by disabling or re-enabling it, and adjusting
    other settings as needed. To customize maxBufferSize, flushInterval, debug, and
    licensedUsers in the Adoption Insights plugin, in your Red Hat Developer Hub app
    config.yaml file, update the relevant settings as shown in the following code:
    ```terminal app: analytics: adoptionInsights: maxBufferSize: _<maximum_buffer_size>_
    1 flushInterval: _<flush_interval>_ 2 debug: _<debug_value>_ 3 licensedUsers:
    _<licensed_users>_ 4 ``` (Optional) Specifies the maximum buffer size for event
    batching. The default value is 20. (Optional) Specifies the flush interval in
    milliseconds for event batching. The default value is 5000ms. (Optional) The default
    value is false. (Optional) Specifies the maximum number of licensed users who
    can access the RHDH instance. The default value is 100. * To disable the Adoption
    Insights plugin, in your dynamic plugins ConfigMap, for example dynamic-plugins-rhdh.yaml
    file, update the package.disabled value of the plugin to true as shown in the
    following example: ```yaml package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin adoption insights disabled: true package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin adoption insights backend dynamic disabled:
    true package: ./dynamic plugins/dist/red hat developer hub backstage plugin analytics
    module adoption insights dynamic disabled: true ``` Optional: Configure the required
    RBAC permission for the users who are not administrators as shown in the following
    example: ```yaml p, role:default/_<your_team>_, adoption insights.events.read,
    read, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` See
    Permission policies in Red Hat Developer Hub. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:51:43.475578'
    uuid: 6c055d34-f54f-42ca-ad15-84ea18f334da
  response: You can disable or enable the Adoption Insights plugin and change other
    parameters by configuring the app-config ConfigMap, which is created by the Red
    Hat Developer Hub Helm chart or Operator.
  user_input: Me and my team, we is using the Helm chart to deploy the Red Hat Developer
    Hub, and we need to know how we can change the settings for the Adoption Insights
    plugin, where is the thing that the Helm chart create that let us do the configuration?
- context:
  - '# Adoption Insights in Red Hat Developer Hub # Adoption Insights The Red Hat
    Developer Hub instance includes the Adoption Insights plugin preinstalled and
    enabled by default. As organizations generate an increasing number of data events,
    there is a growing need for detailed insights into the adoption and engagement
    metrics of the internal developer portal. These insights help platform engineers
    make data-driven decisions to improve its performance, usability, and translate
    them into actionable insights. You can use Adoption Insights in Red Hat Developer
    Hub to visualize key metrics and trends to get information about the usage of
    Developer Hub in your organization. The information provided by Adoption Insights
    in Developer Hub helps you pinpoint areas of improvement, highlights popular features,
    and evaluates progress toward adoption goals. You can also monitor user growth
    against licensed users and identify trends over time. The Adoption Insights dashboard
    in Developer Hub includes the following cards: Active users Total number of users
    Top catalog entities Top 3 templates Top 3 techdocs Top 3 plugins Portal searches
    ![adoption insights] ## Configuring the Adoption Insights plugin in Red Hat Developer
    Hub The Adoption Insights plugin is preinstalled and enabled on a Developer Hub
    instance by default. You can disable or enable the Adoption Insights plugin and
    change other parameters, by configuring the app-config ConfigMap, which is created
    by the Red Hat Developer Hub Helm chart or Operator. [IMPORTANT] ---- If you used
    the Developer Preview of the Adoption Insights plugin and configured the feature
    manually, you must remove those earlier configuration changes as they are no longer
    required. In your dynamic plugins ConfigMap, for example: dynamic-plugins-rhdh.yaml,
    update the package-disabled value of the plugin to false as shown in the following
    example: ```yaml plugins: package: ./dynamic plugins/dist/backstage community
    plugin analytics provider segment disabled: false ``` ---- ## Customizing the
    Adoption Insights plugin in Red Hat Developer Hub You can customize the Adoption
    Insights plugin to suit your needs by disabling or re-enabling it, and adjusting
    other settings as needed. To customize maxBufferSize, flushInterval, debug, and
    licensedUsers in the Adoption Insights plugin, in your Red Hat Developer Hub app
    config.yaml file, update the relevant settings as shown in the following code:
    ```terminal app: analytics: adoptionInsights: maxBufferSize: _<maximum_buffer_size>_
    1 flushInterval: _<flush_interval>_ 2 debug: _<debug_value>_ 3 licensedUsers:
    _<licensed_users>_ 4 ``` (Optional) Specifies the maximum buffer size for event
    batching. The default value is 20. (Optional) Specifies the flush interval in
    milliseconds for event batching. The default value is 5000ms. (Optional) The default
    value is false. (Optional) Specifies the maximum number of licensed users who
    can access the RHDH instance. The default value is 100. * To disable the Adoption
    Insights plugin, in your dynamic plugins ConfigMap, for example dynamic-plugins-rhdh.yaml
    file, update the package.disabled value of the plugin to true as shown in the
    following example: ```yaml package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin adoption insights disabled: true package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin adoption insights backend dynamic disabled:
    true package: ./dynamic plugins/dist/red hat developer hub backstage plugin analytics
    module adoption insights dynamic disabled: true ``` Optional: Configure the required
    RBAC permission for the users who are not administrators as shown in the following
    example: ```yaml p, role:default/_<your_team>_, adoption insights.events.read,
    read, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` See
    Permission policies in Red Hat Developer Hub. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:51:49.955556'
    uuid: 971e6da0-262f-4ee5-b8a2-bf0ff45a33ca
  response: The Adoption Insights plugin in Red Hat Developer Hub provides detailed
    insights into the adoption and engagement metrics of the internal developer portal,
    helping platform engineers make data-driven decisions to improve its performance
    and usability. It allows you to visualize key metrics and trends to get information
    about the usage of Developer Hub in your organization, which helps pinpoint areas
    of improvement, highlight popular features, and evaluate progress toward adoption
    goals.
  user_input: What is the purpose of the Adoption Insights plugin in Red Hat Developer
    Hub?
- context:
  - '# Adoption Insights in Red Hat Developer Hub # Adoption Insights The Red Hat
    Developer Hub instance includes the Adoption Insights plugin preinstalled and
    enabled by default. As organizations generate an increasing number of data events,
    there is a growing need for detailed insights into the adoption and engagement
    metrics of the internal developer portal. These insights help platform engineers
    make data-driven decisions to improve its performance, usability, and translate
    them into actionable insights. You can use Adoption Insights in Red Hat Developer
    Hub to visualize key metrics and trends to get information about the usage of
    Developer Hub in your organization. The information provided by Adoption Insights
    in Developer Hub helps you pinpoint areas of improvement, highlights popular features,
    and evaluates progress toward adoption goals. You can also monitor user growth
    against licensed users and identify trends over time. The Adoption Insights dashboard
    in Developer Hub includes the following cards: Active users Total number of users
    Top catalog entities Top 3 templates Top 3 techdocs Top 3 plugins Portal searches
    ![adoption insights] ## Configuring the Adoption Insights plugin in Red Hat Developer
    Hub The Adoption Insights plugin is preinstalled and enabled on a Developer Hub
    instance by default. You can disable or enable the Adoption Insights plugin and
    change other parameters, by configuring the app-config ConfigMap, which is created
    by the Red Hat Developer Hub Helm chart or Operator. [IMPORTANT] ---- If you used
    the Developer Preview of the Adoption Insights plugin and configured the feature
    manually, you must remove those earlier configuration changes as they are no longer
    required. In your dynamic plugins ConfigMap, for example: dynamic-plugins-rhdh.yaml,
    update the package-disabled value of the plugin to false as shown in the following
    example: ```yaml plugins: package: ./dynamic plugins/dist/backstage community
    plugin analytics provider segment disabled: false ``` ---- ## Customizing the
    Adoption Insights plugin in Red Hat Developer Hub You can customize the Adoption
    Insights plugin to suit your needs by disabling or re-enabling it, and adjusting
    other settings as needed. To customize maxBufferSize, flushInterval, debug, and
    licensedUsers in the Adoption Insights plugin, in your Red Hat Developer Hub app
    config.yaml file, update the relevant settings as shown in the following code:
    ```terminal app: analytics: adoptionInsights: maxBufferSize: _<maximum_buffer_size>_
    1 flushInterval: _<flush_interval>_ 2 debug: _<debug_value>_ 3 licensedUsers:
    _<licensed_users>_ 4 ``` (Optional) Specifies the maximum buffer size for event
    batching. The default value is 20. (Optional) Specifies the flush interval in
    milliseconds for event batching. The default value is 5000ms. (Optional) The default
    value is false. (Optional) Specifies the maximum number of licensed users who
    can access the RHDH instance. The default value is 100. * To disable the Adoption
    Insights plugin, in your dynamic plugins ConfigMap, for example dynamic-plugins-rhdh.yaml
    file, update the package.disabled value of the plugin to true as shown in the
    following example: ```yaml package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin adoption insights disabled: true package: ./dynamic plugins/dist/red
    hat developer hub backstage plugin adoption insights backend dynamic disabled:
    true package: ./dynamic plugins/dist/red hat developer hub backstage plugin analytics
    module adoption insights dynamic disabled: true ``` Optional: Configure the required
    RBAC permission for the users who are not administrators as shown in the following
    example: ```yaml p, role:default/_<your_team>_, adoption insights.events.read,
    read, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` See
    Permission policies in Red Hat Developer Hub. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:52:09.827800'
    uuid: 1e76a4ab-e496-46f3-ab79-01aaaef24e54
  response: You can manage the Adoption Insights plugin by configuring the app-config
    ConfigMap, which is created by the Red Hat Developer Hub Helm chart or Operator.
    This allows you to disable or enable the plugin and change other parameters. For
    example, to disable the plugin, you update the package.disabled value of the plugin
    to true in your dynamic plugins ConfigMap (e.g., dynamic-plugins-rhdh.yaml). If
    you previously used the Developer Preview of the plugin with manual configurations,
    you must remove those earlier changes from your dynamic plugins ConfigMap.
  user_input: How do I use the app-config ConfigMap to manage the Adoption Insights
    plugin in Red Hat Developer Hub?
- context:
  - 'Using Adoption Insights in Red Hat Developer Hub In the Developer Hub application,
    on the navigation menu, click Administration -> Adoption Insights. ### Setting
    the duration of data metrics You can set the data metrics duration using any of
    the time ranges, such as Today, Last week, Last month, Last 28 days (default),
    Last year, or Date range&#8230;&#8203;. 1. On the top of the screen, click the
    dropdown list to display the choices. 2. Select the duration choice for which
    you want to see the data metrics. ![date range] ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:52:19.224559'
    uuid: 18fbcffb-5ecb-4599-a6e6-cb1f3cb01b5d
  response: In the Developer Hub application, you can set the data metrics duration
    by first clicking on Administration -> Adoption Insights in the navigation menu.
    At the top of the screen, click the dropdown list to display time range choices
    such as Today, Last week, Last month, Last 28 days, Last year, or Date range.
    From there, you can select the duration for which you want to see the data metrics.
  user_input: how to set data metrics duration in Red Hat Developer Hub
- context:
  - 'Using Adoption Insights in Red Hat Developer Hub In the Developer Hub application,
    on the navigation menu, click Administration -> Adoption Insights. ### Setting
    the duration of data metrics You can set the data metrics duration using any of
    the time ranges, such as Today, Last week, Last month, Last 28 days (default),
    Last year, or Date range&#8230;&#8203;. 1. On the top of the screen, click the
    dropdown list to display the choices. 2. Select the duration choice for which
    you want to see the data metrics. ![date range] ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:52:28.164954'
    uuid: 70da8553-f877-4f0b-b130-ec43199728e9
  response: Within the Developer Hub application, you can access Adoption Insights
    by clicking on "Administration" in the navigation menu, followed by clicking on
    "Adoption Insights". To adjust the duration of the data metrics, click the dropdown
    list at the top of the screen and select a time range, such as Today, Last week,
    Last month, Last 28 days, Last year, or a specific Date range.
  user_input: From an Administration perspective, what is the procedure for accessing
    the Adoption Insights and adjusting the duration for its data metrics within the
    Red Hat Developer Hub?
- context:
  - 'Using Adoption Insights in Red Hat Developer Hub In the Developer Hub application,
    on the navigation menu, click Administration -> Adoption Insights. ### Setting
    the duration of data metrics You can set the data metrics duration using any of
    the time ranges, such as Today, Last week, Last month, Last 28 days (default),
    Last year, or Date range&#8230;&#8203;. 1. On the top of the screen, click the
    dropdown list to display the choices. 2. Select the duration choice for which
    you want to see the data metrics. ![date range] ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:52:50.479918'
    uuid: 82c7b763-2530-4039-9cd6-91f100bcbf3d
  response: In the Developer Hub application, on the navigation menu, you can click
    Administration to get to Adoption Insights.
  user_input: how do i find the adminstration menu?
- context:
  - 'Viewing the Adoption Insights card ### Viewing the active users The Active users
    card displays the total number of active users over a specified date and time
    period. You can export the user data in a .csv format. Returning users: Existing
    users who have logged into Developer Hub previously New users: New users who have
    registered and logged into Developer Hub for the first time ![active users] To
    view the list of active users in your Red Hat Developer Hub instance, go to Administration
    > Adoption Insights, see the Active users card. To view the exact number of users
    for a particular day, hover over the corresponding date in the Active users card.
    To export the user data in a .csv format, click the Export CSV link. ### Viewing
    the total number of users This card displays the total number of users that have
    license to use Red Hat Developer Hub. It also provides a comparison of the number
    of Logged-in users and Licensed users in numeric and percentage form. Logged in
    users: Total number of users, including licensed and unlicensed users, currently
    logged in to Developer Hub. Licensed users: Total number of licensed users logged
    in to Developer Hub. You can set the target for the number of licensed users in
    your Developer Hub app config.yaml file. To view the total number of users in
    your Developer Hub instance in numeric and percentage forms, go to Administration
    > Adoption Insights and see the Total number of users card. To view a percentage
    representation of the total number of logged in users among the total number of
    licensed users, hover over the tooltip in the Total number of users card. ###
    Viewing the top catalog entities This card lists the most viewed catalog entities
    (like components, APIs, and so on) and documentation entries, including usage
    statistics, in a table. Each item displays the following details: Name: Name of
    the catalog Kind: Type of the catalog Last used: The last time the catalog was
    used Views: The number of times the catalog was viewed To view the most commonly
    used catalog entities in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top catalog entities card. To know more about the displayed
    catalog entity, hover over the catalog entity name. ### Viewing the top 3 templates
    This card lists the three most commonly used templates in a table. You can click
    the down arrow next to 3 rows to view the full list of the commonly used templates.
    Name: Name of the template Mostly in use by: Type of user using this template
    most frequently Executions: Number of times this template was used To view the
    most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 templates card. To know more about the displayed
    template, hover over the template name. ### Viewing the top 3 techdocs This card
    lists the most viewed documentation entries, including the total views, in a table.
    Name: Title of the document Entity: Type of document Last used: The last time
    the document was viewed Views: Number of times the document was visited To view
    the most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 techdocs card. To know more about the displayed
    techdocs, hover over the name of the techdoc. ### Viewing the top 3 plugins This
    card lists the three most commonly used plugins in a table. You can click the
    down arrow next to 3 rows to view the full list of the commonly used plugins.
    Name: Name of the plugin Trend: Popularity of the plugin as a graph Views: Number
    of times this plugin was seen To view the most commonly used plugins and the plugin
    page visit trends in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top 3 plugins card. To know more about the displayed plugin,
    hover over the plugin name. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T15:52:57.716327'
    uuid: 6eceec6c-7649-4482-9489-3d7aa8de09eb
  response: The "Total number of users" card displays the total number of users that
    have a license to use Red Hat Developer Hub. It also provides a comparison between
    the number of "Logged-in users" and "Licensed users" in both numeric and percentage
    form. "Logged in users" are defined as the total number of users, including licensed
    and unlicensed users, currently logged in to Developer Hub, while "Licensed users"
    are the total number of licensed users logged in to Developer Hub.
  user_input: What specific information does the "Total number of users" card display
    to provide insights into user licensing and login activity?
- context:
  - 'Viewing the Adoption Insights card ### Viewing the active users The Active users
    card displays the total number of active users over a specified date and time
    period. You can export the user data in a .csv format. Returning users: Existing
    users who have logged into Developer Hub previously New users: New users who have
    registered and logged into Developer Hub for the first time ![active users] To
    view the list of active users in your Red Hat Developer Hub instance, go to Administration
    > Adoption Insights, see the Active users card. To view the exact number of users
    for a particular day, hover over the corresponding date in the Active users card.
    To export the user data in a .csv format, click the Export CSV link. ### Viewing
    the total number of users This card displays the total number of users that have
    license to use Red Hat Developer Hub. It also provides a comparison of the number
    of Logged-in users and Licensed users in numeric and percentage form. Logged in
    users: Total number of users, including licensed and unlicensed users, currently
    logged in to Developer Hub. Licensed users: Total number of licensed users logged
    in to Developer Hub. You can set the target for the number of licensed users in
    your Developer Hub app config.yaml file. To view the total number of users in
    your Developer Hub instance in numeric and percentage forms, go to Administration
    > Adoption Insights and see the Total number of users card. To view a percentage
    representation of the total number of logged in users among the total number of
    licensed users, hover over the tooltip in the Total number of users card. ###
    Viewing the top catalog entities This card lists the most viewed catalog entities
    (like components, APIs, and so on) and documentation entries, including usage
    statistics, in a table. Each item displays the following details: Name: Name of
    the catalog Kind: Type of the catalog Last used: The last time the catalog was
    used Views: The number of times the catalog was viewed To view the most commonly
    used catalog entities in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top catalog entities card. To know more about the displayed
    catalog entity, hover over the catalog entity name. ### Viewing the top 3 templates
    This card lists the three most commonly used templates in a table. You can click
    the down arrow next to 3 rows to view the full list of the commonly used templates.
    Name: Name of the template Mostly in use by: Type of user using this template
    most frequently Executions: Number of times this template was used To view the
    most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 templates card. To know more about the displayed
    template, hover over the template name. ### Viewing the top 3 techdocs This card
    lists the most viewed documentation entries, including the total views, in a table.
    Name: Title of the document Entity: Type of document Last used: The last time
    the document was viewed Views: Number of times the document was visited To view
    the most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 techdocs card. To know more about the displayed
    techdocs, hover over the name of the techdoc. ### Viewing the top 3 plugins This
    card lists the three most commonly used plugins in a table. You can click the
    down arrow next to 3 rows to view the full list of the commonly used plugins.
    Name: Name of the plugin Trend: Popularity of the plugin as a graph Views: Number
    of times this plugin was seen To view the most commonly used plugins and the plugin
    page visit trends in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top 3 plugins card. To know more about the displayed plugin,
    hover over the plugin name. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:53:11.334915'
    uuid: b488029a-7bc7-4fc5-92e6-e113d7cfbed0
  response: To view adoption insights in your Red Hat Developer Hub instance, navigate
    to Administration > Adoption Insights. There you will find several cards with
    specific data. The "Active users" card displays the total number of active users,
    distinguishing between new and returning users, and allows you to export the data
    as a .csv file. The "Total number of users" card shows the total number of licensed
    users and provides a comparison of logged-in users versus licensed users. For
    popular content, the "Top catalog entities" card lists the most viewed entities
    like components and APIs with details on their name, kind, last use, and view
    count. Lastly, the "Top 3 plugins" card lists the most commonly used plugins,
    showing their name, popularity trend, and the number of times they were seen.
  user_input: As a platform engineer managing our Red Hat Developer Hub instance,
    how can I access and view the detailed adoption insights to understand user activity,
    including active users, licensed users, and the most popular catalog entities
    and plugins?
- context:
  - 'Viewing the Adoption Insights card ### Viewing the active users The Active users
    card displays the total number of active users over a specified date and time
    period. You can export the user data in a .csv format. Returning users: Existing
    users who have logged into Developer Hub previously New users: New users who have
    registered and logged into Developer Hub for the first time ![active users] To
    view the list of active users in your Red Hat Developer Hub instance, go to Administration
    > Adoption Insights, see the Active users card. To view the exact number of users
    for a particular day, hover over the corresponding date in the Active users card.
    To export the user data in a .csv format, click the Export CSV link. ### Viewing
    the total number of users This card displays the total number of users that have
    license to use Red Hat Developer Hub. It also provides a comparison of the number
    of Logged-in users and Licensed users in numeric and percentage form. Logged in
    users: Total number of users, including licensed and unlicensed users, currently
    logged in to Developer Hub. Licensed users: Total number of licensed users logged
    in to Developer Hub. You can set the target for the number of licensed users in
    your Developer Hub app config.yaml file. To view the total number of users in
    your Developer Hub instance in numeric and percentage forms, go to Administration
    > Adoption Insights and see the Total number of users card. To view a percentage
    representation of the total number of logged in users among the total number of
    licensed users, hover over the tooltip in the Total number of users card. ###
    Viewing the top catalog entities This card lists the most viewed catalog entities
    (like components, APIs, and so on) and documentation entries, including usage
    statistics, in a table. Each item displays the following details: Name: Name of
    the catalog Kind: Type of the catalog Last used: The last time the catalog was
    used Views: The number of times the catalog was viewed To view the most commonly
    used catalog entities in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top catalog entities card. To know more about the displayed
    catalog entity, hover over the catalog entity name. ### Viewing the top 3 templates
    This card lists the three most commonly used templates in a table. You can click
    the down arrow next to 3 rows to view the full list of the commonly used templates.
    Name: Name of the template Mostly in use by: Type of user using this template
    most frequently Executions: Number of times this template was used To view the
    most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 templates card. To know more about the displayed
    template, hover over the template name. ### Viewing the top 3 techdocs This card
    lists the most viewed documentation entries, including the total views, in a table.
    Name: Title of the document Entity: Type of document Last used: The last time
    the document was viewed Views: Number of times the document was visited To view
    the most commonly used templates in your Developer Hub instance, go to Administration
    > Adoption Insights and see the Top 3 techdocs card. To know more about the displayed
    techdocs, hover over the name of the techdoc. ### Viewing the top 3 plugins This
    card lists the three most commonly used plugins in a table. You can click the
    down arrow next to 3 rows to view the full list of the commonly used plugins.
    Name: Name of the plugin Trend: Popularity of the plugin as a graph Views: Number
    of times this plugin was seen To view the most commonly used plugins and the plugin
    page visit trends in your Developer Hub instance, go to Administration > Adoption
    Insights and see the Top 3 plugins card. To know more about the displayed plugin,
    hover over the plugin name. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:53:18.194459'
    uuid: 1a7193e2-93a0-4dd2-ae7c-52e7fd27a1aa
  response: The Top 3 plugins card lists the three most commonly used plugins in a
    table. The details provided for each plugin are its Name, its Trend (which is
    its popularity shown as a graph), and its Views (the number of times the plugin
    was seen). To see this information, you can go to Administration > Adoption Insights
    and find the Top 3 plugins card.
  user_input: What details are shown for the Top 3 plugins in Developer Hub?
- context:
  - 'Modifying the number of displayed records You can modify the number of displayed
    records in Adoption Insights for the following cards. Top catalog entities Top
    3 templates Top 3 techdocs Top 3 plugins You can select any of the following number
    of records for display: Top 3 Top 5 Top 10 Top 20 By default, the top three most
    viewed catalog entities are displayed. Go to Administration > Adoption Insights
    and click the Down arrow next to 3 rows to change the number of displayed records.
    ![Catalog Entities dropdown] ## Filtering records to display specific catalog
    entities in Top catalog entities You can use the dropdown filter in the title
    to filter the table display by any of the items. By default, the Top catalog entities
    card displays all of the items in your Developer Hub instance. To view a specific
    catalog entity in the table, complete the following step: Go to Administration
    > Adoption Insights, click the dropdown filter on the Top catalog entities card,
    and select the item that you want to view. ## Viewing Searches In the searches
    card, you can view the following data: Visualizes the number of portal searches
    and trends over time as a graph Displays the total for the period in the card
    title Clarifies the average number each hour/day/week/month depending on the time
    period chosen'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:53:25.199637'
    uuid: 1e61e8da-ef59-4f61-84f7-7a04ad34758d
  response: To modify the number of displayed records for Top catalog entities, you
    need to go to Administration > Adoption Insights and click the Down arrow next
    to 3 rows. You can then select to display the Top 3, Top 5, Top 10, or Top 20
    records.
  user_input: How do I chnage the number of Top catalog entites shown?
- context:
  - 'Modifying the number of displayed records You can modify the number of displayed
    records in Adoption Insights for the following cards. Top catalog entities Top
    3 templates Top 3 techdocs Top 3 plugins You can select any of the following number
    of records for display: Top 3 Top 5 Top 10 Top 20 By default, the top three most
    viewed catalog entities are displayed. Go to Administration > Adoption Insights
    and click the Down arrow next to 3 rows to change the number of displayed records.
    ![Catalog Entities dropdown] ## Filtering records to display specific catalog
    entities in Top catalog entities You can use the dropdown filter in the title
    to filter the table display by any of the items. By default, the Top catalog entities
    card displays all of the items in your Developer Hub instance. To view a specific
    catalog entity in the table, complete the following step: Go to Administration
    > Adoption Insights, click the dropdown filter on the Top catalog entities card,
    and select the item that you want to view. ## Viewing Searches In the searches
    card, you can view the following data: Visualizes the number of portal searches
    and trends over time as a graph Displays the total for the period in the card
    title Clarifies the average number each hour/day/week/month depending on the time
    period chosen'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:53:34.677620'
    uuid: 8d43f953-3bf4-4e3c-a248-f0757671b3db
  response: You can modify the number of displayed records for the Top 3 techdocs
    card in Adoption Insights. You can select to display the Top 3, Top 5, Top 10,
    or Top 20 records. To change the number of displayed records, go to Administration
    > Adoption Insights and click the Down arrow next to 3 rows.
  user_input: Im trying to configure the Adption Insights dashboard for my team, and
    I was wondering what the procdure is for changing the number of records displayed
    on the Top 3 techdocs card?
- context:
  - 'Modifying the number of displayed records You can modify the number of displayed
    records in Adoption Insights for the following cards. Top catalog entities Top
    3 templates Top 3 techdocs Top 3 plugins You can select any of the following number
    of records for display: Top 3 Top 5 Top 10 Top 20 By default, the top three most
    viewed catalog entities are displayed. Go to Administration > Adoption Insights
    and click the Down arrow next to 3 rows to change the number of displayed records.
    ![Catalog Entities dropdown] ## Filtering records to display specific catalog
    entities in Top catalog entities You can use the dropdown filter in the title
    to filter the table display by any of the items. By default, the Top catalog entities
    card displays all of the items in your Developer Hub instance. To view a specific
    catalog entity in the table, complete the following step: Go to Administration
    > Adoption Insights, click the dropdown filter on the Top catalog entities card,
    and select the item that you want to view. ## Viewing Searches In the searches
    card, you can view the following data: Visualizes the number of portal searches
    and trends over time as a graph Displays the total for the period in the card
    title Clarifies the average number each hour/day/week/month depending on the time
    period chosen'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:53:45.373452'
    uuid: e07bebd3-09ea-4bfa-a341-81f656457b21
  response: To modify the number of displayed records for the 'Top catalog entities',
    'Top 3 templates', 'Top 3 techdocs', and 'Top 3 plugins' cards, you can select
    from Top 3, Top 5, Top 10, or Top 20. To do this, go to Administration > Adoption
    Insights and click the Down arrow next to '3 rows'. To filter the 'Top catalog
    entities' card, which by default displays all items in your Developer Hub instance,
    go to Administration > Adoption Insights, click the dropdown filter on the card,
    and select the item you want to view.
  user_input: How do I change the settings in my Developer Hub to modify the number
    of displayed records and filter specific catalog entities on the Adoption Insights
    cards?
- context:
  - '# Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:54:01.283111'
    uuid: 7d054d7c-634c-4c45-a2bf-8079d6e550e5
  response: The context is about integrating Red Hat Developer Hub with GitHub.
  user_input: how do i intergrate Red Hat Developer Hub with github?
- context:
  - '# Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:54:16.847197'
    uuid: e1bf5e53-ce22-4d69-bd5d-2ccac6518c94
  response: The topic is about integrating Red Hat Developer Hub with GitHub.
  user_input: Red Hat Developer Hub GitHub integration?
- context:
  - '# Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:54:29.151323'
    uuid: 9f39bf89-3922-48b7-942c-e8848cd1719b
  response: The context is about integrating Red Hat Developer Hub with GitHub.
  user_input: how do i do the integration for Red Hat Developer Hub with my GitHub?
- context:
  - 'Enabling GitHub repository discovery Consider configuring Developer Hub to discover
    and ingest your GitHub repositories automatically. If a repository contains a
    catalog-info.yaml file, Developer Hub ingests the repository into the catalog
    as a component. You added a custom Developer Hub application configuration, and
    have sufficient permissions to modify it. You have sufficient permissions in GitHub
    to create and manage a GitHub App. To allow users to access GitHub templates or
    plugins that require GitHub authentication, you have configured GitHub either
    as an auxiliary authentication provider or as your main authentication provider.
    1. To allow Developer Hub to access the GitHub API, create a GitHub App. Opt for
    a GitHub App instead of an OAuth app to use fine-grained permissions, gain more
    control over which repositories the application can access, and use short-lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating-with-rhdh-<GUID>.
    Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read-only
    Commit statuses:: Read-only Reading organization data:: Members:: Read-only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read-only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action Repository Variables)
    Secrets:: Read & write (if templates include GitHub Action Repository Secrets)
    Environments:: Read & write (if templates include GitHub Environments) Organization
    permissions:: Members:: Read-only Where can this GitHub App be installed?:: Select
    Only on this account. 2. In the General -> Clients secrets section, click Generate
    a new client secret. 3. In the General -> Private keys section, click Generate
    a private key. 4. In the Install App tab, choose an account to install your GitHub
    App on. 5. Save the following values for the next step: * App ID * Client ID *
    Client secret * Private key 2. To add your GitHub credentials to Developer Hub,
    add the following key/value pairs to your Developer Hub secrets. You can use these
    secrets in the Developer Hub configuration files by using their respective environment
    variable name. GITHUB_INTEGRATION_APP_ID:: Enter the saved App ID. GITHUB_INTEGRATION_CLIENT_ID::
    Enter the saved Client ID. GITHUB_INTEGRATION_CLIENT_SECRET:: Enter the saved
    Client Secret. GITHUB_INTEGRATION_HOST_DOMAIN:: Enter the GitHub host domain:
    github.com. GITHUB_INTEGRATION_ORGANIZATION:: Enter your GitHub organization name,
    such as `<your_github_organization_name>''. GITHUB_INTEGRATION_PRIVATE_KEY_FILE::
    Enter the saved Private key. 3. Enable the plugin-catalog-backend-module-github
    plugin in your dynamic-plugins.yaml file. This plugin discovers catalog entities
    by scanning repositories within a GitHub organization for catalog-info.yaml files.
    It provides an automated alternative to manually registering components via catalog.locations.
    When a repository contains a catalog-info.yaml file, the entity is ingested into
    the catalog as a component. dynamic-plugins.yaml file fragment ```yaml plugins:
    package: ''./dynamic plugins/dist/backstage plugin catalog backend module github''
    disabled: false ``` 4. Configure the GitHub integration, by adding the catalog.providers.github
    and the integrations.github sections to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml file fragment with mandatory fields to enable
    GitHub integration ```yaml catalog: providers: github: providerId: organization:
    "${GITHUB_INTEGRATION_ORGANIZATION}" schedule: frequency: minutes: 30 initialDelay:
    seconds: 15 timeout: minutes: 15 integrations: github: host: ${GITHUB_INTEGRATION_HOST_DOMAIN}
    apps: appId: ${GITHUB_INTEGRATION_APP_ID} clientId: ${GITHUB_INTEGRATION_CLIENT_ID}
    clientSecret: ${GITHUB_INTEGRATION_CLIENT_SECRET} privateKey: | ${GITHUB_INTEGRATION_PRIVATE_KEY_FILE}
    ``` # Bulk importing in Red Hat Developer Hub [IMPORTANT] ---- These features
    are for Technology Preview only. Technology Preview features are not supported
    with Red Hat production service level agreements (SLAs), might not be functionally
    complete, and Red Hat does not recommend using them for production. These features
    provide early access to upcoming product features, enabling customers to test
    functionality and provide feedback during the development process. For more information
    on Red Hat Technology Preview features, see Technology Preview Features Scope.
    ---- Red Hat Developer Hub can automate the onboarding of GitHub repositories
    and GitLab projects, and track their import status. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:54:37.611186'
    uuid: 79d66866-f10b-46ea-a9f0-0c4923dcc44a
  response: To configure the GitHub integration, you must add the `catalog.providers.github`
    and the `integrations.github` sections to your custom Developer Hub `app-config.yaml`
    configuration file. The `catalog.providers.github` section includes `providerId`,
    `organization`, and a `schedule` with `frequency`, `initialDelay`, and `timeout`.
    The `integrations.github` section includes the `host` and an `apps` configuration
    containing the `appId`, `clientId`, `clientSecret`, and `privateKey`.
  user_input: what sections i need to add in the app-config.yaml file for the github
    integration to work right?
- context:
  - 'Enabling GitHub repository discovery Consider configuring Developer Hub to discover
    and ingest your GitHub repositories automatically. If a repository contains a
    catalog-info.yaml file, Developer Hub ingests the repository into the catalog
    as a component. You added a custom Developer Hub application configuration, and
    have sufficient permissions to modify it. You have sufficient permissions in GitHub
    to create and manage a GitHub App. To allow users to access GitHub templates or
    plugins that require GitHub authentication, you have configured GitHub either
    as an auxiliary authentication provider or as your main authentication provider.
    1. To allow Developer Hub to access the GitHub API, create a GitHub App. Opt for
    a GitHub App instead of an OAuth app to use fine-grained permissions, gain more
    control over which repositories the application can access, and use short-lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating-with-rhdh-<GUID>.
    Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read-only
    Commit statuses:: Read-only Reading organization data:: Members:: Read-only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read-only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action Repository Variables)
    Secrets:: Read & write (if templates include GitHub Action Repository Secrets)
    Environments:: Read & write (if templates include GitHub Environments) Organization
    permissions:: Members:: Read-only Where can this GitHub App be installed?:: Select
    Only on this account. 2. In the General -> Clients secrets section, click Generate
    a new client secret. 3. In the General -> Private keys section, click Generate
    a private key. 4. In the Install App tab, choose an account to install your GitHub
    App on. 5. Save the following values for the next step: * App ID * Client ID *
    Client secret * Private key 2. To add your GitHub credentials to Developer Hub,
    add the following key/value pairs to your Developer Hub secrets. You can use these
    secrets in the Developer Hub configuration files by using their respective environment
    variable name. GITHUB_INTEGRATION_APP_ID:: Enter the saved App ID. GITHUB_INTEGRATION_CLIENT_ID::
    Enter the saved Client ID. GITHUB_INTEGRATION_CLIENT_SECRET:: Enter the saved
    Client Secret. GITHUB_INTEGRATION_HOST_DOMAIN:: Enter the GitHub host domain:
    github.com. GITHUB_INTEGRATION_ORGANIZATION:: Enter your GitHub organization name,
    such as `<your_github_organization_name>''. GITHUB_INTEGRATION_PRIVATE_KEY_FILE::
    Enter the saved Private key. 3. Enable the plugin-catalog-backend-module-github
    plugin in your dynamic-plugins.yaml file. This plugin discovers catalog entities
    by scanning repositories within a GitHub organization for catalog-info.yaml files.
    It provides an automated alternative to manually registering components via catalog.locations.
    When a repository contains a catalog-info.yaml file, the entity is ingested into
    the catalog as a component. dynamic-plugins.yaml file fragment ```yaml plugins:
    package: ''./dynamic plugins/dist/backstage plugin catalog backend module github''
    disabled: false ``` 4. Configure the GitHub integration, by adding the catalog.providers.github
    and the integrations.github sections to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml file fragment with mandatory fields to enable
    GitHub integration ```yaml catalog: providers: github: providerId: organization:
    "${GITHUB_INTEGRATION_ORGANIZATION}" schedule: frequency: minutes: 30 initialDelay:
    seconds: 15 timeout: minutes: 15 integrations: github: host: ${GITHUB_INTEGRATION_HOST_DOMAIN}
    apps: appId: ${GITHUB_INTEGRATION_APP_ID} clientId: ${GITHUB_INTEGRATION_CLIENT_ID}
    clientSecret: ${GITHUB_INTEGRATION_CLIENT_SECRET} privateKey: | ${GITHUB_INTEGRATION_PRIVATE_KEY_FILE}
    ``` # Bulk importing in Red Hat Developer Hub [IMPORTANT] ---- These features
    are for Technology Preview only. Technology Preview features are not supported
    with Red Hat production service level agreements (SLAs), might not be functionally
    complete, and Red Hat does not recommend using them for production. These features
    provide early access to upcoming product features, enabling customers to test
    functionality and provide feedback during the development process. For more information
    on Red Hat Technology Preview features, see Technology Preview Features Scope.
    ---- Red Hat Developer Hub can automate the onboarding of GitHub repositories
    and GitLab projects, and track their import status. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:54:49.424983'
    uuid: eb13bd41-587d-4319-8cc9-763d871e810a
  response: 'To configure Developer Hub to automatically discover and ingest your
    GitHub repositories, you must first create a GitHub App. This is preferred over
    an OAuth app for its fine-grained permissions and short-lived tokens. The app
    should be registered with your Developer Hub URL as the Homepage URL, the authentication
    backend URL as the Authorization callback URL, and the Webhook set to inactive.
    Specific app permissions are required: for reading software components, set Contents
    and Commit statuses to Read-only, and Members to Read-only. For publishing software
    templates, set Administration and Contents to Read & write, Metadata and Members
    to Read-only, and Pull requests, Issues, Workflows, Variables, Secrets, and Environments
    to Read & write. After creating the app, generate and save the App ID, Client
    ID, Client secret, and Private key. Next, add these credentials to your Developer
    Hub secrets using the keys GITHUB_INTEGRATION_APP_ID, GITHUB_INTEGRATION_CLIENT_ID,
    GITHUB_INTEGRATION_CLIENT_SECRET, and GITHUB_INTEGRATION_PRIVATE_KEY_FILE, along
    with GITHUB_INTEGRATION_HOST_DOMAIN for ''github.com'' and your GITHUB_INTEGRATION_ORGANIZATION
    name. Following this, you must enable the ''plugin-catalog-backend-module-github''
    in your dynamic-plugins.yaml file. Finally, configure the GitHub integration by
    adding the ''catalog.providers.github'' and ''integrations.github'' sections to
    your custom app-config.yaml file, which will use the secrets you previously configured
    to establish the connection.'
  user_input: As we are building out our unified developer platform, could you provide
    a comprehensive, step-by-step guide on how to configure the Developer Hub to automatically
    discover and ingest our repositories from GitHub, including the specific permissions
    required for the GitHub App, the necessary credentials to be stored as secrets,
    and the plugin configuration needed to enable this integration?
- context:
  - 'Enabling GitHub repository discovery Consider configuring Developer Hub to discover
    and ingest your GitHub repositories automatically. If a repository contains a
    catalog-info.yaml file, Developer Hub ingests the repository into the catalog
    as a component. You added a custom Developer Hub application configuration, and
    have sufficient permissions to modify it. You have sufficient permissions in GitHub
    to create and manage a GitHub App. To allow users to access GitHub templates or
    plugins that require GitHub authentication, you have configured GitHub either
    as an auxiliary authentication provider or as your main authentication provider.
    1. To allow Developer Hub to access the GitHub API, create a GitHub App. Opt for
    a GitHub App instead of an OAuth app to use fine-grained permissions, gain more
    control over which repositories the application can access, and use short-lived
    tokens. 1. Register a GitHub App with the following configuration: GitHub App
    name:: Enter a unique name identifying your GitHub App, such as integrating-with-rhdh-<GUID>.
    Homepage URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>.
    Authorization callback URL:: Enter your Developer Hub authentication backend URL:
    https://<my_developer_hub_domain>/api/auth/github/handler/frame. Webhook:: Clear
    "Active", as this is not needed for authentication and catalog providers. App
    permissions:: Select permissions to define the level of access for the app. Adapt
    permissions to your needs: Reading software components:: Contents:: Read-only
    Commit statuses:: Read-only Reading organization data:: Members:: Read-only Publishing
    software templates:: Set permissions if you intend to use the same GitHub App
    for software templates. Administration:: Read & write (for creating repositories)
    Contents:: Read & write Metadata:: Read-only Pull requests:: Read & write Issues::
    Read & write Workflows:: Read & write (if templates include GitHub workflows)
    Variables:: Read & write (if templates include GitHub Action Repository Variables)
    Secrets:: Read & write (if templates include GitHub Action Repository Secrets)
    Environments:: Read & write (if templates include GitHub Environments) Organization
    permissions:: Members:: Read-only Where can this GitHub App be installed?:: Select
    Only on this account. 2. In the General -> Clients secrets section, click Generate
    a new client secret. 3. In the General -> Private keys section, click Generate
    a private key. 4. In the Install App tab, choose an account to install your GitHub
    App on. 5. Save the following values for the next step: * App ID * Client ID *
    Client secret * Private key 2. To add your GitHub credentials to Developer Hub,
    add the following key/value pairs to your Developer Hub secrets. You can use these
    secrets in the Developer Hub configuration files by using their respective environment
    variable name. GITHUB_INTEGRATION_APP_ID:: Enter the saved App ID. GITHUB_INTEGRATION_CLIENT_ID::
    Enter the saved Client ID. GITHUB_INTEGRATION_CLIENT_SECRET:: Enter the saved
    Client Secret. GITHUB_INTEGRATION_HOST_DOMAIN:: Enter the GitHub host domain:
    github.com. GITHUB_INTEGRATION_ORGANIZATION:: Enter your GitHub organization name,
    such as `<your_github_organization_name>''. GITHUB_INTEGRATION_PRIVATE_KEY_FILE::
    Enter the saved Private key. 3. Enable the plugin-catalog-backend-module-github
    plugin in your dynamic-plugins.yaml file. This plugin discovers catalog entities
    by scanning repositories within a GitHub organization for catalog-info.yaml files.
    It provides an automated alternative to manually registering components via catalog.locations.
    When a repository contains a catalog-info.yaml file, the entity is ingested into
    the catalog as a component. dynamic-plugins.yaml file fragment ```yaml plugins:
    package: ''./dynamic plugins/dist/backstage plugin catalog backend module github''
    disabled: false ``` 4. Configure the GitHub integration, by adding the catalog.providers.github
    and the integrations.github sections to your custom Developer Hub app-config.yaml
    configuration file: app-config.yaml file fragment with mandatory fields to enable
    GitHub integration ```yaml catalog: providers: github: providerId: organization:
    "${GITHUB_INTEGRATION_ORGANIZATION}" schedule: frequency: minutes: 30 initialDelay:
    seconds: 15 timeout: minutes: 15 integrations: github: host: ${GITHUB_INTEGRATION_HOST_DOMAIN}
    apps: appId: ${GITHUB_INTEGRATION_APP_ID} clientId: ${GITHUB_INTEGRATION_CLIENT_ID}
    clientSecret: ${GITHUB_INTEGRATION_CLIENT_SECRET} privateKey: | ${GITHUB_INTEGRATION_PRIVATE_KEY_FILE}
    ``` # Bulk importing in Red Hat Developer Hub [IMPORTANT] ---- These features
    are for Technology Preview only. Technology Preview features are not supported
    with Red Hat production service level agreements (SLAs), might not be functionally
    complete, and Red Hat does not recommend using them for production. These features
    provide early access to upcoming product features, enabling customers to test
    functionality and provide feedback during the development process. For more information
    on Red Hat Technology Preview features, see Technology Preview Features Scope.
    ---- Red Hat Developer Hub can automate the onboarding of GitHub repositories
    and GitLab projects, and track their import status. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:55:02.539960'
    uuid: ff763b79-05bd-47c9-a205-29a9ea5abf54
  response: 'To configure Red Hat Developer Hub to automatically discover and ingest
    your GitHub repositories, you must first create a GitHub App, which is preferred
    over an OAuth app for its fine-grained permissions and use of short-lived tokens.
    When registering the app, you will set a unique name, a Homepage URL pointing
    to your Developer Hub, and an Authorization callback URL for the auth backend.
    The Webhook should be set to inactive. App permissions must be configured for
    reading software components (Contents: Read-only, Commit statuses: Read-only)
    and organization data (Members: Read-only), with additional permissions for publishing
    software templates if needed. After creating the app, generate and save the App
    ID, Client ID, Client secret, and a Private key. Next, add these credentials to
    your Developer Hub secrets using the keys GITHUB_INTEGRATION_APP_ID, GITHUB_INTEGRATION_CLIENT_ID,
    GITHUB_INTEGRATION_CLIENT_SECRET, and GITHUB_INTEGRATION_PRIVATE_KEY_FILE, along
    with your GITHUB_INTEGRATION_HOST_DOMAIN and GITHUB_INTEGRATION_ORGANIZATION.
    Following that, you must enable the "plugin-catalog-backend-module-github" in
    your dynamic-plugins.yaml file, which allows the discovery of catalog entities
    by scanning for catalog-info.yaml files. Finally, configure the integration by
    adding the "catalog.providers.github" and "integrations.github" sections to your
    custom app-config.yaml file, using the secrets you previously configured.'
  user_input: how to set up GitHub repository discovery in Red Hat Developer Hub
- context:
  - 'Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are created,
    and you are redirected to the list of added repositories. 5. Review and merge
    each pull request that creates a catalog-info.yml file. The Added entities list
    displays the repositories you imported, each with an appropriate status: either
    Waiting for approval or Added. For each Waiting for approval import job listed,
    there is a corresponding pull request adding the catalog info.yaml file in the
    corresponding repository. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:55:12.781228'
    uuid: 53d8697e-f1b3-4a33-a1e9-e466078fea7c
  response: To enable the Bulk Import feature in Red Hat Developer Hub, which is available
    for GitHub repositories and GitLab projects, you must edit your dynamic-plugins.yaml
    file to enable the `red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic`
    and `red-hat-developer-hub-backstage-plugin-bulk-import` plugins, as they are
    disabled by default. For users who are not administrators, you must also configure
    the required `bulk.import` RBAC permission. A prerequisite for using this feature
    with GitHub is that you have enabled GitHub repository discovery.
  user_input: What is required to enable the Bulk Import feature in Red Hat Developer
    Hub?
- context:
  - 'Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are created,
    and you are redirected to the list of added repositories. 5. Review and merge
    each pull request that creates a catalog-info.yml file. The Added entities list
    displays the repositories you imported, each with an appropriate status: either
    Waiting for approval or Added. For each Waiting for approval import job listed,
    there is a corresponding pull request adding the catalog info.yaml file in the
    corresponding repository. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:55:21.848912'
    uuid: 54833e38-4298-45af-8e62-04e792cdb292
  response: The Bulk Import feature in Red Hat Developer Hub is available for GitLab
    projects. The Bulk Import page will show a list of added GitLab projects alongside
    GitHub repositories.
  user_input: As a Platform Engineering Lead evaluating Red Hat Developer Hub, what
    capabilities does the Bulk Import feature offer for GitLab projects?
- context:
  - 'Enabling and authorizing Bulk Import capabilities in Red Hat Developer Hub You
    can enable the Bulk Import feature for users and give them the necessary permissions
    to access it. This feature is available for GitHub repositories and GitLab projects.
    For GitHub only: You have enabled GitHub repository discovery. 1. The Bulk Import
    plugins are installed but disabled by default. To enable the ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import-backend-dynamic
    and ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
    plugins, edit your dynamic-plugins.yaml with the following content: dynamic-plugins.yaml
    fragment ```yaml plugins: package: ./dynamic plugins/dist/red hat developer hub
    backstage plugin bulk import backend dynamic disabled: false package: ./dynamic
    plugins/dist/red hat developer hub backstage plugin bulk import disabled: false
    ``` See Installing and viewing plugins in Red Hat Developer Hub. 2. Configure
    the required bulk.import RBAC permission for the users who are not administrators
    as follows: rbac-policy.csv fragment ```csv p, role:default/bulk import, bulk.import,
    use, allow g, user:default/<your_user>, role:default/bulk import ``` Note that
    only Developer Hub administrators or users with the bulk.import permission can
    use the Bulk Import feature. See Permission policies in Red Hat Developer Hub.
    The sidebar displays a Bulk Import option. The Bulk Import page shows a list of
    added GitHub repositories and GitLab projects. ## Importing multiple GitHub repositories
    In Red Hat Developer Hub, you can select your GitHub repositories and automate
    their onboarding to the Developer Hub catalog. You have enabled the Bulk Import
    feature and gave access to it. 1. Click Bulk Import in the left sidebar. 2. Click
    the Add button in the top-right corner to see the list of all repositories accessible
    from the configured GitHub integrations. 1. From the Repositories view, you can
    select any repository, or search for any accessible repositories. For each repository
    selected, a catalog-info.yaml is generated. 2. From the Organizations view, you
    can select any organization by clicking Select in the third column. This option
    allows you to select one or more repositories from the selected organization.
    3. Click Preview file to view or edit the details of the pull request for each
    repository. 1. Review the pull request description and the catalog-info.yaml file
    content. 2. Optional: when the repository has a .github/CODEOWNERS file, you can
    select the Use CODEOWNERS file as Entity Owner checkbox to use it, rather than
    having the content-info.yaml contain a specific entity owner. 3. Click Save. 4.
    Click Create pull requests. At this point, a set of dry-run checks runs against
    the selected repositories to ensure they meet the requirements for import, such
    as: 1. Verifying that there is no entity in the Developer Hub catalog with the
    name specified in the repository catalog-info.yaml 2. Verifying that the repository
    is not empty 3. Verifying that the repository contains a .github/CODEOWNERS file
    if the Use CODEOWNERS file as Entity Owner checkbox is selected for that repository
    * If any errors occur, the pull requests are not created, and you see a Failed
    to create PR error message detailing the issues. To view more details about the
    reasons, click Edit. * If there are no errors, the pull requests are created,
    and you are redirected to the list of added repositories. 5. Review and merge
    each pull request that creates a catalog-info.yml file. The Added entities list
    displays the repositories you imported, each with an appropriate status: either
    Waiting for approval or Added. For each Waiting for approval import job listed,
    there is a corresponding pull request adding the catalog info.yaml file in the
    corresponding repository. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:55:29.607100'
    uuid: c2984ad6-a804-4ffe-a703-db8789bb963f
  response: During the Bulk Import process, when you select a repository from the
    Repositories view, a catalog-info.yaml is generated for each repository selected.
  user_input: when the catalog-info.yaml get generated?
- context:
  - 'Importing multiple GitLab repositories In Red Hat Developer Hub, you can select
    your GitLab projects and automate their onboarding to the Developer Hub catalog.
    This feature is a Technology preview. [IMPORTANT] ---- Technology Preview features
    provide early access to upcoming product innovations, enabling you to test functionality
    and provide feedback during the development process. However, these features are
    not fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- You have include::modules/streamline
    software development and management/proc enabling and authorizing bulk import
    capabilities.adoc[enabled the Bulk Import feature and given access to it]. You
    have set up a GitLab personal access token (PAT). 1. In RHDH, click Bulk Import
    2. Click Import. 3. Select GitLab as your Approval tool option. 4. Use the Project
    and Group views to see the list of all available GitLab projects and groups: *
    Use the Project view to select GitLab projects for importing. * Use the Group
    view to select GitLab groups and their associated projects for importing. 5. In
    GitLab, review the automatically created "Ad catalog-info.yaml file" merge request
    for each project you selected for Bulk Import. 6. Merge the merge request. 1.
    In RHDH, click Bulk Import 2. In the Imported entities list, each imported GitLab
    project has the appropriate status: either Waiting for approval or Added. * For
    each Waiting for approval import job listed, there is a corresponding merge request
    adding the catalog-info.yaml file in the corresponding project. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:56:03.811804'
    uuid: e574f917-cf79-40e8-9a80-e1cd2a59e1d5
  response: Technology Preview features provide early access to upcoming product innovations,
    enabling you to test functionality and provide feedback during the development
    process. However, these features are not fully supported under Red Hat Subscription
    Level Agreements, may not be functionally complete, and are not intended for production
    use.
  user_input: wat does technolgy preview mean?
- context:
  - 'Importing multiple GitLab repositories In Red Hat Developer Hub, you can select
    your GitLab projects and automate their onboarding to the Developer Hub catalog.
    This feature is a Technology preview. [IMPORTANT] ---- Technology Preview features
    provide early access to upcoming product innovations, enabling you to test functionality
    and provide feedback during the development process. However, these features are
    not fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- You have include::modules/streamline
    software development and management/proc enabling and authorizing bulk import
    capabilities.adoc[enabled the Bulk Import feature and given access to it]. You
    have set up a GitLab personal access token (PAT). 1. In RHDH, click Bulk Import
    2. Click Import. 3. Select GitLab as your Approval tool option. 4. Use the Project
    and Group views to see the list of all available GitLab projects and groups: *
    Use the Project view to select GitLab projects for importing. * Use the Group
    view to select GitLab groups and their associated projects for importing. 5. In
    GitLab, review the automatically created "Ad catalog-info.yaml file" merge request
    for each project you selected for Bulk Import. 6. Merge the merge request. 1.
    In RHDH, click Bulk Import 2. In the Imported entities list, each imported GitLab
    project has the appropriate status: either Waiting for approval or Added. * For
    each Waiting for approval import job listed, there is a corresponding merge request
    adding the catalog-info.yaml file in the corresponding project. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T15:56:11.977175'
    uuid: df47d7e3-529c-4265-b0af-c4ad3f7780e6
  response: The feature to import multiple GitLab repositories is a Technology Preview.
    Technology Preview features provide early access to upcoming product innovations,
    enabling you to test functionality and provide feedback during the development
    process. However, these features are not fully supported under Red Hat Subscription
    Level Agreements, may not be functionally complete, and are not intended for production
    use. Red Hat will attempt to resolve any issues that customers experience when
    using these features as it considers making future iterations generally available.
  user_input: As a Platform Engineer responsible for deploying a production-ready
    Red Hat Developer Hub, what are the specific limitations and support implications
    I should be aware of regarding the bulk import feature for GitLab repositories,
    given its current status as a Technology Preview?
- context:
  - 'Importing multiple GitLab repositories In Red Hat Developer Hub, you can select
    your GitLab projects and automate their onboarding to the Developer Hub catalog.
    This feature is a Technology preview. [IMPORTANT] ---- Technology Preview features
    provide early access to upcoming product innovations, enabling you to test functionality
    and provide feedback during the development process. However, these features are
    not fully supported under Red Hat Subscription Level Agreements, may not be functionally
    complete, and are not intended for production use. As Red Hat considers making
    future iterations of Technology Preview features generally available, we will
    attempt to resolve any issues that customers experience when using these features.
    See: Technology Preview support scope. ---- You have include::modules/streamline
    software development and management/proc enabling and authorizing bulk import
    capabilities.adoc[enabled the Bulk Import feature and given access to it]. You
    have set up a GitLab personal access token (PAT). 1. In RHDH, click Bulk Import
    2. Click Import. 3. Select GitLab as your Approval tool option. 4. Use the Project
    and Group views to see the list of all available GitLab projects and groups: *
    Use the Project view to select GitLab projects for importing. * Use the Group
    view to select GitLab groups and their associated projects for importing. 5. In
    GitLab, review the automatically created "Ad catalog-info.yaml file" merge request
    for each project you selected for Bulk Import. 6. Merge the merge request. 1.
    In RHDH, click Bulk Import 2. In the Imported entities list, each imported GitLab
    project has the appropriate status: either Waiting for approval or Added. * For
    each Waiting for approval import job listed, there is a corresponding merge request
    adding the catalog-info.yaml file in the corresponding project. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:56:28.054782'
    uuid: 439562d2-843d-4474-9c03-45f14dd4492f
  response: Technology Preview features provide early access to upcoming product innovations,
    which allows you to test functionality and provide feedback during the development
    process. However, these features are not fully supported under Red Hat Subscription
    Level Agreements, may not be functionally complete, and are not intended for production
    use.
  user_input: what this Technology Preview thing mean?
- context:
  - 'Monitoring Bulk Import actions using audit logs The Bulk Import backend plugin
    adds the following events to the Developer Hub audit logs. See Audit logs in Red
    Hat Developer Hub for more information on how to configure and view audit logs.
    Bulk Import Events: BulkImportUnknownEndpoint:: Tracks requests to unknown endpoints.
    BulkImportPing:: Tracks GET requests to the /ping endpoint, which allows us to
    make sure the bulk import backend is up and running. BulkImportFindAllOrganizations::
    Tracks GET requests to the /organizations endpoint, which returns the list of
    organizations accessible from all configured GitHub Integrations. BulkImportFindRepositoriesByOrganization::
    Tracks GET requests to the /organizations/:orgName/repositories endpoint, which
    returns the list of repositories for the specified organization (accessible from
    any of the configured GitHub Integrations). BulkImportFindAllRepositories:: Tracks
    GET requests to the /repositories endpoint, which returns the list of repositories
    accessible from all configured GitHub Integrations. BulkImportFindAllImports::
    Tracks GET requests to the /imports endpoint, which returns the list of existing
    import jobs along with their statuses. BulkImportCreateImportJobs:: Tracks POST
    requests to the /imports endpoint, which allows to submit requests to bulk-import
    one or many repositories into the Developer Hub catalog, by eventually creating
    import pull requests in the target repositories. BulkImportFindImportStatusByRepo::
    Tracks GET requests to the /import/by-repo endpoint, which fetches details about
    the import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the following example: ```yaml
    bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:56:37.261278'
    uuid: 6f6843fb-29d4-4255-9599-1c33938e6f59
  response: "The Bulk Import plugin analyzes Git repository information and provides\
    \ the following parameters for the Scaffolder template task: \n- repoUrl:: The\
    \ normalized repository URL in the format: `${gitProviderHost}?owner=${owner}&repo=${repository\
    \ name}`\n- name:: The repository name.\n- organization:: The repository owner,\
    \ which can be a user nickname or organization name.\n- branchName:: The proposed\
    \ repository branch, which defaults to `bulk-import-catalog-entity`.\n- targetBranchName::\
    \ The default branch of the Git repository.\n- gitProviderHost:: The Git provider\
    \ host parsed from the repository URL, which can be used to write Git-provider-agnostic\
    \ templates."
  user_input: What specific Git repository information and parameters does the Bulk
    Import plugin analyze and provide for a Scaffolder template task to automate workflows?
- context:
  - 'Monitoring Bulk Import actions using audit logs The Bulk Import backend plugin
    adds the following events to the Developer Hub audit logs. See Audit logs in Red
    Hat Developer Hub for more information on how to configure and view audit logs.
    Bulk Import Events: BulkImportUnknownEndpoint:: Tracks requests to unknown endpoints.
    BulkImportPing:: Tracks GET requests to the /ping endpoint, which allows us to
    make sure the bulk import backend is up and running. BulkImportFindAllOrganizations::
    Tracks GET requests to the /organizations endpoint, which returns the list of
    organizations accessible from all configured GitHub Integrations. BulkImportFindRepositoriesByOrganization::
    Tracks GET requests to the /organizations/:orgName/repositories endpoint, which
    returns the list of repositories for the specified organization (accessible from
    any of the configured GitHub Integrations). BulkImportFindAllRepositories:: Tracks
    GET requests to the /repositories endpoint, which returns the list of repositories
    accessible from all configured GitHub Integrations. BulkImportFindAllImports::
    Tracks GET requests to the /imports endpoint, which returns the list of existing
    import jobs along with their statuses. BulkImportCreateImportJobs:: Tracks POST
    requests to the /imports endpoint, which allows to submit requests to bulk-import
    one or many repositories into the Developer Hub catalog, by eventually creating
    import pull requests in the target repositories. BulkImportFindImportStatusByRepo::
    Tracks GET requests to the /import/by-repo endpoint, which fetches details about
    the import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the following example: ```yaml
    bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog.'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T15:56:48.323822'
    uuid: f87db05c-eae9-4437-9d9f-37ab9d430a32
  response: The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run.
  user_input: what the Orchestrator do when it get the repository list?
- context:
  - 'Monitoring Bulk Import actions using audit logs The Bulk Import backend plugin
    adds the following events to the Developer Hub audit logs. See Audit logs in Red
    Hat Developer Hub for more information on how to configure and view audit logs.
    Bulk Import Events: BulkImportUnknownEndpoint:: Tracks requests to unknown endpoints.
    BulkImportPing:: Tracks GET requests to the /ping endpoint, which allows us to
    make sure the bulk import backend is up and running. BulkImportFindAllOrganizations::
    Tracks GET requests to the /organizations endpoint, which returns the list of
    organizations accessible from all configured GitHub Integrations. BulkImportFindRepositoriesByOrganization::
    Tracks GET requests to the /organizations/:orgName/repositories endpoint, which
    returns the list of repositories for the specified organization (accessible from
    any of the configured GitHub Integrations). BulkImportFindAllRepositories:: Tracks
    GET requests to the /repositories endpoint, which returns the list of repositories
    accessible from all configured GitHub Integrations. BulkImportFindAllImports::
    Tracks GET requests to the /imports endpoint, which returns the list of existing
    import jobs along with their statuses. BulkImportCreateImportJobs:: Tracks POST
    requests to the /imports endpoint, which allows to submit requests to bulk-import
    one or many repositories into the Developer Hub catalog, by eventually creating
    import pull requests in the target repositories. BulkImportFindImportStatusByRepo::
    Tracks GET requests to the /import/by-repo endpoint, which fetches details about
    the import job for the specified repository. BulkImportDeleteImportByRepo:: Tracks
    DELETE requests to the /import/by-repo endpoint, which deletes any existing import
    job for the specified repository, by closing any open import pull request that
    could have been created. ```json { "actor": { "actorId": "user:default/myuser",
    "hostname": "localhost", "ip": "::1", "userAgent": "Mozilla/5.0 (X11; Linux x86_64)
    AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36" }, "eventName":
    "BulkImportFindAllOrganizations", "isAuditLog": true, "level": "info", "message":
    "''get /organizations'' endpoint hit by user:default/myuser", "meta": {}, "plugin":
    "bulk-import", "request": { "body": {}, "method": "GET", "params": {}, "query":
    { "pagePerIntegration": "1", "sizePerIntegration": "5" }, "url": "/api/bulk-import/organizations?pagePerIntegration=1&sizePerIntegration=5"
    }, "response": { "status": 200 }, "service": "backstage", "stage": "completion",
    "status": "succeeded", "timestamp": "2024-08-26 16:41:02" } ``` ## Input parameters
    for Bulk Import Scaffolder template As an administrator, you can use the Bulk
    Import plugin to run a Scaffolder template task with specified parameters, which
    you must define within the template. The Bulk Import plugin analyzes Git repository
    information and provides the following parameters for the Scaffolder template
    task: repoUrl:: Normalized repository URL in the following format: ```yaml ${gitProviderHost}?owner=${owner}&repo=${repository
    name} ``` name:: The repository name. organization:: The repository owner, which
    can be a user nickname or organization name. branchName:: The proposed repository
    branch. By default, the proposed repository branch is bulk-import-catalog-entity.
    targetBranchName:: The default branch of the Git repository. gitProviderHost::
    The Git provider host parsed from the repository URL. You can use this parameter
    to write Git-provider-agnostic templates. Example of a Scaffolder template: ```yaml
    parameters: - title: Repository details required: - repoUrl - branchName - targetBranchName
    - name - organization properties: repoUrl: type: string title: Repository URL
    (Backstage format) description: github.com?owner=Org&repo=repoName organization:
    type: string title: Owner of the repository name: type: string title: Name of
    the repository branchName: type: string title: Branch to add the catalog entity
    to targetBranchName: type: string title: Branch to target the PR/MR to gitProviderHost:
    type: string title: Git provider host ``` ## Setting up a custom Scaffolder workflow
    for Bulk Import As an administrator, you can create a custom Scaffolder template
    in line with the repository conventions of your organization and add the template
    into the Red Hat Developer Hub catalog for use by the Bulk Import plugin on multiple
    selected repositories. You can define various custom tasks, including, but not
    limited to the following: Importing existing catalog entities from a repository
    Creating pull requests for cleanup Calling webhooks for external system integration
    You created a custom Scaffolder template for the Bulk Import plugin. You have
    run your RHDH instance with the following environment variable enabled to allow
    the use of the Scaffolder functionality: ```yaml export NODE_OPTIONS=- no node
    snapshot ``` Configure your app config.yaml configuration to instruct the Bulk
    Import plugin to use your custom template as shown in the following example: ```yaml
    bulkImport: importTemplate: <your_template_entity_reference_or_template_name>
    importAPI: `open pull requests` | `scaffolder`; ``` where: importTemplate::: Enter
    your Scaffolder template entity reference. importAPI:: Set the API to ''scaffolder''
    to trigger the defined workflow for high-fidelity automation. This field defines
    the import workflow and currently supports two following options: open-pull-requests::
    This is the default import workflow, which includes the logic for creating pull
    requests for every selected repository. scaffolder:: This workflow uses an import
    scenario defined in the Scaffolder template to create import jobs. Select this
    option to use the custom import scenario defined in your Scaffolder template.
    Optional: You can direct the Bulk Import plugin to hand off the entire list of
    selected repositories to a custom Orchestrator workflow. [IMPORTANT] ---- The
    Scaffolder template must be generic and not specific to a single repository if
    you want your custom Scaffolder template to run successfully for every repository
    in the bulk list. ---- The Bulk Import plugin runs the custom Scaffolder template
    for the list of repositories using the /task imports API endpoint. ## Data handoff
    and custom workflow design When you configure the Bulk Import plugin by setting
    the importAPI field to scaffolder, the Bulk Import Backend passes all necessary
    context directly to the Scaffolder API. As an administrator, you can define the
    Scaffolder template workflow and structure the workflow to do the following: Define
    template parameters to consume input:: Structure the Scaffolder template to receive
    the repository data as template parameters for the current workflow run. The template
    must be generic, and not specific to a single repository, so that it can successfully
    run for every repository in the bulk list. Automate processing for each repository::
    Implement the custom logic needed for a single repository within the template.
    The Orchestrator iterates through the repository list, launching the template
    once for each repository and passes only the data for that single repository to
    the template run. This allows you to automate tasks such as creating the catalog-info.yaml,
    running compliance checks, or registering the entity with the catalog.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:56:57.464896'
    uuid: e7ff0243-3958-4f74-adbf-9314237b8837
  response: The Bulk Import backend plugin adds the "BulkImportFindAllOrganizations"
    event to the Developer Hub audit logs. This event tracks GET requests to the /organizations
    endpoint, which is designed to return the list of organizations that are accessible
    from all configured GitHub Integrations.
  user_input: How can I see which organizatons are accessible from our configured
    Github integrations using the audit logs?
- context:
  - '# Installing Red Hat Developer Hub on Amazon Elastic Kubernetes Service (EKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Amazon Elastic Kubernetes
    Service (EKS) using either the Operator or Helm chart. # Installing Developer
    Hub on Amazon Elastic Kubernetes Service (EKS) by using the Operator To benefit
    from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On EKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Amazon Elastic Kubernetes Service
    (EKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Amazon Elastic Kubernetes Service (EKS): The
    Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> You have set the context to the EKS cluster in your
    current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create the rhdh-operator namespace to contain
    the Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:57:08.294861'
    uuid: b21c8f66-4a9f-418c-b231-c8d6614893e8
  response: 'On Amazon Elastic Kubernetes Service (EKS), the Operator Lifecycle Manager
    (OLM) framework is not built in, which is a notable difference from an OpenShift-based
    installation. This manual setup is necessary to benefit from over-the-air updates
    and catalogs provided by Operator-based applications distributed with the OLM
    framework. After you have installed the OLM framework, the steps to configure
    it to install the Red Hat Developer Hub Operator are: create the "rhdh-operator"
    namespace; create a pull secret using your Red Hat credentials for the Red Hat
    Container Registry; create a CatalogSource that contains the Red Hat operators;
    create an OperatorGroup to manage your operator subscriptions; and create a Subscription
    to install the Red Hat Developer Hub Operator.'
  user_input: Since the OLM framwork isn't built into EKS like it is on OpenShift,
    what are all the specific steps I need to take to get it configured so I can use
    it to deploy the Red Hat Developer Hub Operator, and why is this manual setup
    nesessary?
- context:
  - '# Installing Red Hat Developer Hub on Amazon Elastic Kubernetes Service (EKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Amazon Elastic Kubernetes
    Service (EKS) using either the Operator or Helm chart. # Installing Developer
    Hub on Amazon Elastic Kubernetes Service (EKS) by using the Operator To benefit
    from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On EKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Amazon Elastic Kubernetes Service
    (EKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Amazon Elastic Kubernetes Service (EKS): The
    Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> You have set the context to the EKS cluster in your
    current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create the rhdh-operator namespace to contain
    the Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:57:17.426917'
    uuid: cc660256-ce39-4fed-909b-ef31a507cc13
  response: The Red Hat Container Registry (registry.redhat.io) contains a distribution
    of the Red Hat Developer Hub Operator, which is aimed at managing your Red Hat
    Developer Hub instance lifecycle.
  user_input: what is in the red hat containr registy?
- context:
  - '# Installing Red Hat Developer Hub on Amazon Elastic Kubernetes Service (EKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Amazon Elastic Kubernetes
    Service (EKS) using either the Operator or Helm chart. # Installing Developer
    Hub on Amazon Elastic Kubernetes Service (EKS) by using the Operator To benefit
    from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On EKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Amazon Elastic Kubernetes Service
    (EKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Amazon Elastic Kubernetes Service (EKS): The
    Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> You have set the context to the EKS cluster in your
    current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create the rhdh-operator namespace to contain
    the Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:57:25.412433'
    uuid: bc82d2aa-e1bb-4401-8a69-4735b1eca271
  response: To deploy a Red Hat Developer Hub (RHDH) instance on Amazon Elastic Kubernetes
    Service (EKS), authorized users can use either the Operator or a Helm chart.
  user_input: how to deploy Red Hat Developer Hub on Amazon Elastic Kubernetes Service
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Amazon Elastic Kubernetes Service (EKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your EKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Amazon Elastic Kubernetes Service (EKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on EKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:57:35.742920'
    uuid: 2d7066f0-d122-42c9-8efb-ecba6cece16c
  response: 'To enable the GitHub repository discovery plugin, you must author a custom
    dynamic-plugins.yaml file. By default, Developer Hub disables plugins that require
    configuration or secrets, such as the GitHub repository discovery plugin. You
    can enable it by setting "disabled: false" for the package "./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github"
    in the dynamic.plugins.yaml file.'
  user_input: how do i enabel the githb plugin?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Amazon Elastic Kubernetes Service (EKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your EKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Amazon Elastic Kubernetes Service (EKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on EKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:57:45.848632'
    uuid: 16a68781-b601-4b60-808c-61e262d14c05
  response: To configure Red Hat Developer Hub on Amazon Elastic Kubernetes Service
    (EKS), you must provision your custom Red Hat Developer Hub config maps and secrets
    to EKS before running the hub. First, you should collect all your secrets in a
    secrets.txt file. Next, you need to author a custom app-config.yaml file for the
    main configuration and a custom dynamic-plugins.yaml file to enable specific plugins.
    After creating these files, you provision them to your EKS cluster by creating
    a namespace, then creating config maps for your app-config.yaml and dynamic-plugins.yaml
    files, and creating a secret for your secrets.txt file. Specifically for EKS,
    because the Red Hat Container Registry pull-secret is not managed globally, you
    must add your pull-secret to your Red Hat Developer Hub instance namespace. This
    is done by creating a pull secret with your Red Hat credentials and then patching
    the default service account to add the image pull secret, which enables pulling
    the necessary container images.
  user_input: so for our new platform we using EKS and i need to know what all the
    steps is for provisioning the custom Red Hat Developer Hub config, like what all
    do i need to do on EKS before i can even run the hub and is there special stuff
    for secrets or the registry?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Amazon Elastic Kubernetes Service (EKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your EKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Amazon Elastic Kubernetes Service (EKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on EKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:57:57.664558'
    uuid: b27420dd-0a76-451b-a44d-9b95b0c4d167
  response: 'On Amazon Elastic Kubernetes Service (EKS), the Red Hat Container Registry
    pull-secret is not managed globally, so you must add it to your Red Hat Developer
    Hub instance namespace. First, create a pull secret using your Red Hat credentials
    to pull container images from registry.redhat.io with the command: `kubectl n
    {my rhdh namespace} create secret docker registry my rhdh pull secret \\ docker
    server=registry.redhat.io \\ docker username=<redhat_user_name> \\ docker password=<redhat_password>
    \\ docker email=<email>`. Second, to enable pulling the images, add the image
    pull secret to the default service account within the namespace using the command:
    `kubectl patch serviceaccount default \\ -p ''{\"imagePullSecrets\": [{\"name\":
    \"my-rhdh-pull-secret\"}]}'' \\ -n {my-rhdh-namespace}`.'
  user_input: What is the procedure for provisioning the Red Hat Container Registry
    pull secret to the namespace for a Red Hat Developer Hub instance on Amazon EKS?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the EKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ## Exposing your operator-based Red Hat Developer Hub instance
    on Amazon Elastic Kubernetes Service (EKS) On Amazon Elastic Kubernetes Service
    (EKS), to expose your Red Hat Developer Hub instance, Kubernetes ingresses replace
    OpenShift Container Platform routes. The Red Hat Developer Hub operator does not
    create ingresses. Therefore, to access your Developer Hub instance via a domain
    name, create the required ingresses on EKS and point your domain name to it. You
    have installed Red Hat Developer Hub by using the Red Hat Developer Hub Operator.
    You have an EKS cluster with AWS Application Load Balancer (ALB) add on installed.
    For more information, see Application load balancing on Amazon Elastic Kubernetes
    Service and Installing the AWS Load Balancer Controller add on. You have configured
    a domain name for your Developer Hub instance. The domain name can be a hosted
    zone entry on Route 53 or managed outside of AWS. For more information, see Configuring
    Amazon Route 53 as your DNS service documentation. You have an entry in the AWS
    Certificate Manager (ACM) for your preferred domain name. Make sure to keep a
    record of your Certificate ARN. You have set the context to the EKS cluster in
    your current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create an Ingress manifest file, named rhdh-ingress.yaml,
    specifying your Developer Hub service name as follows: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my-rhdh-ingress annotations: alb.ingress.kubernetes.io/scheme:
    internet-facing alb.ingress.kubernetes.io/target-type: ip # TODO: Using an ALB
    HTTPS Listener requires a certificate for your own domain. Fill in the ARN of
    your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen-ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl-redirect:
    ''443'' external-dns.alpha.kubernetes.io/hostname: <my_developer_hub_domain> spec:
    ingressClassName: alb rules: - host: <my_developer_hub_domain> http: paths: -
    path: / pathType: Prefix backend: service: name: my-rhdh-custom-resource port:
    name: http-backend EOF ``` Replace <my_developer_hub_domain> with your Developer
    Hub domain name and update the value of alb.ingress.kubernetes.io/certificate-arn
    with your certificate ARN. 2. To deploy the created Ingress, run: ```terminal
    $ kubectl n my rhdh project apply f rhdh ingress.yaml ``` Wait until the DNS name
    is responsive, indicating that your Developer Hub instance is ready for use. #'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:58:08.404242'
    uuid: 6e66e862-9ac9-4674-80e5-0128f9d09306
  response: "To expose your operator-based Red Hat Developer Hub instance on Amazon\
    \ Elastic Kubernetes Service (EKS), you must first meet several prerequisites.\
    \ You need to have installed Red Hat Developer Hub using the Operator, have an\
    \ EKS cluster with the AWS Application Load Balancer (ALB) add-on installed, and\
    \ have a configured domain name for your instance. Additionally, you must have\
    \ an entry in the AWS Certificate Manager (ACM) for your domain name and keep\
    \ a record of your Certificate ARN. Finally, your kubeconfig context must be set\
    \ to the EKS cluster. Once the prerequisites are met, the steps are as follows:\
    \ 1. Create an Ingress manifest file named `rhdh-ingress.yaml`, replacing `<my_developer_hub_domain>`\
    \ with your domain name and updating the `alb.ingress.kubernetes.io/certificate-arn`\
    \ value with your certificate ARN. The file content should be: ```yaml\napiVersion:\
    \ networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-rhdh-ingress\n  annotations:\n\
    \    alb.ingress.kubernetes.io/scheme: internet-facing\n    alb.ingress.kubernetes.io/target-type:\
    \ ip\n    # TODO: Using an ALB HTTPS Listener requires a certificate for your\
    \ own domain. Fill in the ARN of your certificate, e.g.:\n    alb.ingress.kubernetes.io/certificate-arn:\
    \ arn:aws:acm:us-xxx:xxxx:certificate/xxxxxx\n    alb.ingress.kubernetes.io/listen-ports:\
    \ '[{\"HTTP\": 80}, {\"HTTPS\":443}]'\n    alb.ingress.kubernetes.io/ssl-redirect:\
    \ '443'\n    external-dns.alpha.kubernetes.io/hostname: <my_developer_hub_domain>\n\
    spec:\n  ingressClassName: alb\n  rules:\n    - host: <my_developer_hub_domain>\n\
    \      http:\n        paths:\n          - path: /\n            pathType: Prefix\n\
    \            backend:\n              service:\n                name: my-rhdh-custom-resource\n\
    \                port:\n                  name: http-backend\nEOF\n``` 2. Deploy\
    \ the Ingress by running the command: `$ kubectl n my rhdh project apply f rhdh\
    \ ingress.yaml`. You should then wait until the DNS name is responsive."
  user_input: I'm trying to exspose my operater-based Red Hat Developer Hub instance
    on an Amazon EKS claster, wat are all the prerequisits and the spesific stepps
    I need to follow to get it working?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the EKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ## Exposing your operator-based Red Hat Developer Hub instance
    on Amazon Elastic Kubernetes Service (EKS) On Amazon Elastic Kubernetes Service
    (EKS), to expose your Red Hat Developer Hub instance, Kubernetes ingresses replace
    OpenShift Container Platform routes. The Red Hat Developer Hub operator does not
    create ingresses. Therefore, to access your Developer Hub instance via a domain
    name, create the required ingresses on EKS and point your domain name to it. You
    have installed Red Hat Developer Hub by using the Red Hat Developer Hub Operator.
    You have an EKS cluster with AWS Application Load Balancer (ALB) add on installed.
    For more information, see Application load balancing on Amazon Elastic Kubernetes
    Service and Installing the AWS Load Balancer Controller add on. You have configured
    a domain name for your Developer Hub instance. The domain name can be a hosted
    zone entry on Route 53 or managed outside of AWS. For more information, see Configuring
    Amazon Route 53 as your DNS service documentation. You have an entry in the AWS
    Certificate Manager (ACM) for your preferred domain name. Make sure to keep a
    record of your Certificate ARN. You have set the context to the EKS cluster in
    your current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create an Ingress manifest file, named rhdh-ingress.yaml,
    specifying your Developer Hub service name as follows: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my-rhdh-ingress annotations: alb.ingress.kubernetes.io/scheme:
    internet-facing alb.ingress.kubernetes.io/target-type: ip # TODO: Using an ALB
    HTTPS Listener requires a certificate for your own domain. Fill in the ARN of
    your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen-ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl-redirect:
    ''443'' external-dns.alpha.kubernetes.io/hostname: <my_developer_hub_domain> spec:
    ingressClassName: alb rules: - host: <my_developer_hub_domain> http: paths: -
    path: / pathType: Prefix backend: service: name: my-rhdh-custom-resource port:
    name: http-backend EOF ``` Replace <my_developer_hub_domain> with your Developer
    Hub domain name and update the value of alb.ingress.kubernetes.io/certificate-arn
    with your certificate ARN. 2. To deploy the created Ingress, run: ```terminal
    $ kubectl n my rhdh project apply f rhdh ingress.yaml ``` Wait until the DNS name
    is responsive, indicating that your Developer Hub instance is ready for use. #'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:58:28.467540'
    uuid: 5f4a39bd-2931-464d-b62a-683b4e35aa60
  response: To use the Developer Hub Operator with your custom configuration, you
    must author your Backstage custom resource (CR) in a my-rhdh-custom-resource.yaml
    file. This CR is created to use your custom config maps and secrets by mounting
    files provisioned in your config maps and injecting environment variables from
    your secrets. It is noted that no fields are mandatory, and you can create an
    empty Backstage CR to run Developer Hub with the default configuration.
  user_input: How do I auther a Backstge CR with my custm config?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the EKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ## Exposing your operator-based Red Hat Developer Hub instance
    on Amazon Elastic Kubernetes Service (EKS) On Amazon Elastic Kubernetes Service
    (EKS), to expose your Red Hat Developer Hub instance, Kubernetes ingresses replace
    OpenShift Container Platform routes. The Red Hat Developer Hub operator does not
    create ingresses. Therefore, to access your Developer Hub instance via a domain
    name, create the required ingresses on EKS and point your domain name to it. You
    have installed Red Hat Developer Hub by using the Red Hat Developer Hub Operator.
    You have an EKS cluster with AWS Application Load Balancer (ALB) add on installed.
    For more information, see Application load balancing on Amazon Elastic Kubernetes
    Service and Installing the AWS Load Balancer Controller add on. You have configured
    a domain name for your Developer Hub instance. The domain name can be a hosted
    zone entry on Route 53 or managed outside of AWS. For more information, see Configuring
    Amazon Route 53 as your DNS service documentation. You have an entry in the AWS
    Certificate Manager (ACM) for your preferred domain name. Make sure to keep a
    record of your Certificate ARN. You have set the context to the EKS cluster in
    your current kubeconfig. For more information, see Creating or updating a kubeconfig
    file for an Amazon EKS cluster. 1. Create an Ingress manifest file, named rhdh-ingress.yaml,
    specifying your Developer Hub service name as follows: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my-rhdh-ingress annotations: alb.ingress.kubernetes.io/scheme:
    internet-facing alb.ingress.kubernetes.io/target-type: ip # TODO: Using an ALB
    HTTPS Listener requires a certificate for your own domain. Fill in the ARN of
    your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-xxx:xxxx:certificate/xxxxxx
    alb.ingress.kubernetes.io/listen-ports: ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl-redirect:
    ''443'' external-dns.alpha.kubernetes.io/hostname: <my_developer_hub_domain> spec:
    ingressClassName: alb rules: - host: <my_developer_hub_domain> http: paths: -
    path: / pathType: Prefix backend: service: name: my-rhdh-custom-resource port:
    name: http-backend EOF ``` Replace <my_developer_hub_domain> with your Developer
    Hub domain name and update the value of alb.ingress.kubernetes.io/certificate-arn
    with your certificate ARN. 2. To deploy the created Ingress, run: ```terminal
    $ kubectl n my rhdh project apply f rhdh ingress.yaml ``` Wait until the DNS name
    is responsive, indicating that your Developer Hub instance is ready for use. #'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T15:58:36.456820'
    uuid: 0feae1e5-dc11-4afa-821e-c821ba457a24
  response: On Amazon Elastic Kubernetes Service (EKS), to expose your Red Hat Developer
    Hub instance, you must create the required Kubernetes ingresses and point your
    domain name to it. This is necessary because on EKS, Kubernetes ingresses replace
    OpenShift Container Platform routes, and the Red Hat Developer Hub operator does
    not create these ingresses.
  user_input: how do i expose my dev hub on amazn elastic kubernetes servce?
- context:
  - 'Installing Developer Hub on EKS with the Helm chart When you install the Developer
    Hub Helm chart in Elastic Kubernetes Service (EKS), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the AWS ecosystem. You have an EKS cluster with AWS Application Load Balancer
    (ALB) add on installed. For more information, see Application load balancing on
    Amazon Developer Hub and Installing the AWS Load Balancer Controller add on. You
    have configured a domain name for your Developer Hub instance. The domain name
    can be a hosted zone entry on Route 53 or managed outside of AWS. For more information,
    see Configuring Amazon Route 53 as your DNS service documentation. You have an
    entry in the AWS Certificate Manager (ACM) for your preferred domain name. Make
    sure to keep a record of your Certificate ARN. You have subscribed to Red Hat
    Container Registry (registry.redhat.io). For more information, see Red Hat Container
    Registry Authentication. You have set the context to the EKS cluster in your current
    kubeconfig. For more information, see Creating or updating a kubeconfig file for
    an Amazon EKS cluster. You have installed kubectl. For more information, see Installing
    or updating kubectl. You have installed Helm 3 or the latest. For more information,
    see Using Helm with Amazon EKS. Make sure that your system meets the minimum sizing
    requirements. See Sizing requirements for Red Hat Developer Hub. 1. Go to your
    terminal and run the following command to add the Helm chart repository containing
    the Developer Hub chart to your local Helm registry: ```terminal helm repo add
    openshift-helm-charts https://charts.openshift.io/ ``` 2. Create a pull secret
    using the following command: ```terminal kubectl create secret docker registry
    rhdh pull secret \ docker server=registry.redhat.io \ docker username=<user_name>
    \ 1 docker password=<password> \ 2 docker email=<email> 3 ``` Enter your username
    in the command. Enter your password in the command. Enter your email address in
    the command. The created pull secret is used to pull the Developer Hub images
    from the Red Hat Container Registry. 3. Create a file named values.yaml using
    the following template: ```yaml global: # TODO: Set your application domain name.
    host: <your Developer Hub domain name> route: enabled: false upstream: service:
    # NodePort is required for the ALB to route to the Service type: NodePort ingress:
    enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` 4. Run the following command in your terminal to deploy Developer Hub
    using the latest version of Helm Chart and using the values.yaml file created
    in the previous step: ```terminal helm install rhdh \ openshift helm charts/redhat
    developer hub \ [- version 1.8.0] \ values /path/to/values.yaml ``` [NOTE] ----
    For the latest chart version, see https://github.com/openshift-helm-charts/charts/tree/main/charts/redhat/redhat/redhat-developer-hub
    ---- Wait until the DNS name is responsive, indicating that your Developer Hub
    instance is ready for use.'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:58:43.933547'
    uuid: 872b2342-4b3a-4aef-99bf-b38de3245048
  response: As a prerequisite for installing Developer Hub on EKS, you must have a
    configured domain name for your instance. The context specifies that this domain
    name can be a hosted zone entry on Route 53 or, alternatively, it can be managed
    outside of AWS.
  user_input: Regarding the prerequisites for installing Developer Hub on EKS, what
    is the specified role of Route 53 in the domain name configuration?
- context:
  - 'Installing Developer Hub on EKS with the Helm chart When you install the Developer
    Hub Helm chart in Elastic Kubernetes Service (EKS), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the AWS ecosystem. You have an EKS cluster with AWS Application Load Balancer
    (ALB) add on installed. For more information, see Application load balancing on
    Amazon Developer Hub and Installing the AWS Load Balancer Controller add on. You
    have configured a domain name for your Developer Hub instance. The domain name
    can be a hosted zone entry on Route 53 or managed outside of AWS. For more information,
    see Configuring Amazon Route 53 as your DNS service documentation. You have an
    entry in the AWS Certificate Manager (ACM) for your preferred domain name. Make
    sure to keep a record of your Certificate ARN. You have subscribed to Red Hat
    Container Registry (registry.redhat.io). For more information, see Red Hat Container
    Registry Authentication. You have set the context to the EKS cluster in your current
    kubeconfig. For more information, see Creating or updating a kubeconfig file for
    an Amazon EKS cluster. You have installed kubectl. For more information, see Installing
    or updating kubectl. You have installed Helm 3 or the latest. For more information,
    see Using Helm with Amazon EKS. Make sure that your system meets the minimum sizing
    requirements. See Sizing requirements for Red Hat Developer Hub. 1. Go to your
    terminal and run the following command to add the Helm chart repository containing
    the Developer Hub chart to your local Helm registry: ```terminal helm repo add
    openshift-helm-charts https://charts.openshift.io/ ``` 2. Create a pull secret
    using the following command: ```terminal kubectl create secret docker registry
    rhdh pull secret \ docker server=registry.redhat.io \ docker username=<user_name>
    \ 1 docker password=<password> \ 2 docker email=<email> 3 ``` Enter your username
    in the command. Enter your password in the command. Enter your email address in
    the command. The created pull secret is used to pull the Developer Hub images
    from the Red Hat Container Registry. 3. Create a file named values.yaml using
    the following template: ```yaml global: # TODO: Set your application domain name.
    host: <your Developer Hub domain name> route: enabled: false upstream: service:
    # NodePort is required for the ALB to route to the Service type: NodePort ingress:
    enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` 4. Run the following command in your terminal to deploy Developer Hub
    using the latest version of Helm Chart and using the values.yaml file created
    in the previous step: ```terminal helm install rhdh \ openshift helm charts/redhat
    developer hub \ [- version 1.8.0] \ values /path/to/values.yaml ``` [NOTE] ----
    For the latest chart version, see https://github.com/openshift-helm-charts/charts/tree/main/charts/redhat/redhat/redhat-developer-hub
    ---- Wait until the DNS name is responsive, indicating that your Developer Hub
    instance is ready for use.'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:58:52.735680'
    uuid: b4c5fd85-8371-4d0e-a709-dcd46f584002
  response: Before installing the Developer Hub Helm chart in Elastic Kubernetes Service
    (EKS), you must have an EKS cluster with the AWS Application Load Balancer (ALB)
    add-on installed. You also need a configured domain name for your Developer Hub
    instance, an entry in the AWS Certificate Manager (ACM) for that domain, and a
    subscription to Red Hat Container Registry (registry.redhat.io). Additionally,
    you must have set the context to the EKS cluster in your current kubeconfig, have
    kubectl installed, and have Helm 3 or the latest installed. Finally, your system
    must meet the minimum sizing requirements for Red Hat Developer Hub.
  user_input: What are all the prerequisites and system requirements I need to have
    in place before attempting to install the Red Hat Developer Hub using the Helm
    chart on an AWS EKS cluster?
- context:
  - 'Installing Developer Hub on EKS with the Helm chart When you install the Developer
    Hub Helm chart in Elastic Kubernetes Service (EKS), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the AWS ecosystem. You have an EKS cluster with AWS Application Load Balancer
    (ALB) add on installed. For more information, see Application load balancing on
    Amazon Developer Hub and Installing the AWS Load Balancer Controller add on. You
    have configured a domain name for your Developer Hub instance. The domain name
    can be a hosted zone entry on Route 53 or managed outside of AWS. For more information,
    see Configuring Amazon Route 53 as your DNS service documentation. You have an
    entry in the AWS Certificate Manager (ACM) for your preferred domain name. Make
    sure to keep a record of your Certificate ARN. You have subscribed to Red Hat
    Container Registry (registry.redhat.io). For more information, see Red Hat Container
    Registry Authentication. You have set the context to the EKS cluster in your current
    kubeconfig. For more information, see Creating or updating a kubeconfig file for
    an Amazon EKS cluster. You have installed kubectl. For more information, see Installing
    or updating kubectl. You have installed Helm 3 or the latest. For more information,
    see Using Helm with Amazon EKS. Make sure that your system meets the minimum sizing
    requirements. See Sizing requirements for Red Hat Developer Hub. 1. Go to your
    terminal and run the following command to add the Helm chart repository containing
    the Developer Hub chart to your local Helm registry: ```terminal helm repo add
    openshift-helm-charts https://charts.openshift.io/ ``` 2. Create a pull secret
    using the following command: ```terminal kubectl create secret docker registry
    rhdh pull secret \ docker server=registry.redhat.io \ docker username=<user_name>
    \ 1 docker password=<password> \ 2 docker email=<email> 3 ``` Enter your username
    in the command. Enter your password in the command. Enter your email address in
    the command. The created pull secret is used to pull the Developer Hub images
    from the Red Hat Container Registry. 3. Create a file named values.yaml using
    the following template: ```yaml global: # TODO: Set your application domain name.
    host: <your Developer Hub domain name> route: enabled: false upstream: service:
    # NodePort is required for the ALB to route to the Service type: NodePort ingress:
    enabled: true annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme:
    internet facing # TODO: Using an ALB HTTPS Listener requires a certificate for
    your own domain. Fill in the ARN of your certificate, e.g.: alb.ingress.kubernetes.io/certificate-arn:
    arn:aws:acm:xxx:xxxx:certificate/xxxxxx alb.ingress.kubernetes.io/listen ports:
    ''[{"HTTP": 80}, {"HTTPS":443}]'' alb.ingress.kubernetes.io/ssl redirect: ''443''
    # TODO: Set your application domain name. external-dns.alpha.kubernetes.io/hostname:
    <your rhdh domain name> backstage: image: pullSecrets: - rhdh-pull-secret podSecurityContext:
    # you can assign any random value as fsGroup fsGroup: 2000 postgresql: image:
    pullSecrets: - rhdh-pull-secret primary: podSecurityContext: enabled: true # you
    can assign any random value as fsGroup fsGroup: 3000 volumePermissions: enabled:
    true ``` 4. Run the following command in your terminal to deploy Developer Hub
    using the latest version of Helm Chart and using the values.yaml file created
    in the previous step: ```terminal helm install rhdh \ openshift helm charts/redhat
    developer hub \ [- version 1.8.0] \ values /path/to/values.yaml ``` [NOTE] ----
    For the latest chart version, see https://github.com/openshift-helm-charts/charts/tree/main/charts/redhat/redhat/redhat-developer-hub
    ---- Wait until the DNS name is responsive, indicating that your Developer Hub
    instance is ready for use.'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T15:58:58.673637'
    uuid: 398ecb62-33a4-43fc-8fe1-6c4272a7cbd5
  response: 'To install Developer Hub on EKS with a Helm chart, you must first meet
    several prerequisites: have an EKS cluster with the AWS Application Load Balancer
    (ALB) add-on, a configured domain name, an AWS Certificate Manager (ACM) entry
    for your domain, a subscription to Red Hat Container Registry, kubectl and Helm
    3 installed, and ensure your system meets minimum sizing requirements. The installation
    process involves four main steps: 1. Add the Helm chart repository by running
    `helm repo add openshift-helm-charts https://charts.openshift.io/`. 2. Create
    a pull secret for the Red Hat Container Registry using the `kubectl create secret
    docker-registry` command. 3. Create a `values.yaml` file to configure settings
    like your domain name, ingress annotations for ALB, and pull secrets. 4. Deploy
    Developer Hub by running the command `helm install rhdh openshift-helm-charts/redhat-developer-hub
    -f /path/to/values.yaml`.'
  user_input: how to install Developer Hub with helm chart
- context:
  - '# Telemetry data collection and analysis # Telemetry data collection and analysis
    The telemetry data collection feature helps in collecting and analyzing the telemetry
    data to improve your experience with Red Hat Developer Hub. This feature is enabled
    by default. Red Hat collects and analyzes the following data: Web Analytics::
    Web Analytics use the Segment tool. It is the tracking of user behavior and interactions
    with Red Hat Developer Hub. Specifically, it tracks the following: * Events of
    page visits and clicks on links or buttons. * System-related information, for
    example, locale, time zone, user agent including browser and operating system
    details. * Page-related information, for example, title, category, extension name,
    URL, path, referrer, and search parameters. * Anonymized IP addresses, recorded
    as 0.0.0.0. * Anonymized username hashes, which are unique identifiers used solely
    to identify the number of unique users of the RHDH application. System Observability::
    System Observability uses the OpenTelemetry tool. It is the tracking of the performance
    of the RHDH. Specifically, it tracks the following metrics: * Key system metrics
    such as CPU usage, memory usage, and other performance indicators. * Information
    about system components, such as the locale, time zone, and user agent (including
    details of the browser and operating system). * Traces and logs monitor system
    processes, allowing you to troubleshoot potential issues impacting the performance
    of RHDH. With RHDH, you can customize the Web Analytics and System Observability
    configuration based on your needs. # Disabling telemetry data collection in RHDH
    To disable telemetry data collection, you must disable the analytics-provider-segment
    plugin either using the Helm Chart or the Red Hat Developer Hub Operator configuration.
    As an administrator, you can disable the telemetry data collection feature based
    on your needs. For example, in an air-gapped environment, you can disable this
    feature to avoid needless outbound requests affecting the responsiveness of the
    RHDH application. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:59:07.430027'
    uuid: 0fdabc3e-d5d4-4a84-924f-1aea89346943
  response: 'Web Analytics in Red Hat Developer Hub tracks user behavior and interactions
    using the Segment tool. Specifically, it collects the following data: events of
    page visits and clicks on links or buttons; system-related information like locale,
    time zone, and user agent (including browser and OS details); page-related information
    such as title, category, extension name, URL, path, referrer, and search parameters;
    anonymized IP addresses recorded as 0.0.0.0; and anonymized username hashes, which
    are used to identify the number of unique users.'
  user_input: What data does Red Hat Developer Hub Web Analytics collect?
- context:
  - '# Telemetry data collection and analysis # Telemetry data collection and analysis
    The telemetry data collection feature helps in collecting and analyzing the telemetry
    data to improve your experience with Red Hat Developer Hub. This feature is enabled
    by default. Red Hat collects and analyzes the following data: Web Analytics::
    Web Analytics use the Segment tool. It is the tracking of user behavior and interactions
    with Red Hat Developer Hub. Specifically, it tracks the following: * Events of
    page visits and clicks on links or buttons. * System-related information, for
    example, locale, time zone, user agent including browser and operating system
    details. * Page-related information, for example, title, category, extension name,
    URL, path, referrer, and search parameters. * Anonymized IP addresses, recorded
    as 0.0.0.0. * Anonymized username hashes, which are unique identifiers used solely
    to identify the number of unique users of the RHDH application. System Observability::
    System Observability uses the OpenTelemetry tool. It is the tracking of the performance
    of the RHDH. Specifically, it tracks the following metrics: * Key system metrics
    such as CPU usage, memory usage, and other performance indicators. * Information
    about system components, such as the locale, time zone, and user agent (including
    details of the browser and operating system). * Traces and logs monitor system
    processes, allowing you to troubleshoot potential issues impacting the performance
    of RHDH. With RHDH, you can customize the Web Analytics and System Observability
    configuration based on your needs. # Disabling telemetry data collection in RHDH
    To disable telemetry data collection, you must disable the analytics-provider-segment
    plugin either using the Helm Chart or the Red Hat Developer Hub Operator configuration.
    As an administrator, you can disable the telemetry data collection feature based
    on your needs. For example, in an air-gapped environment, you can disable this
    feature to avoid needless outbound requests affecting the responsiveness of the
    RHDH application. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:59:16.490710'
    uuid: 8c1cdb41-8e41-49be-b2e3-87c1895f937c
  response: To disable telemetry data collection, you must disable the analytics-provider-segment
    plugin using the Helm Chart. As an administrator, you can disable the telemetry
    data collection feature based on your needs. For example, in an air-gapped environment,
    you can disable this feature to avoid needless outbound requests affecting the
    responsiveness of the RHDH application.
  user_input: how do i use the Helm Chart to turn off all that telemetry data collection
    stuff?
- context:
  - '# Telemetry data collection and analysis # Telemetry data collection and analysis
    The telemetry data collection feature helps in collecting and analyzing the telemetry
    data to improve your experience with Red Hat Developer Hub. This feature is enabled
    by default. Red Hat collects and analyzes the following data: Web Analytics::
    Web Analytics use the Segment tool. It is the tracking of user behavior and interactions
    with Red Hat Developer Hub. Specifically, it tracks the following: * Events of
    page visits and clicks on links or buttons. * System-related information, for
    example, locale, time zone, user agent including browser and operating system
    details. * Page-related information, for example, title, category, extension name,
    URL, path, referrer, and search parameters. * Anonymized IP addresses, recorded
    as 0.0.0.0. * Anonymized username hashes, which are unique identifiers used solely
    to identify the number of unique users of the RHDH application. System Observability::
    System Observability uses the OpenTelemetry tool. It is the tracking of the performance
    of the RHDH. Specifically, it tracks the following metrics: * Key system metrics
    such as CPU usage, memory usage, and other performance indicators. * Information
    about system components, such as the locale, time zone, and user agent (including
    details of the browser and operating system). * Traces and logs monitor system
    processes, allowing you to troubleshoot potential issues impacting the performance
    of RHDH. With RHDH, you can customize the Web Analytics and System Observability
    configuration based on your needs. # Disabling telemetry data collection in RHDH
    To disable telemetry data collection, you must disable the analytics-provider-segment
    plugin either using the Helm Chart or the Red Hat Developer Hub Operator configuration.
    As an administrator, you can disable the telemetry data collection feature based
    on your needs. For example, in an air-gapped environment, you can disable this
    feature to avoid needless outbound requests affecting the responsiveness of the
    RHDH application. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T15:59:26.477885'
    uuid: b69d1974-d54d-4706-ba73-ee5b5c97700a
  response: System Observability uses the OpenTelemetry tool to track the performance
    of RHDH. It specifically tracks key system metrics such as CPU usage, memory usage,
    and other performance indicators. It also collects information about system components
    like the locale, time zone, and user agent (including browser and operating system
    details). Additionally, it tracks traces and logs to monitor system processes,
    which allows for troubleshooting potential issues that impact the performance
    of RHDH.
  user_input: Can you explain what data is gathered by the Systm Observability feature
    for performence monitoring in RHDH?
- context:
  - "Disabling telemetry data collection using the Operator You can disable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to true. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to true. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true ``` 2. Set the value\
    \ of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Disabling telemetry data collection using the Helm Chart You can\
    \ disable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to disable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ ![disabling telemetry] * If you have configured the plugin, find the Package\
    \ specification of the dynamic plugin to install. It should be usable by the npm\
    \ pack command. field with the ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Select the Disable the plugin checkbox. 5. Click Upgrade. * Using\
    \ YAML view 1. Perform one of the following steps: * If you have not configured\
    \ the plugin, add the following YAML code in your values.yaml Helm configuration\
    \ file: ```yaml # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true # ... ``` If you\
    \ have configured the plugin, search it in your Helm configuration and set the\
    \ value of the plugins.disabled parameter to true. 2. Click Upgrade. #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T15:59:39.991681'
    uuid: 4d5a4944-cd2a-4018-b28d-86e57ded232f
  response: You can disable the telemetry data collection feature using either the
    Operator or the Helm Chart, provided you are logged in as an administrator in
    the OpenShift Container Platform web console. To use the Operator, you set the
    `plugins.disabled` parameter to `true` for the `analytics-provider-segment` plugin
    within the `dynamic-plugins-rhdh` ConfigMap, and then set the `dynamicPluginsConfigMapName`
    parameter in your Backstage custom resource to the name of that config map. To
    use the Helm Chart, you upgrade the Helm release and either select the 'Disable
    the plugin' checkbox in the Form view or set the `plugins.disabled` parameter
    to `true` in the YAML view for the `backstage-community-plugin-analytics-provider-segment`
    plugin before clicking Upgrade.
  user_input: how i turn off telemetry in OpenShift Container Platform?
- context:
  - "Disabling telemetry data collection using the Operator You can disable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to true. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to true. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true ``` 2. Set the value\
    \ of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Disabling telemetry data collection using the Helm Chart You can\
    \ disable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to disable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ ![disabling telemetry] * If you have configured the plugin, find the Package\
    \ specification of the dynamic plugin to install. It should be usable by the npm\
    \ pack command. field with the ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Select the Disable the plugin checkbox. 5. Click Upgrade. * Using\
    \ YAML view 1. Perform one of the following steps: * If you have not configured\
    \ the plugin, add the following YAML code in your values.yaml Helm configuration\
    \ file: ```yaml # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true # ... ``` If you\
    \ have configured the plugin, search it in your Helm configuration and set the\
    \ value of the plugins.disabled parameter to true. 2. Click Upgrade. #"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:00:27.211731'
    uuid: e4e71731-03b5-4fcf-8ebc-deade1cb3be2
  response: 'You can disable the telemetry data collection feature in Red Hat Developer
    Hub using two methods: the Operator or the Helm Chart. When using the Operator,
    you modify the `dynamic-plugins-rhdh` ConfigMap to set the `plugins.disabled`
    parameter to `true` for the `analytics-provider-segment` plugin. When using the
    Helm Chart, you upgrade the Helm release, which can be done through the Form view
    by selecting the "Disable the plugin" checkbox or through the YAML view by setting
    the `plugins.disabled` parameter to `true`.'
  user_input: What methods are available to disable telemetry data collection in Red
    Hat Developer Hub?
- context:
  - "Disabling telemetry data collection using the Operator You can disable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to true. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to true. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true ``` 2. Set the value\
    \ of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Disabling telemetry data collection using the Helm Chart You can\
    \ disable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to disable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ ![disabling telemetry] * If you have configured the plugin, find the Package\
    \ specification of the dynamic plugin to install. It should be usable by the npm\
    \ pack command. field with the ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Select the Disable the plugin checkbox. 5. Click Upgrade. * Using\
    \ YAML view 1. Perform one of the following steps: * If you have not configured\
    \ the plugin, add the following YAML code in your values.yaml Helm configuration\
    \ file: ```yaml # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: true # ... ``` If you\
    \ have configured the plugin, search it in your Helm configuration and set the\
    \ value of the plugins.disabled parameter to true. 2. Click Upgrade. #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:00:40.840100'
    uuid: 030082dc-9438-4e0e-9b84-c7ef81ce3f4a
  response: "If you are using the Operator and have not created the ConfigMap file,\
    \ you can create it with the following YAML code: ```yaml\nkind: ConfigMap\napiVersion:\
    \ v1\nmetadata:\n  name: dynamic plugins rhdh\ndata:\n  dynamic plugins.yaml:\
    \ |\n    includes: dynamic plugins.default.yaml\n    plugins:\n      package:\
    \ './dynamic plugins/dist/backstage community plugin analytics provider segment'\n\
    \      disabled: true\n```. If you are using the Helm Chart and have not configured\
    \ the plugin, you can add the following YAML code to your values.yaml Helm configuration\
    \ file: ```yaml\n# ...\nglobal:\n  dynamic:\n    plugins:\n      package: './dynamic\
    \ plugins/dist/backstage community plugin analytics provider segment'\n      disabled:\
    \ true\n# ...\n```"
  user_input: What is the specific YAML configuration required to disable the telemetry
    data collection plugin in Red Hat Developer Hub if a configuration file does not
    already exist?
- context:
  - "Enabling telemetry data collection in RHDH The telemetry data collection feature\
    \ is enabled by default. However, if you have disabled the feature and want to\
    \ re-enable it, you must enable the analytics-provider-segment plugin either by\
    \ using the Helm Chart or the Red Hat Developer Hub Operator configuration. ##\
    \ Enabling telemetry data collection using the Operator You can enable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to false. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to false. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: false ``` 2. Set the\
    \ value of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Enabling telemetry data collection using the Helm Chart You can\
    \ enable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to enable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ * If you have configured the plugin, find the Package specification of the dynamic\
    \ plugin to install. It should be usable by the npm pack command. field with the\
    \ ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Clear the Disable the plugin checkbox. 5. Click Upgrade. * Using YAML\
    \ view 1. Perform one of the following steps: * If you have not configured the\
    \ plugin, add the following YAML code in your Helm configuration file: ```yaml\
    \ # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage community\
    \ plugin analytics provider segment' disabled: false # ... ``` If you have configured\
    \ the plugin, search it in your Helm configuration and set the value of the plugins.disabled\
    \ parameter to false. 2. Click Upgrade. #"
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:00:53.159732'
    uuid: 9ce3d892-a94c-4198-b2aa-4d8c29d5cdc3
  response: 'To enable telemetry data collection using the Operator, you must set
    the value of the "dynamicPluginsConfigMapName" parameter to the name of your "dynamic-plugins-rhdh"
    config map within your Backstage custom resource. The configuration should look
    like: spec: application: dynamicPluginsConfigMapName: dynamic-plugins-rhdh.'
  user_input: Backstage custom resource telemetry configuration
- context:
  - "Enabling telemetry data collection in RHDH The telemetry data collection feature\
    \ is enabled by default. However, if you have disabled the feature and want to\
    \ re-enable it, you must enable the analytics-provider-segment plugin either by\
    \ using the Helm Chart or the Red Hat Developer Hub Operator configuration. ##\
    \ Enabling telemetry data collection using the Operator You can enable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to false. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to false. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: false ``` 2. Set the\
    \ value of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Enabling telemetry data collection using the Helm Chart You can\
    \ enable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to enable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ * If you have configured the plugin, find the Package specification of the dynamic\
    \ plugin to install. It should be usable by the npm pack command. field with the\
    \ ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Clear the Disable the plugin checkbox. 5. Click Upgrade. * Using YAML\
    \ view 1. Perform one of the following steps: * If you have not configured the\
    \ plugin, add the following YAML code in your Helm configuration file: ```yaml\
    \ # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage community\
    \ plugin analytics provider segment' disabled: false # ... ``` If you have configured\
    \ the plugin, search it in your Helm configuration and set the value of the plugins.disabled\
    \ parameter to false. 2. Click Upgrade. #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:01:02.633625'
    uuid: c7d9473e-e934-40b9-83bf-101dc6eaaf29
  response: "To configure your Backstage custom resource, you must set the value of\
    \ the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map. The YAML should be configured as follows: \n```yaml\n# ...\nspec:\n\
    \  application:\n    dynamicPluginsConfigMapName: dynamic plugins rhdh\n# ...\n\
    ```"
  user_input: what i need to do for my Backstage custom resource so the dynamic plugins
    config map name is set right?
- context:
  - "Enabling telemetry data collection in RHDH The telemetry data collection feature\
    \ is enabled by default. However, if you have disabled the feature and want to\
    \ re-enable it, you must enable the analytics-provider-segment plugin either by\
    \ using the Helm Chart or the Red Hat Developer Hub Operator configuration. ##\
    \ Enabling telemetry data collection using the Operator You can enable the telemetry\
    \ data collection feature by using the Operator. You have logged in as an administrator\
    \ in the OpenShift Container Platform web console. You have installed Red Hat\
    \ Developer Hub on OpenShift Container Platform using the Operator. 1. Perform\
    \ one of the following steps: * If you have created the dynamic-plugins-rhdh ConfigMap\
    \ file and not configured the analytics-provider-segment plugin, add the plugin\
    \ to the list of plugins and set its plugins.disabled parameter to false. * If\
    \ you have created the dynamic-plugins-rhdh ConfigMap file and configured the\
    \ analytics-provider-segment plugin, search the plugin in the list of plugins\
    \ and set its plugins.disabled parameter to false. * If you have not created the\
    \ ConfigMap file, create it with the following YAML code: ```yaml kind: ConfigMap\
    \ apiVersion: v1 metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml:\
    \ | includes: dynamic plugins.default.yaml plugins: package: './dynamic plugins/dist/backstage\
    \ community plugin analytics provider segment' disabled: false ``` 2. Set the\
    \ value of the dynamicPluginsConfigMapName parameter to the name of your dynamic-plugins-rhdh\
    \ config map in your Backstage custom resource: ```yaml # ... spec: application:\
    \ dynamicPluginsConfigMapName: dynamic plugins rhdh # ... ``` 3. Save the configuration\
    \ changes. ## Enabling telemetry data collection using the Helm Chart You can\
    \ enable the telemetry data collection feature by using the Helm Chart. You have\
    \ logged in as an administrator in the OpenShift Container Platform web console.\
    \ You have installed Red Hat Developer Hub on OpenShift Container Platform using\
    \ the Helm Chart. 1. In the Developer perspective of the OpenShift Container Platform\
    \ web console, go to the Helm view to see the list of Helm releases. 2. Click\
    \ the overflow menu on the Helm release that you want to use and select Upgrade.\
    \ [NOTE] ---- You can also create a new Helm release by clicking the Create button\
    \ and edit the configuration to enable telemetry. ---- 3. Use either the Form\
    \ view or YAML view to edit the Helm configuration: * Using Form view 1. Expand\
    \ Root Schema \u2192 global \u2192 Dynamic plugins configuration. \u2192 List\
    \ of dynamic plugins that should be installed in the backstage application. 2.\
    \ Click the Add list of dynamic plugins that should be installed in the backstage\
    \ application. link. 3. Perform one of the following steps: * If you have not\
    \ configured the plugin, add the following value in the Package specification\
    \ of the dynamic plugin to install. It should be usable by the npm pack command.\
    \ field: ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ * If you have configured the plugin, find the Package specification of the dynamic\
    \ plugin to install. It should be usable by the npm pack command. field with the\
    \ ./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\
    \ value. 4. Clear the Disable the plugin checkbox. 5. Click Upgrade. * Using YAML\
    \ view 1. Perform one of the following steps: * If you have not configured the\
    \ plugin, add the following YAML code in your Helm configuration file: ```yaml\
    \ # ... global: dynamic: plugins: package: './dynamic plugins/dist/backstage community\
    \ plugin analytics provider segment' disabled: false # ... ``` If you have configured\
    \ the plugin, search it in your Helm configuration and set the value of the plugins.disabled\
    \ parameter to false. 2. Click Upgrade. #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:01:13.435725'
    uuid: 634d3d42-1978-4a8a-80ea-d284b3fb6542
  response: "To enable the telemetry data collection feature using the Helm Chart,\
    \ you must be logged in as an administrator in the OpenShift Container Platform\
    \ web console and have installed Red Hat Developer Hub using the Helm Chart. First,\
    \ navigate to the Helm view in the Developer perspective to see the list of Helm\
    \ releases. Click the overflow menu on the relevant Helm release and select Upgrade.\
    \ From there, you can use either the Form view or the YAML view to edit the configuration.\
    \ \n\nUsing the Form view:\n1. Expand Root Schema \u2192 global \u2192 Dynamic\
    \ plugins configuration. \u2192 List of dynamic plugins that should be installed\
    \ in the backstage application.\n2. Click the \"Add list of dynamic plugins that\
    \ should be installed in the backstage application.\" link.\n3. If you have not\
    \ configured the plugin, add \"./dynamic-plugins/dist/backstage-community-plugin-analytics-provider-segment\"\
    \ in the \"Package specification of the dynamic plugin to install\" field. If\
    \ you have already configured it, find the field with that value.\n4. Clear the\
    \ \"Disable the plugin\" checkbox.\n5. Click Upgrade.\n\nUsing the YAML view:\n\
    1. If you have not configured the plugin, add the following YAML code to your\
    \ configuration file: \n```yaml\n# ...\nglobal:\n  dynamic:\n    plugins:\n  \
    \    - package: './dynamic plugins/dist/backstage community plugin analytics provider\
    \ segment'\n        disabled: false\n# ...\n```\nIf the plugin is already configured,\
    \ find it in your Helm configuration and set the value of the `plugins.disabled`\
    \ parameter to `false`.\n2. Click Upgrade."
  user_input: As a platform lead, I need to document the proccess for re-enabling
    telemetry data colection in our RHDH instance that was installed with a Helmm
    chart, can you give me the detailed, step-by-step instructions for both the Form
    view and the YAML view methhods?
- context:
  - "Customizing Segment source The analytics-provider-segment plugin sends the collected\
    \ web analytics data to Red Hat by default. However, you can configure a new Segment\
    \ source that receives web analytics data based on your needs. For configuration,\
    \ you need a unique Segment write key that points to the Segment source. [NOTE]\
    \ ---- Create your own web analytics data collection notice for your application\
    \ users. ---- ## Customizing Segment source using the Operator You can configure\
    \ integration with your Segment source by using the Red Hat Developer Hub Operator.\
    \ You have logged in as an administrator in the OpenShift Container Platform web\
    \ console. You have installed Red Hat Developer Hub on OpenShift Container Platform\
    \ using the Operator. 1. Add the following YAML code in your Backstage custom\
    \ resource (CR): ```yaml # ... spec: application: extraEnvs: envs: name: SEGMENT_WRITE_KEY\
    \ value: <segment_key> 1 # ... ``` Replace <segment_key> with a unique identifier\
    \ for your Segment source. 2. Save the configuration changes. ## Customizing Segment\
    \ source using the Helm Chart You can configure integration with your Segment\
    \ source by using the Red Hat Developer Hub Helm Chart. You have logged in as\
    \ an administrator in the OpenShift Container Platform web console. You have installed\
    \ Red Hat Developer Hub on OpenShift Container Platform using the Helm Chart.\
    \ 1. In the Developer perspective of the OpenShift Container Platform web console,\
    \ go to the Helm view to see the list of Helm releases. 2. Click the overflow\
    \ menu on the Helm release that you want to use and select Upgrade. 3. Use either\
    \ the Form view or YAML view to edit the Helm configuration: * Using Form view\
    \ 1. Expand Root Schema \u2192 Backstage Chart Schema \u2192 Backstage Parameters\
    \ \u2192 Backstage container environment variables. 2. Click the Add Backstage\
    \ container environment variables link. 3. Enter the name and value of the Segment\
    \ key. ![segment source helm] 4. Click Upgrade. * Using YAML view 1. Add the following\
    \ YAML code in your Helm configuration file: ```yaml # ... upstream: backstage:\
    \ extraEnvVars: name: SEGMENT_WRITE_KEY value: <segment_key> 1 # ... ``` Replace\
    \ <segment_key> with a unique identifier for your Segment source. 2. Click Upgrade."
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:01:24.288163'
    uuid: 896779e4-0587-47ba-aed1-2b81e35f009c
  response: To configure a new Segment source that receives web analytics data, you
    need a unique Segment write key. You can configure this integration using either
    the Red Hat Developer Hub Operator or the Helm Chart. With the Operator, you add
    an environment variable named `SEGMENT_WRITE_KEY` with your key as the value to
    your Backstage custom resource (CR) under `spec.application.extraEnvs`. With the
    Helm Chart, you can upgrade the release and either use the Form view to add the
    `SEGMENT_WRITE_KEY` under `Backstage container environment variables` or use the
    YAML view to add it under `upstream.backstage.extraEnvVars`.
  user_input: Backstage configure custom Segment source
- context:
  - "Customizing Segment source The analytics-provider-segment plugin sends the collected\
    \ web analytics data to Red Hat by default. However, you can configure a new Segment\
    \ source that receives web analytics data based on your needs. For configuration,\
    \ you need a unique Segment write key that points to the Segment source. [NOTE]\
    \ ---- Create your own web analytics data collection notice for your application\
    \ users. ---- ## Customizing Segment source using the Operator You can configure\
    \ integration with your Segment source by using the Red Hat Developer Hub Operator.\
    \ You have logged in as an administrator in the OpenShift Container Platform web\
    \ console. You have installed Red Hat Developer Hub on OpenShift Container Platform\
    \ using the Operator. 1. Add the following YAML code in your Backstage custom\
    \ resource (CR): ```yaml # ... spec: application: extraEnvs: envs: name: SEGMENT_WRITE_KEY\
    \ value: <segment_key> 1 # ... ``` Replace <segment_key> with a unique identifier\
    \ for your Segment source. 2. Save the configuration changes. ## Customizing Segment\
    \ source using the Helm Chart You can configure integration with your Segment\
    \ source by using the Red Hat Developer Hub Helm Chart. You have logged in as\
    \ an administrator in the OpenShift Container Platform web console. You have installed\
    \ Red Hat Developer Hub on OpenShift Container Platform using the Helm Chart.\
    \ 1. In the Developer perspective of the OpenShift Container Platform web console,\
    \ go to the Helm view to see the list of Helm releases. 2. Click the overflow\
    \ menu on the Helm release that you want to use and select Upgrade. 3. Use either\
    \ the Form view or YAML view to edit the Helm configuration: * Using Form view\
    \ 1. Expand Root Schema \u2192 Backstage Chart Schema \u2192 Backstage Parameters\
    \ \u2192 Backstage container environment variables. 2. Click the Add Backstage\
    \ container environment variables link. 3. Enter the name and value of the Segment\
    \ key. ![segment source helm] 4. Click Upgrade. * Using YAML view 1. Add the following\
    \ YAML code in your Helm configuration file: ```yaml # ... upstream: backstage:\
    \ extraEnvVars: name: SEGMENT_WRITE_KEY value: <segment_key> 1 # ... ``` Replace\
    \ <segment_key> with a unique identifier for your Segment source. 2. Click Upgrade."
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:01:34.849599'
    uuid: 768de5c7-3e46-4ec0-988f-3d12cffecfb8
  response: "To configure integration with your Segment source using the Red Hat Developer\
    \ Hub Helm Chart, you must be logged in as an administrator in the OpenShift Container\
    \ Platform web console. First, go to the Helm view in the Developer perspective\
    \ to see the list of Helm releases. Click the overflow menu on the release you\
    \ want to use and select Upgrade. You can then edit the Helm configuration using\
    \ either the Form view or the YAML view. Using the Form view, expand Root Schema\
    \ \u2192 Backstage Chart Schema \u2192 Backstage Parameters \u2192 Backstage container\
    \ environment variables, click the 'Add Backstage container environment variables'\
    \ link, enter the name and value of the Segment key, and then click Upgrade. Using\
    \ the YAML view, add the following code to your Helm configuration file, replacing\
    \ <segment_key> with a unique identifier for your Segment source, and then click\
    \ Upgrade: 'upstream: backstage: extraEnvVars: name: SEGMENT_WRITE_KEY value:\
    \ <segment_key>'."
  user_input: What are the specific steps for configuring a new Segment source with
    a unique write key in Red Hat Developer Hub on OpenShift using the Helm Chart
    upgrade process?
- context:
  - "Customizing Segment source The analytics-provider-segment plugin sends the collected\
    \ web analytics data to Red Hat by default. However, you can configure a new Segment\
    \ source that receives web analytics data based on your needs. For configuration,\
    \ you need a unique Segment write key that points to the Segment source. [NOTE]\
    \ ---- Create your own web analytics data collection notice for your application\
    \ users. ---- ## Customizing Segment source using the Operator You can configure\
    \ integration with your Segment source by using the Red Hat Developer Hub Operator.\
    \ You have logged in as an administrator in the OpenShift Container Platform web\
    \ console. You have installed Red Hat Developer Hub on OpenShift Container Platform\
    \ using the Operator. 1. Add the following YAML code in your Backstage custom\
    \ resource (CR): ```yaml # ... spec: application: extraEnvs: envs: name: SEGMENT_WRITE_KEY\
    \ value: <segment_key> 1 # ... ``` Replace <segment_key> with a unique identifier\
    \ for your Segment source. 2. Save the configuration changes. ## Customizing Segment\
    \ source using the Helm Chart You can configure integration with your Segment\
    \ source by using the Red Hat Developer Hub Helm Chart. You have logged in as\
    \ an administrator in the OpenShift Container Platform web console. You have installed\
    \ Red Hat Developer Hub on OpenShift Container Platform using the Helm Chart.\
    \ 1. In the Developer perspective of the OpenShift Container Platform web console,\
    \ go to the Helm view to see the list of Helm releases. 2. Click the overflow\
    \ menu on the Helm release that you want to use and select Upgrade. 3. Use either\
    \ the Form view or YAML view to edit the Helm configuration: * Using Form view\
    \ 1. Expand Root Schema \u2192 Backstage Chart Schema \u2192 Backstage Parameters\
    \ \u2192 Backstage container environment variables. 2. Click the Add Backstage\
    \ container environment variables link. 3. Enter the name and value of the Segment\
    \ key. ![segment source helm] 4. Click Upgrade. * Using YAML view 1. Add the following\
    \ YAML code in your Helm configuration file: ```yaml # ... upstream: backstage:\
    \ extraEnvVars: name: SEGMENT_WRITE_KEY value: <segment_key> 1 # ... ``` Replace\
    \ <segment_key> with a unique identifier for your Segment source. 2. Click Upgrade."
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:01:44.830349'
    uuid: 5b08e2c0-70f6-44c3-bb6d-b228d3922e7e
  response: To customize the Segment source in Red Hat Developer Hub, you need a unique
    Segment write key. The configuration process depends on your installation method
    on OpenShift Container Platform. If you used the Operator, you must add the `SEGMENT_WRITE_KEY`
    environment variable with your key as the value to your Backstage custom resource
    (CR) under `spec.application.extraEnvs.envs`. If you used the Helm Chart, you
    can upgrade the release and either use the Form view to add the `SEGMENT_WRITE_KEY`
    environment variable or use the YAML view to add it under `upstream.backstage.extraEnvVars`.
    In both methods, you must replace `<segment_key>` with your unique identifier
    for the Segment source. It is also noted that you should create your own web analytics
    data collection notice for your application users.
  user_input: How do I configure Red Hat Developer Hub to use a custom Segment source
    for web analytics?
- context:
  - '# Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub # Interacting
    with Red Hat Developer Lightspeed for Red Hat Developer Hub ## About Developer
    Lightspeed for RHDH [IMPORTANT] ---- This section describes Developer Preview
    features in the Red Hat Developer Lightspeed for Red Hat Developer Hub plugin.
    Developer Preview features are not supported by Red Hat in any way and are not
    functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    This early access program enables customers to share feedback on the user experience,
    features, capabilities, and any issues encountered. Your input helps ensure that
    Developer Lightspeed for RHDH better meets your needs when it is officially released
    and made generally available. Red Hat Developer Lightspeed for Red Hat Developer
    Hub (Developer Lightspeed for RHDH) is a virtual assistant powered by generative
    Artificial Intelligence (AI) designed for Red Hat Developer Hub(RHDH). The assistant
    offers in-depth insights into RHDH, including its wide range of capabilities.
    You can interact with this assistant to explore and learn more about RHDH in greater
    detail. Developer Lightspeed for RHDH provides a natural language interface within
    the RHDH console, helping you easily find information about the product, understand
    its features, and get answers to your questions. You can experience Developer
    Lightspeed for RHDH Developer Preview by installing the Developer Lightspeed for
    Red Hat Developer Hub plugin within an existing RHDH instance. Alternatively,
    if you prefer to test it locally first, you can try Developer Lightspeed for RHDH
    using RHDH Local. ![developer lightspeed 1 8 0] RHDH Local ## Supported architecture
    for Red Hat Developer Lightspeed for Red Hat Developer Hub Developer Lightspeed
    for RHDH is available as a plugin on all platforms that host RHDH. It requires
    two sidecar containers: the Lightspeed Core Service (LCS) and the Llama Stack
    service. The LCS container acts as the intermediary layer, which interfaces with
    and manages the Llama Stack service. ![developer lightspeed architecture 1 8 0]
    Red Hat Developer Hub Life Cycle and supported platforms ### About Lightspeed
    Core Service and Llama Stack The Lightspeed Core Service and Llama Stack deploy
    together as sidecar containers to augment RHDH functionality. The Llama Stack
    delivers the augmented functionality by integrating and managing core components,
    which include: Large language model (LLM) inference providers Model Context Protocol
    (MCP) or Retrieval Augmented Generation (RAG) tool runtime providers Safety providers
    Vector database settings The Lightspeed Core Service serves as the Llama Stack
    service intermediary. It manages the operational configuration and key data, specifically:
    User feedback collection MCP server configuration Conversation history Llama Stack
    provides the inference functionality that LCS uses to process requests. For more
    information, see What is Llama Stack. The Red Hat Developer Lightspeed for Red
    Hat Developer Hub plugin in RHDH sends prompts and receives LLM responses through
    the LCS sidecar. LCS then uses the Llama Stack sidecar service to perform inference
    and MCP or RAG tool calling. [NOTE] ---- Red Hat Developer Lightspeed for Red
    Hat Developer Hub is a Developer Preview release. You must manually deploy the
    Lightspeed Core Service and Llama Stack sidecar containers, and install the Red
    Hat Developer Lightspeed for Red Hat Developer Hub plugin on your RHDH instance.
    ---- ## Retrieval augmented generation (RAG) embeddings The Red Hat Developer
    Hub documentation serves as the Retrieval-Augmented Generation (RAG) data source.
    RAG initialization occurs through an initialization container, which copies the
    RAG data to a shared volume. The Llama Stack sidecar then mounts this shared volume
    to access the RAG data. The Llama Stack service uses the resulting RAG embeddings
    in the vector database as a reference. This allows the service to provide citations
    to production documentation during the inference process. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:01:52.445002'
    uuid: e19df854-5f7f-4e01-a5e4-20bfea06a572
  response: 'Red Hat Developer Lightspeed for Red Hat Developer Hub is a virtual assistant
    powered by generative Artificial Intelligence (AI) designed for Red Hat Developer
    Hub (RHDH). It provides a natural language interface within the RHDH console to
    help you find information about the product and understand its features. As a
    Developer Preview feature, it is not production-ready. Its architecture is a plugin
    that requires two sidecar containers: the Lightspeed Core Service (LCS) and the
    Llama Stack service. The LCS container serves as an intermediary layer that manages
    the Llama Stack service, which integrates core components like Large language
    model (LLM) inference providers and Retrieval Augmented Generation (RAG) tool
    runtime providers.'
  user_input: what is Red Hat Developer Lightspeed and what is its architecture
- context:
  - '# Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub # Interacting
    with Red Hat Developer Lightspeed for Red Hat Developer Hub ## About Developer
    Lightspeed for RHDH [IMPORTANT] ---- This section describes Developer Preview
    features in the Red Hat Developer Lightspeed for Red Hat Developer Hub plugin.
    Developer Preview features are not supported by Red Hat in any way and are not
    functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    This early access program enables customers to share feedback on the user experience,
    features, capabilities, and any issues encountered. Your input helps ensure that
    Developer Lightspeed for RHDH better meets your needs when it is officially released
    and made generally available. Red Hat Developer Lightspeed for Red Hat Developer
    Hub (Developer Lightspeed for RHDH) is a virtual assistant powered by generative
    Artificial Intelligence (AI) designed for Red Hat Developer Hub(RHDH). The assistant
    offers in-depth insights into RHDH, including its wide range of capabilities.
    You can interact with this assistant to explore and learn more about RHDH in greater
    detail. Developer Lightspeed for RHDH provides a natural language interface within
    the RHDH console, helping you easily find information about the product, understand
    its features, and get answers to your questions. You can experience Developer
    Lightspeed for RHDH Developer Preview by installing the Developer Lightspeed for
    Red Hat Developer Hub plugin within an existing RHDH instance. Alternatively,
    if you prefer to test it locally first, you can try Developer Lightspeed for RHDH
    using RHDH Local. ![developer lightspeed 1 8 0] RHDH Local ## Supported architecture
    for Red Hat Developer Lightspeed for Red Hat Developer Hub Developer Lightspeed
    for RHDH is available as a plugin on all platforms that host RHDH. It requires
    two sidecar containers: the Lightspeed Core Service (LCS) and the Llama Stack
    service. The LCS container acts as the intermediary layer, which interfaces with
    and manages the Llama Stack service. ![developer lightspeed architecture 1 8 0]
    Red Hat Developer Hub Life Cycle and supported platforms ### About Lightspeed
    Core Service and Llama Stack The Lightspeed Core Service and Llama Stack deploy
    together as sidecar containers to augment RHDH functionality. The Llama Stack
    delivers the augmented functionality by integrating and managing core components,
    which include: Large language model (LLM) inference providers Model Context Protocol
    (MCP) or Retrieval Augmented Generation (RAG) tool runtime providers Safety providers
    Vector database settings The Lightspeed Core Service serves as the Llama Stack
    service intermediary. It manages the operational configuration and key data, specifically:
    User feedback collection MCP server configuration Conversation history Llama Stack
    provides the inference functionality that LCS uses to process requests. For more
    information, see What is Llama Stack. The Red Hat Developer Lightspeed for Red
    Hat Developer Hub plugin in RHDH sends prompts and receives LLM responses through
    the LCS sidecar. LCS then uses the Llama Stack sidecar service to perform inference
    and MCP or RAG tool calling. [NOTE] ---- Red Hat Developer Lightspeed for Red
    Hat Developer Hub is a Developer Preview release. You must manually deploy the
    Lightspeed Core Service and Llama Stack sidecar containers, and install the Red
    Hat Developer Lightspeed for Red Hat Developer Hub plugin on your RHDH instance.
    ---- ## Retrieval augmented generation (RAG) embeddings The Red Hat Developer
    Hub documentation serves as the Retrieval-Augmented Generation (RAG) data source.
    RAG initialization occurs through an initialization container, which copies the
    RAG data to a shared volume. The Llama Stack sidecar then mounts this shared volume
    to access the RAG data. The Llama Stack service uses the resulting RAG embeddings
    in the vector database as a reference. This allows the service to provide citations
    to production documentation during the inference process. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:02:00.554642'
    uuid: dadfbaee-321a-4e33-a14d-3440bfd5d9f9
  response: 'The Lightspeed Core Service (LCS) container acts as the intermediary
    layer, which interfaces with and manages the Llama Stack service. The Red Hat
    Developer Lightspeed for Red Hat Developer Hub plugin sends prompts and receives
    LLM responses through the LCS sidecar, which then uses the Llama Stack service
    to perform inference and MCP or RAG tool calling. The LCS manages operational
    configuration and key data, specifically: user feedback collection, MCP server
    configuration, and conversation history.'
  user_input: ok so i'm trying to figure out this whole developer lightspeed setup
    for our RHDH instance, and i see it needs two sidecar containers, so what exactly
    is the job of the LCS, the Lightspeed Core Service, i mean what does it do as
    the intermediary and what specific key data and operational configuration stuff
    is it responsible for managing?
- context:
  - '# Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub # Interacting
    with Red Hat Developer Lightspeed for Red Hat Developer Hub ## About Developer
    Lightspeed for RHDH [IMPORTANT] ---- This section describes Developer Preview
    features in the Red Hat Developer Lightspeed for Red Hat Developer Hub plugin.
    Developer Preview features are not supported by Red Hat in any way and are not
    functionally complete or production-ready. Do not use Developer Preview features
    for production or business-critical workloads. Developer Preview features provide
    early access to functionality in advance of possible inclusion in a Red Hat product
    offering. Customers can use these features to test functionality and provide feedback
    during the development process. Developer Preview features might not have any
    documentation, are subject to change or removal at any time, and have received
    limited testing. Red Hat might provide ways to submit feedback on Developer Preview
    features without an associated SLA. For more information about the support scope
    of Red Hat Developer Preview features, see Developer Preview Support Scope. ----
    This early access program enables customers to share feedback on the user experience,
    features, capabilities, and any issues encountered. Your input helps ensure that
    Developer Lightspeed for RHDH better meets your needs when it is officially released
    and made generally available. Red Hat Developer Lightspeed for Red Hat Developer
    Hub (Developer Lightspeed for RHDH) is a virtual assistant powered by generative
    Artificial Intelligence (AI) designed for Red Hat Developer Hub(RHDH). The assistant
    offers in-depth insights into RHDH, including its wide range of capabilities.
    You can interact with this assistant to explore and learn more about RHDH in greater
    detail. Developer Lightspeed for RHDH provides a natural language interface within
    the RHDH console, helping you easily find information about the product, understand
    its features, and get answers to your questions. You can experience Developer
    Lightspeed for RHDH Developer Preview by installing the Developer Lightspeed for
    Red Hat Developer Hub plugin within an existing RHDH instance. Alternatively,
    if you prefer to test it locally first, you can try Developer Lightspeed for RHDH
    using RHDH Local. ![developer lightspeed 1 8 0] RHDH Local ## Supported architecture
    for Red Hat Developer Lightspeed for Red Hat Developer Hub Developer Lightspeed
    for RHDH is available as a plugin on all platforms that host RHDH. It requires
    two sidecar containers: the Lightspeed Core Service (LCS) and the Llama Stack
    service. The LCS container acts as the intermediary layer, which interfaces with
    and manages the Llama Stack service. ![developer lightspeed architecture 1 8 0]
    Red Hat Developer Hub Life Cycle and supported platforms ### About Lightspeed
    Core Service and Llama Stack The Lightspeed Core Service and Llama Stack deploy
    together as sidecar containers to augment RHDH functionality. The Llama Stack
    delivers the augmented functionality by integrating and managing core components,
    which include: Large language model (LLM) inference providers Model Context Protocol
    (MCP) or Retrieval Augmented Generation (RAG) tool runtime providers Safety providers
    Vector database settings The Lightspeed Core Service serves as the Llama Stack
    service intermediary. It manages the operational configuration and key data, specifically:
    User feedback collection MCP server configuration Conversation history Llama Stack
    provides the inference functionality that LCS uses to process requests. For more
    information, see What is Llama Stack. The Red Hat Developer Lightspeed for Red
    Hat Developer Hub plugin in RHDH sends prompts and receives LLM responses through
    the LCS sidecar. LCS then uses the Llama Stack sidecar service to perform inference
    and MCP or RAG tool calling. [NOTE] ---- Red Hat Developer Lightspeed for Red
    Hat Developer Hub is a Developer Preview release. You must manually deploy the
    Lightspeed Core Service and Llama Stack sidecar containers, and install the Red
    Hat Developer Lightspeed for Red Hat Developer Hub plugin on your RHDH instance.
    ---- ## Retrieval augmented generation (RAG) embeddings The Red Hat Developer
    Hub documentation serves as the Retrieval-Augmented Generation (RAG) data source.
    RAG initialization occurs through an initialization container, which copies the
    RAG data to a shared volume. The Llama Stack sidecar then mounts this shared volume
    to access the RAG data. The Llama Stack service uses the resulting RAG embeddings
    in the vector database as a reference. This allows the service to provide citations
    to production documentation during the inference process. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:02:10.191619'
    uuid: 9300ee0a-0374-4ba3-b918-d5708bacb253
  response: Red Hat Developer Lightspeed for Red Hat Developer Hub (Developer Lightspeed
    for RHDH) is a virtual assistant powered by generative Artificial Intelligence
    (AI) designed for Red Hat Developer Hub(RHDH). The assistant offers in-depth insights
    into RHDH, including its wide range of capabilities. Developer Lightspeed for
    RHDH provides a natural language interface within the RHDH console, helping you
    easily find information about the product, understand its features, and get answers
    to your questions.
  user_input: wht is developer lightspeed for RHDH?
- context:
  - 'Installing and configuring Red Hat Developer Lightspeed for Red Hat Developer
    Hub Developer Lightspeed for RHDH consists of several components which work together
    to deliver virtual assistant (chat) functionality to your developers. The following
    list main components: Llama stack server (container sidecar):: Based on open source
    Llama Stack, this service operates as the main gateway to your LLM inferencing
    provider for chat services. Its modular architecture supports the integration
    of other services, such as Model Context Protocol (MCP). To support the chat functionality
    of Developer Lightspeed for RHDH, you must integrate your LLM provider with the
    Llama Stack server. This dependency on external LLM providers is called Bring
    Your Own Model or BYOM. Lightspeed Core Service (LCS) (container sidecar):: Based
    on the open source Lightspeed Core, this service extends the Llama Stack server
    by providing features such as chat history maintenance and user feedback gathering.
    Red Hat Developer Lightspeed for Red Hat Developer Hub (dynamic plugins):: These
    plugins are required to enable the Developer Lightspeed for RHDH user interface
    within your RHDH instance. Configuring these components to initialise correctly
    and communicate with each other is essential in order to provide Developer Lightspeed
    for RHDH to your users. [TIP] ---- If you are upgrading from the previous Developer
    Lightspeed for RHDH Developer Preview with Road-Core Service, you must remove
    all existing Developer Lightspeed for RHDH configurations and settings before
    you reinstall. To prevent or resolve upgrade inconsistencies, first drop and recreate
    the dynamic plugins volume. This reinstallation is required due to the following
    fundamental architectural changes: * The previous release used Road-Core Service
    as a sidecar container for interfacing with LLM providers. * The updated architecture
    replaces {rcs-short} with the new Lightspeed Core Service and Llama Stack server,
    which necessitates new configurations for the plugins, volumes, containers, and
    secrets. ---- You are logged in to your OpenShift Container Platform account.
    You have an RHDH instance installed using either the Operator or the Helm chart.
    You have created a custom dynamic plugins ConfigMap. You must manually install
    and configure the Developer Lightspeed for RHDH plugin, the Lightspeed Core Service
    (LCS) sidecar container, and the Llama Stack sidecar container. 1. Create the
    Lightspeed Core Service (LCS) ConfigMap: The LCS ConfigMap stores the configuration
    for the Lightspeed Core Service and is mounted to the LCS container. 1. In the
    OpenShift Container Platform web console, navigate to your RHDH instance and select
    the ConfigMaps tab. 2. Click Create ConfigMaps. 3. From the Create ConfigMap page,
    select the YAML view option and edit the file using the following structure. This
    example demonstrates the configuration for the LCS ConfigMap, typically named
    lightspeed-stack, which connects to the Llama Stack service locally on port 8321:
    ```yaml kind: ConfigMap apiVersion: v1 metadata: name: lightspeed-stack data:
    lightspeed-stack.yaml: | name: Lightspeed Core Service (LCS) service: host: 0.0.0.0
    # Use ${LIGHTSPEED_SERVICE_PORT} if you are not running the Service on port `8080`
    # port: ${LIGHTSPEED_SERVICE_PORT} auth_enabled: false workers: 1 color_log: true
    access_log: true llama_stack: use_as_library_client: false url: http://localhost:8321
    user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" authentication:
    module: "noop" conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` where: RHDH_HOST:: Enter the hostname for RHDH. 4. Click Create. 2. Create
    the Developer Lightspeed for RHDH ConfigMap: Create a dedicated Developer Lightspeed
    for RHDH ConfigMap (lightspeed-app-config) to hold specific plugin configurations.
    1. In the OpenShift Container Platform web console, navigate to your RHDH instance
    and select the ConfigMaps tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap
    page, select the YAML view option and add the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: lightspeed-app-config namespace: <__namespace__>
    # Enter your RHDH instance namespace data: app-config.yaml: |- backend: csp: upgrade-insecure-requests:
    false img-src: - "''self''" - "data:" - https://img.freepik.com - https://cdn.dribbble.com
    - https://avatars.githubusercontent.com # This is to load GitHub avatars in the
    UI script-src: - "''self''" - "''unsafe-eval''" - https://cdn.jsdelivr.net lightspeed:
    # OPTIONAL: Custom users prompts displayed to users # If not provided, the plugin
    uses built-in default prompts prompts: - title: `Getting Started with Red Hat
    Developer Hub` message: Can you guide me through the first steps to start using
    {product-short} as a developer, like exploring the Software Catalog and adding
    my service? # OPTIONAL: Port for lightspeed service (default: 8080) # servicePort:
    ${LIGHTSPEED_SERVICE_PORT} # OPTIONAL: Override default RHDH system prompt # systemPrompt:
    "You are a helpful assistant focused on Red Hat Developer Hub development." ```
    4. Click Create. 3. Create Llama Stack Secret file (llama-stack-secrets): This
    file holds sensitive configuration data for your LLM provider and Llama Stack
    environment variables. [NOTE] ---- You must provide an LLM provider that conforms
    to the OpenAI API specification. For more information, see Changing your LLM provider.
    ---- 1. In the OpenShift Container Platform web console, go to Secrets. 2. Click
    Create -> Key/value secret. 3. In the Create key/value secret page, select the
    YAML view option and add the following example: ```yaml apiVersion: v1 kind: Secret
    metadata: name: llama stack secrets type: Opaque stringData: VLLM_URL: "" VLLM_API_KEY:
    "" VLLM_MAX_TOKENS: "" VLLM_TLS_VERIFY: "" VALIDATION_PROVIDER: "" VALIDATION_MODEL_NAME:
    "" ``` where: VLLM_URL:: Required for remote services: Set this to the API endpoint
    URL of your preferred LLM provider, if it is compatible with the OpenAI API specification
    (Examples: OpenAI, Red Hat OpenShift AI, vLLM) VLLM_API_KEY:: Required for remote
    services: Set this to the API key or token required for authentication with your
    remote LLM provider, if it is compatible with the OpenAI API specification VLLM_MAX_TOKENS::
    Optional VLLM_TLS_VERIFY:: Optional VALIDATION_PROVIDER:: Set this as vllm, ollama,
    openai, depending on the key you have set in this configuration file VALIDATION_MODEL_NAME::
    Set the name of the model you want to use for validation 4. Click Create. 4. Update
    the dynamic plugins ConfigMap: Add the Developer Lightspeed for RHDH plugin image
    to your existing dynamic plugins ConfigMap (dynamic-plugins-rhdh). ```yaml includes:
    - dynamic-plugins.default.yaml plugins: - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed
    disabled: false pluginConfig: lightspeed: # OPTIONAL: Custom users prompts displayed
    to users prompts: - title: ''Getting Started with Red Hat Developer Hub'' message:
    Can you guide me through the first steps to start using Developer Hub as a developer,'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:02:22.345637'
    uuid: 8ff91b2b-654b-4fd3-93c9-e6c521be920c
  response: To integrate an external LLM provider with Developer Lightspeed, you must
    integrate it with the Llama Stack server, which acts as the main gateway. This
    dependency is called Bring Your Own Model (BYOM). A secret file named `llama-stack-secrets`
    must be created to hold sensitive configuration data for your LLM provider, including
    the `VLLM_URL` (the API endpoint) and the `VLLM_API_KEY` (the authentication token).
    The LLM provider must conform to the OpenAI API specification.
  user_input: How is an external LLM provider integrated with Developer Lightspeed?
- context:
  - 'Installing and configuring Red Hat Developer Lightspeed for Red Hat Developer
    Hub Developer Lightspeed for RHDH consists of several components which work together
    to deliver virtual assistant (chat) functionality to your developers. The following
    list main components: Llama stack server (container sidecar):: Based on open source
    Llama Stack, this service operates as the main gateway to your LLM inferencing
    provider for chat services. Its modular architecture supports the integration
    of other services, such as Model Context Protocol (MCP). To support the chat functionality
    of Developer Lightspeed for RHDH, you must integrate your LLM provider with the
    Llama Stack server. This dependency on external LLM providers is called Bring
    Your Own Model or BYOM. Lightspeed Core Service (LCS) (container sidecar):: Based
    on the open source Lightspeed Core, this service extends the Llama Stack server
    by providing features such as chat history maintenance and user feedback gathering.
    Red Hat Developer Lightspeed for Red Hat Developer Hub (dynamic plugins):: These
    plugins are required to enable the Developer Lightspeed for RHDH user interface
    within your RHDH instance. Configuring these components to initialise correctly
    and communicate with each other is essential in order to provide Developer Lightspeed
    for RHDH to your users. [TIP] ---- If you are upgrading from the previous Developer
    Lightspeed for RHDH Developer Preview with Road-Core Service, you must remove
    all existing Developer Lightspeed for RHDH configurations and settings before
    you reinstall. To prevent or resolve upgrade inconsistencies, first drop and recreate
    the dynamic plugins volume. This reinstallation is required due to the following
    fundamental architectural changes: * The previous release used Road-Core Service
    as a sidecar container for interfacing with LLM providers. * The updated architecture
    replaces {rcs-short} with the new Lightspeed Core Service and Llama Stack server,
    which necessitates new configurations for the plugins, volumes, containers, and
    secrets. ---- You are logged in to your OpenShift Container Platform account.
    You have an RHDH instance installed using either the Operator or the Helm chart.
    You have created a custom dynamic plugins ConfigMap. You must manually install
    and configure the Developer Lightspeed for RHDH plugin, the Lightspeed Core Service
    (LCS) sidecar container, and the Llama Stack sidecar container. 1. Create the
    Lightspeed Core Service (LCS) ConfigMap: The LCS ConfigMap stores the configuration
    for the Lightspeed Core Service and is mounted to the LCS container. 1. In the
    OpenShift Container Platform web console, navigate to your RHDH instance and select
    the ConfigMaps tab. 2. Click Create ConfigMaps. 3. From the Create ConfigMap page,
    select the YAML view option and edit the file using the following structure. This
    example demonstrates the configuration for the LCS ConfigMap, typically named
    lightspeed-stack, which connects to the Llama Stack service locally on port 8321:
    ```yaml kind: ConfigMap apiVersion: v1 metadata: name: lightspeed-stack data:
    lightspeed-stack.yaml: | name: Lightspeed Core Service (LCS) service: host: 0.0.0.0
    # Use ${LIGHTSPEED_SERVICE_PORT} if you are not running the Service on port `8080`
    # port: ${LIGHTSPEED_SERVICE_PORT} auth_enabled: false workers: 1 color_log: true
    access_log: true llama_stack: use_as_library_client: false url: http://localhost:8321
    user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" authentication:
    module: "noop" conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` where: RHDH_HOST:: Enter the hostname for RHDH. 4. Click Create. 2. Create
    the Developer Lightspeed for RHDH ConfigMap: Create a dedicated Developer Lightspeed
    for RHDH ConfigMap (lightspeed-app-config) to hold specific plugin configurations.
    1. In the OpenShift Container Platform web console, navigate to your RHDH instance
    and select the ConfigMaps tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap
    page, select the YAML view option and add the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: lightspeed-app-config namespace: <__namespace__>
    # Enter your RHDH instance namespace data: app-config.yaml: |- backend: csp: upgrade-insecure-requests:
    false img-src: - "''self''" - "data:" - https://img.freepik.com - https://cdn.dribbble.com
    - https://avatars.githubusercontent.com # This is to load GitHub avatars in the
    UI script-src: - "''self''" - "''unsafe-eval''" - https://cdn.jsdelivr.net lightspeed:
    # OPTIONAL: Custom users prompts displayed to users # If not provided, the plugin
    uses built-in default prompts prompts: - title: `Getting Started with Red Hat
    Developer Hub` message: Can you guide me through the first steps to start using
    {product-short} as a developer, like exploring the Software Catalog and adding
    my service? # OPTIONAL: Port for lightspeed service (default: 8080) # servicePort:
    ${LIGHTSPEED_SERVICE_PORT} # OPTIONAL: Override default RHDH system prompt # systemPrompt:
    "You are a helpful assistant focused on Red Hat Developer Hub development." ```
    4. Click Create. 3. Create Llama Stack Secret file (llama-stack-secrets): This
    file holds sensitive configuration data for your LLM provider and Llama Stack
    environment variables. [NOTE] ---- You must provide an LLM provider that conforms
    to the OpenAI API specification. For more information, see Changing your LLM provider.
    ---- 1. In the OpenShift Container Platform web console, go to Secrets. 2. Click
    Create -> Key/value secret. 3. In the Create key/value secret page, select the
    YAML view option and add the following example: ```yaml apiVersion: v1 kind: Secret
    metadata: name: llama stack secrets type: Opaque stringData: VLLM_URL: "" VLLM_API_KEY:
    "" VLLM_MAX_TOKENS: "" VLLM_TLS_VERIFY: "" VALIDATION_PROVIDER: "" VALIDATION_MODEL_NAME:
    "" ``` where: VLLM_URL:: Required for remote services: Set this to the API endpoint
    URL of your preferred LLM provider, if it is compatible with the OpenAI API specification
    (Examples: OpenAI, Red Hat OpenShift AI, vLLM) VLLM_API_KEY:: Required for remote
    services: Set this to the API key or token required for authentication with your
    remote LLM provider, if it is compatible with the OpenAI API specification VLLM_MAX_TOKENS::
    Optional VLLM_TLS_VERIFY:: Optional VALIDATION_PROVIDER:: Set this as vllm, ollama,
    openai, depending on the key you have set in this configuration file VALIDATION_MODEL_NAME::
    Set the name of the model you want to use for validation 4. Click Create. 4. Update
    the dynamic plugins ConfigMap: Add the Developer Lightspeed for RHDH plugin image
    to your existing dynamic plugins ConfigMap (dynamic-plugins-rhdh). ```yaml includes:
    - dynamic-plugins.default.yaml plugins: - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed
    disabled: false pluginConfig: lightspeed: # OPTIONAL: Custom users prompts displayed
    to users prompts: - title: ''Getting Started with Red Hat Developer Hub'' message:
    Can you guide me through the first steps to start using Developer Hub as a developer,'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:02:30.769824'
    uuid: fc8838a8-9e2e-4d06-b671-16c0eef841c2
  response: For an LLM provider compatible with the OpenAI API specification, you
    must set the VLLM_URL to the API endpoint URL of your provider and the VLLM_API_KEY
    to the API key or token required for authentication. Additionally, the VALIDATION_PROVIDER
    should be set to "openai", and the VALIDATION_MODEL_NAME should be set to the
    name of the model you intend to use for validation.
  user_input: If I want use OpenAI for my LLM provider, what values I need to set
    in the llama-stack-secrets file?
- context:
  - 'Installing and configuring Red Hat Developer Lightspeed for Red Hat Developer
    Hub Developer Lightspeed for RHDH consists of several components which work together
    to deliver virtual assistant (chat) functionality to your developers. The following
    list main components: Llama stack server (container sidecar):: Based on open source
    Llama Stack, this service operates as the main gateway to your LLM inferencing
    provider for chat services. Its modular architecture supports the integration
    of other services, such as Model Context Protocol (MCP). To support the chat functionality
    of Developer Lightspeed for RHDH, you must integrate your LLM provider with the
    Llama Stack server. This dependency on external LLM providers is called Bring
    Your Own Model or BYOM. Lightspeed Core Service (LCS) (container sidecar):: Based
    on the open source Lightspeed Core, this service extends the Llama Stack server
    by providing features such as chat history maintenance and user feedback gathering.
    Red Hat Developer Lightspeed for Red Hat Developer Hub (dynamic plugins):: These
    plugins are required to enable the Developer Lightspeed for RHDH user interface
    within your RHDH instance. Configuring these components to initialise correctly
    and communicate with each other is essential in order to provide Developer Lightspeed
    for RHDH to your users. [TIP] ---- If you are upgrading from the previous Developer
    Lightspeed for RHDH Developer Preview with Road-Core Service, you must remove
    all existing Developer Lightspeed for RHDH configurations and settings before
    you reinstall. To prevent or resolve upgrade inconsistencies, first drop and recreate
    the dynamic plugins volume. This reinstallation is required due to the following
    fundamental architectural changes: * The previous release used Road-Core Service
    as a sidecar container for interfacing with LLM providers. * The updated architecture
    replaces {rcs-short} with the new Lightspeed Core Service and Llama Stack server,
    which necessitates new configurations for the plugins, volumes, containers, and
    secrets. ---- You are logged in to your OpenShift Container Platform account.
    You have an RHDH instance installed using either the Operator or the Helm chart.
    You have created a custom dynamic plugins ConfigMap. You must manually install
    and configure the Developer Lightspeed for RHDH plugin, the Lightspeed Core Service
    (LCS) sidecar container, and the Llama Stack sidecar container. 1. Create the
    Lightspeed Core Service (LCS) ConfigMap: The LCS ConfigMap stores the configuration
    for the Lightspeed Core Service and is mounted to the LCS container. 1. In the
    OpenShift Container Platform web console, navigate to your RHDH instance and select
    the ConfigMaps tab. 2. Click Create ConfigMaps. 3. From the Create ConfigMap page,
    select the YAML view option and edit the file using the following structure. This
    example demonstrates the configuration for the LCS ConfigMap, typically named
    lightspeed-stack, which connects to the Llama Stack service locally on port 8321:
    ```yaml kind: ConfigMap apiVersion: v1 metadata: name: lightspeed-stack data:
    lightspeed-stack.yaml: | name: Lightspeed Core Service (LCS) service: host: 0.0.0.0
    # Use ${LIGHTSPEED_SERVICE_PORT} if you are not running the Service on port `8080`
    # port: ${LIGHTSPEED_SERVICE_PORT} auth_enabled: false workers: 1 color_log: true
    access_log: true llama_stack: use_as_library_client: false url: http://localhost:8321
    user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" authentication:
    module: "noop" conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` where: RHDH_HOST:: Enter the hostname for RHDH. 4. Click Create. 2. Create
    the Developer Lightspeed for RHDH ConfigMap: Create a dedicated Developer Lightspeed
    for RHDH ConfigMap (lightspeed-app-config) to hold specific plugin configurations.
    1. In the OpenShift Container Platform web console, navigate to your RHDH instance
    and select the ConfigMaps tab. 2. Click Create ConfigMap. 3. From the Create ConfigMap
    page, select the YAML view option and add the following example: ```yaml kind:
    ConfigMap apiVersion: v1 metadata: name: lightspeed-app-config namespace: <__namespace__>
    # Enter your RHDH instance namespace data: app-config.yaml: |- backend: csp: upgrade-insecure-requests:
    false img-src: - "''self''" - "data:" - https://img.freepik.com - https://cdn.dribbble.com
    - https://avatars.githubusercontent.com # This is to load GitHub avatars in the
    UI script-src: - "''self''" - "''unsafe-eval''" - https://cdn.jsdelivr.net lightspeed:
    # OPTIONAL: Custom users prompts displayed to users # If not provided, the plugin
    uses built-in default prompts prompts: - title: `Getting Started with Red Hat
    Developer Hub` message: Can you guide me through the first steps to start using
    {product-short} as a developer, like exploring the Software Catalog and adding
    my service? # OPTIONAL: Port for lightspeed service (default: 8080) # servicePort:
    ${LIGHTSPEED_SERVICE_PORT} # OPTIONAL: Override default RHDH system prompt # systemPrompt:
    "You are a helpful assistant focused on Red Hat Developer Hub development." ```
    4. Click Create. 3. Create Llama Stack Secret file (llama-stack-secrets): This
    file holds sensitive configuration data for your LLM provider and Llama Stack
    environment variables. [NOTE] ---- You must provide an LLM provider that conforms
    to the OpenAI API specification. For more information, see Changing your LLM provider.
    ---- 1. In the OpenShift Container Platform web console, go to Secrets. 2. Click
    Create -> Key/value secret. 3. In the Create key/value secret page, select the
    YAML view option and add the following example: ```yaml apiVersion: v1 kind: Secret
    metadata: name: llama stack secrets type: Opaque stringData: VLLM_URL: "" VLLM_API_KEY:
    "" VLLM_MAX_TOKENS: "" VLLM_TLS_VERIFY: "" VALIDATION_PROVIDER: "" VALIDATION_MODEL_NAME:
    "" ``` where: VLLM_URL:: Required for remote services: Set this to the API endpoint
    URL of your preferred LLM provider, if it is compatible with the OpenAI API specification
    (Examples: OpenAI, Red Hat OpenShift AI, vLLM) VLLM_API_KEY:: Required for remote
    services: Set this to the API key or token required for authentication with your
    remote LLM provider, if it is compatible with the OpenAI API specification VLLM_MAX_TOKENS::
    Optional VLLM_TLS_VERIFY:: Optional VALIDATION_PROVIDER:: Set this as vllm, ollama,
    openai, depending on the key you have set in this configuration file VALIDATION_MODEL_NAME::
    Set the name of the model you want to use for validation 4. Click Create. 4. Update
    the dynamic plugins ConfigMap: Add the Developer Lightspeed for RHDH plugin image
    to your existing dynamic plugins ConfigMap (dynamic-plugins-rhdh). ```yaml includes:
    - dynamic-plugins.default.yaml plugins: - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed
    disabled: false pluginConfig: lightspeed: # OPTIONAL: Custom users prompts displayed
    to users prompts: - title: ''Getting Started with Red Hat Developer Hub'' message:
    Can you guide me through the first steps to start using Developer Hub as a developer,'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:02:40.786014'
    uuid: 14c0073f-eeae-47d4-8737-43c46d446d6a
  response: 'Red Hat Developer Lightspeed for RHDH consists of several main components
    that work together. The primary components are: the Llama stack server (container
    sidecar), which operates as the main gateway to your LLM inferencing provider;
    the Lightspeed Core Service (LCS) (container sidecar), which extends the Llama
    Stack server with features like chat history maintenance and user feedback gathering;
    and the Red Hat Developer Lightspeed for Red Hat Developer Hub dynamic plugins,
    which are required to enable the user interface within your RHDH instance.'
  user_input: What are the main components I need to configure for Red Hat Developer
    Lightspeed for RHDH?
- context:
  - 'like exploring the Software Catalog and adding my service? dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-lightspeed: translationResources: - importName:
    lightspeedTranslations module: Alpha ref: lightspeedTranslationRef appIcons: -
    name: LightspeedIcon module: LightspeedPlugin importName: LightspeedIcon dynamicRoutes:
    - path: /lightspeed importName: LightspeedPage module: LightspeedPlugin menuItem:
    icon: LightspeedIcon text: Lightspeed - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed-backend
    disabled: false ``` 5. Update your deployment configuration: Update the deployment
    configuration based on how your RHDH instance was installed. You must add two
    sidecar containers: llama-stack and lightspeed-core. * For an Operator-installed
    RHDH instance (Update Backstage Custom Resource (CR)): 1. In the spec.application.appConfig.configMaps
    section of your Backstage CR, add the Developer Lightspeed for RHDH custom app
    configuration: ```yaml appConfig: configMaps: name: lightspeed app config ```
    2. Update the spec.deployment.patch.spec.template.spec.volumes specification to
    include volumes for LCS configuration (lightspeed-stack), shared storage for feedback
    (shared-storage), and RAG data (rag-data-volume): ```yaml volumes: configMap:
    name: lightspeed stack name: lightspeed stack emptyDir: {} name: shared storage
    emptyDir: {} name: rag data volume ``` 3. Add the initContainers section to initialize
    RAG data: ```yaml initContainers: - name: init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs''
    command: - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 4. Add the Llama Stack and the LCS
    containers to the spec.deployment.patch.spec.template.spec.containers section:
    ```yaml spec: application: - extraEnvs: secrets: - name: lightspeed-secrets containers:
    # ... Your existing RHDH container definition ... - envFrom: - secretRef: name:
    llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1'' # Llama
    Stack image name: llama-stack volumeMounts: - mountPath: /app-root/.llama name:
    shared-storage - mountPath: /app-root/embeddings_model name: rag-data-volume subPath:
    embeddings_model - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume
    subPath: rhdh_product_docs - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    # Lightspeed Core Service image name: lightspeed-core volumeMounts: - mountPath:
    /app-root/lightspeed-stack.yaml name: lightspeed-stack subPath: lightspeed-stack.yaml
    - mountPath: /tmp/data/feedback name: shared-storage - mountPath: /tmp/data/transcripts
    name: shared-storage - mountPath: /tmp/data/conversations name: shared-storage
    ``` 5. Click Save. The Pods are automatically restarted. * For a Helm-installed
    RHDH instance (Update the Helm chart): 1. Add your dynamic plugins configuration
    in the global.dynamic property. 2. Add your Developer Lightspeed for RHDH custom
    app config file to extraAppConfig: ```yaml extraAppConfig: configMapRef: lightspeed
    app config filename: app config.yaml ``` 3. Add the Llama Stack Secret file to
    extraEnvVarsSecrets: ```yaml extraEnvVarsSecrets: llama stack secrets ``` 4. Update
    the extraVolumes section to include the LCS ConfigMap (lightspeed-stack), shared
    storage, and RAG data volume: ```yaml extraVolumes: configMap: name: lightspeed
    stack name: lightspeed stack emptyDir: {} name: shared storage emptyDir: {} name:
    rag data volume ``` 5. Update the initContainers section (if supported by your
    Helm chart structure) to initialize RAG data. ```yaml initContainers: - name:
    init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs'' command:
    - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 6. Add the Llama Stack and LCS container
    definitions to extraContainers [NOTE] ---- If you have Road-Core Service installed
    from the previous Red Hat Developer Lightspeed for Red Hat Developer Hub configuration,
    you must replace the older single container configuration found in source with
    the two sidecars. ---- ```yaml extraContainers: # Llama Stack Container - envFrom:
    - secretRef: name: llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1''
    name: llama-stack volumeMounts: - mountPath: /app-root/.llama name: shared-storage
    - mountPath: /app-root/embeddings_model name: rag-data-volume subPath: embeddings_model
    - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume subPath:
    rhdh_product_docs # Lightspeed Core Service Container - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    name: lightspeed-core volumeMounts: - mountPath: /app-root/lightspeed-stack.yaml
    name: lightspeed-stack subPath: lightspeed-stack.yaml - mountPath: /tmp/data/feedback
    name: shared-storage - mountPath: /tmp/data/transcripts name: shared-storage -
    mountPath: /tmp/data/conversations name: shared-storage ``` 7. Click Save and
    then Helm upgrade. 6. Optional: Manage authorization (RBAC): If you have users
    who are not administrators, you must define permissions and roles for them to
    use Developer Lightspeed for RHDH. The Lightspeed Backend plugin uses Backstage
    RBAC for authorization. * For an Operator-installed RHDH instance: 1. Configure
    the required RBAC permission by defining an rbac-policies.csv file, including
    lightspeed.chat.read, lightspeed.chat.create, and lightspeed.chat.delete permissions:
    ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow p, role:default/_<your_team>_,
    lightspeed.chat.create, create, allow p, role:default/_<your_team>_, lightspeed.chat.delete,
    delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` 2.
    Upload your rbac-policies.csv file to an rbac-policies ConfigMap in your OpenShift
    Container Platform project containing RHDH and update your Backstage CR: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application: extraFiles:
    mountPath: /opt/app root/src configMaps: name: rbac policies ``` For a Helm installed
    RHDH instance: 1. Configure the required RBAC permission by defining an rbac policies.csv
    file: ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
    p, role:default/_<your_team>_, lightspeed.chat.create, create, allow p, role:default/_<your_team>_,
    lightspeed.chat.delete, delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_
    ``` 2. Optional: Declare policy administrators by editing your custom RHDH ConfigMap
    (app-config.yaml) and adding the following code to enable selected authenticated
    users to configure RBAC policies through the REST API or Web UI: ```yaml permission:
    enabled: true rbac: policies csv file: /opt/app root/src/rbac policies.csv policyFileReload:
    true admin: users: name: user:default/<your_policy_administrator_name> ``` 1.
    Log in to your RHDH instance. 2. In your RHDH navigation menu, you are able to
    see and access the Lightspeed menu item. Clicking this menu item takes you to
    the Developer Lightspeed for RHDH screen. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:03:04.124800'
    uuid: 675e46b4-1a62-4edc-afc6-585a2ac67294
  response: For a Helm-installed Red Hat Developer Hub (RHDH) instance, you must update
    the Helm chart by first adding your dynamic plugins configuration in the global.dynamic
    property and adding your Developer Lightspeed for RHDH custom app config file
    to extraAppConfig. Next, add the Llama Stack Secret file to extraEnvVarsSecrets
    and update the extraVolumes section to include the LCS ConfigMap (lightspeed-stack),
    shared storage, and RAG data volume. You should also update the initContainers
    section to initialize RAG data. Then, add the Llama Stack and LCS container definitions
    to extraContainers. Finally, you click Save and then perform a Helm upgrade.
  user_input: how i update helm for lightspeed?
- context:
  - 'like exploring the Software Catalog and adding my service? dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-lightspeed: translationResources: - importName:
    lightspeedTranslations module: Alpha ref: lightspeedTranslationRef appIcons: -
    name: LightspeedIcon module: LightspeedPlugin importName: LightspeedIcon dynamicRoutes:
    - path: /lightspeed importName: LightspeedPage module: LightspeedPlugin menuItem:
    icon: LightspeedIcon text: Lightspeed - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed-backend
    disabled: false ``` 5. Update your deployment configuration: Update the deployment
    configuration based on how your RHDH instance was installed. You must add two
    sidecar containers: llama-stack and lightspeed-core. * For an Operator-installed
    RHDH instance (Update Backstage Custom Resource (CR)): 1. In the spec.application.appConfig.configMaps
    section of your Backstage CR, add the Developer Lightspeed for RHDH custom app
    configuration: ```yaml appConfig: configMaps: name: lightspeed app config ```
    2. Update the spec.deployment.patch.spec.template.spec.volumes specification to
    include volumes for LCS configuration (lightspeed-stack), shared storage for feedback
    (shared-storage), and RAG data (rag-data-volume): ```yaml volumes: configMap:
    name: lightspeed stack name: lightspeed stack emptyDir: {} name: shared storage
    emptyDir: {} name: rag data volume ``` 3. Add the initContainers section to initialize
    RAG data: ```yaml initContainers: - name: init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs''
    command: - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 4. Add the Llama Stack and the LCS
    containers to the spec.deployment.patch.spec.template.spec.containers section:
    ```yaml spec: application: - extraEnvs: secrets: - name: lightspeed-secrets containers:
    # ... Your existing RHDH container definition ... - envFrom: - secretRef: name:
    llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1'' # Llama
    Stack image name: llama-stack volumeMounts: - mountPath: /app-root/.llama name:
    shared-storage - mountPath: /app-root/embeddings_model name: rag-data-volume subPath:
    embeddings_model - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume
    subPath: rhdh_product_docs - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    # Lightspeed Core Service image name: lightspeed-core volumeMounts: - mountPath:
    /app-root/lightspeed-stack.yaml name: lightspeed-stack subPath: lightspeed-stack.yaml
    - mountPath: /tmp/data/feedback name: shared-storage - mountPath: /tmp/data/transcripts
    name: shared-storage - mountPath: /tmp/data/conversations name: shared-storage
    ``` 5. Click Save. The Pods are automatically restarted. * For a Helm-installed
    RHDH instance (Update the Helm chart): 1. Add your dynamic plugins configuration
    in the global.dynamic property. 2. Add your Developer Lightspeed for RHDH custom
    app config file to extraAppConfig: ```yaml extraAppConfig: configMapRef: lightspeed
    app config filename: app config.yaml ``` 3. Add the Llama Stack Secret file to
    extraEnvVarsSecrets: ```yaml extraEnvVarsSecrets: llama stack secrets ``` 4. Update
    the extraVolumes section to include the LCS ConfigMap (lightspeed-stack), shared
    storage, and RAG data volume: ```yaml extraVolumes: configMap: name: lightspeed
    stack name: lightspeed stack emptyDir: {} name: shared storage emptyDir: {} name:
    rag data volume ``` 5. Update the initContainers section (if supported by your
    Helm chart structure) to initialize RAG data. ```yaml initContainers: - name:
    init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs'' command:
    - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 6. Add the Llama Stack and LCS container
    definitions to extraContainers [NOTE] ---- If you have Road-Core Service installed
    from the previous Red Hat Developer Lightspeed for Red Hat Developer Hub configuration,
    you must replace the older single container configuration found in source with
    the two sidecars. ---- ```yaml extraContainers: # Llama Stack Container - envFrom:
    - secretRef: name: llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1''
    name: llama-stack volumeMounts: - mountPath: /app-root/.llama name: shared-storage
    - mountPath: /app-root/embeddings_model name: rag-data-volume subPath: embeddings_model
    - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume subPath:
    rhdh_product_docs # Lightspeed Core Service Container - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    name: lightspeed-core volumeMounts: - mountPath: /app-root/lightspeed-stack.yaml
    name: lightspeed-stack subPath: lightspeed-stack.yaml - mountPath: /tmp/data/feedback
    name: shared-storage - mountPath: /tmp/data/transcripts name: shared-storage -
    mountPath: /tmp/data/conversations name: shared-storage ``` 7. Click Save and
    then Helm upgrade. 6. Optional: Manage authorization (RBAC): If you have users
    who are not administrators, you must define permissions and roles for them to
    use Developer Lightspeed for RHDH. The Lightspeed Backend plugin uses Backstage
    RBAC for authorization. * For an Operator-installed RHDH instance: 1. Configure
    the required RBAC permission by defining an rbac-policies.csv file, including
    lightspeed.chat.read, lightspeed.chat.create, and lightspeed.chat.delete permissions:
    ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow p, role:default/_<your_team>_,
    lightspeed.chat.create, create, allow p, role:default/_<your_team>_, lightspeed.chat.delete,
    delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` 2.
    Upload your rbac-policies.csv file to an rbac-policies ConfigMap in your OpenShift
    Container Platform project containing RHDH and update your Backstage CR: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application: extraFiles:
    mountPath: /opt/app root/src configMaps: name: rbac policies ``` For a Helm installed
    RHDH instance: 1. Configure the required RBAC permission by defining an rbac policies.csv
    file: ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
    p, role:default/_<your_team>_, lightspeed.chat.create, create, allow p, role:default/_<your_team>_,
    lightspeed.chat.delete, delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_
    ``` 2. Optional: Declare policy administrators by editing your custom RHDH ConfigMap
    (app-config.yaml) and adding the following code to enable selected authenticated
    users to configure RBAC policies through the REST API or Web UI: ```yaml permission:
    enabled: true rbac: policies csv file: /opt/app root/src/rbac policies.csv policyFileReload:
    true admin: users: name: user:default/<your_policy_administrator_name> ``` 1.
    Log in to your RHDH instance. 2. In your RHDH navigation menu, you are able to
    see and access the Lightspeed menu item. Clicking this menu item takes you to
    the Developer Lightspeed for RHDH screen. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:03:14.364018'
    uuid: 7e183449-7119-4497-97b4-6c4125926068
  response: 'To update your deployment configuration for Developer Lightspeed for
    RHDH, you must add two sidecar containers: llama-stack and lightspeed-core.'
  user_input: What are the sidecar containrs I need to add to my deployment configeration
    for Developer Lightspeed for RHDH?
- context:
  - 'like exploring the Software Catalog and adding my service? dynamicPlugins: frontend:
    red-hat-developer-hub.backstage-plugin-lightspeed: translationResources: - importName:
    lightspeedTranslations module: Alpha ref: lightspeedTranslationRef appIcons: -
    name: LightspeedIcon module: LightspeedPlugin importName: LightspeedIcon dynamicRoutes:
    - path: /lightspeed importName: LightspeedPage module: LightspeedPlugin menuItem:
    icon: LightspeedIcon text: Lightspeed - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.42.5__1.0.3!red-hat-developer-hub-backstage-plugin-lightspeed-backend
    disabled: false ``` 5. Update your deployment configuration: Update the deployment
    configuration based on how your RHDH instance was installed. You must add two
    sidecar containers: llama-stack and lightspeed-core. * For an Operator-installed
    RHDH instance (Update Backstage Custom Resource (CR)): 1. In the spec.application.appConfig.configMaps
    section of your Backstage CR, add the Developer Lightspeed for RHDH custom app
    configuration: ```yaml appConfig: configMaps: name: lightspeed app config ```
    2. Update the spec.deployment.patch.spec.template.spec.volumes specification to
    include volumes for LCS configuration (lightspeed-stack), shared storage for feedback
    (shared-storage), and RAG data (rag-data-volume): ```yaml volumes: configMap:
    name: lightspeed stack name: lightspeed stack emptyDir: {} name: shared storage
    emptyDir: {} name: rag data volume ``` 3. Add the initContainers section to initialize
    RAG data: ```yaml initContainers: - name: init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs''
    command: - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 4. Add the Llama Stack and the LCS
    containers to the spec.deployment.patch.spec.template.spec.containers section:
    ```yaml spec: application: - extraEnvs: secrets: - name: lightspeed-secrets containers:
    # ... Your existing RHDH container definition ... - envFrom: - secretRef: name:
    llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1'' # Llama
    Stack image name: llama-stack volumeMounts: - mountPath: /app-root/.llama name:
    shared-storage - mountPath: /app-root/embeddings_model name: rag-data-volume subPath:
    embeddings_model - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume
    subPath: rhdh_product_docs - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    # Lightspeed Core Service image name: lightspeed-core volumeMounts: - mountPath:
    /app-root/lightspeed-stack.yaml name: lightspeed-stack subPath: lightspeed-stack.yaml
    - mountPath: /tmp/data/feedback name: shared-storage - mountPath: /tmp/data/transcripts
    name: shared-storage - mountPath: /tmp/data/conversations name: shared-storage
    ``` 5. Click Save. The Pods are automatically restarted. * For a Helm-installed
    RHDH instance (Update the Helm chart): 1. Add your dynamic plugins configuration
    in the global.dynamic property. 2. Add your Developer Lightspeed for RHDH custom
    app config file to extraAppConfig: ```yaml extraAppConfig: configMapRef: lightspeed
    app config filename: app config.yaml ``` 3. Add the Llama Stack Secret file to
    extraEnvVarsSecrets: ```yaml extraEnvVarsSecrets: llama stack secrets ``` 4. Update
    the extraVolumes section to include the LCS ConfigMap (lightspeed-stack), shared
    storage, and RAG data volume: ```yaml extraVolumes: configMap: name: lightspeed
    stack name: lightspeed stack emptyDir: {} name: shared storage emptyDir: {} name:
    rag data volume ``` 5. Update the initContainers section (if supported by your
    Helm chart structure) to initialize RAG data. ```yaml initContainers: - name:
    init-rag-data image: ''quay.io/redhat-ai-dev/rag-content:release-1.8-lcs'' command:
    - "sh" - "-c" - "echo ''Copying RAG data...''; cp -r /rag/vector_db/rhdh_product_docs
    /data/ && cp -r /rag/embeddings_model /data/ && echo ''Copy complete.''" volumeMounts:
    - mountPath: /data name: rag-data-volume ``` 6. Add the Llama Stack and LCS container
    definitions to extraContainers [NOTE] ---- If you have Road-Core Service installed
    from the previous Red Hat Developer Lightspeed for Red Hat Developer Hub configuration,
    you must replace the older single container configuration found in source with
    the two sidecars. ---- ```yaml extraContainers: # Llama Stack Container - envFrom:
    - secretRef: name: llama-stack-secrets image: ''quay.io/redhat-ai-dev/llama-stack:0.1.1''
    name: llama-stack volumeMounts: - mountPath: /app-root/.llama name: shared-storage
    - mountPath: /app-root/embeddings_model name: rag-data-volume subPath: embeddings_model
    - mountPath: /app-root/vector_db/rhdh_product_docs name: rag-data-volume subPath:
    rhdh_product_docs # Lightspeed Core Service Container - image: ''quay.io/lightspeed-core/lightspeed-stack:dev-20251021-ee9f08f''
    name: lightspeed-core volumeMounts: - mountPath: /app-root/lightspeed-stack.yaml
    name: lightspeed-stack subPath: lightspeed-stack.yaml - mountPath: /tmp/data/feedback
    name: shared-storage - mountPath: /tmp/data/transcripts name: shared-storage -
    mountPath: /tmp/data/conversations name: shared-storage ``` 7. Click Save and
    then Helm upgrade. 6. Optional: Manage authorization (RBAC): If you have users
    who are not administrators, you must define permissions and roles for them to
    use Developer Lightspeed for RHDH. The Lightspeed Backend plugin uses Backstage
    RBAC for authorization. * For an Operator-installed RHDH instance: 1. Configure
    the required RBAC permission by defining an rbac-policies.csv file, including
    lightspeed.chat.read, lightspeed.chat.create, and lightspeed.chat.delete permissions:
    ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow p, role:default/_<your_team>_,
    lightspeed.chat.create, create, allow p, role:default/_<your_team>_, lightspeed.chat.delete,
    delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_ ``` 2.
    Upload your rbac-policies.csv file to an rbac-policies ConfigMap in your OpenShift
    Container Platform project containing RHDH and update your Backstage CR: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application: extraFiles:
    mountPath: /opt/app root/src configMaps: name: rbac policies ``` For a Helm installed
    RHDH instance: 1. Configure the required RBAC permission by defining an rbac policies.csv
    file: ```csv p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
    p, role:default/_<your_team>_, lightspeed.chat.create, create, allow p, role:default/_<your_team>_,
    lightspeed.chat.delete, delete, allow g, user:default/_<your_user>_, role:default/_<your_team>_
    ``` 2. Optional: Declare policy administrators by editing your custom RHDH ConfigMap
    (app-config.yaml) and adding the following code to enable selected authenticated
    users to configure RBAC policies through the REST API or Web UI: ```yaml permission:
    enabled: true rbac: policies csv file: /opt/app root/src/rbac policies.csv policyFileReload:
    true admin: users: name: user:default/<your_policy_administrator_name> ``` 1.
    Log in to your RHDH instance. 2. In your RHDH navigation menu, you are able to
    see and access the Lightspeed menu item. Clicking this menu item takes you to
    the Developer Lightspeed for RHDH screen. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:03:25.167414'
    uuid: 048e8609-7cd0-4c5d-9ad4-c784ee5ab443
  response: 'To update the deployment configuration for a Red Hat Developer Hub (RHDH)
    instance, you must add two sidecar containers: `llama-stack` and `lightspeed-core`.
    For an Operator-installed instance, this involves updating the Backstage Custom
    Resource (CR) by adding the Lightspeed custom app configuration, updating volumes
    to include `lightspeed-stack`, `shared-storage`, and `rag-data-volume`, adding
    `initContainers` to initialize RAG data, and adding the Llama Stack and LCS containers.
    For a Helm-installed instance, you must update the Helm chart by adding dynamic
    plugins configuration, adding the custom app config to `extraAppConfig`, adding
    the Llama Stack Secret to `extraEnvVarsSecrets`, updating `extraVolumes` and `initContainers`,
    and adding the Llama Stack and LCS container definitions to `extraContainers`.
    If you have the older Road-Core Service installed, you must replace the single
    container configuration with these two sidecars.'
  user_input: What deployment configuration updates are needed for a Red Hat Developer
    Hub instance to add the Lightspeed plugin?
- context:
  - 'Customizing Developer Lightspeed for RHDH You can customize Developer Lightspeed
    for RHDH functionalities such as gathering feedback, storing chat history in PostgreSQL,
    and configuring Model Context Protocol (MCP) tools. ### Gathering feedback in
    Developer Lightspeed for RHDH Feedback collection is an optional feature configured
    on the LCS. This feature gathers user feedback by providing thumbs-up/down ratings
    and text comments directly from the chat window. LCS collects the feedback, the
    user&#8217;s query, and the response of the model, storing the data as a JSON
    file on the local file system of the Pod. A platform administrator must later
    collect and analyze this data to assess model performance and improve the user
    experience. The collected data resides in the cluster where RHDH and LCS are deployed,
    making it accessible only to platform administrators for that cluster. For data
    removal, users must request this action from their platform administrator, as
    Red Hat neither collects nor accesses this data. To enable feedback collection,
    in the LCS configuration file (lightspeed stack.yaml), add the following settings:
    ```yaml user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" ``` To
    disable feedback collection, in the LCS configuration file (lightspeed stack.yaml),
    add the following settings: ```yaml user_data_collection: feedback_enabled: false
    feedback_storage: "/tmp/data/feedback" transcripts_enabled: true transcripts_storage:
    "/tmp/data/transcripts" ``` ### Updating the system prompt in Developer Lightspeed
    for RHDH You can override the default system prompt that Developer Lightspeed
    for RHDH uses to better frame queries to your LLM. Customizing the system prompt
    allows you to refine the context, personality, and instructions that the LLM receives,
    improving the relevance and accuracy of the responses it creates for your specific
    environment. To set a custom system prompt, in your Developer Lightspeed for RHDH
    app config file, add or modify the lightspeed.systemPrompt key and set its value
    to your preferred prompt string as shown in the following example: ```yaml lightspeed:
    # ... other lightspeed configurations systemPrompt: "You are a helpful assistant
    focused on Red Hat Developer Hub development." ``` Set systemPrompt to prefix
    all queries sent by Developer Lightspeed for RHDH to the LLM with this instruction,
    guiding the model to generate more tailored responses. ### Customizing the chat
    history storage in Developer Lightspeed for RHDH By default, the Developer Lightspeed
    for RHDH service stores chat history in a non-persistent local SQL database within
    in the LCS container. This means that chat history is lost if you create and use
    a new LCS sidecar. You can manually configure Developer Lightspeed for RHDH to
    store the chat history persistently as a long-term backup with PostgreSQL by updating
    your LCS service configuration. + [WARNING] ---- Configuring Developer Lightspeed
    for RHDH to use PostgreSQL records prompts and responses, which platform administrators
    can review. You must assess any data privacy and security implications if user
    chat history contains private, sensitive, or confidential information. For users
    that wish to have their chat data removed, they must request their respective
    platform administrator to perform this action. Red Hat does not collect or access
    this chat history data. ---- 1. Configure the chat history storage type in the
    LCS configuration file (lightspeed-stack.yaml) using any of the relevant options:
    * To enable persistent storage with PostgreSQL, add the following configuration:
    ```yaml conversation_cache: type: postgres postgres: host: _<your_database_host>_
    port: _<your_database_port>_ db: _<your_database_name>_ user: _<your_user_name>_
    password: _<postgres_password>_ ``` To retain the default, non persistent SQLite
    storage, make sure the configuration is set as shown in the following example:
    ```yaml conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` 2. Restart your LCS service to apply the new configuration. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:03:35.612402'
    uuid: 1695c32c-5daf-41be-bc30-cfc859446bb2
  response: The Lightspeed Conversation Service (LCS) collects the user's feedback,
    their query, and the model's response, storing this data as a JSON file on the
    local file system of the Pod. The collected data is located in the cluster where
    RHDH and LCS are deployed. A platform administrator is responsible for later collecting
    and analyzing this data to assess model performance and improve the user experience,
    and the data is accessible only to platform administrators for that cluster.
  user_input: so for the developer lightspeed feedback collection, i enabled it and
    it says it stores the data as a JSON file on the pod's local file system, but
    what data is actually in that file and who is the one that has to go get it and
    analyze it, is it me the platform admin?
- context:
  - 'Customizing Developer Lightspeed for RHDH You can customize Developer Lightspeed
    for RHDH functionalities such as gathering feedback, storing chat history in PostgreSQL,
    and configuring Model Context Protocol (MCP) tools. ### Gathering feedback in
    Developer Lightspeed for RHDH Feedback collection is an optional feature configured
    on the LCS. This feature gathers user feedback by providing thumbs-up/down ratings
    and text comments directly from the chat window. LCS collects the feedback, the
    user&#8217;s query, and the response of the model, storing the data as a JSON
    file on the local file system of the Pod. A platform administrator must later
    collect and analyze this data to assess model performance and improve the user
    experience. The collected data resides in the cluster where RHDH and LCS are deployed,
    making it accessible only to platform administrators for that cluster. For data
    removal, users must request this action from their platform administrator, as
    Red Hat neither collects nor accesses this data. To enable feedback collection,
    in the LCS configuration file (lightspeed stack.yaml), add the following settings:
    ```yaml user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" ``` To
    disable feedback collection, in the LCS configuration file (lightspeed stack.yaml),
    add the following settings: ```yaml user_data_collection: feedback_enabled: false
    feedback_storage: "/tmp/data/feedback" transcripts_enabled: true transcripts_storage:
    "/tmp/data/transcripts" ``` ### Updating the system prompt in Developer Lightspeed
    for RHDH You can override the default system prompt that Developer Lightspeed
    for RHDH uses to better frame queries to your LLM. Customizing the system prompt
    allows you to refine the context, personality, and instructions that the LLM receives,
    improving the relevance and accuracy of the responses it creates for your specific
    environment. To set a custom system prompt, in your Developer Lightspeed for RHDH
    app config file, add or modify the lightspeed.systemPrompt key and set its value
    to your preferred prompt string as shown in the following example: ```yaml lightspeed:
    # ... other lightspeed configurations systemPrompt: "You are a helpful assistant
    focused on Red Hat Developer Hub development." ``` Set systemPrompt to prefix
    all queries sent by Developer Lightspeed for RHDH to the LLM with this instruction,
    guiding the model to generate more tailored responses. ### Customizing the chat
    history storage in Developer Lightspeed for RHDH By default, the Developer Lightspeed
    for RHDH service stores chat history in a non-persistent local SQL database within
    in the LCS container. This means that chat history is lost if you create and use
    a new LCS sidecar. You can manually configure Developer Lightspeed for RHDH to
    store the chat history persistently as a long-term backup with PostgreSQL by updating
    your LCS service configuration. + [WARNING] ---- Configuring Developer Lightspeed
    for RHDH to use PostgreSQL records prompts and responses, which platform administrators
    can review. You must assess any data privacy and security implications if user
    chat history contains private, sensitive, or confidential information. For users
    that wish to have their chat data removed, they must request their respective
    platform administrator to perform this action. Red Hat does not collect or access
    this chat history data. ---- 1. Configure the chat history storage type in the
    LCS configuration file (lightspeed-stack.yaml) using any of the relevant options:
    * To enable persistent storage with PostgreSQL, add the following configuration:
    ```yaml conversation_cache: type: postgres postgres: host: _<your_database_host>_
    port: _<your_database_port>_ db: _<your_database_name>_ user: _<your_user_name>_
    password: _<postgres_password>_ ``` To retain the default, non persistent SQLite
    storage, make sure the configuration is set as shown in the following example:
    ```yaml conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` 2. Restart your LCS service to apply the new configuration. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:03:47.267567'
    uuid: 3e2f4997-6012-40e3-85d9-0bf264c62e36
  response: According to the provided context, if you configure Developer Lightspeed
    for RHDH to use PostgreSQL, it will record prompts and responses which platform
    administrators can review. However, the documentation explicitly states that Red
    Hat does not collect or access this chat history data. If users wish to have their
    chat data removed, they must request this action from their platform administrator.
  user_input: If we store chat history in PostgreSQL for RHDH, does Red Hat have acces
    to that data for anlysis?
- context:
  - 'Customizing Developer Lightspeed for RHDH You can customize Developer Lightspeed
    for RHDH functionalities such as gathering feedback, storing chat history in PostgreSQL,
    and configuring Model Context Protocol (MCP) tools. ### Gathering feedback in
    Developer Lightspeed for RHDH Feedback collection is an optional feature configured
    on the LCS. This feature gathers user feedback by providing thumbs-up/down ratings
    and text comments directly from the chat window. LCS collects the feedback, the
    user&#8217;s query, and the response of the model, storing the data as a JSON
    file on the local file system of the Pod. A platform administrator must later
    collect and analyze this data to assess model performance and improve the user
    experience. The collected data resides in the cluster where RHDH and LCS are deployed,
    making it accessible only to platform administrators for that cluster. For data
    removal, users must request this action from their platform administrator, as
    Red Hat neither collects nor accesses this data. To enable feedback collection,
    in the LCS configuration file (lightspeed stack.yaml), add the following settings:
    ```yaml user_data_collection: feedback_enabled: true feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true transcripts_storage: "/tmp/data/transcripts" ``` To
    disable feedback collection, in the LCS configuration file (lightspeed stack.yaml),
    add the following settings: ```yaml user_data_collection: feedback_enabled: false
    feedback_storage: "/tmp/data/feedback" transcripts_enabled: true transcripts_storage:
    "/tmp/data/transcripts" ``` ### Updating the system prompt in Developer Lightspeed
    for RHDH You can override the default system prompt that Developer Lightspeed
    for RHDH uses to better frame queries to your LLM. Customizing the system prompt
    allows you to refine the context, personality, and instructions that the LLM receives,
    improving the relevance and accuracy of the responses it creates for your specific
    environment. To set a custom system prompt, in your Developer Lightspeed for RHDH
    app config file, add or modify the lightspeed.systemPrompt key and set its value
    to your preferred prompt string as shown in the following example: ```yaml lightspeed:
    # ... other lightspeed configurations systemPrompt: "You are a helpful assistant
    focused on Red Hat Developer Hub development." ``` Set systemPrompt to prefix
    all queries sent by Developer Lightspeed for RHDH to the LLM with this instruction,
    guiding the model to generate more tailored responses. ### Customizing the chat
    history storage in Developer Lightspeed for RHDH By default, the Developer Lightspeed
    for RHDH service stores chat history in a non-persistent local SQL database within
    in the LCS container. This means that chat history is lost if you create and use
    a new LCS sidecar. You can manually configure Developer Lightspeed for RHDH to
    store the chat history persistently as a long-term backup with PostgreSQL by updating
    your LCS service configuration. + [WARNING] ---- Configuring Developer Lightspeed
    for RHDH to use PostgreSQL records prompts and responses, which platform administrators
    can review. You must assess any data privacy and security implications if user
    chat history contains private, sensitive, or confidential information. For users
    that wish to have their chat data removed, they must request their respective
    platform administrator to perform this action. Red Hat does not collect or access
    this chat history data. ---- 1. Configure the chat history storage type in the
    LCS configuration file (lightspeed-stack.yaml) using any of the relevant options:
    * To enable persistent storage with PostgreSQL, add the following configuration:
    ```yaml conversation_cache: type: postgres postgres: host: _<your_database_host>_
    port: _<your_database_port>_ db: _<your_database_name>_ user: _<your_user_name>_
    password: _<postgres_password>_ ``` To retain the default, non persistent SQLite
    storage, make sure the configuration is set as shown in the following example:
    ```yaml conversation_cache: type: "sqlite" sqlite: db_path: "/tmp/data/conversations/lcs_cache.db"
    ``` 2. Restart your LCS service to apply the new configuration. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:03:57.245527'
    uuid: 1c9e8da3-b713-4891-abf2-cb37d452fc7d
  response: 'By default, the Developer Lightspeed for RHDH service stores chat history
    in a non-persistent local SQL database within the LCS container, meaning chat
    history is lost if you create and use a new LCS sidecar. You can manually configure
    the service to store chat history persistently with PostgreSQL by updating your
    LCS service configuration. In the LCS configuration file (lightspeed-stack.yaml),
    you must add the following configuration to enable persistent storage with PostgreSQL:
    `conversation_cache: type: postgres postgres: host: _<your_database_host>_ port:
    _<your_database_port>_ db: _<your_database_name>_ user: _<your_user_name>_ password:
    _<postgres_password>_`. After updating the configuration, you must restart your
    LCS service to apply the changes. A warning is provided that this configuration
    records prompts and responses, which platform administrators can review, and any
    data privacy and security implications must be assessed.'
  user_input: so how do i make the chat history not get lost when a new sidecar is
    made, i want to use PostgreSQL for a long-term backup so its persistent, what
    is the configuration i need to put in the LCS service config file to make this
    happen?
- context:
  - "Using Developer Lightspeed for RHDH Red Hat Developer Lightspeed for Red Hat\
    \ Developer Hub is designed to support you when performing various tasks during\
    \ your development workflow. [NOTE] ---- The Question Validation feature is enabled\
    \ by default if you are using the quay.io/redhat-ai-dev/llama-stack image without\
    \ overriding the run.yaml configuration file in the image. To disable Question\
    \ Validation, you must mount a run.yaml file to the container with the following\
    \ sections removed: * Safety * Shields * External_providers_dir set to null ----\
    \ With Question Validation enabled, you can ask Developer Lightspeed for RHDH\
    \ the following types of questions: \u201CTell me about Red Hat Developer Hub.\u201D\
    \ \u201CWhat are the benefits of RHDH?\u201D \u201CCan I use RHDH on an OpenShift\
    \ Container Platform?\u201D \u201CHow do I install plugins on Red Hat Developer\
    \ Hub?\u201D With Question Validation disabled, the scope of prompts you can put\
    \ to Developer Lightspeed for RHDH is much broader. This allows Developer Lightspeed\
    \ for RHDH to support you in a much more varied range of work situations as described\
    \ in the following examples: \u201CAnalyze this log for me\u2026\u201D \u201C\
    Suggest libraries and frameworks I can use to build Event Driven Architecture\
    \ microservices.\u201D \u201CI'm not familiar with this language, so explain to\
    \ me what this code snippet is doing\u2026\u201D \u201CCreate a Kubernetes deployment\
    \ for this service\u2026\u201D \u201CCreate a test plan for the following scenarios\
    \ and conditions\u2026\u201D \u201CCreate a Jira record that describes the following\
    \ feature\u2026\u201D \u201CDraft the end user documentation describing how to\
    \ use the following cli command\u2026\u201D ### Using Developer Lightspeed for\
    \ RHDH to start a chat for the first time You can start a chat with Developer\
    \ Lightspeed for RHDH for quick answers on a number of topics depending on your\
    \ settings. You can manually start a chat with the Developer Lightspeed for RHDH\
    \ or use the following sample prompts we have provided to help you get started:\
    \ Getting Started with Red Hat Developer Hub Deploy with Tekton Create an OpenShift\
    \ Deployment You have the Developer Lightspeed for RHDH plugin configured in your\
    \ RHDH instance. 1. In your RHDH navigation menu, click Lightspeed. 2. You can\
    \ start a chat in either of the following ways: * To manually start a chat, in\
    \ the Send a message text box, you can do any of the following tasks: * Type your\
    \ query and press Enter. * To attach a file in the chat, click the Attach icon\
    \ or drag and drop the file in your chat. [NOTE] ---- The following file types\
    \ are supported: yaml, json, and txt. ---- * Click Open. * To start a chat using\
    \ the existing prompts, in the Developer Lightspeed for RHDH virtual assistant\
    \ interface, click any of the relevant prompt tiles. ### Using Developer Lightspeed\
    \ for RHDH to create new chats after the first chat After you have started an\
    \ initial chat with the Developer Lightspeed for RHDH, you can begin a chat on\
    \ a new topic at any time. Even if you log out and log back in, your previous\
    \ chats are still available in your chat history for you to view. You have the\
    \ Developer Lightspeed for RHDH plugin configured in your RHDH instance. 1. In\
    \ your RHDH navigation menu, click Lightspeed. 2. In the Developer Lightspeed\
    \ for RHDH virtual assistant interface, click New chat. ### Using Developer Lightspeed\
    \ for RHDH to view chat history Your chats with Developer Lightspeed for RHDH\
    \ are automatically saved in your RHDH instance. You can easily revisit your chat\
    \ history at any time, switch between chats, and revisit any previous chats. Each\
    \ chat remains active, enabling you to go back to any of your previous chats and\
    \ continue from where you left off. You have the Developer Lightspeed for RHDH\
    \ plugin configured in your RHDH instance. 1. In your RHDH navigation menu, click\
    \ Lightspeed. Developer Lightspeed for RHDH opens with your previous chat. 2.\
    \ In the Developer Lightspeed for RHDH virtual assistant interface, do any of\
    \ the following tasks: * Select a chat title to open and view the full chat. *\
    \ In Search previous chats&#8230;&#8203;, enter the text that you want to find\
    \ from the earlier chats. ### Using Developer Lightspeed for RHDH to delete a\
    \ chat You have the Developer Lightspeed for RHDH plugin configured in your RHDH\
    \ instance. 1. In your RHDH navigation menu, click Lightspeed. Developer Lightspeed\
    \ for RHDH opens with your previous chat. 2. In Developer Lightspeed for RHDH,\
    \ select the vertical ellipsis for the chat title of the chat that you want to\
    \ delete. 3. Select Delete. ## Appendix: LLM requirements ### Large language model\
    \ (LLM) requirements Developer Lightspeed for RHDH follows a Bring Your Own Model\
    \ approach. This model means that to function, Developer Lightspeed for RHDH requires\
    \ access to a large language model (LLM) which you must provide. An LLM is a type\
    \ of generative AI that interprets natural language and generates human-like text\
    \ or audio responses. When an LLM is used as a virtual assistant, the LLM can\
    \ interpret questions and provide answers in a conversational manner. LLMs are\
    \ usually provided by a service or server. Because Developer Lightspeed for RHDH\
    \ does not provide an LLM for you, you must configure your preferred LLM provider\
    \ during installation. You can configure the underlying Llama Stack server to\
    \ integrate with a number of LLM providers that offer compatibility with the OpenAI\
    \ API including the following inference providers: OpenAI (cloud based inference\
    \ service) Red Hat OpenShift AI (enterprise model builder and inference server)\
    \ Red Hat Enterprise Linux AI (enterprise inference server) Ollama (popular desktop\
    \ inference server) vLLM (popular enterprise inference server) ### OpenAI OpenAI\
    \ offers a range of generative AI models, such as GPT 5, which can be used to\
    \ provide inference services for applications like Developer Lightspeed for RHDH.\
    \ To use OpenAI with Developer Lightspeed for RHDH, you need access to the OpenAI\
    \ API platform. For more information, see the OpenAI developer platform documentation.\
    \ ### Ollama Ollama is a powerful and easy-to-use open-source project that simplifies\
    \ the process of running large language models (LLMs) locally on your computer.\
    \ It provides a simple"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:04:18.131660'
    uuid: 9ce79a52-b682-427f-8b48-902d253f4679
  response: Developer Lightspeed for Red Hat Developer Hub (RHDH) utilizes a Bring
    Your Own Model approach, meaning that to function, it requires access to a large
    language model (LLM) which you must provide. You must configure your preferred
    LLM provider during installation. The underlying Llama Stack server can be configured
    to integrate with a number of LLM providers that offer compatibility with the
    OpenAI API, including OpenAI, Red Hat OpenShift AI, Red Hat Enterprise Linux AI,
    Ollama, and vLLM.
  user_input: What are the large language model requirements for using Developer Lightspeed
    within the Red Hat Developer Hub?
- context:
  - "Using Developer Lightspeed for RHDH Red Hat Developer Lightspeed for Red Hat\
    \ Developer Hub is designed to support you when performing various tasks during\
    \ your development workflow. [NOTE] ---- The Question Validation feature is enabled\
    \ by default if you are using the quay.io/redhat-ai-dev/llama-stack image without\
    \ overriding the run.yaml configuration file in the image. To disable Question\
    \ Validation, you must mount a run.yaml file to the container with the following\
    \ sections removed: * Safety * Shields * External_providers_dir set to null ----\
    \ With Question Validation enabled, you can ask Developer Lightspeed for RHDH\
    \ the following types of questions: \u201CTell me about Red Hat Developer Hub.\u201D\
    \ \u201CWhat are the benefits of RHDH?\u201D \u201CCan I use RHDH on an OpenShift\
    \ Container Platform?\u201D \u201CHow do I install plugins on Red Hat Developer\
    \ Hub?\u201D With Question Validation disabled, the scope of prompts you can put\
    \ to Developer Lightspeed for RHDH is much broader. This allows Developer Lightspeed\
    \ for RHDH to support you in a much more varied range of work situations as described\
    \ in the following examples: \u201CAnalyze this log for me\u2026\u201D \u201C\
    Suggest libraries and frameworks I can use to build Event Driven Architecture\
    \ microservices.\u201D \u201CI'm not familiar with this language, so explain to\
    \ me what this code snippet is doing\u2026\u201D \u201CCreate a Kubernetes deployment\
    \ for this service\u2026\u201D \u201CCreate a test plan for the following scenarios\
    \ and conditions\u2026\u201D \u201CCreate a Jira record that describes the following\
    \ feature\u2026\u201D \u201CDraft the end user documentation describing how to\
    \ use the following cli command\u2026\u201D ### Using Developer Lightspeed for\
    \ RHDH to start a chat for the first time You can start a chat with Developer\
    \ Lightspeed for RHDH for quick answers on a number of topics depending on your\
    \ settings. You can manually start a chat with the Developer Lightspeed for RHDH\
    \ or use the following sample prompts we have provided to help you get started:\
    \ Getting Started with Red Hat Developer Hub Deploy with Tekton Create an OpenShift\
    \ Deployment You have the Developer Lightspeed for RHDH plugin configured in your\
    \ RHDH instance. 1. In your RHDH navigation menu, click Lightspeed. 2. You can\
    \ start a chat in either of the following ways: * To manually start a chat, in\
    \ the Send a message text box, you can do any of the following tasks: * Type your\
    \ query and press Enter. * To attach a file in the chat, click the Attach icon\
    \ or drag and drop the file in your chat. [NOTE] ---- The following file types\
    \ are supported: yaml, json, and txt. ---- * Click Open. * To start a chat using\
    \ the existing prompts, in the Developer Lightspeed for RHDH virtual assistant\
    \ interface, click any of the relevant prompt tiles. ### Using Developer Lightspeed\
    \ for RHDH to create new chats after the first chat After you have started an\
    \ initial chat with the Developer Lightspeed for RHDH, you can begin a chat on\
    \ a new topic at any time. Even if you log out and log back in, your previous\
    \ chats are still available in your chat history for you to view. You have the\
    \ Developer Lightspeed for RHDH plugin configured in your RHDH instance. 1. In\
    \ your RHDH navigation menu, click Lightspeed. 2. In the Developer Lightspeed\
    \ for RHDH virtual assistant interface, click New chat. ### Using Developer Lightspeed\
    \ for RHDH to view chat history Your chats with Developer Lightspeed for RHDH\
    \ are automatically saved in your RHDH instance. You can easily revisit your chat\
    \ history at any time, switch between chats, and revisit any previous chats. Each\
    \ chat remains active, enabling you to go back to any of your previous chats and\
    \ continue from where you left off. You have the Developer Lightspeed for RHDH\
    \ plugin configured in your RHDH instance. 1. In your RHDH navigation menu, click\
    \ Lightspeed. Developer Lightspeed for RHDH opens with your previous chat. 2.\
    \ In the Developer Lightspeed for RHDH virtual assistant interface, do any of\
    \ the following tasks: * Select a chat title to open and view the full chat. *\
    \ In Search previous chats&#8230;&#8203;, enter the text that you want to find\
    \ from the earlier chats. ### Using Developer Lightspeed for RHDH to delete a\
    \ chat You have the Developer Lightspeed for RHDH plugin configured in your RHDH\
    \ instance. 1. In your RHDH navigation menu, click Lightspeed. Developer Lightspeed\
    \ for RHDH opens with your previous chat. 2. In Developer Lightspeed for RHDH,\
    \ select the vertical ellipsis for the chat title of the chat that you want to\
    \ delete. 3. Select Delete. ## Appendix: LLM requirements ### Large language model\
    \ (LLM) requirements Developer Lightspeed for RHDH follows a Bring Your Own Model\
    \ approach. This model means that to function, Developer Lightspeed for RHDH requires\
    \ access to a large language model (LLM) which you must provide. An LLM is a type\
    \ of generative AI that interprets natural language and generates human-like text\
    \ or audio responses. When an LLM is used as a virtual assistant, the LLM can\
    \ interpret questions and provide answers in a conversational manner. LLMs are\
    \ usually provided by a service or server. Because Developer Lightspeed for RHDH\
    \ does not provide an LLM for you, you must configure your preferred LLM provider\
    \ during installation. You can configure the underlying Llama Stack server to\
    \ integrate with a number of LLM providers that offer compatibility with the OpenAI\
    \ API including the following inference providers: OpenAI (cloud based inference\
    \ service) Red Hat OpenShift AI (enterprise model builder and inference server)\
    \ Red Hat Enterprise Linux AI (enterprise inference server) Ollama (popular desktop\
    \ inference server) vLLM (popular enterprise inference server) ### OpenAI OpenAI\
    \ offers a range of generative AI models, such as GPT 5, which can be used to\
    \ provide inference services for applications like Developer Lightspeed for RHDH.\
    \ To use OpenAI with Developer Lightspeed for RHDH, you need access to the OpenAI\
    \ API platform. For more information, see the OpenAI developer platform documentation.\
    \ ### Ollama Ollama is a powerful and easy-to-use open-source project that simplifies\
    \ the process of running large language models (LLMs) locally on your computer.\
    \ It provides a simple"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:04:28.910760'
    uuid: 82471b87-59a8-4afb-b675-ab61ffa81e0f
  response: Developer Lightspeed for Red Hat Developer Hub (RHDH) follows a Bring
    Your Own Model approach, which means that to function, it requires access to a
    large language model (LLM) that you must provide. You must configure your preferred
    LLM provider during installation. The underlying Llama Stack server can be configured
    to integrate with a number of LLM providers compatible with the OpenAI API, including
    OpenAI, Red Hat OpenShift AI, Red Hat Enterprise Linux AI, Ollama, and vLLM.
  user_input: What are the large langage model requirments for getting the Red Hat
    Develeper Hub to work, and what providers are compatible?
- context:
  - "Using Developer Lightspeed for RHDH Red Hat Developer Lightspeed for Red Hat\
    \ Developer Hub is designed to support you when performing various tasks during\
    \ your development workflow. [NOTE] ---- The Question Validation feature is enabled\
    \ by default if you are using the quay.io/redhat-ai-dev/llama-stack image without\
    \ overriding the run.yaml configuration file in the image. To disable Question\
    \ Validation, you must mount a run.yaml file to the container with the following\
    \ sections removed: * Safety * Shields * External_providers_dir set to null ----\
    \ With Question Validation enabled, you can ask Developer Lightspeed for RHDH\
    \ the following types of questions: \u201CTell me about Red Hat Developer Hub.\u201D\
    \ \u201CWhat are the benefits of RHDH?\u201D \u201CCan I use RHDH on an OpenShift\
    \ Container Platform?\u201D \u201CHow do I install plugins on Red Hat Developer\
    \ Hub?\u201D With Question Validation disabled, the scope of prompts you can put\
    \ to Developer Lightspeed for RHDH is much broader. This allows Developer Lightspeed\
    \ for RHDH to support you in a much more varied range of work situations as described\
    \ in the following examples: \u201CAnalyze this log for me\u2026\u201D \u201C\
    Suggest libraries and frameworks I can use to build Event Driven Architecture\
    \ microservices.\u201D \u201CI'm not familiar with this language, so explain to\
    \ me what this code snippet is doing\u2026\u201D \u201CCreate a Kubernetes deployment\
    \ for this service\u2026\u201D \u201CCreate a test plan for the following scenarios\
    \ and conditions\u2026\u201D \u201CCreate a Jira record that describes the following\
    \ feature\u2026\u201D \u201CDraft the end user documentation describing how to\
    \ use the following cli command\u2026\u201D ### Using Developer Lightspeed for\
    \ RHDH to start a chat for the first time You can start a chat with Developer\
    \ Lightspeed for RHDH for quick answers on a number of topics depending on your\
    \ settings. You can manually start a chat with the Developer Lightspeed for RHDH\
    \ or use the following sample prompts we have provided to help you get started:\
    \ Getting Started with Red Hat Developer Hub Deploy with Tekton Create an OpenShift\
    \ Deployment You have the Developer Lightspeed for RHDH plugin configured in your\
    \ RHDH instance. 1. In your RHDH navigation menu, click Lightspeed. 2. You can\
    \ start a chat in either of the following ways: * To manually start a chat, in\
    \ the Send a message text box, you can do any of the following tasks: * Type your\
    \ query and press Enter. * To attach a file in the chat, click the Attach icon\
    \ or drag and drop the file in your chat. [NOTE] ---- The following file types\
    \ are supported: yaml, json, and txt. ---- * Click Open. * To start a chat using\
    \ the existing prompts, in the Developer Lightspeed for RHDH virtual assistant\
    \ interface, click any of the relevant prompt tiles. ### Using Developer Lightspeed\
    \ for RHDH to create new chats after the first chat After you have started an\
    \ initial chat with the Developer Lightspeed for RHDH, you can begin a chat on\
    \ a new topic at any time. Even if you log out and log back in, your previous\
    \ chats are still available in your chat history for you to view. You have the\
    \ Developer Lightspeed for RHDH plugin configured in your RHDH instance. 1. In\
    \ your RHDH navigation menu, click Lightspeed. 2. In the Developer Lightspeed\
    \ for RHDH virtual assistant interface, click New chat. ### Using Developer Lightspeed\
    \ for RHDH to view chat history Your chats with Developer Lightspeed for RHDH\
    \ are automatically saved in your RHDH instance. You can easily revisit your chat\
    \ history at any time, switch between chats, and revisit any previous chats. Each\
    \ chat remains active, enabling you to go back to any of your previous chats and\
    \ continue from where you left off. You have the Developer Lightspeed for RHDH\
    \ plugin configured in your RHDH instance. 1. In your RHDH navigation menu, click\
    \ Lightspeed. Developer Lightspeed for RHDH opens with your previous chat. 2.\
    \ In the Developer Lightspeed for RHDH virtual assistant interface, do any of\
    \ the following tasks: * Select a chat title to open and view the full chat. *\
    \ In Search previous chats&#8230;&#8203;, enter the text that you want to find\
    \ from the earlier chats. ### Using Developer Lightspeed for RHDH to delete a\
    \ chat You have the Developer Lightspeed for RHDH plugin configured in your RHDH\
    \ instance. 1. In your RHDH navigation menu, click Lightspeed. Developer Lightspeed\
    \ for RHDH opens with your previous chat. 2. In Developer Lightspeed for RHDH,\
    \ select the vertical ellipsis for the chat title of the chat that you want to\
    \ delete. 3. Select Delete. ## Appendix: LLM requirements ### Large language model\
    \ (LLM) requirements Developer Lightspeed for RHDH follows a Bring Your Own Model\
    \ approach. This model means that to function, Developer Lightspeed for RHDH requires\
    \ access to a large language model (LLM) which you must provide. An LLM is a type\
    \ of generative AI that interprets natural language and generates human-like text\
    \ or audio responses. When an LLM is used as a virtual assistant, the LLM can\
    \ interpret questions and provide answers in a conversational manner. LLMs are\
    \ usually provided by a service or server. Because Developer Lightspeed for RHDH\
    \ does not provide an LLM for you, you must configure your preferred LLM provider\
    \ during installation. You can configure the underlying Llama Stack server to\
    \ integrate with a number of LLM providers that offer compatibility with the OpenAI\
    \ API including the following inference providers: OpenAI (cloud based inference\
    \ service) Red Hat OpenShift AI (enterprise model builder and inference server)\
    \ Red Hat Enterprise Linux AI (enterprise inference server) Ollama (popular desktop\
    \ inference server) vLLM (popular enterprise inference server) ### OpenAI OpenAI\
    \ offers a range of generative AI models, such as GPT 5, which can be used to\
    \ provide inference services for applications like Developer Lightspeed for RHDH.\
    \ To use OpenAI with Developer Lightspeed for RHDH, you need access to the OpenAI\
    \ API platform. For more information, see the OpenAI developer platform documentation.\
    \ ### Ollama Ollama is a powerful and easy-to-use open-source project that simplifies\
    \ the process of running large language models (LLMs) locally on your computer.\
    \ It provides a simple"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:04:43.263830'
    uuid: 2884235a-1afd-4900-ab68-f33a4388faba
  response: "With the Question Validation feature enabled, you can ask Developer Lightspeed\
    \ for RHDH questions such as, \u201CCan I use RHDH on an OpenShift Container Platform?\u201D\
    . In terms of Large Language Model (LLM) requirements, Developer Lightspeed for\
    \ RHDH follows a Bring Your Own Model approach. You can configure the underlying\
    \ Llama Stack server to integrate with a number of LLM providers, including Red\
    \ Hat OpenShift AI, which is an enterprise model builder and inference server."
  user_input: As a platform lead, I'm looking at how Develper Litespeed works. Can
    you tell me how OpnShft is used with this tool, specifically regarding the LLM
    requirements?
- context:
  - "command-line interface for downloading, managing, and running a wide variety\
    \ of open-source models, such as Llama 3, Mistral, and many others, all without\
    \ requiring a dedicated server or cloud service. By abstracting away the complex\
    \ setup and dependencies, Ollama makes it accessible for developers, researchers,\
    \ and enthusiasts to experiment with, build on, and integrate state-of-the-art\
    \ LLMs into their applications directly from their personal machines. The open\
    \ source Ollama server in container form provides a convenient local testbed for\
    \ LLM models that is very accessible and easily controlled. Ollama Ollama server\
    \ container ### vLLM vLLM is an open-source, high-throughput serving engine for\
    \ large language models (LLMs) that significantly improves upon traditional serving\
    \ systems. It achieves this by introducing several key optimizations to reduce\
    \ memory usage and eliminate redundant computations. vLLM prominently increases\
    \ the number of concurrent requests an LLM can handle, making it a powerful tool\
    \ for deploying and scaling LLM-based applications. ## Appendix About user data\
    \ security ### About data use Developer Lightspeed for RHDH is a virtual assistant\
    \ you interact with using natural language. Using the Developer Lightspeed for\
    \ RHDH interface, you send chat messages that Developer Lightspeed for RHDH transforms\
    \ and sends to the large language model (LLM) provider you have configured for\
    \ your environment. These messages could potentially contain information provided\
    \ by your users about themselves, your cluster, cluster resources, or other aspects\
    \ of your business or working environment. Developer Lightspeed for RHDH has limited\
    \ capabilities to filter or redact the information you provide to the LLM. Do\
    \ not enter information into Developer Lightspeed for RHDH that you do not want\
    \ to send to the LLM provider. To remind end users not to share private or confidential\
    \ information, Developer Lightspeed for RHDH begins each new chat with an 'Important'\
    \ message asking them not to \u201Cinclude personal or sensitive information\u201D\
    \ in their chat messages. ### About feedback collection Developer Lightspeed for\
    \ RHDH collects feedback from users who engage with the feedback feature in the\
    \ virtual assistant interface. If a user submits feedback, the feedback score\
    \ (thumbs up or down), text feedback (if entered), the user query, and the LLM\
    \ provider response are stored locally in the file system of the Pod. Red Hat\
    \ does not have access to the collected feedback data. ### About Bring Your Own\
    \ Model Developer Lightspeed for RHDH does not provide its own inference services,\
    \ but uses a Bring Your Own Model approach. This means that you can configure\
    \ the Lightspeed Core Service to talk to the inference server or service of your\
    \ choice. This also means that you are responsible for ensuring that the configured\
    \ service meets your particular company policies and legal requirements, including\
    \ any applicable terms with the third-party model provider. The only technical\
    \ requirements for inference services are: The service must conform to the OpenAI\
    \ API specification. The service must be configured correctly following the installation\
    \ and configuration instructions. There are many commercial and open source inference\
    \ services that support the OpenAI API specification for chat completions. The\
    \ cost, performance, and security of these services can differ and it is up to\
    \ you to choose, through evaluation and testing, the inference service that best\
    \ meets your company's needs. OpenAI API specification ### Your responsibility\
    \ All of the information your users share in their questions and responses with\
    \ Developer Lightspeed for RHDH are shared with the LLM inference service you\
    \ configured. You are responsible for ensuring compliance with your company&#8217;s\
    \ policies regarding the sharing of data with your chosen inference service."
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:05:02.597900'
    uuid: c866fda7-0ead-40f9-a05a-60fdffe71944
  response: The primary technical requirement for an inference service to be used
    with Developer Lightspeed for RHDH is that the service must conform to the OpenAI
    API specification. This is part of the "Bring Your Own Model" approach, and the
    service must also be configured correctly following the installation and configuration
    instructions. Many commercial and open source inference services support the OpenAI
    API specification for chat completions.
  user_input: What is the OpenAI API requirement for an inference service to integrate
    with Developer Lightspeed for RHDH?
- context:
  - "command-line interface for downloading, managing, and running a wide variety\
    \ of open-source models, such as Llama 3, Mistral, and many others, all without\
    \ requiring a dedicated server or cloud service. By abstracting away the complex\
    \ setup and dependencies, Ollama makes it accessible for developers, researchers,\
    \ and enthusiasts to experiment with, build on, and integrate state-of-the-art\
    \ LLMs into their applications directly from their personal machines. The open\
    \ source Ollama server in container form provides a convenient local testbed for\
    \ LLM models that is very accessible and easily controlled. Ollama Ollama server\
    \ container ### vLLM vLLM is an open-source, high-throughput serving engine for\
    \ large language models (LLMs) that significantly improves upon traditional serving\
    \ systems. It achieves this by introducing several key optimizations to reduce\
    \ memory usage and eliminate redundant computations. vLLM prominently increases\
    \ the number of concurrent requests an LLM can handle, making it a powerful tool\
    \ for deploying and scaling LLM-based applications. ## Appendix About user data\
    \ security ### About data use Developer Lightspeed for RHDH is a virtual assistant\
    \ you interact with using natural language. Using the Developer Lightspeed for\
    \ RHDH interface, you send chat messages that Developer Lightspeed for RHDH transforms\
    \ and sends to the large language model (LLM) provider you have configured for\
    \ your environment. These messages could potentially contain information provided\
    \ by your users about themselves, your cluster, cluster resources, or other aspects\
    \ of your business or working environment. Developer Lightspeed for RHDH has limited\
    \ capabilities to filter or redact the information you provide to the LLM. Do\
    \ not enter information into Developer Lightspeed for RHDH that you do not want\
    \ to send to the LLM provider. To remind end users not to share private or confidential\
    \ information, Developer Lightspeed for RHDH begins each new chat with an 'Important'\
    \ message asking them not to \u201Cinclude personal or sensitive information\u201D\
    \ in their chat messages. ### About feedback collection Developer Lightspeed for\
    \ RHDH collects feedback from users who engage with the feedback feature in the\
    \ virtual assistant interface. If a user submits feedback, the feedback score\
    \ (thumbs up or down), text feedback (if entered), the user query, and the LLM\
    \ provider response are stored locally in the file system of the Pod. Red Hat\
    \ does not have access to the collected feedback data. ### About Bring Your Own\
    \ Model Developer Lightspeed for RHDH does not provide its own inference services,\
    \ but uses a Bring Your Own Model approach. This means that you can configure\
    \ the Lightspeed Core Service to talk to the inference server or service of your\
    \ choice. This also means that you are responsible for ensuring that the configured\
    \ service meets your particular company policies and legal requirements, including\
    \ any applicable terms with the third-party model provider. The only technical\
    \ requirements for inference services are: The service must conform to the OpenAI\
    \ API specification. The service must be configured correctly following the installation\
    \ and configuration instructions. There are many commercial and open source inference\
    \ services that support the OpenAI API specification for chat completions. The\
    \ cost, performance, and security of these services can differ and it is up to\
    \ you to choose, through evaluation and testing, the inference service that best\
    \ meets your company's needs. OpenAI API specification ### Your responsibility\
    \ All of the information your users share in their questions and responses with\
    \ Developer Lightspeed for RHDH are shared with the LLM inference service you\
    \ configured. You are responsible for ensuring compliance with your company&#8217;s\
    \ policies regarding the sharing of data with your chosen inference service."
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:05:14.101334'
    uuid: dc6ae376-ece9-443a-aeaf-b02ccb217520
  response: When a user submits feedback through the virtual assistant interface in
    Developer Lightspeed for RHDH, the feedback score, text feedback, user query,
    and the LLM provider response are stored locally in the file system of the Pod.
    Red Hat does not have access to the collected feedback data.
  user_input: Regarding the feedback collection feature in Developer Lightspeed for
    RHDH, what level of access does Red Hat have to the data submitted by users?
- context:
  - "command-line interface for downloading, managing, and running a wide variety\
    \ of open-source models, such as Llama 3, Mistral, and many others, all without\
    \ requiring a dedicated server or cloud service. By abstracting away the complex\
    \ setup and dependencies, Ollama makes it accessible for developers, researchers,\
    \ and enthusiasts to experiment with, build on, and integrate state-of-the-art\
    \ LLMs into their applications directly from their personal machines. The open\
    \ source Ollama server in container form provides a convenient local testbed for\
    \ LLM models that is very accessible and easily controlled. Ollama Ollama server\
    \ container ### vLLM vLLM is an open-source, high-throughput serving engine for\
    \ large language models (LLMs) that significantly improves upon traditional serving\
    \ systems. It achieves this by introducing several key optimizations to reduce\
    \ memory usage and eliminate redundant computations. vLLM prominently increases\
    \ the number of concurrent requests an LLM can handle, making it a powerful tool\
    \ for deploying and scaling LLM-based applications. ## Appendix About user data\
    \ security ### About data use Developer Lightspeed for RHDH is a virtual assistant\
    \ you interact with using natural language. Using the Developer Lightspeed for\
    \ RHDH interface, you send chat messages that Developer Lightspeed for RHDH transforms\
    \ and sends to the large language model (LLM) provider you have configured for\
    \ your environment. These messages could potentially contain information provided\
    \ by your users about themselves, your cluster, cluster resources, or other aspects\
    \ of your business or working environment. Developer Lightspeed for RHDH has limited\
    \ capabilities to filter or redact the information you provide to the LLM. Do\
    \ not enter information into Developer Lightspeed for RHDH that you do not want\
    \ to send to the LLM provider. To remind end users not to share private or confidential\
    \ information, Developer Lightspeed for RHDH begins each new chat with an 'Important'\
    \ message asking them not to \u201Cinclude personal or sensitive information\u201D\
    \ in their chat messages. ### About feedback collection Developer Lightspeed for\
    \ RHDH collects feedback from users who engage with the feedback feature in the\
    \ virtual assistant interface. If a user submits feedback, the feedback score\
    \ (thumbs up or down), text feedback (if entered), the user query, and the LLM\
    \ provider response are stored locally in the file system of the Pod. Red Hat\
    \ does not have access to the collected feedback data. ### About Bring Your Own\
    \ Model Developer Lightspeed for RHDH does not provide its own inference services,\
    \ but uses a Bring Your Own Model approach. This means that you can configure\
    \ the Lightspeed Core Service to talk to the inference server or service of your\
    \ choice. This also means that you are responsible for ensuring that the configured\
    \ service meets your particular company policies and legal requirements, including\
    \ any applicable terms with the third-party model provider. The only technical\
    \ requirements for inference services are: The service must conform to the OpenAI\
    \ API specification. The service must be configured correctly following the installation\
    \ and configuration instructions. There are many commercial and open source inference\
    \ services that support the OpenAI API specification for chat completions. The\
    \ cost, performance, and security of these services can differ and it is up to\
    \ you to choose, through evaluation and testing, the inference service that best\
    \ meets your company's needs. OpenAI API specification ### Your responsibility\
    \ All of the information your users share in their questions and responses with\
    \ Developer Lightspeed for RHDH are shared with the LLM inference service you\
    \ configured. You are responsible for ensuring compliance with your company&#8217;s\
    \ policies regarding the sharing of data with your chosen inference service."
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:05:23.460253'
    uuid: f749f1dd-df15-400d-9118-fac9acf70852
  response: The open source Ollama server in container form provides a convenient
    local testbed for LLM models that is very accessible and easily controlled.
  user_input: According to the provided information, what is the function of the open
    source Ollama server when it is used in its container form?
- context:
  - "# Dynamic plugins reference The dynamic plugin support is based on the backend\
    \ plugin manager package, which is a service that scans a configured root directory\
    \ (dynamicPlugins.rootDirectory in the app config) for dynamic plugin packages\
    \ and loads them dynamically. You can use the dynamic plugins that come preinstalled\
    \ with Red Hat Developer Hub or install external dynamic plugins from a public\
    \ NPM registry. # Preinstalled dynamic plugins Red Hat Developer Hub is preinstalled\
    \ with a selection of dynamic plugins. The following preinstalled dynamic plugins\
    \ are enabled by default: @backstage community/plugin analytics provider segment\
    \ @backstage community/plugin scaffolder backend module quay @backstage community/plugin\
    \ scaffolder backend module regex @backstage/plugin events backend @backstage/plugin\
    \ techdocs @backstage/plugin techdocs backend @backstage/plugin techdocs module\
    \ addons contrib @red hat developer hub/backstage plugin catalog backend module\
    \ marketplace @red hat developer hub/backstage plugin dynamic home page @red hat\
    \ developer hub/backstage plugin global floating action button @red hat developer\
    \ hub/backstage plugin global header @red hat developer hub/backstage plugin marketplace\
    \ @red hat developer hub/backstage plugin marketplace backend @red hat developer\
    \ hub/backstage plugin adoption insights @red hat developer hub/backstage plugin\
    \ adoption insights backend @red hat developer hub/backstage plugin analytics\
    \ module adoption insights @red hat developer hub/backstage plugin quickstart\
    \ The dynamic plugins that require custom configuration are disabled by default.\
    \ Upon application startup, for each plugin that is disabled by default, the install-dynamic-plugins\
    \ init container within the Developer Hub pod log displays a message similar to\
    \ the following: ```yaml ======= Skipping disabled dynamic plugin ./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic\
    \ ``` To enable this plugin, add a package with the same name to the Helm chart\
    \ and change the value in the disabled field to \u2018false\u2019. For example:\
    \ ```java global: dynamic: includes: dynamic plugins.default.yaml plugins: package:\
    \ ./dynamic plugins/dist/backstage plugin catalog backend module github dynamic\
    \ disabled: false ``` [NOTE] ---- The default configuration for a plugin is extracted\
    \ from the dynamic-plugins.default.yaml file, however, you can use a pluginConfig\
    \ entry to override the default configuration. ---- ### Red Hat supported plugins\
    \ Red Hat supports the following 28 plugins: [NOTE] ---- * For more information\
    \ about configuring KeyCloak, see Configuring dynamic plugins. * For more information\
    \ about configuring TechDocs, see Configuring TechDocs. ---- ### Technology Preview\
    \ plugins [IMPORTANT] ---- Red Hat Developer Hub includes a select number of Technology\
    \ Preview plugins, available for customers to configure and enable. These plugins\
    \ are provided with support scoped per Technical Preview terms, might not be functionally\
    \ complete, and Red Hat does not recommend using them for production. These features\
    \ provide early access to upcoming product features, enabling customers to test\
    \ functionality and provide feedback during the development process. For more\
    \ information on Red Hat Technology Preview features, see Technology Preview Features\
    \ Scope. ---- #### Red Hat Technology Preview plugins Red Hat provides Technology\
    \ Preview support for the following 56 plugins: #### Deprecated plugins [IMPORTANT]\
    \ ---- Red Hat Developer Hub (RHDH) includes a number of deprecated plugins, which\
    \ are no longer being actively developed. It is recommended that if you depend\
    \ on any of these plugins, you migrate to an alternative solution as soon as possible,\
    \ as these plugins will be removed in a future release. ---- RHDH includes the\
    \ following 2 deprecated plugins: #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:05:34.024370'
    uuid: 4e5b9a69-cf29-4156-b7ec-e899ad7714f0
  response: Red Hat Developer Hub is preinstalled with a selection of dynamic plugins.
    Some are enabled by default, while the dynamic plugins that require custom configuration
    are disabled by default. The platform includes 28 Red Hat supported plugins, 56
    Technology Preview plugins, and 2 deprecated plugins. To enable a plugin that
    is disabled by default, you must add a package with the same name to the Helm
    chart and change the value in the disabled field to 'false'.
  user_input: what kind of plugins is preinstalled with Red Hat Developer Hub and
    how do i turn on the ones that is disabled by default?
- context:
  - "# Dynamic plugins reference The dynamic plugin support is based on the backend\
    \ plugin manager package, which is a service that scans a configured root directory\
    \ (dynamicPlugins.rootDirectory in the app config) for dynamic plugin packages\
    \ and loads them dynamically. You can use the dynamic plugins that come preinstalled\
    \ with Red Hat Developer Hub or install external dynamic plugins from a public\
    \ NPM registry. # Preinstalled dynamic plugins Red Hat Developer Hub is preinstalled\
    \ with a selection of dynamic plugins. The following preinstalled dynamic plugins\
    \ are enabled by default: @backstage community/plugin analytics provider segment\
    \ @backstage community/plugin scaffolder backend module quay @backstage community/plugin\
    \ scaffolder backend module regex @backstage/plugin events backend @backstage/plugin\
    \ techdocs @backstage/plugin techdocs backend @backstage/plugin techdocs module\
    \ addons contrib @red hat developer hub/backstage plugin catalog backend module\
    \ marketplace @red hat developer hub/backstage plugin dynamic home page @red hat\
    \ developer hub/backstage plugin global floating action button @red hat developer\
    \ hub/backstage plugin global header @red hat developer hub/backstage plugin marketplace\
    \ @red hat developer hub/backstage plugin marketplace backend @red hat developer\
    \ hub/backstage plugin adoption insights @red hat developer hub/backstage plugin\
    \ adoption insights backend @red hat developer hub/backstage plugin analytics\
    \ module adoption insights @red hat developer hub/backstage plugin quickstart\
    \ The dynamic plugins that require custom configuration are disabled by default.\
    \ Upon application startup, for each plugin that is disabled by default, the install-dynamic-plugins\
    \ init container within the Developer Hub pod log displays a message similar to\
    \ the following: ```yaml ======= Skipping disabled dynamic plugin ./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic\
    \ ``` To enable this plugin, add a package with the same name to the Helm chart\
    \ and change the value in the disabled field to \u2018false\u2019. For example:\
    \ ```java global: dynamic: includes: dynamic plugins.default.yaml plugins: package:\
    \ ./dynamic plugins/dist/backstage plugin catalog backend module github dynamic\
    \ disabled: false ``` [NOTE] ---- The default configuration for a plugin is extracted\
    \ from the dynamic-plugins.default.yaml file, however, you can use a pluginConfig\
    \ entry to override the default configuration. ---- ### Red Hat supported plugins\
    \ Red Hat supports the following 28 plugins: [NOTE] ---- * For more information\
    \ about configuring KeyCloak, see Configuring dynamic plugins. * For more information\
    \ about configuring TechDocs, see Configuring TechDocs. ---- ### Technology Preview\
    \ plugins [IMPORTANT] ---- Red Hat Developer Hub includes a select number of Technology\
    \ Preview plugins, available for customers to configure and enable. These plugins\
    \ are provided with support scoped per Technical Preview terms, might not be functionally\
    \ complete, and Red Hat does not recommend using them for production. These features\
    \ provide early access to upcoming product features, enabling customers to test\
    \ functionality and provide feedback during the development process. For more\
    \ information on Red Hat Technology Preview features, see Technology Preview Features\
    \ Scope. ---- #### Red Hat Technology Preview plugins Red Hat provides Technology\
    \ Preview support for the following 56 plugins: #### Deprecated plugins [IMPORTANT]\
    \ ---- Red Hat Developer Hub (RHDH) includes a number of deprecated plugins, which\
    \ are no longer being actively developed. It is recommended that if you depend\
    \ on any of these plugins, you migrate to an alternative solution as soon as possible,\
    \ as these plugins will be removed in a future release. ---- RHDH includes the\
    \ following 2 deprecated plugins: #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:05:42.430607'
    uuid: b726543d-84e3-40f9-bb18-3c1007e90ab1
  response: 'Red Hat Developer Hub is preinstalled with the following dynamic plugins
    that are enabled by default: @backstage/plugin techdocs, @backstage/plugin techdocs
    backend, and @backstage/plugin techdocs module addons contrib.'
  user_input: Which TechDocs plugins are preinstalled and enabled by default in Red
    Hat Developer Hub?
- context:
  - "# Dynamic plugins reference The dynamic plugin support is based on the backend\
    \ plugin manager package, which is a service that scans a configured root directory\
    \ (dynamicPlugins.rootDirectory in the app config) for dynamic plugin packages\
    \ and loads them dynamically. You can use the dynamic plugins that come preinstalled\
    \ with Red Hat Developer Hub or install external dynamic plugins from a public\
    \ NPM registry. # Preinstalled dynamic plugins Red Hat Developer Hub is preinstalled\
    \ with a selection of dynamic plugins. The following preinstalled dynamic plugins\
    \ are enabled by default: @backstage community/plugin analytics provider segment\
    \ @backstage community/plugin scaffolder backend module quay @backstage community/plugin\
    \ scaffolder backend module regex @backstage/plugin events backend @backstage/plugin\
    \ techdocs @backstage/plugin techdocs backend @backstage/plugin techdocs module\
    \ addons contrib @red hat developer hub/backstage plugin catalog backend module\
    \ marketplace @red hat developer hub/backstage plugin dynamic home page @red hat\
    \ developer hub/backstage plugin global floating action button @red hat developer\
    \ hub/backstage plugin global header @red hat developer hub/backstage plugin marketplace\
    \ @red hat developer hub/backstage plugin marketplace backend @red hat developer\
    \ hub/backstage plugin adoption insights @red hat developer hub/backstage plugin\
    \ adoption insights backend @red hat developer hub/backstage plugin analytics\
    \ module adoption insights @red hat developer hub/backstage plugin quickstart\
    \ The dynamic plugins that require custom configuration are disabled by default.\
    \ Upon application startup, for each plugin that is disabled by default, the install-dynamic-plugins\
    \ init container within the Developer Hub pod log displays a message similar to\
    \ the following: ```yaml ======= Skipping disabled dynamic plugin ./dynamic-plugins/dist/backstage-plugin-catalog-backend-module-github-dynamic\
    \ ``` To enable this plugin, add a package with the same name to the Helm chart\
    \ and change the value in the disabled field to \u2018false\u2019. For example:\
    \ ```java global: dynamic: includes: dynamic plugins.default.yaml plugins: package:\
    \ ./dynamic plugins/dist/backstage plugin catalog backend module github dynamic\
    \ disabled: false ``` [NOTE] ---- The default configuration for a plugin is extracted\
    \ from the dynamic-plugins.default.yaml file, however, you can use a pluginConfig\
    \ entry to override the default configuration. ---- ### Red Hat supported plugins\
    \ Red Hat supports the following 28 plugins: [NOTE] ---- * For more information\
    \ about configuring KeyCloak, see Configuring dynamic plugins. * For more information\
    \ about configuring TechDocs, see Configuring TechDocs. ---- ### Technology Preview\
    \ plugins [IMPORTANT] ---- Red Hat Developer Hub includes a select number of Technology\
    \ Preview plugins, available for customers to configure and enable. These plugins\
    \ are provided with support scoped per Technical Preview terms, might not be functionally\
    \ complete, and Red Hat does not recommend using them for production. These features\
    \ provide early access to upcoming product features, enabling customers to test\
    \ functionality and provide feedback during the development process. For more\
    \ information on Red Hat Technology Preview features, see Technology Preview Features\
    \ Scope. ---- #### Red Hat Technology Preview plugins Red Hat provides Technology\
    \ Preview support for the following 56 plugins: #### Deprecated plugins [IMPORTANT]\
    \ ---- Red Hat Developer Hub (RHDH) includes a number of deprecated plugins, which\
    \ are no longer being actively developed. It is recommended that if you depend\
    \ on any of these plugins, you migrate to an alternative solution as soon as possible,\
    \ as these plugins will be removed in a future release. ---- RHDH includes the\
    \ following 2 deprecated plugins: #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:05:50.642386'
    uuid: 65b4b015-dc02-42e9-a18e-266b72dd516a
  response: For more information about configuring KeyCloak, you should see the documentation
    for "Configuring dynamic plugins".
  user_input: Where can I find more information about configuring KeyCloak?
- context:
  - 'Other installable plugins The following Technology Preview plugins are not preinstalled
    and must be installed from an external source:'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:06:01.170055'
    uuid: 8394fdc3-f61e-4c65-9c02-1bcd8b917e4b
  response: The Technology Preview plugins are not preinstalled and must be installed
    from an external source.
  user_input: Are the technolgy preview plugins preinstalled, or do we need to get
    them from an external sorce?
- context:
  - 'Other installable plugins The following Technology Preview plugins are not preinstalled
    and must be installed from an external source:'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:06:10.949373'
    uuid: 40c830b1-703d-41f5-b234-33be7c0c7c95
  response: Technology Preview plugins are not preinstalled and must be installed
    from an external source.
  user_input: How we get Technology Preview plugins?
- context:
  - 'Other installable plugins The following Technology Preview plugins are not preinstalled
    and must be installed from an external source:'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:06:20.932230'
    uuid: 49b67fc0-0701-4dfb-be4f-4d1ae84e6957
  response: The Technology Preview plugins are not preinstalled and must be installed
    from an external source.
  user_input: Are the Technlogy Prevew plugins already included or do we need to install
    them from somewhere else?
- context:
  - '# Installing Red Hat Developer Hub on Google Kubernetes Engine (GKE) Red Hat
    Developer Hub (RHDH) is an enterprise-grade platform for building developer portals.
    Administrative users can configure roles, permissions, and other settings to enable
    other authorized users to deploy a RHDH instance on Google Kubernetes Engine (GKE)
    using either the Operator or Helm chart. # Installing Developer Hub on Google
    Kubernetes Engine (GKE) by using the Operator To benefit from over-the-air updates
    and catalogs provided by Operator-based applications distributed with the Operator
    Lifecycle Manager (OLM) framework, consider installing Red Hat Developer Hub by
    using the Red Hat Developer Hub Operator distributed in the Red Hat Container
    Registry. On GKE, the most notable differences over an OpenShift-based installation
    are: The OLM framework and the Red Hat Container Registry are not built in. The
    Red Hat Container Registry pull secret is not managed globally. To expose the
    application, Ingresses replace OpenShift Routes. For clarity, the content is broken
    down in sections highlighting these platform-specific additional steps. ## Installing
    the Developer Hub Operator on Google Kubernetes Engine (GKE) by using the OLM
    framework The Red Hat Container Registry (registry.redhat.io), based on the Operator
    Lifecycle Manager (OLM) framework, contains a distribution of the Red Hat Developer
    Hub Operator, aimed at managing your Red Hat Developer Hub instance lifecycle.
    However, on Google Kubernetes Engine (GKE): The Operator Lifecycle Manager (OLM)
    framework and the Red Hat Container Registry are not built in. The Red Hat Container
    Registry pull secret is not managed globally. Therefore, install the OLM framework,
    the Red Hat Container Registry, and provision your Red Hat Container Registry
    pull secret to install Developer Hub Operator. You have installed the kubectl
    CLI on your local environment. Your system meets the sizing requirements for Red
    Hat Developer Hub. You have installed the Operator Lifecycle Manager (OLM). Your
    credentials to the Red Hat Container Registry: <redhat_user_name> <redhat_password>
    <email> You have logged in to your Google account and created a GKE Autopilot
    or GKE Standard cluster. 1. Connect to your GKE cluster: ```terminal $ gcloud
    container clusters get-credentials <cluster-name> --location=<cluster-location>
    ``` <cluster-name>:: Enter your GKE cluster name. <cluster-location>:: Enter your
    GKE cluster location. 2. Create the rhdh-operator namespace to contain the Red
    Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 3. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 4. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 5. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 6. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 7. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 8. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:06:30.423650'
    uuid: 40d1877c-38eb-47fb-82ab-7e70ed0ddf08
  response: On Google Kubernetes Engine (GKE), the Operator Lifecycle Manager (OLM)
    framework is not built in. Therefore, to install the Developer Hub Operator, you
    must install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret. The provided documentation lists
    "You have installed the Operator Lifecycle Manager (OLM)" as a prerequisite before
    you can begin the steps to install the Red Hat Developer Hub Operator.
  user_input: Since GKE doesnt have OLM built-in like OpenShift, what are the specific
    pre-requsites and steps I need to take to get the OLM framwork installed so I
    can use it to manage the Red Hat Developer Hub Operator lifecyle?
- context:
  - '# Installing Red Hat Developer Hub on Google Kubernetes Engine (GKE) Red Hat
    Developer Hub (RHDH) is an enterprise-grade platform for building developer portals.
    Administrative users can configure roles, permissions, and other settings to enable
    other authorized users to deploy a RHDH instance on Google Kubernetes Engine (GKE)
    using either the Operator or Helm chart. # Installing Developer Hub on Google
    Kubernetes Engine (GKE) by using the Operator To benefit from over-the-air updates
    and catalogs provided by Operator-based applications distributed with the Operator
    Lifecycle Manager (OLM) framework, consider installing Red Hat Developer Hub by
    using the Red Hat Developer Hub Operator distributed in the Red Hat Container
    Registry. On GKE, the most notable differences over an OpenShift-based installation
    are: The OLM framework and the Red Hat Container Registry are not built in. The
    Red Hat Container Registry pull secret is not managed globally. To expose the
    application, Ingresses replace OpenShift Routes. For clarity, the content is broken
    down in sections highlighting these platform-specific additional steps. ## Installing
    the Developer Hub Operator on Google Kubernetes Engine (GKE) by using the OLM
    framework The Red Hat Container Registry (registry.redhat.io), based on the Operator
    Lifecycle Manager (OLM) framework, contains a distribution of the Red Hat Developer
    Hub Operator, aimed at managing your Red Hat Developer Hub instance lifecycle.
    However, on Google Kubernetes Engine (GKE): The Operator Lifecycle Manager (OLM)
    framework and the Red Hat Container Registry are not built in. The Red Hat Container
    Registry pull secret is not managed globally. Therefore, install the OLM framework,
    the Red Hat Container Registry, and provision your Red Hat Container Registry
    pull secret to install Developer Hub Operator. You have installed the kubectl
    CLI on your local environment. Your system meets the sizing requirements for Red
    Hat Developer Hub. You have installed the Operator Lifecycle Manager (OLM). Your
    credentials to the Red Hat Container Registry: <redhat_user_name> <redhat_password>
    <email> You have logged in to your Google account and created a GKE Autopilot
    or GKE Standard cluster. 1. Connect to your GKE cluster: ```terminal $ gcloud
    container clusters get-credentials <cluster-name> --location=<cluster-location>
    ``` <cluster-name>:: Enter your GKE cluster name. <cluster-location>:: Enter your
    GKE cluster location. 2. Create the rhdh-operator namespace to contain the Red
    Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 3. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 4. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 5. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 6. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 7. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 8. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:06:39.756303'
    uuid: ee0ba557-2f73-4341-9a5a-000d2fdb6187
  response: 'To install the Red Hat Developer Hub Operator on Google Kubernetes Engine
    (GKE) using the Operator Lifecycle Manager (OLM) framework, you must first ensure
    prerequisites are met, including having the kubectl CLI, meeting sizing requirements,
    having OLM installed, possessing credentials for the Red Hat Container Registry,
    and having a created GKE cluster. The installation process involves these steps:
    1. Connect to your GKE cluster. 2. Create the "rhdh-operator" namespace. 3. Create
    a pull secret with your Red Hat credentials to pull images from the Red Hat Container
    Registry. 4. Create a CatalogSource containing the Red Hat operators. 5. Create
    an OperatorGroup to manage operator subscriptions. 6. Create a Subscription to
    install the Red Hat Developer Hub Operator. 7. Wait for the Operator deployment
    to complete. 8. Patch the Operator deployment manifest to include your pull secret
    name to avoid ImagePullBackOff errors.'
  user_input: How to install the Red Hat Developer Hub Operator on Google Kubernetes
    Engine using the OLM framework?
- context:
  - '# Installing Red Hat Developer Hub on Google Kubernetes Engine (GKE) Red Hat
    Developer Hub (RHDH) is an enterprise-grade platform for building developer portals.
    Administrative users can configure roles, permissions, and other settings to enable
    other authorized users to deploy a RHDH instance on Google Kubernetes Engine (GKE)
    using either the Operator or Helm chart. # Installing Developer Hub on Google
    Kubernetes Engine (GKE) by using the Operator To benefit from over-the-air updates
    and catalogs provided by Operator-based applications distributed with the Operator
    Lifecycle Manager (OLM) framework, consider installing Red Hat Developer Hub by
    using the Red Hat Developer Hub Operator distributed in the Red Hat Container
    Registry. On GKE, the most notable differences over an OpenShift-based installation
    are: The OLM framework and the Red Hat Container Registry are not built in. The
    Red Hat Container Registry pull secret is not managed globally. To expose the
    application, Ingresses replace OpenShift Routes. For clarity, the content is broken
    down in sections highlighting these platform-specific additional steps. ## Installing
    the Developer Hub Operator on Google Kubernetes Engine (GKE) by using the OLM
    framework The Red Hat Container Registry (registry.redhat.io), based on the Operator
    Lifecycle Manager (OLM) framework, contains a distribution of the Red Hat Developer
    Hub Operator, aimed at managing your Red Hat Developer Hub instance lifecycle.
    However, on Google Kubernetes Engine (GKE): The Operator Lifecycle Manager (OLM)
    framework and the Red Hat Container Registry are not built in. The Red Hat Container
    Registry pull secret is not managed globally. Therefore, install the OLM framework,
    the Red Hat Container Registry, and provision your Red Hat Container Registry
    pull secret to install Developer Hub Operator. You have installed the kubectl
    CLI on your local environment. Your system meets the sizing requirements for Red
    Hat Developer Hub. You have installed the Operator Lifecycle Manager (OLM). Your
    credentials to the Red Hat Container Registry: <redhat_user_name> <redhat_password>
    <email> You have logged in to your Google account and created a GKE Autopilot
    or GKE Standard cluster. 1. Connect to your GKE cluster: ```terminal $ gcloud
    container clusters get-credentials <cluster-name> --location=<cluster-location>
    ``` <cluster-name>:: Enter your GKE cluster name. <cluster-location>:: Enter your
    GKE cluster location. 2. Create the rhdh-operator namespace to contain the Red
    Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 3. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 4. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 5. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 6. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 7. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 8. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:06:50.147253'
    uuid: b4ba45f5-11a4-4be6-b9ef-1c88b42cb9fb
  response: 'To configure access to the Red Hat Container Registry on a Google Kubernetes
    Engine (GKE) cluster, you must install the OLM framework, the Red Hat Container
    Registry, and provision a pull secret. The specific steps are as follows: First,
    create the `rhdh-operator` namespace with the command: `kubectl create namespace
    rhdh-operator`. Second, create a pull secret using your Red Hat credentials to
    pull images from the protected Red Hat Container Registry (`registry.redhat.io`)
    by running: `kubectl n rhdh operator create secret docker registry rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email>`. Third, create a catalog source
    that contains the Red Hat operators by applying the following configuration: `apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators`. Finally, to avoid
    `ImagePullBackOff` errors, you must include your pull secret name in the Operator
    deployment manifest with the command: `kubectl n rhdh operator patch deployment
    \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge`.'
  user_input: What are the specific steps and kubectl commands required to configure
    access to the Red Hat Container Registry on a Google Kubernetes Engine cluster
    when installing the Red Hat Developer Hub Operator?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Google Kubernetes Engine (GKE) before running Red Hat Developer Hub.
    [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step to
    run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your GKE cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Google Kubernetes Engine (GKE), the Red Hat Container
    Registry pull-secret is not managed globally. Therefore add your pull-secret in
    your Red Hat Developer Hub instance namespace. Your credentials to the Red Hat
    Container Registry: <redhat_user_name> <redhat_password> <email> You created the
    {my rhdh project} namespace on GKE to host your Developer Hub instance. 1. Create
    a pull secret using your Red Hat credentials to pull the container images from
    the protected Red Hat Container Registry (registry.redhat.io): ```terminal $ kubectl
    n {my rhdh namespace} create secret docker registry my rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 2. To enable pulling Developer Hub images from the
    Red Hat Container Registry, add the image pull secret in the default service account
    within the namespace where the Developer Hub instance is being deployed: ```terminal
    $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets": [{"name": "my-rhdh-pull-secret"}]}''
    \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:06:59.685482'
    uuid: 43f0f6a9-1a78-4bd1-9dca-51b79df26856
  response: You need to provision your PostgreSQL database secrets.
  user_input: what i do for PostgreSQL secrets?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Google Kubernetes Engine (GKE) before running Red Hat Developer Hub.
    [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step to
    run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your GKE cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Google Kubernetes Engine (GKE), the Red Hat Container
    Registry pull-secret is not managed globally. Therefore add your pull-secret in
    your Red Hat Developer Hub instance namespace. Your credentials to the Red Hat
    Container Registry: <redhat_user_name> <redhat_password> <email> You created the
    {my rhdh project} namespace on GKE to host your Developer Hub instance. 1. Create
    a pull secret using your Red Hat credentials to pull the container images from
    the protected Red Hat Container Registry (registry.redhat.io): ```terminal $ kubectl
    n {my rhdh namespace} create secret docker registry my rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 2. To enable pulling Developer Hub images from the
    Red Hat Container Registry, add the image pull secret in the default service account
    within the namespace where the Developer Hub instance is being deployed: ```terminal
    $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets": [{"name": "my-rhdh-pull-secret"}]}''
    \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:07:10.742293'
    uuid: 252e9ada-1963-4153-9027-ef8299b44df9
  response: 'On Google Kubernetes Engine (GKE), the Red Hat Container Registry pull-secret
    is not managed globally, so you must add it to your Red Hat Developer Hub instance
    namespace. First, create a pull secret using your Red Hat credentials (`<redhat_user_name>`,
    `<redhat_password>`, `<email>`) to pull container images from registry.redhat.io.
    Then, to enable pulling Developer Hub images, you must add the image pull secret
    to the default service account within the namespace where the Developer Hub instance
    is being deployed using the command: `$ kubectl patch serviceaccount default \
    -p ''{\"imagePullSecrets\": [{\"name\": \"my-rhdh-pull-secret\"}]}'' \ -n {my-rhdh-namespace}`.'
  user_input: How do I provison the pull secret for the Red Hat Contaner Regestry
    on my GKE cluster so my dev hub can pull images?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Google Kubernetes Engine (GKE) before running Red Hat Developer Hub.
    [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step to
    run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your GKE cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ## Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Google Kubernetes Engine (GKE), the Red Hat Container
    Registry pull-secret is not managed globally. Therefore add your pull-secret in
    your Red Hat Developer Hub instance namespace. Your credentials to the Red Hat
    Container Registry: <redhat_user_name> <redhat_password> <email> You created the
    {my rhdh project} namespace on GKE to host your Developer Hub instance. 1. Create
    a pull secret using your Red Hat credentials to pull the container images from
    the protected Red Hat Container Registry (registry.redhat.io): ```terminal $ kubectl
    n {my rhdh namespace} create secret docker registry my rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 2. To enable pulling Developer Hub images from the
    Red Hat Container Registry, add the image pull secret in the default service account
    within the namespace where the Developer Hub instance is being deployed: ```terminal
    $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets": [{"name": "my-rhdh-pull-secret"}]}''
    \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:07:21.255111'
    uuid: e8016a20-0556-49bf-9f78-8d747d010541
  response: "By default, Developer Hub disables plugins that require configuration\
    \ or secrets, such as the GitHub repository discovery plugin. To enable this feature,\
    \ you must author a custom `dynamic-plugins.yaml` file. The configuration to enable\
    \ the GitHub repository discovery plugin is as follows: ```yaml\nincludes: dynamic\
    \ plugins.default.yaml\nplugins:\n  - package: ./dynamic plugins/dist/backstage\
    \ plugin catalog backend module github\n    disabled: false\n```"
  user_input: I'm trying to set up our Red Hat Developer Hub instance, but the default
    configuraton seems to have the GitHub repository discovery plguin disabeld. What
    specific file and code snippet do I need to use to enable this feature?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the GKE cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:07:31.279502'
    uuid: 2f0481a8-5c71-45a1-89c4-52c42ff60f0a
  response: "To configure RBAC policies, you must mount the files from the `rbac-policies`\
    \ config map in your Backstage Custom Resource. This is done by adding `name:\
    \ rbac policies` to the list under `spec.application.appConfig.configMaps`. An\
    \ example of a custom resource with RBAC policies config maps includes the following\
    \ snippet: ```yaml\nspec:\n  application:\n    appConfig:\n      mountPath: /opt/app\
    \ root/src\n      configMaps:\n        - name: my rhdh app config\n        - name:\
    \ rbac policies\n```"
  user_input: Red Hat Developer Hub CR RBAC configuration
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the GKE cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:07:53.946193'
    uuid: 2d3d5f62-4829-4dac-a68a-4590a26ba505
  response: To use the Developer Hub Operator to run Red Hat Developer Hub with a
    custom configuration, you must create a Backstage custom resource (CR). This CR
    is authored in a YAML file and is designed to mount files from your custom config
    maps and inject environment variables from your custom secrets. The CR can be
    configured with optional fields such as `spec.application.appConfig.configMaps`
    to list config maps, `spec.application.extraEnvs.secrets` for environment variable
    secrets, and `spec.database.enableLocalDb` to manage the local PostgreSQL database.
    After authoring the file, you apply the Backstage CR using the command `oc apply
    -filename=my-rhdh-custom-resource.yaml` to start or update your Developer Hub
    instance.
  user_input: What is the process for using the Developer Hub Operator to run a Red
    Hat Developer Hub instance with a custom configuration?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the GKE cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:08:04.494095'
    uuid: c8dc8f1b-8db4-4216-917a-6d1d2b90db28
  response: To run Red Hat Developer Hub with a custom configuration, you create a
    Backstage custom resource (CR) that mounts files from your custom config maps
    and injects environment variables from your custom secrets. This CR is authored
    in a `.yaml` file and then applied using the command `$ oc apply - filename=my
    rhdh custom resource.yaml - namespace=my rhdh project` to start or update your
    Developer Hub instance.
  user_input: How is a custom configuration applied to the Red Hat Developer Hub?
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Google Kubernetes
    Engine (GKE) On Google Kubernetes Engine (GKE), to expose your Red Hat Developer
    Hub instance, Kubernetes ingresses replace OpenShift Container Platform routes.
    The Red Hat Developer Hub operator does not create ingresses. Therefore, to access
    your Developer Hub instance via a domain name, create the required ingresses on
    GKE and point your domain name to it. You have installed Red Hat Developer Hub
    by using the Red Hat Developer Hub Operator. You have configured a domain name
    for your Developer Hub instance. You have reserved a static external Premium IPv4
    Global IP address that is not attached to any virtual machine (VM). For more information
    see Reserve a new static external IP address You have configured the DNS records
    for your domain name to point to the IP address that has been reserved. [NOTE]
    ---- You need to create an A record with the value equal to the IP address. This
    process can take up to one hour to propagate. ---- 1. Create a Google-managed
    certificate manifest file, named managed-certificate.yaml: ```yaml apiVersion:
    networking.gke.io/v1 kind: ManagedCertificate metadata: name: my rhdh certificate
    name spec: domains: <my_developer_hub_domain> ``` For more information about setting
    up a Google-managed certificate, see Setting up a Google-managed certificate.
    2. Deploy the managed certificate: ```terminal $ kubectl n my rhdh project apply
    f managed certificate.yaml ``` 3. Create a frontend config manifest file, named
    frontend-config.yaml, to set a policy for redirecting to HTTPS. ```yaml apiVersion:
    networking.gke.io/v1beta1 kind: FrontendConfig metadata: name: my ingress_security_config
    spec: sslPolicy: gke ingress ssl policy https redirectToHttps: enabled: true ```
    For more information about setting a policy to redirect to HTTPS, see HTTP to
    HTTPS redirects. 4. Deploy the frontend config: ```terminal $ kubectl n my rhdh
    project apply f frontend config.yaml ``` 5. Create an ingress manifest file, named
    rhdh-ingress.yaml, specifying your Developer Hub service name, and using your
    managed certificate and your frontend config: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my rhdh ingress annotations: kubernetes.io/ingress.class:
    "gce" kubernetes.io/ingress.global static ip name: <ADDRESS_NAME> networking.gke.io/managed
    certificates: my rhdh certificate name networking.gke.io/v1beta1.FrontendConfig:
    my ingress_security_config spec: ingressClassName: gce rules: host: <my_developer_hub_domain>
    http: paths: path: / pathType: Prefix backend: service: name: my rhdh custom resource
    port: name: http backend ``` 6. Deploy the ingress: ```terminal $ kubectl n my
    rhdh project apply f rhdh ingress.yaml ``` Wait for the ManagedCertificate to
    be provisioned. This process can take a couple of hours. Access RHDH with https://<my_developer_hub_domain>.
    For more information on setting up GKE using Ingress with TLS, see Secure GKE
    Ingress. #'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:08:17.024091'
    uuid: 118405c1-720d-4532-9560-585610de2288
  response: 'To expose your Red Hat Developer Hub instance on Google Kubernetes Engine
    (GKE) and configure it for HTTPS, you must first create a Google-managed certificate
    manifest file (`managed-certificate.yaml`) specifying your domain, and then deploy
    it. Second, create a frontend config manifest file (`frontend-config.yaml`) to
    set a policy for redirecting to HTTPS, and deploy that as well. Third, create
    an ingress manifest file (`rhdh-ingress.yaml`) that specifies your Developer Hub
    service name and uses your managed certificate and frontend config. This ingress
    manifest should include the annotations `kubernetes.io/ingress.class: "gce"`,
    `kubernetes.io/ingress.global-static-ip-name: <ADDRESS_NAME>`, `networking.gke.io/managed-certificates:
    my-rhdh-certificate-name`, and `networking.gke.io/v1beta1.FrontendConfig: my-ingress_security_config`.
    Finally, deploy the ingress. After deployment, you must wait for the ManagedCertificate
    to be provisioned, which can take a couple of hours.'
  user_input: I'm trying to expose my Red Hat Developer Hub on GKE and I need to setup
    Tls termination, but I'm not sure how. What are the exact steps i need to follow
    to configur the ingress with a Google-managed certificat and make sure all trafic
    redirects to https?
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Google Kubernetes
    Engine (GKE) On Google Kubernetes Engine (GKE), to expose your Red Hat Developer
    Hub instance, Kubernetes ingresses replace OpenShift Container Platform routes.
    The Red Hat Developer Hub operator does not create ingresses. Therefore, to access
    your Developer Hub instance via a domain name, create the required ingresses on
    GKE and point your domain name to it. You have installed Red Hat Developer Hub
    by using the Red Hat Developer Hub Operator. You have configured a domain name
    for your Developer Hub instance. You have reserved a static external Premium IPv4
    Global IP address that is not attached to any virtual machine (VM). For more information
    see Reserve a new static external IP address You have configured the DNS records
    for your domain name to point to the IP address that has been reserved. [NOTE]
    ---- You need to create an A record with the value equal to the IP address. This
    process can take up to one hour to propagate. ---- 1. Create a Google-managed
    certificate manifest file, named managed-certificate.yaml: ```yaml apiVersion:
    networking.gke.io/v1 kind: ManagedCertificate metadata: name: my rhdh certificate
    name spec: domains: <my_developer_hub_domain> ``` For more information about setting
    up a Google-managed certificate, see Setting up a Google-managed certificate.
    2. Deploy the managed certificate: ```terminal $ kubectl n my rhdh project apply
    f managed certificate.yaml ``` 3. Create a frontend config manifest file, named
    frontend-config.yaml, to set a policy for redirecting to HTTPS. ```yaml apiVersion:
    networking.gke.io/v1beta1 kind: FrontendConfig metadata: name: my ingress_security_config
    spec: sslPolicy: gke ingress ssl policy https redirectToHttps: enabled: true ```
    For more information about setting a policy to redirect to HTTPS, see HTTP to
    HTTPS redirects. 4. Deploy the frontend config: ```terminal $ kubectl n my rhdh
    project apply f frontend config.yaml ``` 5. Create an ingress manifest file, named
    rhdh-ingress.yaml, specifying your Developer Hub service name, and using your
    managed certificate and your frontend config: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my rhdh ingress annotations: kubernetes.io/ingress.class:
    "gce" kubernetes.io/ingress.global static ip name: <ADDRESS_NAME> networking.gke.io/managed
    certificates: my rhdh certificate name networking.gke.io/v1beta1.FrontendConfig:
    my ingress_security_config spec: ingressClassName: gce rules: host: <my_developer_hub_domain>
    http: paths: path: / pathType: Prefix backend: service: name: my rhdh custom resource
    port: name: http backend ``` 6. Deploy the ingress: ```terminal $ kubectl n my
    rhdh project apply f rhdh ingress.yaml ``` Wait for the ManagedCertificate to
    be provisioned. This process can take a couple of hours. Access RHDH with https://<my_developer_hub_domain>.
    For more information on setting up GKE using Ingress with TLS, see Secure GKE
    Ingress. #'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:08:34.476678'
    uuid: cefa044b-2e3f-47ad-9e3a-25190acbcc71
  response: On Google Kubernetes Engine (GKE), you must use Kubernetes ingresses to
    expose your Red Hat Developer Hub instance. The Red Hat Developer Hub Operator
    does not create these ingresses for you. To provide access via a domain name,
    you must manually create the required ingresses on GKE. This process requires
    a configured domain name with its DNS records pointing to a reserved static external
    Premium IPv4 Global IP address. You will then need to create and deploy a Google-managed
    certificate manifest, a frontend config manifest to redirect to HTTPS, and an
    ingress manifest that uses the certificate and frontend config to route traffic
    to your Developer Hub service.
  user_input: How do I expose a service deployed with the Red Hat Developer Hub Operator
    on GKE?
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Google Kubernetes
    Engine (GKE) On Google Kubernetes Engine (GKE), to expose your Red Hat Developer
    Hub instance, Kubernetes ingresses replace OpenShift Container Platform routes.
    The Red Hat Developer Hub operator does not create ingresses. Therefore, to access
    your Developer Hub instance via a domain name, create the required ingresses on
    GKE and point your domain name to it. You have installed Red Hat Developer Hub
    by using the Red Hat Developer Hub Operator. You have configured a domain name
    for your Developer Hub instance. You have reserved a static external Premium IPv4
    Global IP address that is not attached to any virtual machine (VM). For more information
    see Reserve a new static external IP address You have configured the DNS records
    for your domain name to point to the IP address that has been reserved. [NOTE]
    ---- You need to create an A record with the value equal to the IP address. This
    process can take up to one hour to propagate. ---- 1. Create a Google-managed
    certificate manifest file, named managed-certificate.yaml: ```yaml apiVersion:
    networking.gke.io/v1 kind: ManagedCertificate metadata: name: my rhdh certificate
    name spec: domains: <my_developer_hub_domain> ``` For more information about setting
    up a Google-managed certificate, see Setting up a Google-managed certificate.
    2. Deploy the managed certificate: ```terminal $ kubectl n my rhdh project apply
    f managed certificate.yaml ``` 3. Create a frontend config manifest file, named
    frontend-config.yaml, to set a policy for redirecting to HTTPS. ```yaml apiVersion:
    networking.gke.io/v1beta1 kind: FrontendConfig metadata: name: my ingress_security_config
    spec: sslPolicy: gke ingress ssl policy https redirectToHttps: enabled: true ```
    For more information about setting a policy to redirect to HTTPS, see HTTP to
    HTTPS redirects. 4. Deploy the frontend config: ```terminal $ kubectl n my rhdh
    project apply f frontend config.yaml ``` 5. Create an ingress manifest file, named
    rhdh-ingress.yaml, specifying your Developer Hub service name, and using your
    managed certificate and your frontend config: ```yaml apiVersion: networking.k8s.io/v1
    kind: Ingress metadata: name: my rhdh ingress annotations: kubernetes.io/ingress.class:
    "gce" kubernetes.io/ingress.global static ip name: <ADDRESS_NAME> networking.gke.io/managed
    certificates: my rhdh certificate name networking.gke.io/v1beta1.FrontendConfig:
    my ingress_security_config spec: ingressClassName: gce rules: host: <my_developer_hub_domain>
    http: paths: path: / pathType: Prefix backend: service: name: my rhdh custom resource
    port: name: http backend ``` 6. Deploy the ingress: ```terminal $ kubectl n my
    rhdh project apply f rhdh ingress.yaml ``` Wait for the ManagedCertificate to
    be provisioned. This process can take a couple of hours. Access RHDH with https://<my_developer_hub_domain>.
    For more information on setting up GKE using Ingress with TLS, see Secure GKE
    Ingress. #'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:08:42.567675'
    uuid: e1040fe1-febe-4cb6-a205-bc9d23db5250
  response: On Google Kubernetes Engine (GKE), to expose your Red Hat Developer Hub
    instance and access it via a domain name, you need to create the required ingresses.
    This involves creating a Google-managed certificate manifest file, a frontend
    config manifest file to set a policy for redirecting to HTTPS, and an ingress
    manifest file that specifies your Developer Hub service name while using your
    managed certificate and frontend config.
  user_input: What do I need to create to expose my Developer Hub instanc on GKE?
- context:
  - 'Installing Developer Hub on GKE with the Helm chart When you install the Developer
    Hub Helm chart in Google Kubernetes Engine (GKE), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the GKE ecosystem. You have subscribed to the Red Hat Container Registry (registry.redhat.io).
    For more information, see Red Hat Container Registry Authentication. You have
    installed kubectl. For more information, see Install kubetl. You have installed
    the Google Cloud CLI. For more information, see Install the gcloud CLI. You have
    logged in to your Google account and created a GKE Autopilot or GKE Standard cluster.
    You have configured a domain name for your Developer Hub instance. You have reserved
    a static external Premium IPv4 Global IP address that is not attached to any VM.
    For more information see Reserve a new static external IP address You have configured
    the DNS records for your domain name to point to the IP address that has been
    reserved. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. [NOTE] ---- You need to create
    an A record with the value equal to the IP address. This process can take up to
    one hour to propagate. ---- * You have installed Helm 3 or the latest. For more
    information, see Installing Helm. 1. Go to your terminal and run the following
    command to add the Helm chart repository containing the Developer Hub chart to
    your local Helm registry: ```terminal helm repo add openshift-helm-charts https://charts.openshift.io/
    ``` 2. Create a pull secret using the following command: ```terminal kubectl n
    <your namespace> create secret docker registry rhdh pull secret \ 1 docker server=registry.redhat.io
    \ docker username=<user_name> \ 2 docker password=<password> \ 3 docker email=<email>
    4 ``` Enter your GKE namespace in the command. Enter your username in the command.
    Enter your password in the command. Enter your email address in the command. The
    created pull secret is used to pull the Developer Hub images from the Red Hat
    Container Registry. 3. Set up a Google-managed certificate by creating a ManagedCertificate
    object that you must attach to the ingress. ```yaml apiVersion: networking.gke.io/v1
    kind: ManagedCertificate metadata: name: <rhdh_certificate_name> spec: domains:
    <rhdh_domain_name> ``` For more information about setting up a Google-managed
    certificate, see Setting up a Google-managed certificate. 4. Create a FrontendConfig
    object to set a policy for redirecting to HTTPS. You must attach this policy to
    the ingress. ```yaml apiVersion: networking.gke.io/v1beta1 kind: FrontendConfig
    metadata: name: <ingress_security_config> spec: sslPolicy: gke ingress ssl policy
    https redirectToHttps: enabled: true ``` For more information about setting a
    policy to redirect to HTTPS, see HTTP to HTTPS redirects. 5. Create a file named
    values.yaml using the following template: Example values.yaml file ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 6. Run the following
    command in your terminal to deploy Developer Hub using the latest version of Helm
    Chart and using the values.yaml file: ```terminal helm n <your_namespace> install
    f values.yaml <your_deploy_name> \ openshift helm charts/redhat developer hub
    \ version 1.8.0 ``` For the latest Helm Chart version, see this Helm Charts repository.
    Confirm that the deployment is complete. ```terminal kubectl get deploy <your_deploy_name>
    developer hub n <your_namespace> ``` Verify that the service and ingress were
    created. ```terminal kubectl get service n <your_namespace> kubectl get ingress
    n <your_namespace> ``` [NOTE] ---- Wait for the ManagedCertificate to be provisioned.
    This process can take a couple of hours. ---- * Access RHDH with https://<my_developer_hub_domain>.
    * To upgrade your deployment, use the following command: ```terminal helm n <your_namespace>
    upgrade f values.yaml <your_deploy_name> openshift helm charts/redhat developer
    hub - version <UPGRADE_CHART_VERSION> ``` To delete your deployment, use the following
    command: ```terminal helm n <your_namespace> delete <your_deploy_name> ```'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:08:52.691265'
    uuid: 5473e406-3566-4ed7-8732-2bc11a330921
  response: 'In the example `values.yaml` file, the configuration for `postgresql`
    specifies `rhdh-pull-secret` for `image.pullSecrets`. For the `primary` instance,
    `podSecurityContext` is set to `enabled: true` with an `fsGroup` of 3000, and
    `volumePermissions` is also set to `enabled: true`.'
  user_input: What are the configuration settings for PostgreSQL in the Developer
    Hub Helm chart's values.yaml file?
- context:
  - 'Installing Developer Hub on GKE with the Helm chart When you install the Developer
    Hub Helm chart in Google Kubernetes Engine (GKE), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the GKE ecosystem. You have subscribed to the Red Hat Container Registry (registry.redhat.io).
    For more information, see Red Hat Container Registry Authentication. You have
    installed kubectl. For more information, see Install kubetl. You have installed
    the Google Cloud CLI. For more information, see Install the gcloud CLI. You have
    logged in to your Google account and created a GKE Autopilot or GKE Standard cluster.
    You have configured a domain name for your Developer Hub instance. You have reserved
    a static external Premium IPv4 Global IP address that is not attached to any VM.
    For more information see Reserve a new static external IP address You have configured
    the DNS records for your domain name to point to the IP address that has been
    reserved. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. [NOTE] ---- You need to create
    an A record with the value equal to the IP address. This process can take up to
    one hour to propagate. ---- * You have installed Helm 3 or the latest. For more
    information, see Installing Helm. 1. Go to your terminal and run the following
    command to add the Helm chart repository containing the Developer Hub chart to
    your local Helm registry: ```terminal helm repo add openshift-helm-charts https://charts.openshift.io/
    ``` 2. Create a pull secret using the following command: ```terminal kubectl n
    <your namespace> create secret docker registry rhdh pull secret \ 1 docker server=registry.redhat.io
    \ docker username=<user_name> \ 2 docker password=<password> \ 3 docker email=<email>
    4 ``` Enter your GKE namespace in the command. Enter your username in the command.
    Enter your password in the command. Enter your email address in the command. The
    created pull secret is used to pull the Developer Hub images from the Red Hat
    Container Registry. 3. Set up a Google-managed certificate by creating a ManagedCertificate
    object that you must attach to the ingress. ```yaml apiVersion: networking.gke.io/v1
    kind: ManagedCertificate metadata: name: <rhdh_certificate_name> spec: domains:
    <rhdh_domain_name> ``` For more information about setting up a Google-managed
    certificate, see Setting up a Google-managed certificate. 4. Create a FrontendConfig
    object to set a policy for redirecting to HTTPS. You must attach this policy to
    the ingress. ```yaml apiVersion: networking.gke.io/v1beta1 kind: FrontendConfig
    metadata: name: <ingress_security_config> spec: sslPolicy: gke ingress ssl policy
    https redirectToHttps: enabled: true ``` For more information about setting a
    policy to redirect to HTTPS, see HTTP to HTTPS redirects. 5. Create a file named
    values.yaml using the following template: Example values.yaml file ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 6. Run the following
    command in your terminal to deploy Developer Hub using the latest version of Helm
    Chart and using the values.yaml file: ```terminal helm n <your_namespace> install
    f values.yaml <your_deploy_name> \ openshift helm charts/redhat developer hub
    \ version 1.8.0 ``` For the latest Helm Chart version, see this Helm Charts repository.
    Confirm that the deployment is complete. ```terminal kubectl get deploy <your_deploy_name>
    developer hub n <your_namespace> ``` Verify that the service and ingress were
    created. ```terminal kubectl get service n <your_namespace> kubectl get ingress
    n <your_namespace> ``` [NOTE] ---- Wait for the ManagedCertificate to be provisioned.
    This process can take a couple of hours. ---- * Access RHDH with https://<my_developer_hub_domain>.
    * To upgrade your deployment, use the following command: ```terminal helm n <your_namespace>
    upgrade f values.yaml <your_deploy_name> openshift helm charts/redhat developer
    hub - version <UPGRADE_CHART_VERSION> ``` To delete your deployment, use the following
    command: ```terminal helm n <your_namespace> delete <your_deploy_name> ```'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:02.416182'
    uuid: 40f4e4da-cc65-4ffe-a48e-1d2779ebeb75
  response: 'To install Developer Hub on Google Kubernetes Engine (GKE), you must
    have the following prerequisites in place: a subscription to the Red Hat Container
    Registry, kubectl installed, and the Google Cloud CLI installed. You need to be
    logged into your Google account and have created a GKE Autopilot or GKE Standard
    cluster. Additionally, you must have configured a domain name, reserved a static
    external Premium IPv4 Global IP address that is not attached to a VM, and configured
    the DNS A record for your domain to point to that IP address. Your system must
    also meet the minimum sizing requirements, and you need Helm 3 or the latest version
    installed.'
  user_input: what are the prerequisites for installing Developer Hub on Google Kubernetes
    Engine
- context:
  - 'Installing Developer Hub on GKE with the Helm chart When you install the Developer
    Hub Helm chart in Google Kubernetes Engine (GKE), it orchestrates the deployment
    of a Developer Hub instance, which provides a robust developer platform within
    the GKE ecosystem. You have subscribed to the Red Hat Container Registry (registry.redhat.io).
    For more information, see Red Hat Container Registry Authentication. You have
    installed kubectl. For more information, see Install kubetl. You have installed
    the Google Cloud CLI. For more information, see Install the gcloud CLI. You have
    logged in to your Google account and created a GKE Autopilot or GKE Standard cluster.
    You have configured a domain name for your Developer Hub instance. You have reserved
    a static external Premium IPv4 Global IP address that is not attached to any VM.
    For more information see Reserve a new static external IP address You have configured
    the DNS records for your domain name to point to the IP address that has been
    reserved. Make sure that your system meets the minimum sizing requirements. See
    Sizing requirements for Red Hat Developer Hub. [NOTE] ---- You need to create
    an A record with the value equal to the IP address. This process can take up to
    one hour to propagate. ---- * You have installed Helm 3 or the latest. For more
    information, see Installing Helm. 1. Go to your terminal and run the following
    command to add the Helm chart repository containing the Developer Hub chart to
    your local Helm registry: ```terminal helm repo add openshift-helm-charts https://charts.openshift.io/
    ``` 2. Create a pull secret using the following command: ```terminal kubectl n
    <your namespace> create secret docker registry rhdh pull secret \ 1 docker server=registry.redhat.io
    \ docker username=<user_name> \ 2 docker password=<password> \ 3 docker email=<email>
    4 ``` Enter your GKE namespace in the command. Enter your username in the command.
    Enter your password in the command. Enter your email address in the command. The
    created pull secret is used to pull the Developer Hub images from the Red Hat
    Container Registry. 3. Set up a Google-managed certificate by creating a ManagedCertificate
    object that you must attach to the ingress. ```yaml apiVersion: networking.gke.io/v1
    kind: ManagedCertificate metadata: name: <rhdh_certificate_name> spec: domains:
    <rhdh_domain_name> ``` For more information about setting up a Google-managed
    certificate, see Setting up a Google-managed certificate. 4. Create a FrontendConfig
    object to set a policy for redirecting to HTTPS. You must attach this policy to
    the ingress. ```yaml apiVersion: networking.gke.io/v1beta1 kind: FrontendConfig
    metadata: name: <ingress_security_config> spec: sslPolicy: gke ingress ssl policy
    https redirectToHttps: enabled: true ``` For more information about setting a
    policy to redirect to HTTPS, see HTTP to HTTPS redirects. 5. Create a file named
    values.yaml using the following template: Example values.yaml file ```yaml global:
    host: <rhdh_domain_name> route: enabled: false upstream: service: type: NodePort
    ingress: enabled: true annotations: kubernetes.io/ingress.class: gce kubernetes.io/ingress.global
    static ip name: <ADDRESS_NAME> networking.gke.io/managed certificates: <rhdh_certificate_name>
    networking.gke.io/v1beta1.FrontendConfig: <ingress_security_config> className:
    gce backstage: image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup:
    2000 postgresql: image: pullSecrets: rhdh pull secret primary: podSecurityContext:
    enabled: true fsGroup: 3000 volumePermissions: enabled: true ``` 6. Run the following
    command in your terminal to deploy Developer Hub using the latest version of Helm
    Chart and using the values.yaml file: ```terminal helm n <your_namespace> install
    f values.yaml <your_deploy_name> \ openshift helm charts/redhat developer hub
    \ version 1.8.0 ``` For the latest Helm Chart version, see this Helm Charts repository.
    Confirm that the deployment is complete. ```terminal kubectl get deploy <your_deploy_name>
    developer hub n <your_namespace> ``` Verify that the service and ingress were
    created. ```terminal kubectl get service n <your_namespace> kubectl get ingress
    n <your_namespace> ``` [NOTE] ---- Wait for the ManagedCertificate to be provisioned.
    This process can take a couple of hours. ---- * Access RHDH with https://<my_developer_hub_domain>.
    * To upgrade your deployment, use the following command: ```terminal helm n <your_namespace>
    upgrade f values.yaml <your_deploy_name> openshift helm charts/redhat developer
    hub - version <UPGRADE_CHART_VERSION> ``` To delete your deployment, use the following
    command: ```terminal helm n <your_namespace> delete <your_deploy_name> ```'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:09.480367'
    uuid: c1458ded-8ea1-4f62-aa88-1a0e7abda303
  response: A pull secret is created and used to pull the Developer Hub images from
    the Red Hat Container Registry.
  user_input: why i need red hat container registry for this install?
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Dedicated on Google Cloud You
    can install Developer Hub on OpenShift Dedicated on Google Cloud (Google Cloud)
    using one of the following methods: * The Red Hat Developer Hub Operator * The
    Red Hat Developer Hub Helm chart [IMPORTANT] ---- You must set the baseUrl in
    app-config.yaml to match the external URL of your Developer Hub instance. This
    value is required for the Red Hat Developer Hub to function correctly. If it is
    not set, frontend and backend services cannot communicate properly, and features
    may not work as expected. ---- # Installing Red Hat Developer Hub on OpenShift
    Dedicated on Google Cloud using the Operator You can install Developer Hub on
    OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Operator.
    You have a valid Google Cloud account. Your OpenShift Dedicated cluster is running
    on Google Cloud. For more information, seeCreating a cluster on GCP in Red Hat
    OpenShift Dedicated documentation. You have administrator access to OpenShift
    Dedicated cluster and Google Cloud project. Make sure that your system meets the
    minimum sizing requirements. See Sizing requirements for Red Hat Developer Hub.
    1. In the OpenShift Container Platform web console menu, go to Operators > OperatorHub.
    2. In the Filter by keyword field, enter Developer Hub and click the Red Hat Developer
    Hub Operator card. 3. On the Red Hat Developer Hub Operator page, click Install.
    4. After the installation completes, navigate to Installed Operators and select
    Red Hat Developer Hub Operator. 5. Provision your custom configuration: ```yaml
    apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh data: "app-config.yaml":
    | app: title: Red Hat Developer Hub baseUrl: https://__<my_developer_hub_domain>__
    backend: auth: externalAccess: - type: legacy options: subject: legacy-default-config
    secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__ cors:
    origin: https://__<my_developer_hub_domain>__ ``` You must create a config map
    named app-config-rhdh and a Kubernetes Secret containing the BACKEND_SECRET. These
    resources are used by the Developer Hub instance for authentication and application
    settings. For further steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 6. Create a config map named app-config-rhdh that includes your
    app-config.yaml as shown: ```yaml apiVersion: v1 kind: ConfigMap metadata: name:
    app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer Hub baseUrl:
    https://__<my_developer_hub_domain>__ backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__
    cors: origin: https://__<my_developer_hub_domain>__ ``` 7. Create a secret named
    my-rhdh-secrets and add a key named BACKEND_SECRET with a Base64-encoded string
    as value: ```yaml apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets
    stringData: # TODO: Add the necessary auth secrets for service-to-service auth
    setup BACKEND_SECRET: "xxx" # Replace with your Base64-encoded secret ``` 8. Return
    to the Developer Hub Operator page and click Create New Instance. 9. Specify the
    name and target namespace for the Developer Hub deployment. 10. Configure required
    options such as Git integration, secrets, and user permissions. 11. Review the
    configuration, select deployment options, and click Create. To access the Developer
    Hub, navigate to the Developer Hub URL provided in the OpenShift Container Platform
    web console. Configuring Red Hat Developer Hub'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:18.805506'
    uuid: 341b8657-60f4-46e1-93d7-d90ac7701a33
  response: 'To install Red Hat Developer Hub on OpenShift Dedicated on Google Cloud
    using the Red Hat Developer Hub Operator, you must first meet several prerequisites:
    have a valid Google Cloud account, an OpenShift Dedicated cluster running on Google
    Cloud, administrator access to both the cluster and the Google Cloud project,
    and ensure your system meets minimum sizing requirements. The installation process
    begins in the OpenShift Container Platform web console by navigating to Operators
    > OperatorHub, searching for "Developer Hub", and clicking the Red Hat Developer
    Hub Operator card to install it. Once installed, you must provision a custom configuration
    by creating a ConfigMap named "app-config-rhdh" that contains your "app-config.yaml"
    file, which must include the correct "baseUrl". You also need to create a Kubernetes
    Secret, such as one named "my-rhdh-secrets", which contains a key named "BACKEND_SECRET"
    with a Base64-encoded string as its value. After these resources are created,
    return to the Developer Hub Operator page, click "Create New Instance", specify
    a name and target namespace, configure options like Git integration and secrets,
    review the configuration, and click "Create".'
  user_input: Considering the need to establish a standardized deployment process,
    what is the complete, step-by-step procedure for installing Red Hat Developer
    Hub on an OpenShift Dedicated cluster on Google Cloud by utilizing the Red Hat
    Developer Hub Operator, including all necessary prerequisites and the specific
    configuration of required resources such as the 'app-config-rhdh' ConfigMap and
    the Kubernetes Secret for the BACKEND_SECRET?
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Dedicated on Google Cloud You
    can install Developer Hub on OpenShift Dedicated on Google Cloud (Google Cloud)
    using one of the following methods: * The Red Hat Developer Hub Operator * The
    Red Hat Developer Hub Helm chart [IMPORTANT] ---- You must set the baseUrl in
    app-config.yaml to match the external URL of your Developer Hub instance. This
    value is required for the Red Hat Developer Hub to function correctly. If it is
    not set, frontend and backend services cannot communicate properly, and features
    may not work as expected. ---- # Installing Red Hat Developer Hub on OpenShift
    Dedicated on Google Cloud using the Operator You can install Developer Hub on
    OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Operator.
    You have a valid Google Cloud account. Your OpenShift Dedicated cluster is running
    on Google Cloud. For more information, seeCreating a cluster on GCP in Red Hat
    OpenShift Dedicated documentation. You have administrator access to OpenShift
    Dedicated cluster and Google Cloud project. Make sure that your system meets the
    minimum sizing requirements. See Sizing requirements for Red Hat Developer Hub.
    1. In the OpenShift Container Platform web console menu, go to Operators > OperatorHub.
    2. In the Filter by keyword field, enter Developer Hub and click the Red Hat Developer
    Hub Operator card. 3. On the Red Hat Developer Hub Operator page, click Install.
    4. After the installation completes, navigate to Installed Operators and select
    Red Hat Developer Hub Operator. 5. Provision your custom configuration: ```yaml
    apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh data: "app-config.yaml":
    | app: title: Red Hat Developer Hub baseUrl: https://__<my_developer_hub_domain>__
    backend: auth: externalAccess: - type: legacy options: subject: legacy-default-config
    secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__ cors:
    origin: https://__<my_developer_hub_domain>__ ``` You must create a config map
    named app-config-rhdh and a Kubernetes Secret containing the BACKEND_SECRET. These
    resources are used by the Developer Hub instance for authentication and application
    settings. For further steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 6. Create a config map named app-config-rhdh that includes your
    app-config.yaml as shown: ```yaml apiVersion: v1 kind: ConfigMap metadata: name:
    app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer Hub baseUrl:
    https://__<my_developer_hub_domain>__ backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__
    cors: origin: https://__<my_developer_hub_domain>__ ``` 7. Create a secret named
    my-rhdh-secrets and add a key named BACKEND_SECRET with a Base64-encoded string
    as value: ```yaml apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets
    stringData: # TODO: Add the necessary auth secrets for service-to-service auth
    setup BACKEND_SECRET: "xxx" # Replace with your Base64-encoded secret ``` 8. Return
    to the Developer Hub Operator page and click Create New Instance. 9. Specify the
    name and target namespace for the Developer Hub deployment. 10. Configure required
    options such as Git integration, secrets, and user permissions. 11. Review the
    configuration, select deployment options, and click Create. To access the Developer
    Hub, navigate to the Developer Hub URL provided in the OpenShift Container Platform
    web console. Configuring Red Hat Developer Hub'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:26.733357'
    uuid: 49b348a5-4df4-42cc-acd1-80e77bed2333
  response: 'According to the provided context, you can install Red Hat Developer
    Hub on OpenShift Dedicated on Google Cloud using one of two methods: the Red Hat
    Developer Hub Operator or the Red Hat Developer Hub Helm chart. The document provides
    a detailed, step-by-step guide for the Operator installation method but does not
    offer a procedural walkthrough for the Helm chart installation.'
  user_input: Based on the provided installation guide for Red Hat Developer Hub on
    OpenShift Dedicated on Google Cloud, what are the officially documented methods
    for deployment, and does the guide offer a procedural walkthrough for the installation
    using the Helm chart?
- context:
  - '# Installing Red Hat Developer Hub on OpenShift Dedicated on Google Cloud You
    can install Developer Hub on OpenShift Dedicated on Google Cloud (Google Cloud)
    using one of the following methods: * The Red Hat Developer Hub Operator * The
    Red Hat Developer Hub Helm chart [IMPORTANT] ---- You must set the baseUrl in
    app-config.yaml to match the external URL of your Developer Hub instance. This
    value is required for the Red Hat Developer Hub to function correctly. If it is
    not set, frontend and backend services cannot communicate properly, and features
    may not work as expected. ---- # Installing Red Hat Developer Hub on OpenShift
    Dedicated on Google Cloud using the Operator You can install Developer Hub on
    OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Operator.
    You have a valid Google Cloud account. Your OpenShift Dedicated cluster is running
    on Google Cloud. For more information, seeCreating a cluster on GCP in Red Hat
    OpenShift Dedicated documentation. You have administrator access to OpenShift
    Dedicated cluster and Google Cloud project. Make sure that your system meets the
    minimum sizing requirements. See Sizing requirements for Red Hat Developer Hub.
    1. In the OpenShift Container Platform web console menu, go to Operators > OperatorHub.
    2. In the Filter by keyword field, enter Developer Hub and click the Red Hat Developer
    Hub Operator card. 3. On the Red Hat Developer Hub Operator page, click Install.
    4. After the installation completes, navigate to Installed Operators and select
    Red Hat Developer Hub Operator. 5. Provision your custom configuration: ```yaml
    apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh data: "app-config.yaml":
    | app: title: Red Hat Developer Hub baseUrl: https://__<my_developer_hub_domain>__
    backend: auth: externalAccess: - type: legacy options: subject: legacy-default-config
    secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__ cors:
    origin: https://__<my_developer_hub_domain>__ ``` You must create a config map
    named app-config-rhdh and a Kubernetes Secret containing the BACKEND_SECRET. These
    resources are used by the Developer Hub instance for authentication and application
    settings. For further steps, see Provisioning your custom Red Hat Developer Hub
    configuration. 6. Create a config map named app-config-rhdh that includes your
    app-config.yaml as shown: ```yaml apiVersion: v1 kind: ConfigMap metadata: name:
    app-config-rhdh data: "app-config.yaml": | app: title: Red Hat Developer Hub baseUrl:
    https://__<my_developer_hub_domain>__ backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://__<my_developer_hub_domain>__
    cors: origin: https://__<my_developer_hub_domain>__ ``` 7. Create a secret named
    my-rhdh-secrets and add a key named BACKEND_SECRET with a Base64-encoded string
    as value: ```yaml apiVersion: v1 kind: Secret metadata: name: my-rhdh-secrets
    stringData: # TODO: Add the necessary auth secrets for service-to-service auth
    setup BACKEND_SECRET: "xxx" # Replace with your Base64-encoded secret ``` 8. Return
    to the Developer Hub Operator page and click Create New Instance. 9. Specify the
    name and target namespace for the Developer Hub deployment. 10. Configure required
    options such as Git integration, secrets, and user permissions. 11. Review the
    configuration, select deployment options, and click Create. To access the Developer
    Hub, navigate to the Developer Hub URL provided in the OpenShift Container Platform
    web console. Configuring Red Hat Developer Hub'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:35.296046'
    uuid: a46e74d9-b624-44e0-a0ed-42270f518d57
  response: To install Developer Hub on OpenShift Dedicated on Google Cloud using
    the Red Hat Developer Hub Operator, you must have a valid Google Cloud account,
    an OpenShift Dedicated cluster running on Google Cloud, and administrator access.
    In the OpenShift Container Platform web console, go to Operators > OperatorHub,
    enter "Developer Hub" in the filter field, and click the Red Hat Developer Hub
    Operator card, then click Install. Once the installation is complete, go to Installed
    Operators and select the Red Hat Developer Hub Operator. You must provision a
    custom configuration by creating a config map named app-config-rhdh that includes
    your app-config.yaml, ensuring the baseUrl is set to match the external URL. You
    also must create a Kubernetes Secret containing the BACKEND_SECRET, such as a
    secret named my-rhdh-secrets with a key named BACKEND_SECRET. Finally, return
    to the Developer Hub Operator page, click Create New Instance, specify the name
    and namespace, configure the required options, and click Create.
  user_input: My team is looking at this Red Hat Developer Hub Operator for our OpenShift
    on Google Cloud, and we is trying to figure out what all the steps is to get it
    installed, like what do we need to do in the OpenShift console and what kind of
    configurations or secrets we has to make for it to work right?
- context:
  - "Customizing Red Hat Developer Hub # Installing Red Hat Developer Hub on OpenShift\
    \ Dedicated on Google Cloud using the Helm Chart You can install Developer Hub\
    \ on OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Helm\
    \ Chart. You have a valid Google Cloud account. Your OpenShift Dedicated cluster\
    \ is running on Google Cloud. For more information, seeCreating a cluster on Google\
    \ Cloud in Red Hat OpenShift Dedicated documentation. You have installed Helm\
    \ 3 or the latest. Make sure that your system meets the minimum sizing requirements.\
    \ See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective\
    \ on the Developer Hub web console, click +Add. 2. From the Developer Catalog\
    \ panel, click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub\
    \ and click the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub\
    \ page, click Create. 5. From your cluster, copy the OpenShift Container Platform\
    \ router host (for example: apps.<clusterName>.com). 6. Select the radio button\
    \ to configure the Developer Hub instance with either the form view or YAML view.\
    \ [IMPORTANT] ---- Before deploying Developer Hub using the Helm chart, you must\
    \ define custom configuration settings such as the public baseUrl for your instance.\
    \ Without setting baseUrl, the application cannot function correctly. You can\
    \ define this configuration either through the Form view or the YAML view in the\
    \ Helm install wizard. To configure the baseUrl, set the following values in your\
    \ Helm configuration: ```yaml global: app: baseUrl: https://<your developer hub\
    \ link> backend: baseUrl: https://<your developer hub link> cors: origin: https://<your\
    \ developer hub link> ``` You can also define additional secrets, plugins, and\
    \ advanced configuration in your values.yaml file. For full instructions, see:\
    \ Provisioning your custom Red Hat Developer Hub configuration. ---- The Form\
    \ view is selected by default. 1. Using Form view 1. To configure the instance\
    \ with the Form view, go to Root Schema \u2192 global \u2192 Enable service authentication\
    \ within Backstage instance and paste your OpenShift Container Platform router\
    \ host into the field on the form. 2. Using YAML view 1. To configure the instance\
    \ with the YAML view, paste your OpenShift Container Platform router hostname\
    \ in the global.clusterRouterBase parameter value as shown in the following example:\
    \ ```yaml global: auth: backend: enabled: true clusterRouterBase: apps.<clusterName>.com\
    \ # other Red Hat Developer Hub Helm Chart configurations ``` 7. Edit the other\
    \ values if needed, then click Create and wait for the database and Developer\
    \ Hub to start. To access the the Developer Hub, click the Open URL icon. Configuring\
    \ Red Hat Developer Hub Customizing Red Hat Developer Hub"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:09:59.706378'
    uuid: 6f52c86a-8976-46c8-a7d1-37711dba1209
  response: Before deploying Red Hat Developer Hub using the Helm chart, you must
    define custom configuration settings, specifically the public baseUrl for your
    instance. The application cannot function correctly without setting the baseUrl.
    This can be configured through either the Form view or the YAML view in the Helm
    install wizard.
  user_input: What is a mandatory configuration step when deploying the Red Hat Developer
    Hub Helm chart?
- context:
  - "Customizing Red Hat Developer Hub # Installing Red Hat Developer Hub on OpenShift\
    \ Dedicated on Google Cloud using the Helm Chart You can install Developer Hub\
    \ on OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Helm\
    \ Chart. You have a valid Google Cloud account. Your OpenShift Dedicated cluster\
    \ is running on Google Cloud. For more information, seeCreating a cluster on Google\
    \ Cloud in Red Hat OpenShift Dedicated documentation. You have installed Helm\
    \ 3 or the latest. Make sure that your system meets the minimum sizing requirements.\
    \ See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective\
    \ on the Developer Hub web console, click +Add. 2. From the Developer Catalog\
    \ panel, click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub\
    \ and click the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub\
    \ page, click Create. 5. From your cluster, copy the OpenShift Container Platform\
    \ router host (for example: apps.<clusterName>.com). 6. Select the radio button\
    \ to configure the Developer Hub instance with either the form view or YAML view.\
    \ [IMPORTANT] ---- Before deploying Developer Hub using the Helm chart, you must\
    \ define custom configuration settings such as the public baseUrl for your instance.\
    \ Without setting baseUrl, the application cannot function correctly. You can\
    \ define this configuration either through the Form view or the YAML view in the\
    \ Helm install wizard. To configure the baseUrl, set the following values in your\
    \ Helm configuration: ```yaml global: app: baseUrl: https://<your developer hub\
    \ link> backend: baseUrl: https://<your developer hub link> cors: origin: https://<your\
    \ developer hub link> ``` You can also define additional secrets, plugins, and\
    \ advanced configuration in your values.yaml file. For full instructions, see:\
    \ Provisioning your custom Red Hat Developer Hub configuration. ---- The Form\
    \ view is selected by default. 1. Using Form view 1. To configure the instance\
    \ with the Form view, go to Root Schema \u2192 global \u2192 Enable service authentication\
    \ within Backstage instance and paste your OpenShift Container Platform router\
    \ host into the field on the form. 2. Using YAML view 1. To configure the instance\
    \ with the YAML view, paste your OpenShift Container Platform router hostname\
    \ in the global.clusterRouterBase parameter value as shown in the following example:\
    \ ```yaml global: auth: backend: enabled: true clusterRouterBase: apps.<clusterName>.com\
    \ # other Red Hat Developer Hub Helm Chart configurations ``` 7. Edit the other\
    \ values if needed, then click Create and wait for the database and Developer\
    \ Hub to start. To access the the Developer Hub, click the Open URL icon. Configuring\
    \ Red Hat Developer Hub Customizing Red Hat Developer Hub"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:10:10.953074'
    uuid: 85c909ca-5cdc-4922-83f6-f22a4fd1e48b
  response: "When installing Red Hat Developer Hub, you must copy the OpenShift Container\
    \ Platform router host from your cluster. If you are using the Form view for configuration,\
    \ you paste the router host into the field under Root Schema \u2192 global \u2192\
    \ Enable service authentication within Backstage instance. If you are using the\
    \ YAML view, you paste the OpenShift Container Platform router hostname as the\
    \ value for the `global.clusterRouterBase` parameter."
  user_input: According to the installation instructions, what is the specific purpose
    of the OpenShift Container Platform router host when configuring a Red Hat Developer
    Hub instance via the Helm chart?
- context:
  - "Customizing Red Hat Developer Hub # Installing Red Hat Developer Hub on OpenShift\
    \ Dedicated on Google Cloud using the Helm Chart You can install Developer Hub\
    \ on OpenShift Dedicated on Google Cloud using the Red Hat Developer Hub Helm\
    \ Chart. You have a valid Google Cloud account. Your OpenShift Dedicated cluster\
    \ is running on Google Cloud. For more information, seeCreating a cluster on Google\
    \ Cloud in Red Hat OpenShift Dedicated documentation. You have installed Helm\
    \ 3 or the latest. Make sure that your system meets the minimum sizing requirements.\
    \ See Sizing requirements for Red Hat Developer Hub. 1. From the Developer perspective\
    \ on the Developer Hub web console, click +Add. 2. From the Developer Catalog\
    \ panel, click Helm Chart. 3. In the Filter by keyword box, enter Developer Hub\
    \ and click the Red Hat Developer Hub card. 4. From the Red Hat Developer Hub\
    \ page, click Create. 5. From your cluster, copy the OpenShift Container Platform\
    \ router host (for example: apps.<clusterName>.com). 6. Select the radio button\
    \ to configure the Developer Hub instance with either the form view or YAML view.\
    \ [IMPORTANT] ---- Before deploying Developer Hub using the Helm chart, you must\
    \ define custom configuration settings such as the public baseUrl for your instance.\
    \ Without setting baseUrl, the application cannot function correctly. You can\
    \ define this configuration either through the Form view or the YAML view in the\
    \ Helm install wizard. To configure the baseUrl, set the following values in your\
    \ Helm configuration: ```yaml global: app: baseUrl: https://<your developer hub\
    \ link> backend: baseUrl: https://<your developer hub link> cors: origin: https://<your\
    \ developer hub link> ``` You can also define additional secrets, plugins, and\
    \ advanced configuration in your values.yaml file. For full instructions, see:\
    \ Provisioning your custom Red Hat Developer Hub configuration. ---- The Form\
    \ view is selected by default. 1. Using Form view 1. To configure the instance\
    \ with the Form view, go to Root Schema \u2192 global \u2192 Enable service authentication\
    \ within Backstage instance and paste your OpenShift Container Platform router\
    \ host into the field on the form. 2. Using YAML view 1. To configure the instance\
    \ with the YAML view, paste your OpenShift Container Platform router hostname\
    \ in the global.clusterRouterBase parameter value as shown in the following example:\
    \ ```yaml global: auth: backend: enabled: true clusterRouterBase: apps.<clusterName>.com\
    \ # other Red Hat Developer Hub Helm Chart configurations ``` 7. Edit the other\
    \ values if needed, then click Create and wait for the database and Developer\
    \ Hub to start. To access the the Developer Hub, click the Open URL icon. Configuring\
    \ Red Hat Developer Hub Customizing Red Hat Developer Hub"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:10:18.821727'
    uuid: b433624f-3886-4cf8-b524-cddbf2b8a2d2
  response: "Before deploying Red Hat Developer Hub using the Helm chart, you must\
    \ define custom configuration settings like the public baseUrl, as the application\
    \ cannot function correctly without it. You can define this configuration using\
    \ either the Form view or the YAML view in the Helm install wizard. To configure\
    \ the baseUrl in the YAML view, you must set the values for \"global.app.baseUrl\"\
    , \"global.backend.baseUrl\", and \"global.cors.origin\". You can also configure\
    \ the instance by pasting your OpenShift Container Platform router hostname in\
    \ the \"global.clusterRouterBase\" parameter in the YAML view, or by going to\
    \ Root Schema \u2192 global \u2192 Enable service authentication within Backstage\
    \ instance and pasting the router host into the field on the Form view."
  user_input: how do i configure the helm chartt?
- context:
  - '# TechDocs for Red Hat Developer Hub # About TechDocs The Red Hat Developer Hub
    instance comes with the TechDocs plugin preinstalled and enabled by default. Your
    organization can use the TechDocs plugin to create, find, and manage documentation
    in a central location and in a standardized way. You can also enhance your technical
    documentation experience with built-in TechDocs features and add-ons. For example:
    Docs-like-code approach:: Write your technical documentation in Markdown files
    that are stored inside your project repository along with your code. Documentation
    site generation:: Use MkDocs to create a full-featured, Markdown-based, static
    HTML site for your documentation that is rendered centrally in Developer Hub.
    Documentation site metadata and integrations:: See additional metadata about the
    documentation site alongside the static documentation, such as the date of the
    last update, the site owner, top contributors, open GitHub issues, Slack support
    channels, and Stack Overflow Enterprise tags. Built-in navigation and search::
    Locate the information that you need within a document quickly and easily. Add-ons::
    Make your documentation more functional and interactive with supported TechDocs
    add-ons. Some add-ons are preinstalled and enabled by default. To extend the default
    functionality, you can dynamically load external and third-party add-ons into
    your Red Hat Developer Hub instance. If you want to further customize your TechDocs
    experience, you can create add-ons that meet specific documentation needs for
    your organization. # Configuring TechDocs The TechDocs plugin is preinstalled
    and enabled on a Developer Hub instance by default. You can disable or enable
    the TechDocs plugin, and change other parameters, by configuring the Red Hat Developer
    Hub Helm chart or the Red Hat Developer Hub Operator ConfigMap. [IMPORTANT] ----
    Red Hat Developer Hub includes a built-in TechDocs builder that generates static
    HTML documentation from your codebase. However, the default basic setup of the
    local builder is not intended for production. ---- You can use a CI/CD pipeline
    with the repository that has a dedicated job to generate docs for TechDocs. The
    generated static files are stored in OpenShift Data Foundation or in a cloud storage
    solution of your choice and published to a static HTML documentation site. After
    you configure OpenShift Data Foundation to store the files that TechDocs generates,
    you can configure the TechDocs plugin to use the OpenShift Data Foundation for
    cloud storage. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:10:28.963291'
    uuid: e8a46fb5-5cea-4ef0-91bd-8cf84e8866dd
  response: MkDocs is used to create a full-featured, Markdown-based, static HTML
    site for your documentation that is rendered centrally in Developer Hub.
  user_input: how mkdocs is used for techdocs?
- context:
  - '# TechDocs for Red Hat Developer Hub # About TechDocs The Red Hat Developer Hub
    instance comes with the TechDocs plugin preinstalled and enabled by default. Your
    organization can use the TechDocs plugin to create, find, and manage documentation
    in a central location and in a standardized way. You can also enhance your technical
    documentation experience with built-in TechDocs features and add-ons. For example:
    Docs-like-code approach:: Write your technical documentation in Markdown files
    that are stored inside your project repository along with your code. Documentation
    site generation:: Use MkDocs to create a full-featured, Markdown-based, static
    HTML site for your documentation that is rendered centrally in Developer Hub.
    Documentation site metadata and integrations:: See additional metadata about the
    documentation site alongside the static documentation, such as the date of the
    last update, the site owner, top contributors, open GitHub issues, Slack support
    channels, and Stack Overflow Enterprise tags. Built-in navigation and search::
    Locate the information that you need within a document quickly and easily. Add-ons::
    Make your documentation more functional and interactive with supported TechDocs
    add-ons. Some add-ons are preinstalled and enabled by default. To extend the default
    functionality, you can dynamically load external and third-party add-ons into
    your Red Hat Developer Hub instance. If you want to further customize your TechDocs
    experience, you can create add-ons that meet specific documentation needs for
    your organization. # Configuring TechDocs The TechDocs plugin is preinstalled
    and enabled on a Developer Hub instance by default. You can disable or enable
    the TechDocs plugin, and change other parameters, by configuring the Red Hat Developer
    Hub Helm chart or the Red Hat Developer Hub Operator ConfigMap. [IMPORTANT] ----
    Red Hat Developer Hub includes a built-in TechDocs builder that generates static
    HTML documentation from your codebase. However, the default basic setup of the
    local builder is not intended for production. ---- You can use a CI/CD pipeline
    with the repository that has a dedicated job to generate docs for TechDocs. The
    generated static files are stored in OpenShift Data Foundation or in a cloud storage
    solution of your choice and published to a static HTML documentation site. After
    you configure OpenShift Data Foundation to store the files that TechDocs generates,
    you can configure the TechDocs plugin to use the OpenShift Data Foundation for
    cloud storage. ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:10:36.827024'
    uuid: ef98420f-a2f1-44b0-be56-7f91bd5a33a5
  response: The TechDocs plugin allows you to see additional metadata about the documentation
    site alongside the static documentation, which can include open GitHub issues,
    the date of the last update, the site owner, top contributors, Slack support channels,
    and Stack Overflow Enterprise tags.
  user_input: I'm trying to set up the TechDocs plugin for my dev teams, and I'm wondering
    what kind of integraton with Githib is possible, like can I see open Githib issues
    directly in the documentation site?
- context:
  - '# TechDocs for Red Hat Developer Hub # About TechDocs The Red Hat Developer Hub
    instance comes with the TechDocs plugin preinstalled and enabled by default. Your
    organization can use the TechDocs plugin to create, find, and manage documentation
    in a central location and in a standardized way. You can also enhance your technical
    documentation experience with built-in TechDocs features and add-ons. For example:
    Docs-like-code approach:: Write your technical documentation in Markdown files
    that are stored inside your project repository along with your code. Documentation
    site generation:: Use MkDocs to create a full-featured, Markdown-based, static
    HTML site for your documentation that is rendered centrally in Developer Hub.
    Documentation site metadata and integrations:: See additional metadata about the
    documentation site alongside the static documentation, such as the date of the
    last update, the site owner, top contributors, open GitHub issues, Slack support
    channels, and Stack Overflow Enterprise tags. Built-in navigation and search::
    Locate the information that you need within a document quickly and easily. Add-ons::
    Make your documentation more functional and interactive with supported TechDocs
    add-ons. Some add-ons are preinstalled and enabled by default. To extend the default
    functionality, you can dynamically load external and third-party add-ons into
    your Red Hat Developer Hub instance. If you want to further customize your TechDocs
    experience, you can create add-ons that meet specific documentation needs for
    your organization. # Configuring TechDocs The TechDocs plugin is preinstalled
    and enabled on a Developer Hub instance by default. You can disable or enable
    the TechDocs plugin, and change other parameters, by configuring the Red Hat Developer
    Hub Helm chart or the Red Hat Developer Hub Operator ConfigMap. [IMPORTANT] ----
    Red Hat Developer Hub includes a built-in TechDocs builder that generates static
    HTML documentation from your codebase. However, the default basic setup of the
    local builder is not intended for production. ---- You can use a CI/CD pipeline
    with the repository that has a dedicated job to generate docs for TechDocs. The
    generated static files are stored in OpenShift Data Foundation or in a cloud storage
    solution of your choice and published to a static HTML documentation site. After
    you configure OpenShift Data Foundation to store the files that TechDocs generates,
    you can configure the TechDocs plugin to use the OpenShift Data Foundation for
    cloud storage. ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T16:10:47.578925'
    uuid: 6870c7ee-f267-4e52-8bf6-08b160c12527
  response: The TechDocs plugin for Red Hat Developer Hub allows for the display of
    additional metadata about a documentation site alongside the static documentation,
    which can include information such as the site owner, top contributors, and open
    GitHub issues.
  user_input: From a platform engineering perspective, how does the TechDocs plugin
    for Red Hat Developer Hub integrate with GitHub to provide developers with relevant
    project metadata?
- context:
  - 'Configuring storage for TechDocs files The TechDocs publisher stores generated
    files in local storage or in cloud storage, such as AWS S3 or OpenShift Data Foundation.
    ### Configuring Amazon S3 for file storage You can create a dedicated Amazon S3
    bucket to store TechDocs sites. {product} uploads TechDocs to this bucket and
    serves them from the same location. You are logged in to your AWS account as an
    administrator. 1. On the AWS console, create an AWS S3 bucket. 1. On the Create
    bucket page, enter a Bucket name and use the default selections for all other
    settings. 2. Create an IAM policy to give authorized users permissions to generate
    and publish TechDocs for your organization. 3. On the Create policy > Specify
    permissions page, in the Policy editor, enter the following JSON content: ```JSON
    { "Version": "2012 10 17", "Statement": [ { "Sid": "TechDocsList", "Effect": "Allow",
    "Action": "s3:ListBucket", "Resource": "arn:aws:s3:::_<bucket_name>_" }, { "Sid":
    "TechDocsObjects", "Effect": "Allow", "Action": [ "s3:GetObject", "s3:PutObject",
    "s3:DeleteObject", "s3:DeleteObjectVersion" ], "Resource": "arn:aws:s3:::_<bucket_name>_/
    " } ] } ``` where <bucket_name>:: Specifies the name of your Amazon S3 bucket.
    4. On the Create policy > Specify permissions page, enter a Policy name. 2. Assign
    the IAM policy to a new or existing user. 3. Generate a new access key and a new
    secret access key. [NOTE] ---- You can use the newly created access keys to generate
    a TechDocs pipeline with GitHub Actions. ---- 4. From the OpenShift Container
    Platform web console, click Topology > Actions > Restart rollout to restart the
    pod. [NOTE] ---- You must restart the pod to apply the configuration changes.
    ---- 1. Go to your Amazon S3 bucket to see a set of static site files in your
    Objects list. ### Configuring OpenShift Data Foundation for file storage You can
    configure OpenShift Data Foundation to store the files that TechDocs generates
    instead of relying on other cloud storage solutions. OpenShift Data Foundation
    provides an ObjectBucketClaim custom resource (CR) that you can use to request
    an S3-compatible bucket backend. You must install the OpenShift Data Foundation
    Operator to use this feature. + [NOTE] ---- For air-gapped environments, using
    OpenShift Data Foundation is the recommended storage for TechDocs. ---- An OpenShift
    Container Platform administrator has installed the OpenShift Data Foundation Operator
    in Red Hat OpenShift Container Platform, created an OpenShift Data Foundation
    cluster and configured the StorageSystem schema. For more information, see Deploying
    OpenShift Data Foundation using Amazon Web Services. Create an ObjectBucketClaim
    CR where the generated TechDocs files are stored. For example: ```yaml apiVersion:
    objectbucket.io/v1alpha1 kind: ObjectBucketClaim metadata: name: <rhdh_bucket_claim_name>
    spec: generateBucketName: <rhdh_bucket_claim_name> storageClassName: openshift
    storage.noobaa.io ``` [NOTE] ---- Creating the Developer Hub ObjectBucketClaim
    CR automatically creates both the Developer Hub ObjectBucketClaim config map and
    secret. The config map and secret have the same name as the ObjectBucketClaim
    CR. ---- After you create the ObjectBucketClaim CR, you can use the information
    stored in the config map and secret to make the information accessible to the
    Developer Hub container as environment variables. Depending on the method that
    you used to install Developer Hub, you add the access information to either the
    Red Hat Developer Hub Helm chart or Operator configuration. OpenShift Data Foundation
    Object Bucket Claim #### Making object storage accessible to containers by using
    the Helm chart Creating a ObjectBucketClaim custom resource (CR) automatically
    generates both the Developer Hub ObjectBucketClaim config map and secret. The
    config map and secret contain ObjectBucket access information. Adding the access
    information to the Helm chart configuration makes it accessible to the Developer
    Hub container by adding the following environment variables to the container:
    BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION AWS_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs plugin configuration.
    You have installed Red Hat Developer Hub on OpenShift Container Platform using
    the Helm chart. You have created an ObjectBucketClaim CR for storing files generated
    by TechDocs. For more information see Using OpenShift Data Foundation for file
    storage In the upstream.backstage key in the Helm chart values, enter the name
    of the Developer Hub ObjectBucketClaim secret as the value for the extraEnvVarsSecrets
    field and the extraEnvVarsCM field. For example: ```yaml upstream: backstage:
    extraEnvVarsSecrets: <rhdh_bucket_claim_name> extraEnvVarsCM: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Helm chart The following
    example shows a Developer Hub Helm chart configuration for the TechDocs plugin:
    ```yaml global: dynamic: includes: ''dynamic plugins.default.yaml'' plugins: disabled:
    false package: ./dynamic plugins/dist/backstage plugin techdocs backend dynamic
    pluginConfig: techdocs: builder: external generator: runIn: local publisher: awsS3:
    bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` #### Making
    object storage accessible to containers by using the Operator Creating a ObjectBucketClaim
    custom resource (CR) automatically generates both the Developer Hub ObjectBucketClaim
    config map and secret. The config map and secret contain ObjectBucket access information.
    Adding the access information to the Operator configuration makes it accessible
    to the Developer Hub container by adding the following environment variables to
    the container: BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION
    AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs
    plugin configuration. You have installed Red Hat Developer Hub on OpenShift Container
    Platform using the Operator. You have created an ObjectBucketClaim CR for storing
    files generated by TechDocs. In your Backstage CR, enter the name of the Developer
    Hub ObjectBucketClaim config map as the value for the spec.application.extraEnvs.configMaps
    field and enter the Developer Hub ObjectBucketClaim secret name as the value for
    the spec.application.extraEnvs.secrets field. For example: ```yaml apiVersion:
    rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: <name> spec: application:
    extraEnvs: configMaps: name: <rhdh_bucket_claim_name> secrets: name: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Operator The following
    example shows a Red Hat Developer Hub Operator config map configuration for the
    TechDocs plugin: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: ./dynamic plugins/dist/backstage plugin techdocs
    backend dynamic pluginConfig: techdocs: builder: external generator: runIn: local
    publisher: awsS3: bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:11:00.359348'
    uuid: f467c543-5740-4bd6-9374-d150544f05f0
  response: An IAM policy is created to give authorized users permissions to generate
    and publish TechDocs for your organization. The policy grants permissions for
    actions such as "s3:ListBucket", "s3:GetObject", "s3:PutObject", "s3:DeleteObject",
    and "s3:DeleteObjectVersion" on the specified Amazon S3 bucket.
  user_input: What is the purpose of the IAM policy when configuring Amazon S3 for
    TechDocs?
- context:
  - 'Configuring storage for TechDocs files The TechDocs publisher stores generated
    files in local storage or in cloud storage, such as AWS S3 or OpenShift Data Foundation.
    ### Configuring Amazon S3 for file storage You can create a dedicated Amazon S3
    bucket to store TechDocs sites. {product} uploads TechDocs to this bucket and
    serves them from the same location. You are logged in to your AWS account as an
    administrator. 1. On the AWS console, create an AWS S3 bucket. 1. On the Create
    bucket page, enter a Bucket name and use the default selections for all other
    settings. 2. Create an IAM policy to give authorized users permissions to generate
    and publish TechDocs for your organization. 3. On the Create policy > Specify
    permissions page, in the Policy editor, enter the following JSON content: ```JSON
    { "Version": "2012 10 17", "Statement": [ { "Sid": "TechDocsList", "Effect": "Allow",
    "Action": "s3:ListBucket", "Resource": "arn:aws:s3:::_<bucket_name>_" }, { "Sid":
    "TechDocsObjects", "Effect": "Allow", "Action": [ "s3:GetObject", "s3:PutObject",
    "s3:DeleteObject", "s3:DeleteObjectVersion" ], "Resource": "arn:aws:s3:::_<bucket_name>_/
    " } ] } ``` where <bucket_name>:: Specifies the name of your Amazon S3 bucket.
    4. On the Create policy > Specify permissions page, enter a Policy name. 2. Assign
    the IAM policy to a new or existing user. 3. Generate a new access key and a new
    secret access key. [NOTE] ---- You can use the newly created access keys to generate
    a TechDocs pipeline with GitHub Actions. ---- 4. From the OpenShift Container
    Platform web console, click Topology > Actions > Restart rollout to restart the
    pod. [NOTE] ---- You must restart the pod to apply the configuration changes.
    ---- 1. Go to your Amazon S3 bucket to see a set of static site files in your
    Objects list. ### Configuring OpenShift Data Foundation for file storage You can
    configure OpenShift Data Foundation to store the files that TechDocs generates
    instead of relying on other cloud storage solutions. OpenShift Data Foundation
    provides an ObjectBucketClaim custom resource (CR) that you can use to request
    an S3-compatible bucket backend. You must install the OpenShift Data Foundation
    Operator to use this feature. + [NOTE] ---- For air-gapped environments, using
    OpenShift Data Foundation is the recommended storage for TechDocs. ---- An OpenShift
    Container Platform administrator has installed the OpenShift Data Foundation Operator
    in Red Hat OpenShift Container Platform, created an OpenShift Data Foundation
    cluster and configured the StorageSystem schema. For more information, see Deploying
    OpenShift Data Foundation using Amazon Web Services. Create an ObjectBucketClaim
    CR where the generated TechDocs files are stored. For example: ```yaml apiVersion:
    objectbucket.io/v1alpha1 kind: ObjectBucketClaim metadata: name: <rhdh_bucket_claim_name>
    spec: generateBucketName: <rhdh_bucket_claim_name> storageClassName: openshift
    storage.noobaa.io ``` [NOTE] ---- Creating the Developer Hub ObjectBucketClaim
    CR automatically creates both the Developer Hub ObjectBucketClaim config map and
    secret. The config map and secret have the same name as the ObjectBucketClaim
    CR. ---- After you create the ObjectBucketClaim CR, you can use the information
    stored in the config map and secret to make the information accessible to the
    Developer Hub container as environment variables. Depending on the method that
    you used to install Developer Hub, you add the access information to either the
    Red Hat Developer Hub Helm chart or Operator configuration. OpenShift Data Foundation
    Object Bucket Claim #### Making object storage accessible to containers by using
    the Helm chart Creating a ObjectBucketClaim custom resource (CR) automatically
    generates both the Developer Hub ObjectBucketClaim config map and secret. The
    config map and secret contain ObjectBucket access information. Adding the access
    information to the Helm chart configuration makes it accessible to the Developer
    Hub container by adding the following environment variables to the container:
    BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION AWS_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs plugin configuration.
    You have installed Red Hat Developer Hub on OpenShift Container Platform using
    the Helm chart. You have created an ObjectBucketClaim CR for storing files generated
    by TechDocs. For more information see Using OpenShift Data Foundation for file
    storage In the upstream.backstage key in the Helm chart values, enter the name
    of the Developer Hub ObjectBucketClaim secret as the value for the extraEnvVarsSecrets
    field and the extraEnvVarsCM field. For example: ```yaml upstream: backstage:
    extraEnvVarsSecrets: <rhdh_bucket_claim_name> extraEnvVarsCM: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Helm chart The following
    example shows a Developer Hub Helm chart configuration for the TechDocs plugin:
    ```yaml global: dynamic: includes: ''dynamic plugins.default.yaml'' plugins: disabled:
    false package: ./dynamic plugins/dist/backstage plugin techdocs backend dynamic
    pluginConfig: techdocs: builder: external generator: runIn: local publisher: awsS3:
    bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` #### Making
    object storage accessible to containers by using the Operator Creating a ObjectBucketClaim
    custom resource (CR) automatically generates both the Developer Hub ObjectBucketClaim
    config map and secret. The config map and secret contain ObjectBucket access information.
    Adding the access information to the Operator configuration makes it accessible
    to the Developer Hub container by adding the following environment variables to
    the container: BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION
    AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs
    plugin configuration. You have installed Red Hat Developer Hub on OpenShift Container
    Platform using the Operator. You have created an ObjectBucketClaim CR for storing
    files generated by TechDocs. In your Backstage CR, enter the name of the Developer
    Hub ObjectBucketClaim config map as the value for the spec.application.extraEnvs.configMaps
    field and enter the Developer Hub ObjectBucketClaim secret name as the value for
    the spec.application.extraEnvs.secrets field. For example: ```yaml apiVersion:
    rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: <name> spec: application:
    extraEnvs: configMaps: name: <rhdh_bucket_claim_name> secrets: name: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Operator The following
    example shows a Red Hat Developer Hub Operator config map configuration for the
    TechDocs plugin: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: ./dynamic plugins/dist/backstage plugin techdocs
    backend dynamic pluginConfig: techdocs: builder: external generator: runIn: local
    publisher: awsS3: bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:11:10.103271'
    uuid: 24251609-eb00-4f4e-a5d6-9edf1faa924f
  response: To configure OpenShift Data Foundation for TechDocs file storage, you
    must first have the OpenShift Data Foundation Operator installed in Red Hat OpenShift
    Container Platform, an OpenShift Data Foundation cluster created, and the StorageSystem
    schema configured. After that, you create an ObjectBucketClaim custom resource
    (CR) to request an S3-compatible bucket backend. Creating the ObjectBucketClaim
    CR automatically generates a config map and a secret with the same name, which
    contain the ObjectBucket access information. To make this information accessible
    to the Developer Hub container, you add the access information to either the Red
    Hat Developer Hub Helm chart or the Operator configuration. For the Helm chart,
    you add the name of the secret and config map to the `extraEnvVarsSecrets` and
    `extraEnvVarsCM` fields. For the Operator, you enter the config map name in the
    `spec.application.extraEnvs.configMaps` field and the secret name in the `spec.application.extraEnvs.secrets`
    field within your Backstage CR.
  user_input: ok so for the team i need to setup storage for techdocs and i wanna
    use OpenShift Data Foundation instead of s3, what all do i gotta do to configure
    it, like what do i need installed first and how do i make that ObjectBucketClaim
    CR and then how does the developer hub container get the access info from the
    config map and secret that gets made?
- context:
  - 'Configuring storage for TechDocs files The TechDocs publisher stores generated
    files in local storage or in cloud storage, such as AWS S3 or OpenShift Data Foundation.
    ### Configuring Amazon S3 for file storage You can create a dedicated Amazon S3
    bucket to store TechDocs sites. {product} uploads TechDocs to this bucket and
    serves them from the same location. You are logged in to your AWS account as an
    administrator. 1. On the AWS console, create an AWS S3 bucket. 1. On the Create
    bucket page, enter a Bucket name and use the default selections for all other
    settings. 2. Create an IAM policy to give authorized users permissions to generate
    and publish TechDocs for your organization. 3. On the Create policy > Specify
    permissions page, in the Policy editor, enter the following JSON content: ```JSON
    { "Version": "2012 10 17", "Statement": [ { "Sid": "TechDocsList", "Effect": "Allow",
    "Action": "s3:ListBucket", "Resource": "arn:aws:s3:::_<bucket_name>_" }, { "Sid":
    "TechDocsObjects", "Effect": "Allow", "Action": [ "s3:GetObject", "s3:PutObject",
    "s3:DeleteObject", "s3:DeleteObjectVersion" ], "Resource": "arn:aws:s3:::_<bucket_name>_/
    " } ] } ``` where <bucket_name>:: Specifies the name of your Amazon S3 bucket.
    4. On the Create policy > Specify permissions page, enter a Policy name. 2. Assign
    the IAM policy to a new or existing user. 3. Generate a new access key and a new
    secret access key. [NOTE] ---- You can use the newly created access keys to generate
    a TechDocs pipeline with GitHub Actions. ---- 4. From the OpenShift Container
    Platform web console, click Topology > Actions > Restart rollout to restart the
    pod. [NOTE] ---- You must restart the pod to apply the configuration changes.
    ---- 1. Go to your Amazon S3 bucket to see a set of static site files in your
    Objects list. ### Configuring OpenShift Data Foundation for file storage You can
    configure OpenShift Data Foundation to store the files that TechDocs generates
    instead of relying on other cloud storage solutions. OpenShift Data Foundation
    provides an ObjectBucketClaim custom resource (CR) that you can use to request
    an S3-compatible bucket backend. You must install the OpenShift Data Foundation
    Operator to use this feature. + [NOTE] ---- For air-gapped environments, using
    OpenShift Data Foundation is the recommended storage for TechDocs. ---- An OpenShift
    Container Platform administrator has installed the OpenShift Data Foundation Operator
    in Red Hat OpenShift Container Platform, created an OpenShift Data Foundation
    cluster and configured the StorageSystem schema. For more information, see Deploying
    OpenShift Data Foundation using Amazon Web Services. Create an ObjectBucketClaim
    CR where the generated TechDocs files are stored. For example: ```yaml apiVersion:
    objectbucket.io/v1alpha1 kind: ObjectBucketClaim metadata: name: <rhdh_bucket_claim_name>
    spec: generateBucketName: <rhdh_bucket_claim_name> storageClassName: openshift
    storage.noobaa.io ``` [NOTE] ---- Creating the Developer Hub ObjectBucketClaim
    CR automatically creates both the Developer Hub ObjectBucketClaim config map and
    secret. The config map and secret have the same name as the ObjectBucketClaim
    CR. ---- After you create the ObjectBucketClaim CR, you can use the information
    stored in the config map and secret to make the information accessible to the
    Developer Hub container as environment variables. Depending on the method that
    you used to install Developer Hub, you add the access information to either the
    Red Hat Developer Hub Helm chart or Operator configuration. OpenShift Data Foundation
    Object Bucket Claim #### Making object storage accessible to containers by using
    the Helm chart Creating a ObjectBucketClaim custom resource (CR) automatically
    generates both the Developer Hub ObjectBucketClaim config map and secret. The
    config map and secret contain ObjectBucket access information. Adding the access
    information to the Helm chart configuration makes it accessible to the Developer
    Hub container by adding the following environment variables to the container:
    BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION AWS_ACCESS_KEY_ID
    AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs plugin configuration.
    You have installed Red Hat Developer Hub on OpenShift Container Platform using
    the Helm chart. You have created an ObjectBucketClaim CR for storing files generated
    by TechDocs. For more information see Using OpenShift Data Foundation for file
    storage In the upstream.backstage key in the Helm chart values, enter the name
    of the Developer Hub ObjectBucketClaim secret as the value for the extraEnvVarsSecrets
    field and the extraEnvVarsCM field. For example: ```yaml upstream: backstage:
    extraEnvVarsSecrets: <rhdh_bucket_claim_name> extraEnvVarsCM: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Helm chart The following
    example shows a Developer Hub Helm chart configuration for the TechDocs plugin:
    ```yaml global: dynamic: includes: ''dynamic plugins.default.yaml'' plugins: disabled:
    false package: ./dynamic plugins/dist/backstage plugin techdocs backend dynamic
    pluginConfig: techdocs: builder: external generator: runIn: local publisher: awsS3:
    bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` #### Making
    object storage accessible to containers by using the Operator Creating a ObjectBucketClaim
    custom resource (CR) automatically generates both the Developer Hub ObjectBucketClaim
    config map and secret. The config map and secret contain ObjectBucket access information.
    Adding the access information to the Operator configuration makes it accessible
    to the Developer Hub container by adding the following environment variables to
    the container: BUCKET_NAME BUCKET_HOST BUCKET_PORT BUCKET_REGION BUCKET_SUBREGION
    AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY These variables are then used in the TechDocs
    plugin configuration. You have installed Red Hat Developer Hub on OpenShift Container
    Platform using the Operator. You have created an ObjectBucketClaim CR for storing
    files generated by TechDocs. In your Backstage CR, enter the name of the Developer
    Hub ObjectBucketClaim config map as the value for the spec.application.extraEnvs.configMaps
    field and enter the Developer Hub ObjectBucketClaim secret name as the value for
    the spec.application.extraEnvs.secrets field. For example: ```yaml apiVersion:
    rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: <name> spec: application:
    extraEnvs: configMaps: name: <rhdh_bucket_claim_name> secrets: name: <rhdh_bucket_claim_name>
    ``` ##### Example TechDocs Plugin configuration for the Operator The following
    example shows a Red Hat Developer Hub Operator config map configuration for the
    TechDocs plugin: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: disabled: false package: ./dynamic plugins/dist/backstage plugin techdocs
    backend dynamic pluginConfig: techdocs: builder: external generator: runIn: local
    publisher: awsS3: bucketName: ''${BUCKET_NAME}'' credentials: accessKeyId: ''${AWS_ACCESS_KEY_ID}''
    secretAccessKey: ''${AWS_SECRET_ACCESS_KEY}'' endpoint: ''https://${BUCKET_HOST}''
    region: ''${BUCKET_REGION}'' s3ForcePathStyle: true type: awsS3 ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:11:21.253639'
    uuid: ab6e019d-c18a-41b5-a9f2-8c1efe3a880c
  response: "After you create the ObjectBucketClaim custom resource (CR), a config\
    \ map and secret are automatically generated that contain the ObjectBucket access\
    \ information. To make this information accessible to the Developer Hub container\
    \ when using the Helm chart, you must add it to the Helm chart configuration.\
    \ In the upstream.backstage key in the Helm chart values, you must enter the name\
    \ of the Developer Hub ObjectBucketClaim secret as the value for the extraEnvVarsSecrets\
    \ field and the name of the config map as the value for the extraEnvVarsCM field.\
    \ An example configuration is: ```yaml\nupstream:\n  backstage:\n    extraEnvVarsSecrets:\
    \ <rhdh_bucket_claim_name>\n    extraEnvVarsCM: <rhdh_bucket_claim_name>\n```\
    \ This process adds environment variables such as BUCKET_NAME, BUCKET_HOST, AWS_ACCESS_KEY_ID,\
    \ and AWS_SECRET_ACCESS_KEY to the container."
  user_input: i created the ObjectBucketClaim CR, how do i get the container to see
    the access info using the Helm chart? what values i need to set?
- context:
  - 'Installing and configuring a TechDocs add-on TechDocs add-ons supported by Red
    Hat are exported to the TechDocs plugin by the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package, which is preinstalled on Red Hat Developer Hub and enabled by
    default. The <ReportIssue /> add-on is part of the default configuration of this
    plugin package and comes ready to use in the TechDocs plugin. You can install
    other supported TechDocs add-ons by configuring the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package in the Red Hat Developer Hub ConfigMap or Helm chart, depending
    on whether you use the Operator or Helm chart for installation. If you want to
    customize your TechDocs experience beyond the functions of the supported add-ons,
    you can install third-party add-ons on your TechDocs plugin, including add-ons
    that you create yourself. ### Installing and configuring an external TechDocs
    add-on using the Operator You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Operator to install
    the dynamic plugin, you can add TechDocs add-ons to the plugin package in your
    ConfigMap. Preinstalled add-ons, such as ReportIssue, are included in the default
    backstage-plugin-techdocs-module-addons-contrib package configuration. External
    add-ons that are supported by Red Hat are installed by manually adding them to
    the techdocsAddons section of the configuration file. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps > Create ConfigMap.
    2. From the Create ConfigMap page, select the YAML view option in the Configure
    via field. 3. In the newly created ConfigMap, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue ``` 4.
    In the techdocsAddons section of the ConfigMap, add importName: <external_techdocs_add-on>
    for each external TechDocs add-on that you want to add from the specified plugin
    package. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to install, for example, TextSize or LightBox.
    5. Click Create. 6. In the web console navigation menu, click Topology. 7. Click
    on the overflow menu for the Red Hat Developer Hub instance that you want to use
    and select Edit Backstage to load the YAML view of the Red Hat Developer Hub instance.
    8. In your Backstage CR, add the dynamicPluginsConfigMapName: <dynamic_plugins_configmap>
    key-value pair. For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: my rhdh spec: application: # ... dynamicPluginsConfigMapName:
    _<dynamic_plugins_configmap>_ # ... ``` where: <dynamic_plugins_configmap>:: Specifies
    the name of your dynamic plugins ConfigMap for your Red Hat Developer Hub instance,
    for example, dynamic-plugins-rhdh. 9. Click Save. 10. In the web console navigation
    menu, click Topology and wait for the Red Hat Developer Hub pod to start. 11.
    Click the Open URL icon to start using the Red Hat Developer Hub platform with
    the new configuration changes. ### Installing and configuring an external TechDocs
    add-on using the Helm chart You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Helm chart to
    install the dynamic plugin, you can add TechDocs add-ons to the plugin package
    in your Helm chart. Preinstalled add-ons, such as ReportIssue, are included in
    the default backstage-plugin-techdocs-module-addons-contrib package configuration.
    External add-ons that are supported by Red Hat are installed by manually adding
    them to the techdocsAddons section of the configuration file. The TechDocs plugin
    is installed and enabled. 1. In your Helm chart, add the global.dynamic parameters
    required to install a dynamic plugin, as shown in Installing dynamic plugins using
    the Helm chart [NOTE] ---- The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins, including TechDocs add-ons, that
    are preinstalled in Red Hat Developer Hub, whether they are enabled or disabled
    by default. ---- 2. In your Helm chart, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml global: dynamic: plugins: package:
    ./dynamic plugins/dist/backstage plugin techdocs module addons contrib disabled:
    false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs module
    addons contrib: techdocsAddons: importName: ReportIssue ``` 3. In the techdocsAddons
    section of the Helm chart, add importName: <external_techdocs_add-on> for each
    external TechDocs add-on that you want to add from the specified plugin package.
    For example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to install, for example,
    TextSize or LightBox. ### Installing and configuring a third-party TechDocs add-on
    You can install compatible third-party TechDocs add-on on your Red Hat Developer
    Hub instance as a front-end dynamic plugin. The third party TechDocs add on has
    a valid package.json file in its root directory, containing all required metadata
    and dependencies. The third party plugin is packaged as a dynamic plugin in an
    OCI image. For alternative package types, see Installing third party plugins in
    Red Hat Developer Hub. You have installed the yarn package manager. The third
    party plugin is packaged as a dynamic plugin in an OCI image. You have installed
    and configured Node.js and NPM. 1. Install the third-party plugin that you want
    to use to import your third-party add-on by entering the following command: ```terminal
    yarn install ``` 2. Obtain the source code for the third-party TechDocs add-on
    that you want to use. 3. Export the TechDocs add-on as a dynamic plugin using
    the following command: ```terminal npx @red hat developer hub/cli@latest plugin
    export ``` [NOTE] ---- The @latest tag pulls the latest version of the @red-hat-developer-hub/cli
    package, which is compatible with the most recent features and fixes. Use a version
    that is compatible with your Red Hat Developer Hub version. ---- 4. To package
    the'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:11:32.925031'
    uuid: 87b5b7a7-edc6-435c-8d28-470a0918d75b
  response: 'TechDocs add-ons supported by Red Hat are installed by manually adding
    them to the techdocsAddons section of the configuration file. You can install
    these add-ons by configuring the `backstage-plugin-techdocs-module-addons-contrib`
    plugin package in the Red Hat Developer Hub ConfigMap or Helm chart, depending
    on your installation method. For either method, you add `importName: <external_techdocs_add-on>`
    for each external add-on you want to install.'
  user_input: how i install the red hat supported addons?
- context:
  - 'Installing and configuring a TechDocs add-on TechDocs add-ons supported by Red
    Hat are exported to the TechDocs plugin by the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package, which is preinstalled on Red Hat Developer Hub and enabled by
    default. The <ReportIssue /> add-on is part of the default configuration of this
    plugin package and comes ready to use in the TechDocs plugin. You can install
    other supported TechDocs add-ons by configuring the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package in the Red Hat Developer Hub ConfigMap or Helm chart, depending
    on whether you use the Operator or Helm chart for installation. If you want to
    customize your TechDocs experience beyond the functions of the supported add-ons,
    you can install third-party add-ons on your TechDocs plugin, including add-ons
    that you create yourself. ### Installing and configuring an external TechDocs
    add-on using the Operator You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Operator to install
    the dynamic plugin, you can add TechDocs add-ons to the plugin package in your
    ConfigMap. Preinstalled add-ons, such as ReportIssue, are included in the default
    backstage-plugin-techdocs-module-addons-contrib package configuration. External
    add-ons that are supported by Red Hat are installed by manually adding them to
    the techdocsAddons section of the configuration file. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps > Create ConfigMap.
    2. From the Create ConfigMap page, select the YAML view option in the Configure
    via field. 3. In the newly created ConfigMap, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue ``` 4.
    In the techdocsAddons section of the ConfigMap, add importName: <external_techdocs_add-on>
    for each external TechDocs add-on that you want to add from the specified plugin
    package. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to install, for example, TextSize or LightBox.
    5. Click Create. 6. In the web console navigation menu, click Topology. 7. Click
    on the overflow menu for the Red Hat Developer Hub instance that you want to use
    and select Edit Backstage to load the YAML view of the Red Hat Developer Hub instance.
    8. In your Backstage CR, add the dynamicPluginsConfigMapName: <dynamic_plugins_configmap>
    key-value pair. For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: my rhdh spec: application: # ... dynamicPluginsConfigMapName:
    _<dynamic_plugins_configmap>_ # ... ``` where: <dynamic_plugins_configmap>:: Specifies
    the name of your dynamic plugins ConfigMap for your Red Hat Developer Hub instance,
    for example, dynamic-plugins-rhdh. 9. Click Save. 10. In the web console navigation
    menu, click Topology and wait for the Red Hat Developer Hub pod to start. 11.
    Click the Open URL icon to start using the Red Hat Developer Hub platform with
    the new configuration changes. ### Installing and configuring an external TechDocs
    add-on using the Helm chart You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Helm chart to
    install the dynamic plugin, you can add TechDocs add-ons to the plugin package
    in your Helm chart. Preinstalled add-ons, such as ReportIssue, are included in
    the default backstage-plugin-techdocs-module-addons-contrib package configuration.
    External add-ons that are supported by Red Hat are installed by manually adding
    them to the techdocsAddons section of the configuration file. The TechDocs plugin
    is installed and enabled. 1. In your Helm chart, add the global.dynamic parameters
    required to install a dynamic plugin, as shown in Installing dynamic plugins using
    the Helm chart [NOTE] ---- The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins, including TechDocs add-ons, that
    are preinstalled in Red Hat Developer Hub, whether they are enabled or disabled
    by default. ---- 2. In your Helm chart, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml global: dynamic: plugins: package:
    ./dynamic plugins/dist/backstage plugin techdocs module addons contrib disabled:
    false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs module
    addons contrib: techdocsAddons: importName: ReportIssue ``` 3. In the techdocsAddons
    section of the Helm chart, add importName: <external_techdocs_add-on> for each
    external TechDocs add-on that you want to add from the specified plugin package.
    For example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to install, for example,
    TextSize or LightBox. ### Installing and configuring a third-party TechDocs add-on
    You can install compatible third-party TechDocs add-on on your Red Hat Developer
    Hub instance as a front-end dynamic plugin. The third party TechDocs add on has
    a valid package.json file in its root directory, containing all required metadata
    and dependencies. The third party plugin is packaged as a dynamic plugin in an
    OCI image. For alternative package types, see Installing third party plugins in
    Red Hat Developer Hub. You have installed the yarn package manager. The third
    party plugin is packaged as a dynamic plugin in an OCI image. You have installed
    and configured Node.js and NPM. 1. Install the third-party plugin that you want
    to use to import your third-party add-on by entering the following command: ```terminal
    yarn install ``` 2. Obtain the source code for the third-party TechDocs add-on
    that you want to use. 3. Export the TechDocs add-on as a dynamic plugin using
    the following command: ```terminal npx @red hat developer hub/cli@latest plugin
    export ``` [NOTE] ---- The @latest tag pulls the latest version of the @red-hat-developer-hub/cli
    package, which is compatible with the most recent features and fixes. Use a version
    that is compatible with your Red Hat Developer Hub version. ---- 4. To package
    the'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:11:45.793375'
    uuid: bfbca364-929f-4522-95b8-fd42555019f1
  response: 'When using the Red Hat Developer Hub Operator, you can install external
    TechDocs add-ons by adding them to the plugin package in your ConfigMap. The process
    involves several steps: First, from the Developer perspective in the OpenShift
    Container Platform web console, create a new ConfigMap using the YAML view. In
    this new ConfigMap, you must add the default `backstage-plugin-techdocs-module-addons-contrib`
    package configuration. Following that, in the `techdocsAddons` section of the
    ConfigMap, you add `importName: <external_techdocs_add-on>` for each external
    add-on you want to install. After clicking ''Create'', you must edit the Backstage
    Custom Resource (CR) for your Red Hat Developer Hub instance and add the `dynamicPluginsConfigMapName`
    key-value pair, specifying the name of the ConfigMap you just created. Once you
    save these changes, you wait for the Red Hat Developer Hub pod to restart with
    the new configuration.'
  user_input: According to the documentation, what is the procedure for using a ConfigMap
    to install and configure an external TechDocs add-on when managing Red Hat Developer
    Hub with the Operator?
- context:
  - 'Installing and configuring a TechDocs add-on TechDocs add-ons supported by Red
    Hat are exported to the TechDocs plugin by the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package, which is preinstalled on Red Hat Developer Hub and enabled by
    default. The <ReportIssue /> add-on is part of the default configuration of this
    plugin package and comes ready to use in the TechDocs plugin. You can install
    other supported TechDocs add-ons by configuring the`backstage-plugin-techdocs-module-addons-contrib`
    plugin package in the Red Hat Developer Hub ConfigMap or Helm chart, depending
    on whether you use the Operator or Helm chart for installation. If you want to
    customize your TechDocs experience beyond the functions of the supported add-ons,
    you can install third-party add-ons on your TechDocs plugin, including add-ons
    that you create yourself. ### Installing and configuring an external TechDocs
    add-on using the Operator You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Operator to install
    the dynamic plugin, you can add TechDocs add-ons to the plugin package in your
    ConfigMap. Preinstalled add-ons, such as ReportIssue, are included in the default
    backstage-plugin-techdocs-module-addons-contrib package configuration. External
    add-ons that are supported by Red Hat are installed by manually adding them to
    the techdocsAddons section of the configuration file. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps > Create ConfigMap.
    2. From the Create ConfigMap page, select the YAML view option in the Configure
    via field. 3. In the newly created ConfigMap, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata:
    name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue ``` 4.
    In the techdocsAddons section of the ConfigMap, add importName: <external_techdocs_add-on>
    for each external TechDocs add-on that you want to add from the specified plugin
    package. For example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic
    plugins rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml
    plugins: package: ./dynamic plugins/dist/backstage plugin techdocs module addons
    contrib disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to install, for example, TextSize or LightBox.
    5. Click Create. 6. In the web console navigation menu, click Topology. 7. Click
    on the overflow menu for the Red Hat Developer Hub instance that you want to use
    and select Edit Backstage to load the YAML view of the Red Hat Developer Hub instance.
    8. In your Backstage CR, add the dynamicPluginsConfigMapName: <dynamic_plugins_configmap>
    key-value pair. For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: my rhdh spec: application: # ... dynamicPluginsConfigMapName:
    _<dynamic_plugins_configmap>_ # ... ``` where: <dynamic_plugins_configmap>:: Specifies
    the name of your dynamic plugins ConfigMap for your Red Hat Developer Hub instance,
    for example, dynamic-plugins-rhdh. 9. Click Save. 10. In the web console navigation
    menu, click Topology and wait for the Red Hat Developer Hub pod to start. 11.
    Click the Open URL icon to start using the Red Hat Developer Hub platform with
    the new configuration changes. ### Installing and configuring an external TechDocs
    add-on using the Helm chart You can use a dynamic plugin to import TechDocs add-ons
    into your TechDocs plugin. If you use the Red Hat Developer Hub Helm chart to
    install the dynamic plugin, you can add TechDocs add-ons to the plugin package
    in your Helm chart. Preinstalled add-ons, such as ReportIssue, are included in
    the default backstage-plugin-techdocs-module-addons-contrib package configuration.
    External add-ons that are supported by Red Hat are installed by manually adding
    them to the techdocsAddons section of the configuration file. The TechDocs plugin
    is installed and enabled. 1. In your Helm chart, add the global.dynamic parameters
    required to install a dynamic plugin, as shown in Installing dynamic plugins using
    the Helm chart [NOTE] ---- The default configuration includes the dynamic-plugins.default.yaml
    file, which contains all of the dynamic plugins, including TechDocs add-ons, that
    are preinstalled in Red Hat Developer Hub, whether they are enabled or disabled
    by default. ---- 2. In your Helm chart, add the default backstage-plugin-techdocs-module-addons-contrib
    package configuration. For example: ```yaml global: dynamic: plugins: package:
    ./dynamic plugins/dist/backstage plugin techdocs module addons contrib disabled:
    false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs module
    addons contrib: techdocsAddons: importName: ReportIssue ``` 3. In the techdocsAddons
    section of the Helm chart, add importName: <external_techdocs_add-on> for each
    external TechDocs add-on that you want to add from the specified plugin package.
    For example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to install, for example,
    TextSize or LightBox. ### Installing and configuring a third-party TechDocs add-on
    You can install compatible third-party TechDocs add-on on your Red Hat Developer
    Hub instance as a front-end dynamic plugin. The third party TechDocs add on has
    a valid package.json file in its root directory, containing all required metadata
    and dependencies. The third party plugin is packaged as a dynamic plugin in an
    OCI image. For alternative package types, see Installing third party plugins in
    Red Hat Developer Hub. You have installed the yarn package manager. The third
    party plugin is packaged as a dynamic plugin in an OCI image. You have installed
    and configured Node.js and NPM. 1. Install the third-party plugin that you want
    to use to import your third-party add-on by entering the following command: ```terminal
    yarn install ``` 2. Obtain the source code for the third-party TechDocs add-on
    that you want to use. 3. Export the TechDocs add-on as a dynamic plugin using
    the following command: ```terminal npx @red hat developer hub/cli@latest plugin
    export ``` [NOTE] ---- The @latest tag pulls the latest version of the @red-hat-developer-hub/cli
    package, which is compatible with the most recent features and fixes. Use a version
    that is compatible with your Red Hat Developer Hub version. ---- 4. To package
    the'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:11:56.219151'
    uuid: 24570938-aa46-4afe-b5ab-4fabf8580861
  response: The `<ReportIssue />` add-on is exported to the TechDocs plugin by the
    `backstage-plugin-techdocs-module-addons-contrib` plugin package, which is preinstalled
    on Red Hat Developer Hub and enabled by default. The add-on is part of the default
    configuration of this plugin package, comes ready to use, and is included in the
    default package configuration for installations using either the Operator or a
    Helm chart.
  user_input: How is the ReportIssue TechDocs add-on configured by default in Red
    Hat Developer Hub and which plugin package is responsible for it?
- context:
  - 'Configuring CI/CD to generate and publish TechDocs sites TechDocs reads the static
    generated documentation files from a cloud storage bucket, such as OpenShift Data
    Foundation. The documentation site is generated on the CI/CD workflow associated
    with the repository containing the documentation files. You can generate docs
    on CI and publish to a cloud storage using the techdocs-cli CLI tool. You can
    use the following example to create a script for TechDocs publication: ```shell
    # Prepare REPOSITORY_URL=''https://github.com/org/repo'' git clone $REPOSITORY_URL
    cd repo # Install @techdocs/cli, mkdocs and mkdocs plugins npm install -g @techdocs/cli
    pip install "mkdocs-techdocs-core==1.*" # Generate techdocs cli generate - no
    docker # Publish techdocs cli publish - publisher type awsS3 - storage name <bucket/container>
    - entity <Namespace/Kind/Name> ``` The TechDocs workflow starts the CI when a
    user makes changes in the repository containing the documentation files. You can
    configure the workflow to start only when files inside the docs/ directory or
    mkdocs.yml are changed. Configuring dynamic plugins # TechDocs add ons TechDocs
    add-ons are dynamic plugins that extend the functionality of the built-in TechDocs
    plugin. For example, you can use add-ons to report documentation issues, change
    text size, or view images in overlay in either the TechDocs Reader page or an
    Entity page. The following table describes the TechDocs add-ons that are available
    for Red Hat Developer Hub 1.8: The backstage-plugin-techdocs-module-addons-contrib
    plugin package exports both preinstalled and external add-ons supported by Red
    Hat to the TechDocs plugin. This plugin package is preinstalled on Red Hat Developer
    Hub and is enabled by default. If the plugin package is disabled, all of the TechDocs
    add-ons exported by the package as also disabled. ## third-party TechDocs add-on
    as a dynamic plugin, navigate to the root directory where the plugin is stored
    (not the dist-dynamic directory) and run the npx command with the --tag option
    to specify the image name and tag. For example: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/<user_name>/<techdocs_add on_image>:latest
    ``` [NOTE] ---- The output of the package-dynamic-plugins command provides the
    file path to the plugin for use in the dynamic-plugin-config.yaml file. ---- 5.
    To publish the third-party TechDocs add-on to a Quay repository, push the image
    to a registry using one of the following commands, depending on your virtualization
    tool: * To use podman, enter the following command: ```terminal podman push quay.io/<user_name>/<techdocs_add
    on_image>:latest ``` To use docker, enter the following command: ```terminal docker
    push quay.io/<user_name>/<techdocs_add on_image>:latest ``` 6. Open your dynamic-plugins.yaml
    file to view or modify the configuration for the third-party TechDocs add-on.
    For example: ```yaml plugins: package: oci://quay.io/<user_name>/<techdocs_add
    on_image>:latest!<techdocs_add on_package> disabled: false pluginConfig: dynamicPlugins:
    frontend: <techdocs_add on_package> techdocsAddons: importName: <third party_add
    on_name> config: props: <techdocs_add on_property_key>: <techdocs_add on_property_value>
    ``` where <user_name>:: Specifies your Quay user name or organization name. <techdocs_add-on_image>::
    Specifies the name of the image for the third-party add-on that you want to use,
    for example, mermaid. <techdocs_add-on_package>:: Specifies the , for example,
    backstage-plugin-techdocs-addon-mermaid. <third-party_add-on_name>:: Specifies
    the name of the third-party add-on that you want to use, for example, Mermaid.
    <techdocs_add-on_property_key>:: Specifies the name of the custom property that
    can be passed to the third-party add-on, for example, themeVariables. Properties
    are specific to each add-on. You can list multiple properties for an add-on. <techdocs_add-on_property_value>::
    Specifies the value of a property key for the third-party add-on, for example,
    lineColor: #000000. Configuring dynamic plugins Installing and viewing plugins
    in Red Hat Developer Hub ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:12:12.978059'
    uuid: 84177689-4960-4d26-b986-0a4a0913c9da
  response: 'To publish a third-party TechDocs add-on to a Quay repository using docker,
    you enter the following command: `docker push quay.io/<user_name>/<techdocs_add
    on_image>:latest`.'
  user_input: Wat is the doker comand for publishin a third-party TechDocs add-on
    to a Quay repository?
- context:
  - 'Configuring CI/CD to generate and publish TechDocs sites TechDocs reads the static
    generated documentation files from a cloud storage bucket, such as OpenShift Data
    Foundation. The documentation site is generated on the CI/CD workflow associated
    with the repository containing the documentation files. You can generate docs
    on CI and publish to a cloud storage using the techdocs-cli CLI tool. You can
    use the following example to create a script for TechDocs publication: ```shell
    # Prepare REPOSITORY_URL=''https://github.com/org/repo'' git clone $REPOSITORY_URL
    cd repo # Install @techdocs/cli, mkdocs and mkdocs plugins npm install -g @techdocs/cli
    pip install "mkdocs-techdocs-core==1.*" # Generate techdocs cli generate - no
    docker # Publish techdocs cli publish - publisher type awsS3 - storage name <bucket/container>
    - entity <Namespace/Kind/Name> ``` The TechDocs workflow starts the CI when a
    user makes changes in the repository containing the documentation files. You can
    configure the workflow to start only when files inside the docs/ directory or
    mkdocs.yml are changed. Configuring dynamic plugins # TechDocs add ons TechDocs
    add-ons are dynamic plugins that extend the functionality of the built-in TechDocs
    plugin. For example, you can use add-ons to report documentation issues, change
    text size, or view images in overlay in either the TechDocs Reader page or an
    Entity page. The following table describes the TechDocs add-ons that are available
    for Red Hat Developer Hub 1.8: The backstage-plugin-techdocs-module-addons-contrib
    plugin package exports both preinstalled and external add-ons supported by Red
    Hat to the TechDocs plugin. This plugin package is preinstalled on Red Hat Developer
    Hub and is enabled by default. If the plugin package is disabled, all of the TechDocs
    add-ons exported by the package as also disabled. ## third-party TechDocs add-on
    as a dynamic plugin, navigate to the root directory where the plugin is stored
    (not the dist-dynamic directory) and run the npx command with the --tag option
    to specify the image name and tag. For example: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/<user_name>/<techdocs_add on_image>:latest
    ``` [NOTE] ---- The output of the package-dynamic-plugins command provides the
    file path to the plugin for use in the dynamic-plugin-config.yaml file. ---- 5.
    To publish the third-party TechDocs add-on to a Quay repository, push the image
    to a registry using one of the following commands, depending on your virtualization
    tool: * To use podman, enter the following command: ```terminal podman push quay.io/<user_name>/<techdocs_add
    on_image>:latest ``` To use docker, enter the following command: ```terminal docker
    push quay.io/<user_name>/<techdocs_add on_image>:latest ``` 6. Open your dynamic-plugins.yaml
    file to view or modify the configuration for the third-party TechDocs add-on.
    For example: ```yaml plugins: package: oci://quay.io/<user_name>/<techdocs_add
    on_image>:latest!<techdocs_add on_package> disabled: false pluginConfig: dynamicPlugins:
    frontend: <techdocs_add on_package> techdocsAddons: importName: <third party_add
    on_name> config: props: <techdocs_add on_property_key>: <techdocs_add on_property_value>
    ``` where <user_name>:: Specifies your Quay user name or organization name. <techdocs_add-on_image>::
    Specifies the name of the image for the third-party add-on that you want to use,
    for example, mermaid. <techdocs_add-on_package>:: Specifies the , for example,
    backstage-plugin-techdocs-addon-mermaid. <third-party_add-on_name>:: Specifies
    the name of the third-party add-on that you want to use, for example, Mermaid.
    <techdocs_add-on_property_key>:: Specifies the name of the custom property that
    can be passed to the third-party add-on, for example, themeVariables. Properties
    are specific to each add-on. You can list multiple properties for an add-on. <techdocs_add-on_property_value>::
    Specifies the value of a property key for the third-party add-on, for example,
    lineColor: #000000. Configuring dynamic plugins Installing and viewing plugins
    in Red Hat Developer Hub ##'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:12:23.627299'
    uuid: 35a677b0-d3cb-470c-84fb-4be8b725579a
  response: You can use the techdocs-cli CLI tool to generate docs on CI and publish
    them to a cloud storage. The command to generate is "techdocs cli generate - no
    docker", and the command to publish is "techdocs cli publish - publisher type
    awsS3 - storage name <bucket/container> - entity <Namespace/Kind/Name>".
  user_input: how do i use the techdocs-cli to generat and publish?
- context:
  - 'Configuring CI/CD to generate and publish TechDocs sites TechDocs reads the static
    generated documentation files from a cloud storage bucket, such as OpenShift Data
    Foundation. The documentation site is generated on the CI/CD workflow associated
    with the repository containing the documentation files. You can generate docs
    on CI and publish to a cloud storage using the techdocs-cli CLI tool. You can
    use the following example to create a script for TechDocs publication: ```shell
    # Prepare REPOSITORY_URL=''https://github.com/org/repo'' git clone $REPOSITORY_URL
    cd repo # Install @techdocs/cli, mkdocs and mkdocs plugins npm install -g @techdocs/cli
    pip install "mkdocs-techdocs-core==1.*" # Generate techdocs cli generate - no
    docker # Publish techdocs cli publish - publisher type awsS3 - storage name <bucket/container>
    - entity <Namespace/Kind/Name> ``` The TechDocs workflow starts the CI when a
    user makes changes in the repository containing the documentation files. You can
    configure the workflow to start only when files inside the docs/ directory or
    mkdocs.yml are changed. Configuring dynamic plugins # TechDocs add ons TechDocs
    add-ons are dynamic plugins that extend the functionality of the built-in TechDocs
    plugin. For example, you can use add-ons to report documentation issues, change
    text size, or view images in overlay in either the TechDocs Reader page or an
    Entity page. The following table describes the TechDocs add-ons that are available
    for Red Hat Developer Hub 1.8: The backstage-plugin-techdocs-module-addons-contrib
    plugin package exports both preinstalled and external add-ons supported by Red
    Hat to the TechDocs plugin. This plugin package is preinstalled on Red Hat Developer
    Hub and is enabled by default. If the plugin package is disabled, all of the TechDocs
    add-ons exported by the package as also disabled. ## third-party TechDocs add-on
    as a dynamic plugin, navigate to the root directory where the plugin is stored
    (not the dist-dynamic directory) and run the npx command with the --tag option
    to specify the image name and tag. For example: ```terminal npx @red hat developer
    hub/cli@latest plugin package - tag quay.io/<user_name>/<techdocs_add on_image>:latest
    ``` [NOTE] ---- The output of the package-dynamic-plugins command provides the
    file path to the plugin for use in the dynamic-plugin-config.yaml file. ---- 5.
    To publish the third-party TechDocs add-on to a Quay repository, push the image
    to a registry using one of the following commands, depending on your virtualization
    tool: * To use podman, enter the following command: ```terminal podman push quay.io/<user_name>/<techdocs_add
    on_image>:latest ``` To use docker, enter the following command: ```terminal docker
    push quay.io/<user_name>/<techdocs_add on_image>:latest ``` 6. Open your dynamic-plugins.yaml
    file to view or modify the configuration for the third-party TechDocs add-on.
    For example: ```yaml plugins: package: oci://quay.io/<user_name>/<techdocs_add
    on_image>:latest!<techdocs_add on_package> disabled: false pluginConfig: dynamicPlugins:
    frontend: <techdocs_add on_package> techdocsAddons: importName: <third party_add
    on_name> config: props: <techdocs_add on_property_key>: <techdocs_add on_property_value>
    ``` where <user_name>:: Specifies your Quay user name or organization name. <techdocs_add-on_image>::
    Specifies the name of the image for the third-party add-on that you want to use,
    for example, mermaid. <techdocs_add-on_package>:: Specifies the , for example,
    backstage-plugin-techdocs-addon-mermaid. <third-party_add-on_name>:: Specifies
    the name of the third-party add-on that you want to use, for example, Mermaid.
    <techdocs_add-on_property_key>:: Specifies the name of the custom property that
    can be passed to the third-party add-on, for example, themeVariables. Properties
    are specific to each add-on. You can list multiple properties for an add-on. <techdocs_add-on_property_value>::
    Specifies the value of a property key for the third-party add-on, for example,
    lineColor: #000000. Configuring dynamic plugins Installing and viewing plugins
    in Red Hat Developer Hub ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:12:31.469369'
    uuid: 2c462fa4-ce22-485d-8f17-188ed5d49d99
  response: TechDocs add-ons are dynamic plugins that extend the functionality of
    the built-in TechDocs plugin. They can be used to report documentation issues,
    change text size, or view images in an overlay on either the TechDocs Reader page
    or an Entity page. The backstage-plugin-techdocs-module-addons-contrib plugin
    package, which is preinstalled and enabled by default on Red Hat Developer Hub,
    exports both preinstalled and external add-ons to the TechDocs plugin.
  user_input: what is TechDocs addons for?
- context:
  - 'Removing a TechDocs add-on Administrators can remove installed TechDocs add-ons
    from your Red Hat Developer Hub instance by using either the Operator or Helm
    chart, depending on the method used to install the add-on. If you used the Operator
    to install the add-on, remove it from the ConfigMap. If you used the Helm chart
    to install the add-on, remove it from the Helm chart. If you want to disable a
    plugin instead of removing it from your Red Hat Developer Hub instance, you can
    disable the plugin that you are using to import the TechDocs add-on. Since the
    disabled status is controlled at the plugin level, disabling the plugin disables
    all of the TechDocs add-ons in the specified plugin package. ### Removing an external
    TechDocs add-on from your ConfigMap If you no longer want to use the functionality
    of a TechDocs add-on that is imported from a particular plugin that you installed
    on your Red Hat Developer Hub instance with the Operator, you can temporarily
    disable it or permanently remove it from your ConfigMap. The disabled status is
    controlled at the plugin level, therefore, disabling the plugin disables all of
    the TechDocs add-ons in the disabled plugin package. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps. 2. From the
    ConfigMaps page, click the ConfigMap that contains the TechDocs add-on that you
    want to remove. 3. Select the YAML view option in the Configure via field. 4.
    In the plugins section of the ConfigMap, do one of the following actions based
    on whether you want to disable or remove a TechDocs add-on: * To temporarily disable
    all of the TechDocs add-ons in a particular plugin package, change the value of
    the disabled field to true. For example: ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    techdocs module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend:
    backstage.plugin techdocs module addons contrib: techdocsAddons: importName: ReportIssue
    importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    * To remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your ConfigMap. For
    example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins
    rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin techdocs module addons contrib
    disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs
    module addons contrib: techdocsAddons: importName: ReportIssue importName: <external_techdocs_add
    on> ``` where: <external_techdocs_add-on>:: Specifies the external TechDocs add-on
    that you want to remove, for example, TextSize. 5. Click Save. 6. In the web console
    navigation menu, click Topology and wait for the Red Hat Developer Hub pod to
    start. 7. Click the Open URL icon to start using the Red Hat Developer Hub platform
    with the new configuration changes. ### Removing an external TechDocs add-on from
    your Helm chart If you no longer want to use the functionality of a TechDocs add-on
    that is imported from a particular plugin that you installed on your Red Hat Developer
    Hub instance with the Helm chart, you can temporarily disable it or permanently
    remove it from your Helm chart. The disabled status is controlled at the plugin
    level, therefore, disabling the plugin disables all of the TechDocs add-ons in
    the disabled plugin package. In the plugins section of the Helm chart, do one
    of the following actions based on whether you want to disable or remove a TechDocs
    add on: To temporarily disable all of the TechDocs add ons in a particular plugin
    package, change the value of the disabled field to true. For example: ```yaml
    global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin techdocs
    module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to remove, for example, TextSize. * To
    remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your Helm chart. For
    example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    ## Using TechDocs add ons After an administrator installs a TechDocs add-on in
    your Red Hat Developer Hub instance, you can use it to extend the functionality
    of the TechDocs plugin and enhance your documentation experience. ### Using the
    ReportIssue TechDocs add-on If you find an error in your organization&#8217;s
    TechDocs documentation, you can use the ReportIssue add-on to open a new GitHub
    or GitLab issue directly from the documentation. ReportIssue automatically imports
    the text that you highlight in the document into a new issue template in your
    repository. The ReportIssue add on is installed and enabled in your TechDocs plugin.
    You have permissions to create issues in the repository where documentation issues
    are reported. 1. In your TechDocs documentation, highlight the text that you want
    to report an issue for. 2. Click the text in the ReportIssue box, for example,
    Open new GitHub issue. 3. From the new issue page in your repository, use the
    template to create the issue that you want to report. [NOTE] ---- The default
    issue title is Documentation feedback: <highlighted_text>, where <highlighted_text>
    is the text that you highlighted in your TechDocs documentation. In the issue
    description, <highlighted_text> is the default value for the The highlighted text
    field. ---- The issue that you created is listed on the issues page in your repository.
    ### Using the TextSize TechDocs add-on You can use the TextSize add-on to change
    the size of the text on either the TechDocs Reader page or an Entity page. The
    TextSize add on is installed'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:12:43.386842'
    uuid: cef901b4-29a7-46df-a391-5b0358e37b7d
  response: 'If you installed a TechDocs add-on using the Operator, you can remove
    it from the ConfigMap. First, from the Developer perspective in the OpenShift
    Container Platform web console, click on ConfigMaps and then select the specific
    ConfigMap containing the add-on. Choose the YAML view and locate the plugins section.
    To permanently remove an add-on, delete the line "importName: <external_techdocs_add-on>"
    for each add-on you wish to remove from the techdocsAddons section. Alternatively,
    to temporarily disable all add-ons in a plugin package, change the value of the
    disabled field to true. After making changes, click Save, navigate to Topology,
    and wait for the Red Hat Developer Hub pod to restart. Finally, click the Open
    URL icon to use the platform with the new configuration.'
  user_input: My team is trying to standardize our workflows, so can you explain the
    proccess for geting rid of a TechDocs addon if we originaly installed it using
    the Oparator and not the Helm chart?
- context:
  - 'Removing a TechDocs add-on Administrators can remove installed TechDocs add-ons
    from your Red Hat Developer Hub instance by using either the Operator or Helm
    chart, depending on the method used to install the add-on. If you used the Operator
    to install the add-on, remove it from the ConfigMap. If you used the Helm chart
    to install the add-on, remove it from the Helm chart. If you want to disable a
    plugin instead of removing it from your Red Hat Developer Hub instance, you can
    disable the plugin that you are using to import the TechDocs add-on. Since the
    disabled status is controlled at the plugin level, disabling the plugin disables
    all of the TechDocs add-ons in the specified plugin package. ### Removing an external
    TechDocs add-on from your ConfigMap If you no longer want to use the functionality
    of a TechDocs add-on that is imported from a particular plugin that you installed
    on your Red Hat Developer Hub instance with the Operator, you can temporarily
    disable it or permanently remove it from your ConfigMap. The disabled status is
    controlled at the plugin level, therefore, disabling the plugin disables all of
    the TechDocs add-ons in the disabled plugin package. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps. 2. From the
    ConfigMaps page, click the ConfigMap that contains the TechDocs add-on that you
    want to remove. 3. Select the YAML view option in the Configure via field. 4.
    In the plugins section of the ConfigMap, do one of the following actions based
    on whether you want to disable or remove a TechDocs add-on: * To temporarily disable
    all of the TechDocs add-ons in a particular plugin package, change the value of
    the disabled field to true. For example: ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    techdocs module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend:
    backstage.plugin techdocs module addons contrib: techdocsAddons: importName: ReportIssue
    importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    * To remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your ConfigMap. For
    example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins
    rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin techdocs module addons contrib
    disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs
    module addons contrib: techdocsAddons: importName: ReportIssue importName: <external_techdocs_add
    on> ``` where: <external_techdocs_add-on>:: Specifies the external TechDocs add-on
    that you want to remove, for example, TextSize. 5. Click Save. 6. In the web console
    navigation menu, click Topology and wait for the Red Hat Developer Hub pod to
    start. 7. Click the Open URL icon to start using the Red Hat Developer Hub platform
    with the new configuration changes. ### Removing an external TechDocs add-on from
    your Helm chart If you no longer want to use the functionality of a TechDocs add-on
    that is imported from a particular plugin that you installed on your Red Hat Developer
    Hub instance with the Helm chart, you can temporarily disable it or permanently
    remove it from your Helm chart. The disabled status is controlled at the plugin
    level, therefore, disabling the plugin disables all of the TechDocs add-ons in
    the disabled plugin package. In the plugins section of the Helm chart, do one
    of the following actions based on whether you want to disable or remove a TechDocs
    add on: To temporarily disable all of the TechDocs add ons in a particular plugin
    package, change the value of the disabled field to true. For example: ```yaml
    global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin techdocs
    module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to remove, for example, TextSize. * To
    remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your Helm chart. For
    example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    ## Using TechDocs add ons After an administrator installs a TechDocs add-on in
    your Red Hat Developer Hub instance, you can use it to extend the functionality
    of the TechDocs plugin and enhance your documentation experience. ### Using the
    ReportIssue TechDocs add-on If you find an error in your organization&#8217;s
    TechDocs documentation, you can use the ReportIssue add-on to open a new GitHub
    or GitLab issue directly from the documentation. ReportIssue automatically imports
    the text that you highlight in the document into a new issue template in your
    repository. The ReportIssue add on is installed and enabled in your TechDocs plugin.
    You have permissions to create issues in the repository where documentation issues
    are reported. 1. In your TechDocs documentation, highlight the text that you want
    to report an issue for. 2. Click the text in the ReportIssue box, for example,
    Open new GitHub issue. 3. From the new issue page in your repository, use the
    template to create the issue that you want to report. [NOTE] ---- The default
    issue title is Documentation feedback: <highlighted_text>, where <highlighted_text>
    is the text that you highlighted in your TechDocs documentation. In the issue
    description, <highlighted_text> is the default value for the The highlighted text
    field. ---- The issue that you created is listed on the issues page in your repository.
    ### Using the TextSize TechDocs add-on You can use the TextSize add-on to change
    the size of the text on either the TechDocs Reader page or an Entity page. The
    TextSize add on is installed'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:12:52.297168'
    uuid: 7b89953f-4715-402d-986f-502710776f1e
  response: You can use the TextSize add-on to change the size of the text on either
    the TechDocs Reader page or an Entity page.
  user_input: My developers they keep asking me about this TextSize add-on thing,
    I need to know what it does exactly, like what is its purpose and where can they
    use it to change the text size on what pages?
- context:
  - 'Removing a TechDocs add-on Administrators can remove installed TechDocs add-ons
    from your Red Hat Developer Hub instance by using either the Operator or Helm
    chart, depending on the method used to install the add-on. If you used the Operator
    to install the add-on, remove it from the ConfigMap. If you used the Helm chart
    to install the add-on, remove it from the Helm chart. If you want to disable a
    plugin instead of removing it from your Red Hat Developer Hub instance, you can
    disable the plugin that you are using to import the TechDocs add-on. Since the
    disabled status is controlled at the plugin level, disabling the plugin disables
    all of the TechDocs add-ons in the specified plugin package. ### Removing an external
    TechDocs add-on from your ConfigMap If you no longer want to use the functionality
    of a TechDocs add-on that is imported from a particular plugin that you installed
    on your Red Hat Developer Hub instance with the Operator, you can temporarily
    disable it or permanently remove it from your ConfigMap. The disabled status is
    controlled at the plugin level, therefore, disabling the plugin disables all of
    the TechDocs add-ons in the disabled plugin package. 1. From the Developer perspective
    in the OpenShift Container Platform web console, click ConfigMaps. 2. From the
    ConfigMaps page, click the ConfigMap that contains the TechDocs add-on that you
    want to remove. 3. Select the YAML view option in the Configure via field. 4.
    In the plugins section of the ConfigMap, do one of the following actions based
    on whether you want to disable or remove a TechDocs add-on: * To temporarily disable
    all of the TechDocs add-ons in a particular plugin package, change the value of
    the disabled field to true. For example: ```yaml kind: ConfigMap apiVersion: v1
    metadata: name: dynamic plugins rhdh data: dynamic plugins.yaml: | includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    techdocs module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend:
    backstage.plugin techdocs module addons contrib: techdocsAddons: importName: ReportIssue
    importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    * To remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your ConfigMap. For
    example: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins
    rhdh data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin techdocs module addons contrib
    disabled: false pluginConfig: dynamicPlugins: frontend: backstage.plugin techdocs
    module addons contrib: techdocsAddons: importName: ReportIssue importName: <external_techdocs_add
    on> ``` where: <external_techdocs_add-on>:: Specifies the external TechDocs add-on
    that you want to remove, for example, TextSize. 5. Click Save. 6. In the web console
    navigation menu, click Topology and wait for the Red Hat Developer Hub pod to
    start. 7. Click the Open URL icon to start using the Red Hat Developer Hub platform
    with the new configuration changes. ### Removing an external TechDocs add-on from
    your Helm chart If you no longer want to use the functionality of a TechDocs add-on
    that is imported from a particular plugin that you installed on your Red Hat Developer
    Hub instance with the Helm chart, you can temporarily disable it or permanently
    remove it from your Helm chart. The disabled status is controlled at the plugin
    level, therefore, disabling the plugin disables all of the TechDocs add-ons in
    the disabled plugin package. In the plugins section of the Helm chart, do one
    of the following actions based on whether you want to disable or remove a TechDocs
    add on: To temporarily disable all of the TechDocs add ons in a particular plugin
    package, change the value of the disabled field to true. For example: ```yaml
    global: dynamic: plugins: package: ./dynamic plugins/dist/backstage plugin techdocs
    module addons contrib disabled: true pluginConfig: dynamicPlugins: frontend: backstage.plugin
    techdocs module addons contrib: techdocsAddons: importName: ReportIssue importName:
    <external_techdocs_add on> ``` where: <external_techdocs_add-on>:: Specifies the
    external TechDocs add-on that you want to remove, for example, TextSize. * To
    remove one or more TechDocs add-ons from your Red Hat Developer Hub instance,
    delete importName: <external_techdocs_add-on> for each external TechDocs add-on
    that you want to remove from the techdocsAddons section of your Helm chart. For
    example: ```yaml global: dynamic: plugins: package: ./dynamic plugins/dist/backstage
    plugin techdocs module addons contrib disabled: false pluginConfig: dynamicPlugins:
    frontend: backstage.plugin techdocs module addons contrib: techdocsAddons: importName:
    ReportIssue importName: <external_techdocs_add on> ``` where: <external_techdocs_add-on>::
    Specifies the external TechDocs add-on that you want to remove, for example, TextSize.
    ## Using TechDocs add ons After an administrator installs a TechDocs add-on in
    your Red Hat Developer Hub instance, you can use it to extend the functionality
    of the TechDocs plugin and enhance your documentation experience. ### Using the
    ReportIssue TechDocs add-on If you find an error in your organization&#8217;s
    TechDocs documentation, you can use the ReportIssue add-on to open a new GitHub
    or GitLab issue directly from the documentation. ReportIssue automatically imports
    the text that you highlight in the document into a new issue template in your
    repository. The ReportIssue add on is installed and enabled in your TechDocs plugin.
    You have permissions to create issues in the repository where documentation issues
    are reported. 1. In your TechDocs documentation, highlight the text that you want
    to report an issue for. 2. Click the text in the ReportIssue box, for example,
    Open new GitHub issue. 3. From the new issue page in your repository, use the
    template to create the issue that you want to report. [NOTE] ---- The default
    issue title is Documentation feedback: <highlighted_text>, where <highlighted_text>
    is the text that you highlighted in your TechDocs documentation. In the issue
    description, <highlighted_text> is the default value for the The highlighted text
    field. ---- The issue that you created is listed on the issues page in your repository.
    ### Using the TextSize TechDocs add-on You can use the TextSize add-on to change
    the size of the text on either the TechDocs Reader page or an Entity page. The
    TextSize add on is installed'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:13:03.857890'
    uuid: 491a3695-e28c-4ed7-b3f8-a8af04aaa809
  response: 'To remove a TechDocs add-on from your Red Hat Developer Hub instance
    that was installed with the Operator, you must remove it from your ConfigMap.
    First, from the OpenShift Container Platform web console, go to the ConfigMaps
    page and click the ConfigMap with the add-on you want to remove. Select the YAML
    view, and in the `techdocsAddons` section, delete the `importName: <external_techdocs_add-on>`
    line for each add-on you are removing. Finally, click Save and wait for the Red
    Hat Developer Hub pod to start again.'
  user_input: how do i remove an addon from a confgmap?
- context:
  - 'and enabled in your TechDocs plugin. 1. In your TechDocs header, click the Settings
    icon. 2. Use the sliding scale to adjust the size of your documentation text.
    [NOTE] ---- * The default text size is 100% * The minimize text size is 90% *
    The maximum text size is 150% ---- ### Using the LightBox TechDocs add-on If your
    TechDocs documentation contains an image, you can use the LightBox add-on to view
    an enlarged version of the image in a lightbox, or overlay window. You can also
    zoom to change the size the lightbox image. If a single documentation page contains
    multiple images, you can navigate between images in the lightbox. The LightBox
    add on is installed and enabled in your TechDocs plugin. 1. In your TechDocs documentation,
    click on the image that you want to view in a lightbox. 2. In the lightbox, you
    can do any of the following actions: * Click the image or scroll to zoom in or
    zoom out. * Click the arrow to navigate between images. # Creating a TechDocs
    add-on If your organization has documentation needs that are not met by the functions
    of existing TechDocs add-ons, developers can create a new add-on for your TechDocs
    plugin. A TechDocs add-on is a React component that is imported from a front-end
    plugin. If you do not have an existing plugin that you can use to export your
    TechDocs add-on, you can create a new plugin by using backstage-cli to generate
    a default front-end plugin structure that you can customize. The folder structure
    of a new plugin that can be used to import TechDocs add-ons into the TechDocs
    plugin looks similar to the following example: ```json <new_plugin_for_techdocs_add
    on>/ dev/ index.ts src/ components/ <new_techdocs_add on_component>/ <new_techdocs_add
    on_component>.test.tsx <new_techdocs_add on_component>.tsx index.ts <new_techdocs_add
    on_fetch component>/ <new_techdocs_add on_fetch component>.test.tsx <new_techdocs_add
    on_fetch component>.tsx index.ts index.ts plugin.test.ts plugin.ts routes.ts setupTests.ts
    .eslintrc.js package.json README.md ``` The yarn package manager is installed.
    Docker v3.2.0 or later or Podman v3.2.0 or later is installed and running. 1.
    In the terminal, navigate to the root folder of the repository where you want
    to create your new plugin. 2. To create a new front-end plugin, run the following
    command: ```terminal $ yarn new ``` Example output: ```terminal ? What do you
    want to create? plugin - A new frontend plugin ? Enter the ID of the plugin [required]
    ``` 3. In the terminal prompt, type a name for the new plugin. For example: ```terminal
    ? Enter the ID of the plugin [required] <new_plugin_for_techdocs_add-on> ``` Example
    output ```terminal Successfully created plugin ``` Upon completion of this action,
    a sub-directory with the same name that you gave to your plugin is automatically
    generated inside the plugins directory. The directory contains all of the files
    that you need to configure to create your new plugin. 4. In the terminal, navigate
    to your new plugin directory. For example: ```terminal cd plugins/<new_techdocs_add
    on_directory> ``` 5. Add the`@backstage/plugin-techdocs-react` package to get
    frontend utilities for TechDocs add-ons. For example: ```terminal yarn add @backstage/plugin
    techdocs react ``` 6. In the directory containing the components of your custom
    TechDocs add-on, delete any default files or file components that are not required
    for your add-on, such as the routes.ts file or components of the index.tsx and
    plugins.ts files. 7. In the plugins.ts file, add the following code: ```java import
    { createPlugin } from ''@backstage/core-plugin-api''; import { createTechDocsAddonExtension
    } from ''@backstage/plugin-techdocs-react''; export const <new_plugin_for_techdocs_add
    on> = createPlugin({ id: ''<new_techdocs_add on>'', }); / @public / export const
    <new_techdocs_add on> = <new_plugin_for_techdocs_add on>.provide( createTechDocsAddonExtension<_<new_techdocs_addon_props>_>({
    name: ''<new_techdocs_add on>'', location: TechDocsAddonLocations.Content, component:
    <new_techdocs_add on_component>, }), ); ``` where <new_plugin_for_techdocs_add-on>::
    Specifies the new plugin that you use to import the TechDocs add-on to your Red
    Hat Developer Hub instance. <new_techdocs_add-on>:: Specifies the custom TechDocs
    add-on that you want to create. <new_techdocs_addon_props> (Optional):: Specifies
    the props for your new TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx
    file, if applicable. <new_techdocs_add-on_component>:: Specifies the React component
    for the custom TechDocs add-on that you want to create. You will create this component
    in a .tsx file in a later step. 8. In the index.ts file, export the custom TechDocs
    add-on that you want to create by adding the following code: ```java export {
    <new_plugin_for_techdocs_add on>, <new_techdocs_add on> } from ''./plugin''; ```
    9. Create a new <new_techdocs_add-on>.tsx file and add the code for your new TechDocs
    add-on component. 10. Create a new index.tsx file and use it to export your new
    TechDocs add-on component by adding the following code: ```java export { <new_techdocs_add-on>,
    type <new_techdocs_addon_props>} from ''./<new_techdocs_add-on_directory>'' ```
    where <new_techdocs_addon_props> (Optional):: Specifies the props for your new
    TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx file, if applicable.
    11. In the plugins.ts file, import your new TechDocs add-on component. 12. Install
    and configure your new TechDocs add-on by following the steps in Installing and
    configuring a TechDocs add-on 1. Restart the RHDH application and verify that
    the plugin is successfully activated and configured. 2. Verify the application
    logs for confirmation and ensure the plugin is functioning as expected.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:13:13.289419'
    uuid: 3c76a292-544e-4cfd-8fd5-32f28b5a72de
  response: After installing and configuring your new TechDocs add-on, you need to
    restart the RHDH application. Once restarted, you should verify that the plugin
    is successfully activated and configured, and also check the application logs
    for confirmation that the plugin is functioning as expected.
  user_input: How do I restrat the RHDH aplication after making a new plugin?
- context:
  - 'and enabled in your TechDocs plugin. 1. In your TechDocs header, click the Settings
    icon. 2. Use the sliding scale to adjust the size of your documentation text.
    [NOTE] ---- * The default text size is 100% * The minimize text size is 90% *
    The maximum text size is 150% ---- ### Using the LightBox TechDocs add-on If your
    TechDocs documentation contains an image, you can use the LightBox add-on to view
    an enlarged version of the image in a lightbox, or overlay window. You can also
    zoom to change the size the lightbox image. If a single documentation page contains
    multiple images, you can navigate between images in the lightbox. The LightBox
    add on is installed and enabled in your TechDocs plugin. 1. In your TechDocs documentation,
    click on the image that you want to view in a lightbox. 2. In the lightbox, you
    can do any of the following actions: * Click the image or scroll to zoom in or
    zoom out. * Click the arrow to navigate between images. # Creating a TechDocs
    add-on If your organization has documentation needs that are not met by the functions
    of existing TechDocs add-ons, developers can create a new add-on for your TechDocs
    plugin. A TechDocs add-on is a React component that is imported from a front-end
    plugin. If you do not have an existing plugin that you can use to export your
    TechDocs add-on, you can create a new plugin by using backstage-cli to generate
    a default front-end plugin structure that you can customize. The folder structure
    of a new plugin that can be used to import TechDocs add-ons into the TechDocs
    plugin looks similar to the following example: ```json <new_plugin_for_techdocs_add
    on>/ dev/ index.ts src/ components/ <new_techdocs_add on_component>/ <new_techdocs_add
    on_component>.test.tsx <new_techdocs_add on_component>.tsx index.ts <new_techdocs_add
    on_fetch component>/ <new_techdocs_add on_fetch component>.test.tsx <new_techdocs_add
    on_fetch component>.tsx index.ts index.ts plugin.test.ts plugin.ts routes.ts setupTests.ts
    .eslintrc.js package.json README.md ``` The yarn package manager is installed.
    Docker v3.2.0 or later or Podman v3.2.0 or later is installed and running. 1.
    In the terminal, navigate to the root folder of the repository where you want
    to create your new plugin. 2. To create a new front-end plugin, run the following
    command: ```terminal $ yarn new ``` Example output: ```terminal ? What do you
    want to create? plugin - A new frontend plugin ? Enter the ID of the plugin [required]
    ``` 3. In the terminal prompt, type a name for the new plugin. For example: ```terminal
    ? Enter the ID of the plugin [required] <new_plugin_for_techdocs_add-on> ``` Example
    output ```terminal Successfully created plugin ``` Upon completion of this action,
    a sub-directory with the same name that you gave to your plugin is automatically
    generated inside the plugins directory. The directory contains all of the files
    that you need to configure to create your new plugin. 4. In the terminal, navigate
    to your new plugin directory. For example: ```terminal cd plugins/<new_techdocs_add
    on_directory> ``` 5. Add the`@backstage/plugin-techdocs-react` package to get
    frontend utilities for TechDocs add-ons. For example: ```terminal yarn add @backstage/plugin
    techdocs react ``` 6. In the directory containing the components of your custom
    TechDocs add-on, delete any default files or file components that are not required
    for your add-on, such as the routes.ts file or components of the index.tsx and
    plugins.ts files. 7. In the plugins.ts file, add the following code: ```java import
    { createPlugin } from ''@backstage/core-plugin-api''; import { createTechDocsAddonExtension
    } from ''@backstage/plugin-techdocs-react''; export const <new_plugin_for_techdocs_add
    on> = createPlugin({ id: ''<new_techdocs_add on>'', }); / @public / export const
    <new_techdocs_add on> = <new_plugin_for_techdocs_add on>.provide( createTechDocsAddonExtension<_<new_techdocs_addon_props>_>({
    name: ''<new_techdocs_add on>'', location: TechDocsAddonLocations.Content, component:
    <new_techdocs_add on_component>, }), ); ``` where <new_plugin_for_techdocs_add-on>::
    Specifies the new plugin that you use to import the TechDocs add-on to your Red
    Hat Developer Hub instance. <new_techdocs_add-on>:: Specifies the custom TechDocs
    add-on that you want to create. <new_techdocs_addon_props> (Optional):: Specifies
    the props for your new TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx
    file, if applicable. <new_techdocs_add-on_component>:: Specifies the React component
    for the custom TechDocs add-on that you want to create. You will create this component
    in a .tsx file in a later step. 8. In the index.ts file, export the custom TechDocs
    add-on that you want to create by adding the following code: ```java export {
    <new_plugin_for_techdocs_add on>, <new_techdocs_add on> } from ''./plugin''; ```
    9. Create a new <new_techdocs_add-on>.tsx file and add the code for your new TechDocs
    add-on component. 10. Create a new index.tsx file and use it to export your new
    TechDocs add-on component by adding the following code: ```java export { <new_techdocs_add-on>,
    type <new_techdocs_addon_props>} from ''./<new_techdocs_add-on_directory>'' ```
    where <new_techdocs_addon_props> (Optional):: Specifies the props for your new
    TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx file, if applicable.
    11. In the plugins.ts file, import your new TechDocs add-on component. 12. Install
    and configure your new TechDocs add-on by following the steps in Installing and
    configuring a TechDocs add-on 1. Restart the RHDH application and verify that
    the plugin is successfully activated and configured. 2. Verify the application
    logs for confirmation and ensure the plugin is functioning as expected.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:13:22.011626'
    uuid: 0314079c-0ec0-4047-a6c6-fa7f95057ec5
  response: If an organization's documentation needs are not met by existing TechDocs
    add-ons, developers can create a new one, which is a React component imported
    from a front-end plugin. The process involves using the `yarn new` command to
    create a new front-end plugin. After navigating to the new plugin's directory,
    add the `@backstage/plugin-techdocs-react` package. You then delete any unrequired
    default files and configure the `plugins.ts` file to define the add-on using `createTechDocsAddonExtension`.
    The add-on is then exported in the `index.ts` file. A new `.tsx` file must be
    created for the add-on component's code, and another `index.tsx` file is used
    to export that component. After importing the new component in the `plugins.ts`
    file, you install and configure the add-on, restart the application, and verify
    it is functioning correctly via the application logs.
  user_input: How do you create a new TechDocs add-on for custom documentation needs?
- context:
  - 'and enabled in your TechDocs plugin. 1. In your TechDocs header, click the Settings
    icon. 2. Use the sliding scale to adjust the size of your documentation text.
    [NOTE] ---- * The default text size is 100% * The minimize text size is 90% *
    The maximum text size is 150% ---- ### Using the LightBox TechDocs add-on If your
    TechDocs documentation contains an image, you can use the LightBox add-on to view
    an enlarged version of the image in a lightbox, or overlay window. You can also
    zoom to change the size the lightbox image. If a single documentation page contains
    multiple images, you can navigate between images in the lightbox. The LightBox
    add on is installed and enabled in your TechDocs plugin. 1. In your TechDocs documentation,
    click on the image that you want to view in a lightbox. 2. In the lightbox, you
    can do any of the following actions: * Click the image or scroll to zoom in or
    zoom out. * Click the arrow to navigate between images. # Creating a TechDocs
    add-on If your organization has documentation needs that are not met by the functions
    of existing TechDocs add-ons, developers can create a new add-on for your TechDocs
    plugin. A TechDocs add-on is a React component that is imported from a front-end
    plugin. If you do not have an existing plugin that you can use to export your
    TechDocs add-on, you can create a new plugin by using backstage-cli to generate
    a default front-end plugin structure that you can customize. The folder structure
    of a new plugin that can be used to import TechDocs add-ons into the TechDocs
    plugin looks similar to the following example: ```json <new_plugin_for_techdocs_add
    on>/ dev/ index.ts src/ components/ <new_techdocs_add on_component>/ <new_techdocs_add
    on_component>.test.tsx <new_techdocs_add on_component>.tsx index.ts <new_techdocs_add
    on_fetch component>/ <new_techdocs_add on_fetch component>.test.tsx <new_techdocs_add
    on_fetch component>.tsx index.ts index.ts plugin.test.ts plugin.ts routes.ts setupTests.ts
    .eslintrc.js package.json README.md ``` The yarn package manager is installed.
    Docker v3.2.0 or later or Podman v3.2.0 or later is installed and running. 1.
    In the terminal, navigate to the root folder of the repository where you want
    to create your new plugin. 2. To create a new front-end plugin, run the following
    command: ```terminal $ yarn new ``` Example output: ```terminal ? What do you
    want to create? plugin - A new frontend plugin ? Enter the ID of the plugin [required]
    ``` 3. In the terminal prompt, type a name for the new plugin. For example: ```terminal
    ? Enter the ID of the plugin [required] <new_plugin_for_techdocs_add-on> ``` Example
    output ```terminal Successfully created plugin ``` Upon completion of this action,
    a sub-directory with the same name that you gave to your plugin is automatically
    generated inside the plugins directory. The directory contains all of the files
    that you need to configure to create your new plugin. 4. In the terminal, navigate
    to your new plugin directory. For example: ```terminal cd plugins/<new_techdocs_add
    on_directory> ``` 5. Add the`@backstage/plugin-techdocs-react` package to get
    frontend utilities for TechDocs add-ons. For example: ```terminal yarn add @backstage/plugin
    techdocs react ``` 6. In the directory containing the components of your custom
    TechDocs add-on, delete any default files or file components that are not required
    for your add-on, such as the routes.ts file or components of the index.tsx and
    plugins.ts files. 7. In the plugins.ts file, add the following code: ```java import
    { createPlugin } from ''@backstage/core-plugin-api''; import { createTechDocsAddonExtension
    } from ''@backstage/plugin-techdocs-react''; export const <new_plugin_for_techdocs_add
    on> = createPlugin({ id: ''<new_techdocs_add on>'', }); / @public / export const
    <new_techdocs_add on> = <new_plugin_for_techdocs_add on>.provide( createTechDocsAddonExtension<_<new_techdocs_addon_props>_>({
    name: ''<new_techdocs_add on>'', location: TechDocsAddonLocations.Content, component:
    <new_techdocs_add on_component>, }), ); ``` where <new_plugin_for_techdocs_add-on>::
    Specifies the new plugin that you use to import the TechDocs add-on to your Red
    Hat Developer Hub instance. <new_techdocs_add-on>:: Specifies the custom TechDocs
    add-on that you want to create. <new_techdocs_addon_props> (Optional):: Specifies
    the props for your new TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx
    file, if applicable. <new_techdocs_add-on_component>:: Specifies the React component
    for the custom TechDocs add-on that you want to create. You will create this component
    in a .tsx file in a later step. 8. In the index.ts file, export the custom TechDocs
    add-on that you want to create by adding the following code: ```java export {
    <new_plugin_for_techdocs_add on>, <new_techdocs_add on> } from ''./plugin''; ```
    9. Create a new <new_techdocs_add-on>.tsx file and add the code for your new TechDocs
    add-on component. 10. Create a new index.tsx file and use it to export your new
    TechDocs add-on component by adding the following code: ```java export { <new_techdocs_add-on>,
    type <new_techdocs_addon_props>} from ''./<new_techdocs_add-on_directory>'' ```
    where <new_techdocs_addon_props> (Optional):: Specifies the props for your new
    TechDocs add-on, as specified in your <new_techdocs_add-on>.tsx file, if applicable.
    11. In the plugins.ts file, import your new TechDocs add-on component. 12. Install
    and configure your new TechDocs add-on by following the steps in Installing and
    configuring a TechDocs add-on 1. Restart the RHDH application and verify that
    the plugin is successfully activated and configured. 2. Verify the application
    logs for confirmation and ensure the plugin is functioning as expected.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:13:29.262941'
    uuid: 7439df23-6353-47ef-9f85-6e2988ec47ae
  response: To create a new TechDocs add-on for your Red Hat Developer Hub instance,
    developers can follow these steps, assuming the yarn package manager and either
    Docker v3.2.0 (or later) or Podman v3.2.0 (or later) are installed and running.
    First, create a new front-end plugin by navigating to the repository's root folder
    in the terminal and running the command `$ yarn new`. When prompted, select 'plugin'
    and provide a unique ID for it. This action generates a new sub-directory for
    your plugin. Next, navigate into this new directory and add the necessary frontend
    utilities by running `yarn add @backstage/plugin techdocs react`. After this,
    you should delete any default files or components not required for your add-on,
    such as `routes.ts`. The next phase involves code modification. In the `plugins.ts`
    file, you must add code to create and provide the TechDocs add-on extension, specifying
    the new plugin name, the add-on name, its location, and the React component. In
    the `index.ts` file, you will export the custom add-on. Following this, you will
    create a new `.tsx` file for your add-on component's code and another `index.tsx`
    file to export that component. Finally, import your new component in the `plugins.ts`
    file, install and configure the add-on, and then restart the RHDH application.
    You should verify that the plugin is activated and functioning as expected by
    checking the application logs.
  user_input: As a Platform Engineering Lead, I need to understand the complete process
    for my team to develop and integrate a custom TechDocs add-on within our Red Hat
    Developer Hub instance; could you provide a detailed, step-by-step guide, including
    prerequisites, necessary commands, and code modifications?
- context:
  - '# Authorization in Red Hat Developer Hub Administrators can authorize users to
    perform actions and define what users can do in Developer Hub. Role-based access
    control (RBAC) is a security concept that defines how to control access to resources
    in a system by specifying a mapping between users of the system and the actions
    that those users can perform on resources in the system. You can use RBAC to define
    roles with specific permissions and then assign the roles to users and groups.
    RBAC on Developer Hub is built on top of the Permissions framework, which defines
    RBAC policies in code. Rather than defining policies in code, you can use the
    Developer Hub RBAC feature to define policies in a declarative fashion by using
    a simple CSV based format. You can define the policies by using Developer Hub
    web interface or REST API instead of editing the CSV directly. An administrator
    can define authorizations in Developer Hub by taking the following steps: 1. Enable
    the RBAC feature and give authorized users access to the feature. 2. Define roles
    and policies by combining the following methods: * The Developer Hub policy administrator
    uses the Developer Hub web interface or REST API. * The Developer Hub administrator
    edits the main Developer Hub configuration file. * The Developer Hub administrator
    edits external files. #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:13:36.631531'
    uuid: d80cab82-9391-4d0a-89ea-4cbaa0c2f426
  response: In Red Hat Developer Hub, Role-based access control (RBAC) is built on
    top of the Permissions framework, which is used to define RBAC policies in code.
    However, administrators can use the Developer Hub RBAC feature to define policies
    declaratively through a CSV-based format, web interface, or REST API, rather than
    defining them in code directly.
  user_input: Red Hat Developer Hub RBAC and Permissions framework relationship
- context:
  - '# Authorization in Red Hat Developer Hub Administrators can authorize users to
    perform actions and define what users can do in Developer Hub. Role-based access
    control (RBAC) is a security concept that defines how to control access to resources
    in a system by specifying a mapping between users of the system and the actions
    that those users can perform on resources in the system. You can use RBAC to define
    roles with specific permissions and then assign the roles to users and groups.
    RBAC on Developer Hub is built on top of the Permissions framework, which defines
    RBAC policies in code. Rather than defining policies in code, you can use the
    Developer Hub RBAC feature to define policies in a declarative fashion by using
    a simple CSV based format. You can define the policies by using Developer Hub
    web interface or REST API instead of editing the CSV directly. An administrator
    can define authorizations in Developer Hub by taking the following steps: 1. Enable
    the RBAC feature and give authorized users access to the feature. 2. Define roles
    and policies by combining the following methods: * The Developer Hub policy administrator
    uses the Developer Hub web interface or REST API. * The Developer Hub administrator
    edits the main Developer Hub configuration file. * The Developer Hub administrator
    edits external files. #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:13:45.582396'
    uuid: 69d1d196-3419-4e7f-b453-9317f53f7254
  response: 'In Red Hat Developer Hub, administrators can authorize users using Role-based
    access control (RBAC), which is built on the Permissions framework. Instead of
    defining policies in code, the Developer Hub RBAC feature allows you to define
    policies in a declarative fashion using a simple CSV-based format. An administrator
    can define authorizations by taking the following steps: 1. Enable the RBAC feature
    and give authorized users access to it. 2. Define roles and policies by combining
    methods, which include using the Developer Hub web interface or REST API, editing
    the main Developer Hub configuration file, or editing external files.'
  user_input: As a Platform Engineering Lead tasked with implementing our new unified
    platform, could you please provide a comprehensive overview of the mechanisms
    and specific steps an administrator must follow to configure and manage user authorizations
    using the role-based access control policies within the Red Hat Developer Hub?
- context:
  - '# Authorization in Red Hat Developer Hub Administrators can authorize users to
    perform actions and define what users can do in Developer Hub. Role-based access
    control (RBAC) is a security concept that defines how to control access to resources
    in a system by specifying a mapping between users of the system and the actions
    that those users can perform on resources in the system. You can use RBAC to define
    roles with specific permissions and then assign the roles to users and groups.
    RBAC on Developer Hub is built on top of the Permissions framework, which defines
    RBAC policies in code. Rather than defining policies in code, you can use the
    Developer Hub RBAC feature to define policies in a declarative fashion by using
    a simple CSV based format. You can define the policies by using Developer Hub
    web interface or REST API instead of editing the CSV directly. An administrator
    can define authorizations in Developer Hub by taking the following steps: 1. Enable
    the RBAC feature and give authorized users access to the feature. 2. Define roles
    and policies by combining the following methods: * The Developer Hub policy administrator
    uses the Developer Hub web interface or REST API. * The Developer Hub administrator
    edits the main Developer Hub configuration file. * The Developer Hub administrator
    edits external files. #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:13:54.043235'
    uuid: 6a034d15-41c2-4da3-97ca-05531d632267
  response: In Red Hat Developer Hub, rather than defining Role-based access control
    (RBAC) policies in code, you can use the Developer Hub RBAC feature to define
    policies in a declarative fashion by using a simple CSV based format. You can
    define these policies by using the Developer Hub web interface or REST API instead
    of editing the CSV directly.
  user_input: My team is lookin into Red Hat Developer Hub for our platform, and I'm
    tryin to understand the autherization options. How exactly does the declairative
    policy managment work, specifically regarding the use of a simple CSV based formatt
    insted of defining policies directly in code?
- context:
  - 'Enabling and giving access to the Role-Based Access Control (RBAC) feature The
    Role-Based Access Control (RBAC) feature is disabled by default. Enable the RBAC
    plugin and declare policy administrators to start using RBAC features. The permission
    policies for users and groups in the Developer Hub are managed by permission policy
    administrators. Only permission policy administrators can access the Role-Based
    Access Control REST API. You have added a custom Developer Hub application configuration,
    and have necessary permissions to modify it. You have enabled an authentication
    provider. 1. The RBAC plugin is installed but disabled by default. To enable the
    ./dynamic-plugins/dist/backstage-community-plugin-rbac plugin, edit your dynamic-plugins.yaml
    with the following content. dynamic-plugins.yaml fragment ```yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin rbac disabled: false ``` See
    Installing and viewing plugins in Red Hat Developer Hub. 2. Declare policy administrators
    to enable a select number of authenticated users to configure RBAC policies through
    the REST API or Web UI, instead of modifying the CSV file directly. The permissions
    can be specified in a separate CSV file referenced in your my-rhdh-app-config
    config map, or permissions can be created using the REST API or Web UI. To declare
    users such as <your_policy_administrator_name> as policy administrators, edit
    your custom Developer Hub ConfigMap, such as app-config-rhdh, and add following
    code to the app-config.yaml content: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    ``` 3. In order to display the available permissions provided by installed plugins
    in the Developer Hub UI, you must supply the corresponding list of plugin IDs.
    There are two ways to do this, by updating your application configuration or by
    using the RBAC REST API permissions endpoint. 1. To provide plugins by updating
    your application configuration, you can specify the plugins with permissions in
    your app-config.yaml file as follows: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: catalog scaffolder permission ``` 2. To specify the plugins
    with permissions by using the RBAC REST API permissions endpoint, see the RBAC
    REST API permissions endpoint. 1. Sign out from the existing Red Hat Developer
    Hub session and log in again using the declared policy administrator account.
    2. With RBAC enabled, most features are disabled by default. 1. Navigate to the
    Catalog page in RHDH. The Create button is not visible. You cannot create new
    components. 2. Navigate to the API page. The Register button is not visible. Explicitly
    enable permissions to resources in Developer Hub. # Determining permission policy
    and role configuration source You can configure Red Hat Developer Hub policy and
    roles by using different sources. To maintain data consistency, Developer Hub
    associates each permission policy and role with one unique source. You can only
    use this source to change the resource. The available sources are: Configuration
    file:: Configure roles and policies in the Developer Hub app-config.yaml configuration
    file, for instance to declare your policy administrators. The Configuration file
    pertains to the default role:default/rbac_admin role provided by the RBAC plugin.
    The default role has limited permissions to create, read, update, delete permission
    policies or roles, and to read catalog entities. [NOTE] ---- In case the default
    permissions are insufficient for your administrative requirements, you can create
    a custom admin role with the required permission policies. ---- REST API:: Configure
    roles and policies by using the Developer Hub Web UI or by using the REST API.
    CSV file:: Configure roles and policies by using external CSV files. Legacy::
    The legacy source applies to policies and roles defined before RBAC backend plugin
    version 2.1.3, and is the least restrictive among the source location options.
    [IMPORTANT] ---- Replace the permissions and roles using the legacy source with
    the permissions using the REST API or the CSV file sources. ---- To determine
    the source of a role or policy, use a GET request. # Policy effect The policy
    effect determines whether the access request must be approved if multiple policy
    rules match the request. In Red Hat Developer Hub, when one rule permits and the
    other denies, the deny rule takes precedence, and the policy effect is to deny.
    #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:03.616425'
    uuid: f3ebff34-38bd-4d3b-b640-4cd1790d5333
  response: Only permission policy administrators are permitted to access the Role-Based
    Access Control REST API. This API enables administrators to configure RBAC policies,
    create permissions, and configure both roles and policies. It can also be used
    as an alternative to the application configuration file for supplying the list
    of plugin IDs with permissions in order to display them in the Developer Hub UI
    via the permissions endpoint. The REST API is considered a source for configuring
    and changing permission policies and roles, and it is recommended to use it to
    replace any permissions and roles that were defined using the legacy source.
  user_input: Given the necessity of managing permissions within our Red Hat Developer
    Hub instance, what are the specific administrative functions that can be performed
    using the Role-Based Access Control REST API, and what are the explicit requirements
    for a user to be granted access to this interface?
- context:
  - 'Enabling and giving access to the Role-Based Access Control (RBAC) feature The
    Role-Based Access Control (RBAC) feature is disabled by default. Enable the RBAC
    plugin and declare policy administrators to start using RBAC features. The permission
    policies for users and groups in the Developer Hub are managed by permission policy
    administrators. Only permission policy administrators can access the Role-Based
    Access Control REST API. You have added a custom Developer Hub application configuration,
    and have necessary permissions to modify it. You have enabled an authentication
    provider. 1. The RBAC plugin is installed but disabled by default. To enable the
    ./dynamic-plugins/dist/backstage-community-plugin-rbac plugin, edit your dynamic-plugins.yaml
    with the following content. dynamic-plugins.yaml fragment ```yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin rbac disabled: false ``` See
    Installing and viewing plugins in Red Hat Developer Hub. 2. Declare policy administrators
    to enable a select number of authenticated users to configure RBAC policies through
    the REST API or Web UI, instead of modifying the CSV file directly. The permissions
    can be specified in a separate CSV file referenced in your my-rhdh-app-config
    config map, or permissions can be created using the REST API or Web UI. To declare
    users such as <your_policy_administrator_name> as policy administrators, edit
    your custom Developer Hub ConfigMap, such as app-config-rhdh, and add following
    code to the app-config.yaml content: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    ``` 3. In order to display the available permissions provided by installed plugins
    in the Developer Hub UI, you must supply the corresponding list of plugin IDs.
    There are two ways to do this, by updating your application configuration or by
    using the RBAC REST API permissions endpoint. 1. To provide plugins by updating
    your application configuration, you can specify the plugins with permissions in
    your app-config.yaml file as follows: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: catalog scaffolder permission ``` 2. To specify the plugins
    with permissions by using the RBAC REST API permissions endpoint, see the RBAC
    REST API permissions endpoint. 1. Sign out from the existing Red Hat Developer
    Hub session and log in again using the declared policy administrator account.
    2. With RBAC enabled, most features are disabled by default. 1. Navigate to the
    Catalog page in RHDH. The Create button is not visible. You cannot create new
    components. 2. Navigate to the API page. The Register button is not visible. Explicitly
    enable permissions to resources in Developer Hub. # Determining permission policy
    and role configuration source You can configure Red Hat Developer Hub policy and
    roles by using different sources. To maintain data consistency, Developer Hub
    associates each permission policy and role with one unique source. You can only
    use this source to change the resource. The available sources are: Configuration
    file:: Configure roles and policies in the Developer Hub app-config.yaml configuration
    file, for instance to declare your policy administrators. The Configuration file
    pertains to the default role:default/rbac_admin role provided by the RBAC plugin.
    The default role has limited permissions to create, read, update, delete permission
    policies or roles, and to read catalog entities. [NOTE] ---- In case the default
    permissions are insufficient for your administrative requirements, you can create
    a custom admin role with the required permission policies. ---- REST API:: Configure
    roles and policies by using the Developer Hub Web UI or by using the REST API.
    CSV file:: Configure roles and policies by using external CSV files. Legacy::
    The legacy source applies to policies and roles defined before RBAC backend plugin
    version 2.1.3, and is the least restrictive among the source location options.
    [IMPORTANT] ---- Replace the permissions and roles using the legacy source with
    the permissions using the REST API or the CSV file sources. ---- To determine
    the source of a role or policy, use a GET request. # Policy effect The policy
    effect determines whether the access request must be approved if multiple policy
    rules match the request. In Red Hat Developer Hub, when one rule permits and the
    other denies, the deny rule takes precedence, and the policy effect is to deny.
    #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:13.500702'
    uuid: 0f5c21f6-52d2-450c-a429-14a1f0de849a
  response: You can configure Red Hat Developer Hub policy and roles by using the
    Developer Hub app-config.yaml configuration file. For instance, you can declare
    policy administrators by editing your custom Developer Hub ConfigMap and adding
    code to the app-config.yaml content under `permission.rbac.admin.users`. You can
    also supply the list of plugin IDs to display available permissions in the Developer
    Hub UI by specifying the plugins with permissions in your app-config.yaml file
    under `pluginsWithPermission`.
  user_input: what all things i can do with the app-config.yaml file for setting up
    permissions?
- context:
  - 'Enabling and giving access to the Role-Based Access Control (RBAC) feature The
    Role-Based Access Control (RBAC) feature is disabled by default. Enable the RBAC
    plugin and declare policy administrators to start using RBAC features. The permission
    policies for users and groups in the Developer Hub are managed by permission policy
    administrators. Only permission policy administrators can access the Role-Based
    Access Control REST API. You have added a custom Developer Hub application configuration,
    and have necessary permissions to modify it. You have enabled an authentication
    provider. 1. The RBAC plugin is installed but disabled by default. To enable the
    ./dynamic-plugins/dist/backstage-community-plugin-rbac plugin, edit your dynamic-plugins.yaml
    with the following content. dynamic-plugins.yaml fragment ```yaml plugins: package:
    ./dynamic plugins/dist/backstage community plugin rbac disabled: false ``` See
    Installing and viewing plugins in Red Hat Developer Hub. 2. Declare policy administrators
    to enable a select number of authenticated users to configure RBAC policies through
    the REST API or Web UI, instead of modifying the CSV file directly. The permissions
    can be specified in a separate CSV file referenced in your my-rhdh-app-config
    config map, or permissions can be created using the REST API or Web UI. To declare
    users such as <your_policy_administrator_name> as policy administrators, edit
    your custom Developer Hub ConfigMap, such as app-config-rhdh, and add following
    code to the app-config.yaml content: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    ``` 3. In order to display the available permissions provided by installed plugins
    in the Developer Hub UI, you must supply the corresponding list of plugin IDs.
    There are two ways to do this, by updating your application configuration or by
    using the RBAC REST API permissions endpoint. 1. To provide plugins by updating
    your application configuration, you can specify the plugins with permissions in
    your app-config.yaml file as follows: app-config.yaml fragment ```yaml permission:
    enabled: true rbac: admin: users: name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: catalog scaffolder permission ``` 2. To specify the plugins
    with permissions by using the RBAC REST API permissions endpoint, see the RBAC
    REST API permissions endpoint. 1. Sign out from the existing Red Hat Developer
    Hub session and log in again using the declared policy administrator account.
    2. With RBAC enabled, most features are disabled by default. 1. Navigate to the
    Catalog page in RHDH. The Create button is not visible. You cannot create new
    components. 2. Navigate to the API page. The Register button is not visible. Explicitly
    enable permissions to resources in Developer Hub. # Determining permission policy
    and role configuration source You can configure Red Hat Developer Hub policy and
    roles by using different sources. To maintain data consistency, Developer Hub
    associates each permission policy and role with one unique source. You can only
    use this source to change the resource. The available sources are: Configuration
    file:: Configure roles and policies in the Developer Hub app-config.yaml configuration
    file, for instance to declare your policy administrators. The Configuration file
    pertains to the default role:default/rbac_admin role provided by the RBAC plugin.
    The default role has limited permissions to create, read, update, delete permission
    policies or roles, and to read catalog entities. [NOTE] ---- In case the default
    permissions are insufficient for your administrative requirements, you can create
    a custom admin role with the required permission policies. ---- REST API:: Configure
    roles and policies by using the Developer Hub Web UI or by using the REST API.
    CSV file:: Configure roles and policies by using external CSV files. Legacy::
    The legacy source applies to policies and roles defined before RBAC backend plugin
    version 2.1.3, and is the least restrictive among the source location options.
    [IMPORTANT] ---- Replace the permissions and roles using the legacy source with
    the permissions using the REST API or the CSV file sources. ---- To determine
    the source of a role or policy, use a GET request. # Policy effect The policy
    effect determines whether the access request must be approved if multiple policy
    rules match the request. In Red Hat Developer Hub, when one rule permits and the
    other denies, the deny rule takes precedence, and the policy effect is to deny.
    #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:22.560972'
    uuid: c7cba22c-9118-4fdc-ae48-97b833049997
  response: 'To enable and configure the Role-Based Access Control (RBAC) feature,
    which is disabled by default, you must first enable the RBAC plugin and then declare
    policy administrators. The process is as follows: 1. Edit your dynamic-plugins.yaml
    file to enable the "./dynamic-plugins/dist/backstage-community-plugin-rbac" plugin
    by setting its "disabled" property to false. 2. Declare policy administrators
    by editing your custom Developer Hub ConfigMap, such as app-config-rhdh. Add a
    configuration block to the app-config.yaml content that sets "permission.enabled"
    to true and lists the administrators under "rbac.admin.users". This allows these
    users to configure RBAC policies through the REST API or Web UI. 3. To make the
    permissions provided by installed plugins visible in the Developer Hub UI, you
    must supply the corresponding plugin IDs. This can be done by either updating
    your application configuration in the app-config.yaml file or by using the RBAC
    REST API permissions endpoint. 4. After these configurations, you must sign out
    from the existing Red Hat Developer Hub session and log in again using a declared
    policy administrator account. Be aware that with RBAC enabled, most features are
    disabled by default, and you will need to explicitly enable permissions for resources.'
  user_input: As a Platform Engineer responsible for our Red Hat Developer Hub instance,
    what is the complete, sequential process for activating and performing the initial
    configuration of the Role-Based Access Control (RBAC) feature, beginning from
    its default disabled state and including the critical step of designating policy
    administrators?
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE. #"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:31.111941'
    uuid: 4d1598b0-944b-4b6b-8764-9c0bbb90472f
  response: The policies generated from a policy.csv or ConfigMap file cannot be edited
    or deleted using the Developer Hub Web UI.
  user_input: What are the specific limitations I should be aware of when trying to
    manage RBAC policies in the Red Hat Developer Hub Web UI if those policies were
    originally generated from a ConfigMap file?
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE. #"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:39.683247'
    uuid: 81235f5c-2b84-474a-aae5-58502bbc2740
  response: 'As a policy administrator, you can use the Developer Hub web interface
    (Web UI) to allocate roles and permissions. The prerequisites for managing roles
    are that you have enabled RBAC, possess a policy administrator role in Developer
    Hub, and have added plugins with permission.


    To create a role:

    1. Navigate to Administration in the sidebar, which will display the RBAC tab.

    2. Click CREATE.

    3. Enter the role''s name and description, then click NEXT.

    4. Add the desired users and groups and click NEXT.

    5. In the ''Add permission policies'' section, select the Plugin and Permission,
    then set the Policy and click NEXT.

    6. Review the information and click CREATE. The new role will appear in the RBAC
    tab list.


    To edit a role created in the Developer Hub:

    1. Go to the RBAC tab within Administration.

    2. Select the edit icon for the role you want to change.

    3. Modify the role''s details, such as its name, description, users, groups, or
    permission policies, and click NEXT.

    4. Review the edited details and click SAVE. You can also edit users, groups,
    or permissions from the role''s OVERVIEW page.


    To delete a role created in the Developer Hub:

    1. Go to the RBAC tab.

    2. Select the delete icon from the Actions column for the specific role.

    3. When the ''Delete this role?'' pop-up appears, click DELETE.


    A critical limitation to note is that policies generated from a policy.csv or
    ConfigMap file cannot be edited or deleted using the Developer Hub Web UI.'
  user_input: "As a policy administrator responsible for our organization's instance,\
    \ could you provide a comprehensive, step-by-step guide on how to manage user\
    \ roles\u2014including their creation, modification, and deletion\u2014using the\
    \ Red Hat Developer Hub Web UI, and what are the specific prerequisites and limitations\
    \ I must be aware of for these operations?"
- context:
  - "Managing role-based access controls (RBAC) using the Red Hat Developer Hub Web\
    \ UI Policy administrators can use the Developer Hub web interface (Web UI) to\
    \ allocate specific roles and permissions to individual users or groups. Allocating\
    \ roles ensures that access to resources and functionalities is regulated across\
    \ the Developer Hub. With the policy administrator role in Developer Hub, you\
    \ can assign permissions to users and groups. This role allows you to view, create,\
    \ modify, and delete the roles using Developer Hub Web UI. ## Creating a role\
    \ in the Red Hat Developer Hub Web UI You can create a role in the Red Hat Developer\
    \ Hub using the Web UI. You have enabled RBAC, have a policy administrator role\
    \ in Developer Hub, and have added plugins with permission. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Click CREATE to create a\
    \ role. 4. Enter the name and description of the role in the given fields and\
    \ click NEXT. 5. Add users and groups using the search field, and click NEXT.\
    \ 6. Select Plugin and Permission from the drop-downs in the Add permission policies\
    \ section. 7. Select or clear the Policy that you want to set in the Add permission\
    \ policies section, and click NEXT. 8. Review the added information in the Review\
    \ and create section. 9. Click CREATE. The created role appears in the list available\
    \ in the RBAC tab. ## Editing a role in the Red Hat Developer Hub Web UI You can\
    \ edit a role in the Red Hat Developer Hub using the Web UI. [NOTE] ---- The policies\
    \ generated from a policy.csv or ConfigMap file cannot be edited or deleted using\
    \ the Developer Hub Web UI. ---- You have enabled RBAC, have a policy administrator\
    \ role in Developer Hub, and have added plugins with permission. The role that\
    \ you want to edit is created in the Developer Hub. 1. Go to Administration at\
    \ the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the edit icon for\
    \ the role that you want to edit. 4. Edit the details of the role, such as name,\
    \ description, users and groups, and permission policies, and click NEXT. 5. Review\
    \ the edited details of the role and click SAVE. After editing a role, you can\
    \ view the edited details of a role on the OVERVIEW page of a role. You can also\
    \ edit a role\u2019s users and groups or permissions by using the edit icon on\
    \ the respective cards on the OVERVIEW page. ## Deleting a role in the Red Hat\
    \ Developer Hub Web UI You can delete a role in the Red Hat Developer Hub using\
    \ the Web UI. [NOTE] ---- The policies generated from a policy.csv or ConfigMap\
    \ file cannot be edited or deleted using the Developer Hub Web UI. ---- You have\
    \ enabled RBAC and have a policy administrator role in Developer Hub. The role\
    \ that you want to delete is created in the Developer Hub. 1. Go to Administration\
    \ at the bottom of the sidebar in the Developer Hub. The RBAC tab appears, displaying\
    \ all the created roles in the Developer Hub. 2. (Optional) Click any role to\
    \ view the role information on the OVERVIEW page. 3. Select the delete icon from\
    \ the Actions column for the role that you want to delete. Delete this role? pop-up\
    \ appears on the screen. 4. Click DELETE. #"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:47.801259'
    uuid: 664f43bf-74e7-4e21-a783-2ddfd2600809
  response: In the Red Hat Developer Hub, a policy administrator can manage roles
    through the Web UI by creating, editing, or deleting them. These actions are performed
    in the RBAC tab located in the Administration section. To create a role, you enter
    a name and description, add users and groups, select plugin permissions and policies,
    review the information, and then click CREATE. To edit an existing role, you select
    the edit icon, modify the details such as name, description, users, groups, or
    permission policies, and then save the changes. To delete a role, you select the
    delete icon for that role and confirm the action. It is important to note that
    policies generated from a policy.csv or ConfigMap file cannot be edited or deleted
    using the Developer Hub Web UI.
  user_input: How are roles managed within the Red Hat Developer Hub?
- context:
  - 'Managing authorizations by using the REST API To automate the maintenance of
    Red Hat Developer Hub permission policies and roles, you can use Developer Hub
    role-based access control (RBAC) REST API. You can perform the following actions
    with the REST API: Retrieve information about: All permission policies Specific
    permission policies Specific roles Static plugins permission policies Create,
    update, or delete: Permission policy Role ## Sending requests to the RBAC REST
    API by using the curl utility You can send RBAC REST API requests by using the
    curl utility. You have access to the RBAC feature. 1. Find your Bearer token to
    authenticate to the REST API. 1. In your browser, open the web console Network
    tab. 2. In the main screen, reload the Developer Hub Homepage. 3. In the web console
    Network tab, search for the query?term= network call. 4. Save the token in the
    response JSON for the next steps. 2. In a terminal, run the curl command and review
    the response: ``` curl -v \ -H "Authorization: Bearer <token>" \ -X <method> "https://<my_developer_hub_domain>/<endpoint>"
    \ ``` ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer
    <token>" \ -X POST "https://<my_developer_hub_domain>/<endpoint>" \ -d <body>
    ``` <token>:: Enter your saved authorization token. <method>:: Enter the HTTP
    method for your API endpoint. * GET: To retrieve specified information from a
    specified resource endpoint. * POST: To create or update a resource. * PUT: To
    update a resource. * DELETE: To delete a resource. https://<my_developer_hub_domain>::
    Enter your Developer Hub URL. <endpoint>:: Enter the API endpoint to which you
    want to send a request, such as /api/permission/policies. <body>:: Enter the JSON
    body with data that your API endpoint might need with the HTTP POST or PUT request.
    ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer <token>"
    \ -X POST "https://<my_developer_hub_domain>/api/permission/roles" \ -d ''{ "memberReferences":
    ["group:default/example"], "name": "role:default/test", "metadata": { "description":
    "This is a test role" } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer <token>" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/role/default/test"
    \ -d ''{ "oldRole": { "memberReferences": [ "group:default/example" ], "name":
    "role:default/test" }, "newRole": { "memberReferences": [ "group:default/example",
    "user:default/test" ], "name": "role:default/test" } }'' ``` ``` curl -v -H "Content-Type:
    application/json" \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/policies"
    \ -d ''[{ "entityReference":"role:default/test", "permission": "catalog-entity",
    "policy": "read", "effect":"allow" }]'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/policies/role/default/test"
    \ -d ''{ "oldPolicy": [ { "permission": "catalog-entity", "policy": "read", "effect":
    "allow" } ], "newPolicy": [ { "permission": "policy-entity", "policy": "read",
    "effect": "allow" } ] }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/roles/conditions"
    \ -d ''{ "result": "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId":
    "catalog", "resourceType": "catalog-entity", "permissionMapping": ["read"], "conditions":
    { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params": {"claims":
    ["group:default/janus-authors"]} } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/conditions/1"
    \ -d ''{ "result":"CONDITIONAL", "roleEntityRef":"role:default/test", "pluginId":"catalog",
    "resourceType":"catalog-entity", "permissionMapping": ["read", "update", "delete"],
    "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params":
    {"claims": ["group:default/janus-authors"]} } }'' ``` Review the returned HTTP
    status code: 200 OK:: The request was successful. 201 Created:: The request resulted
    in a new resource being successfully created. 204 No Content:: The request was
    successful, and the response payload has no more content. 400 Bad Request:: Input
    error with the request. 401 Unauthorized:: Lacks valid authentication for the
    requested resource. 403 Forbidden:: Refusal to authorize request. 404 Not Found::
    Could not find requested resource. 409 Conflict:: Request conflict with the current
    state and the target resource. ## Sending requests to the RBAC REST API by using
    a REST client You can send RBAC REST API requests using any REST client. You have
    access to the RBAC feature. 1. Find your Bearer token to authenticate to the REST
    API. 1. In your browser, open the web console Network tab. 2. In the main screen,
    reload the Developer Hub Homepage. 3. In the web console Network tab, search for
    the query?term= network call. 4. Save the token in the response JSON for the next
    steps. 2. In your REST client, run a command with the following parameters and
    review the response: Authorization:: Enter your saved authorization token. HTTP
    method:: Enter the HTTP method for your API endpoint. * GET: To retrieve specified
    information from a specified resource endpoint. * POST: To create or update a
    resource. * PUT: To update a resource. * DELETE: To delete a resource. URL:: Enter
    your Developer Hub URL and API endpoint: https://<my_developer_hub_domain>/<endpoint>,
    such as https://<my_developer_hub_domain>/api/permission/policies. Body:: Enter
    the JSON body with data that your API endpoint might need with the HTTP POST request.
    ## Supported RBAC REST API endpoints The RBAC REST API provides endpoints for
    managing roles, permissions, and conditional policies in the Developer Hub and
    for retrieving information about the roles and policies. ### Roles The RBAC REST
    API supports the following endpoints for managing roles in the Red Hat Developer
    Hub. [GET] /api/permission/roles:: Returns all roles in Developer Hub. ```json
    [ { "memberReferences": ["user:default/username"], "name": "role:default/guests"
    }, { "memberReferences": [ "group:default/groupname", "user:default/username"
    ], "name": "role:default/rbac_admin" } ] ``` [GET] /api/permission/roles/<kind>/<namespace>/<name>::
    Returns information for a single role in Developer Hub. ```json [ { "memberReferences":
    [ "group:default/groupname", "user:default/username" ], "name": "role:default/rbac_admin"
    } ] ``` [POST] /api/permission/roles/<kind>/<namespace>/<name>:: Creates a role
    in Developer Hub. ```json { "memberReferences": ["group:default/test"], "name":
    "role:default/test_admin" } ``` ``` 201 Created ``` [PUT] /api/permission/roles/<kind>/<namespace>/<name>::
    Updates memberReferences, kind, namespace, or name for a role in Developer Hub.
    The request body contains the oldRole and newRole objects: ```json { "oldRole":
    { "memberReferences": ["group:default/test"], "name": "role:default/test_admin"
    }, "newRole": { "memberReferences": ["group:default/test", "user:default/test2"],
    "name": "role:default/test_admin" } } ``` ``` 200 OK ``` [DELETE] /api/permission/roles/<kind>/<namespace>/<name>?memberReferences=<VALUE>::
    Deletes the specified user or group from a role in Developer Hub. ``` 204 ```
    [DELETE] /api/permission/roles/<kind>/<namespace>/<name>:: Deletes a specified
    role from Developer Hub. ``` 204 ``` ### Permission policies The RBAC REST API
    supports the following endpoints for managing permission policies in the Red Hat
    Developer Hub. [GET] /api/permission/policies:: Returns permission policies list
    for all users. ```json [ { "entityReference": "role:default/test", "permission":
    "catalog-entity", "policy":'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:14:55.331759'
    uuid: 0ed52334-9a32-4279-8f5f-758a4371c25b
  response: To automate the maintenance of Red Hat Developer Hub permission policies
    and roles, you can use the Developer Hub role-based access control (RBAC) REST
    API. With this API, you can perform actions such as retrieving information about
    permission policies and roles, as well as creating, updating, or deleting them.
  user_input: How can the maintenance of permission policies and roles be automated
    in the Developer Hub?
- context:
  - 'Managing authorizations by using the REST API To automate the maintenance of
    Red Hat Developer Hub permission policies and roles, you can use Developer Hub
    role-based access control (RBAC) REST API. You can perform the following actions
    with the REST API: Retrieve information about: All permission policies Specific
    permission policies Specific roles Static plugins permission policies Create,
    update, or delete: Permission policy Role ## Sending requests to the RBAC REST
    API by using the curl utility You can send RBAC REST API requests by using the
    curl utility. You have access to the RBAC feature. 1. Find your Bearer token to
    authenticate to the REST API. 1. In your browser, open the web console Network
    tab. 2. In the main screen, reload the Developer Hub Homepage. 3. In the web console
    Network tab, search for the query?term= network call. 4. Save the token in the
    response JSON for the next steps. 2. In a terminal, run the curl command and review
    the response: ``` curl -v \ -H "Authorization: Bearer <token>" \ -X <method> "https://<my_developer_hub_domain>/<endpoint>"
    \ ``` ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer
    <token>" \ -X POST "https://<my_developer_hub_domain>/<endpoint>" \ -d <body>
    ``` <token>:: Enter your saved authorization token. <method>:: Enter the HTTP
    method for your API endpoint. * GET: To retrieve specified information from a
    specified resource endpoint. * POST: To create or update a resource. * PUT: To
    update a resource. * DELETE: To delete a resource. https://<my_developer_hub_domain>::
    Enter your Developer Hub URL. <endpoint>:: Enter the API endpoint to which you
    want to send a request, such as /api/permission/policies. <body>:: Enter the JSON
    body with data that your API endpoint might need with the HTTP POST or PUT request.
    ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer <token>"
    \ -X POST "https://<my_developer_hub_domain>/api/permission/roles" \ -d ''{ "memberReferences":
    ["group:default/example"], "name": "role:default/test", "metadata": { "description":
    "This is a test role" } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer <token>" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/role/default/test"
    \ -d ''{ "oldRole": { "memberReferences": [ "group:default/example" ], "name":
    "role:default/test" }, "newRole": { "memberReferences": [ "group:default/example",
    "user:default/test" ], "name": "role:default/test" } }'' ``` ``` curl -v -H "Content-Type:
    application/json" \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/policies"
    \ -d ''[{ "entityReference":"role:default/test", "permission": "catalog-entity",
    "policy": "read", "effect":"allow" }]'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/policies/role/default/test"
    \ -d ''{ "oldPolicy": [ { "permission": "catalog-entity", "policy": "read", "effect":
    "allow" } ], "newPolicy": [ { "permission": "policy-entity", "policy": "read",
    "effect": "allow" } ] }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/roles/conditions"
    \ -d ''{ "result": "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId":
    "catalog", "resourceType": "catalog-entity", "permissionMapping": ["read"], "conditions":
    { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params": {"claims":
    ["group:default/janus-authors"]} } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/conditions/1"
    \ -d ''{ "result":"CONDITIONAL", "roleEntityRef":"role:default/test", "pluginId":"catalog",
    "resourceType":"catalog-entity", "permissionMapping": ["read", "update", "delete"],
    "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params":
    {"claims": ["group:default/janus-authors"]} } }'' ``` Review the returned HTTP
    status code: 200 OK:: The request was successful. 201 Created:: The request resulted
    in a new resource being successfully created. 204 No Content:: The request was
    successful, and the response payload has no more content. 400 Bad Request:: Input
    error with the request. 401 Unauthorized:: Lacks valid authentication for the
    requested resource. 403 Forbidden:: Refusal to authorize request. 404 Not Found::
    Could not find requested resource. 409 Conflict:: Request conflict with the current
    state and the target resource. ## Sending requests to the RBAC REST API by using
    a REST client You can send RBAC REST API requests using any REST client. You have
    access to the RBAC feature. 1. Find your Bearer token to authenticate to the REST
    API. 1. In your browser, open the web console Network tab. 2. In the main screen,
    reload the Developer Hub Homepage. 3. In the web console Network tab, search for
    the query?term= network call. 4. Save the token in the response JSON for the next
    steps. 2. In your REST client, run a command with the following parameters and
    review the response: Authorization:: Enter your saved authorization token. HTTP
    method:: Enter the HTTP method for your API endpoint. * GET: To retrieve specified
    information from a specified resource endpoint. * POST: To create or update a
    resource. * PUT: To update a resource. * DELETE: To delete a resource. URL:: Enter
    your Developer Hub URL and API endpoint: https://<my_developer_hub_domain>/<endpoint>,
    such as https://<my_developer_hub_domain>/api/permission/policies. Body:: Enter
    the JSON body with data that your API endpoint might need with the HTTP POST request.
    ## Supported RBAC REST API endpoints The RBAC REST API provides endpoints for
    managing roles, permissions, and conditional policies in the Developer Hub and
    for retrieving information about the roles and policies. ### Roles The RBAC REST
    API supports the following endpoints for managing roles in the Red Hat Developer
    Hub. [GET] /api/permission/roles:: Returns all roles in Developer Hub. ```json
    [ { "memberReferences": ["user:default/username"], "name": "role:default/guests"
    }, { "memberReferences": [ "group:default/groupname", "user:default/username"
    ], "name": "role:default/rbac_admin" } ] ``` [GET] /api/permission/roles/<kind>/<namespace>/<name>::
    Returns information for a single role in Developer Hub. ```json [ { "memberReferences":
    [ "group:default/groupname", "user:default/username" ], "name": "role:default/rbac_admin"
    } ] ``` [POST] /api/permission/roles/<kind>/<namespace>/<name>:: Creates a role
    in Developer Hub. ```json { "memberReferences": ["group:default/test"], "name":
    "role:default/test_admin" } ``` ``` 201 Created ``` [PUT] /api/permission/roles/<kind>/<namespace>/<name>::
    Updates memberReferences, kind, namespace, or name for a role in Developer Hub.
    The request body contains the oldRole and newRole objects: ```json { "oldRole":
    { "memberReferences": ["group:default/test"], "name": "role:default/test_admin"
    }, "newRole": { "memberReferences": ["group:default/test", "user:default/test2"],
    "name": "role:default/test_admin" } } ``` ``` 200 OK ``` [DELETE] /api/permission/roles/<kind>/<namespace>/<name>?memberReferences=<VALUE>::
    Deletes the specified user or group from a role in Developer Hub. ``` 204 ```
    [DELETE] /api/permission/roles/<kind>/<namespace>/<name>:: Deletes a specified
    role from Developer Hub. ``` 204 ``` ### Permission policies The RBAC REST API
    supports the following endpoints for managing permission policies in the Red Hat
    Developer Hub. [GET] /api/permission/policies:: Returns permission policies list
    for all users. ```json [ { "entityReference": "role:default/test", "permission":
    "catalog-entity", "policy":'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:15:02.115455'
    uuid: a6322f70-597a-42f9-aa4d-3f598137d059
  response: You can use the Developer Hub role-based access control (RBAC) REST API
    to automate the maintenance of Red Hat Developer Hub permission policies and roles.
    With the REST API, you can retrieve information about all permission policies,
    specific permission policies, specific roles, and static plugins permission policies.
    You can also create, update, or delete a permission policy or a role.
  user_input: wat can i do with the RBAC REST API?
- context:
  - 'Managing authorizations by using the REST API To automate the maintenance of
    Red Hat Developer Hub permission policies and roles, you can use Developer Hub
    role-based access control (RBAC) REST API. You can perform the following actions
    with the REST API: Retrieve information about: All permission policies Specific
    permission policies Specific roles Static plugins permission policies Create,
    update, or delete: Permission policy Role ## Sending requests to the RBAC REST
    API by using the curl utility You can send RBAC REST API requests by using the
    curl utility. You have access to the RBAC feature. 1. Find your Bearer token to
    authenticate to the REST API. 1. In your browser, open the web console Network
    tab. 2. In the main screen, reload the Developer Hub Homepage. 3. In the web console
    Network tab, search for the query?term= network call. 4. Save the token in the
    response JSON for the next steps. 2. In a terminal, run the curl command and review
    the response: ``` curl -v \ -H "Authorization: Bearer <token>" \ -X <method> "https://<my_developer_hub_domain>/<endpoint>"
    \ ``` ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer
    <token>" \ -X POST "https://<my_developer_hub_domain>/<endpoint>" \ -d <body>
    ``` <token>:: Enter your saved authorization token. <method>:: Enter the HTTP
    method for your API endpoint. * GET: To retrieve specified information from a
    specified resource endpoint. * POST: To create or update a resource. * PUT: To
    update a resource. * DELETE: To delete a resource. https://<my_developer_hub_domain>::
    Enter your Developer Hub URL. <endpoint>:: Enter the API endpoint to which you
    want to send a request, such as /api/permission/policies. <body>:: Enter the JSON
    body with data that your API endpoint might need with the HTTP POST or PUT request.
    ``` curl -v -H "Content-Type: application/json" \ -H "Authorization: Bearer <token>"
    \ -X POST "https://<my_developer_hub_domain>/api/permission/roles" \ -d ''{ "memberReferences":
    ["group:default/example"], "name": "role:default/test", "metadata": { "description":
    "This is a test role" } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer <token>" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/role/default/test"
    \ -d ''{ "oldRole": { "memberReferences": [ "group:default/example" ], "name":
    "role:default/test" }, "newRole": { "memberReferences": [ "group:default/example",
    "user:default/test" ], "name": "role:default/test" } }'' ``` ``` curl -v -H "Content-Type:
    application/json" \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/policies"
    \ -d ''[{ "entityReference":"role:default/test", "permission": "catalog-entity",
    "policy": "read", "effect":"allow" }]'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/policies/role/default/test"
    \ -d ''{ "oldPolicy": [ { "permission": "catalog-entity", "policy": "read", "effect":
    "allow" } ], "newPolicy": [ { "permission": "policy-entity", "policy": "read",
    "effect": "allow" } ] }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X POST "https://<my_developer_hub_domain>/api/permission/roles/conditions"
    \ -d ''{ "result": "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId":
    "catalog", "resourceType": "catalog-entity", "permissionMapping": ["read"], "conditions":
    { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params": {"claims":
    ["group:default/janus-authors"]} } }'' ``` ``` curl -v -H "Content-Type: application/json"
    \ -H "Authorization: Bearer $token" \ -X PUT "https://<my_developer_hub_domain>/api/permission/roles/conditions/1"
    \ -d ''{ "result":"CONDITIONAL", "roleEntityRef":"role:default/test", "pluginId":"catalog",
    "resourceType":"catalog-entity", "permissionMapping": ["read", "update", "delete"],
    "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog-entity", "params":
    {"claims": ["group:default/janus-authors"]} } }'' ``` Review the returned HTTP
    status code: 200 OK:: The request was successful. 201 Created:: The request resulted
    in a new resource being successfully created. 204 No Content:: The request was
    successful, and the response payload has no more content. 400 Bad Request:: Input
    error with the request. 401 Unauthorized:: Lacks valid authentication for the
    requested resource. 403 Forbidden:: Refusal to authorize request. 404 Not Found::
    Could not find requested resource. 409 Conflict:: Request conflict with the current
    state and the target resource. ## Sending requests to the RBAC REST API by using
    a REST client You can send RBAC REST API requests using any REST client. You have
    access to the RBAC feature. 1. Find your Bearer token to authenticate to the REST
    API. 1. In your browser, open the web console Network tab. 2. In the main screen,
    reload the Developer Hub Homepage. 3. In the web console Network tab, search for
    the query?term= network call. 4. Save the token in the response JSON for the next
    steps. 2. In your REST client, run a command with the following parameters and
    review the response: Authorization:: Enter your saved authorization token. HTTP
    method:: Enter the HTTP method for your API endpoint. * GET: To retrieve specified
    information from a specified resource endpoint. * POST: To create or update a
    resource. * PUT: To update a resource. * DELETE: To delete a resource. URL:: Enter
    your Developer Hub URL and API endpoint: https://<my_developer_hub_domain>/<endpoint>,
    such as https://<my_developer_hub_domain>/api/permission/policies. Body:: Enter
    the JSON body with data that your API endpoint might need with the HTTP POST request.
    ## Supported RBAC REST API endpoints The RBAC REST API provides endpoints for
    managing roles, permissions, and conditional policies in the Developer Hub and
    for retrieving information about the roles and policies. ### Roles The RBAC REST
    API supports the following endpoints for managing roles in the Red Hat Developer
    Hub. [GET] /api/permission/roles:: Returns all roles in Developer Hub. ```json
    [ { "memberReferences": ["user:default/username"], "name": "role:default/guests"
    }, { "memberReferences": [ "group:default/groupname", "user:default/username"
    ], "name": "role:default/rbac_admin" } ] ``` [GET] /api/permission/roles/<kind>/<namespace>/<name>::
    Returns information for a single role in Developer Hub. ```json [ { "memberReferences":
    [ "group:default/groupname", "user:default/username" ], "name": "role:default/rbac_admin"
    } ] ``` [POST] /api/permission/roles/<kind>/<namespace>/<name>:: Creates a role
    in Developer Hub. ```json { "memberReferences": ["group:default/test"], "name":
    "role:default/test_admin" } ``` ``` 201 Created ``` [PUT] /api/permission/roles/<kind>/<namespace>/<name>::
    Updates memberReferences, kind, namespace, or name for a role in Developer Hub.
    The request body contains the oldRole and newRole objects: ```json { "oldRole":
    { "memberReferences": ["group:default/test"], "name": "role:default/test_admin"
    }, "newRole": { "memberReferences": ["group:default/test", "user:default/test2"],
    "name": "role:default/test_admin" } } ``` ``` 200 OK ``` [DELETE] /api/permission/roles/<kind>/<namespace>/<name>?memberReferences=<VALUE>::
    Deletes the specified user or group from a role in Developer Hub. ``` 204 ```
    [DELETE] /api/permission/roles/<kind>/<namespace>/<name>:: Deletes a specified
    role from Developer Hub. ``` 204 ``` ### Permission policies The RBAC REST API
    supports the following endpoints for managing permission policies in the Red Hat
    Developer Hub. [GET] /api/permission/policies:: Returns permission policies list
    for all users. ```json [ { "entityReference": "role:default/test", "permission":
    "catalog-entity", "policy":'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:15:08.535741'
    uuid: b26fb7a8-825b-4327-92f2-5c42d274de31
  response: The Developer Hub role-based access control (RBAC) REST API can be used
    to automate the maintenance of Red Hat Developer Hub permission policies and roles.
    The actions you can perform with the REST API include retrieving information about
    all permission policies, specific permission policies, specific roles, and static
    plugins permission policies. You can also create, update, or delete a permission
    policy or a role.
  user_input: wat can i do with the RBAC REST API?
- context:
  - '"read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } }, ] ``` [GET] /api/permission/policies/<kind>/<namespace>/<name>::
    Returns permission policies related to the specified entity reference. ```json
    [ { "entityReference": "role:default/test", "permission": "catalog-entity", "policy":
    "read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } } ] ``` [POST] /api/permission/policies::
    Creates a permission policy for a specified entity. ```json [ { "entityReference":
    "role:default/test", "permission": "catalog entity", "policy": "read", "effect":
    "allow" } ] ``` ``` 201 Created ``` [PUT] /api/permission/policies/<kind>/<namespace>/<name>::
    Updates a permission policy for a specified entity. The request body contains
    the oldPolicy and newPolicy objects: ```json { "oldPolicy": [ { "permission":
    "catalog entity", "policy": "read", "effect": "allow" }, { "permission": "catalog.entity.create",
    "policy": "create", "effect": "allow" } ], "newPolicy": [ { "permission": "catalog
    entity", "policy": "read", "effect": "deny" }, { "permission": "policy entity",
    "policy": "read", "effect": "allow" } ] } ``` ``` 200 ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>?permission={value1}&policy={value2}&effect={value3}::
    Deletes a permission policy added to the specified entity. ``` 204 No Content
    ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>:: Deletes all
    permission policies added to the specified entity. ``` 204 No Content ``` [GET]
    /api/permission/plugins/policies:: Returns permission policies for all static
    plugins. ```json [ { "pluginId": "catalog", "policies": [ { "isResourced": true,
    "permission": "catalog entity", "policy": "read" }, { "isResourced": false, "permission":
    "catalog.entity.create", "policy": "create" }, { "isResourced": true, "permission":
    "catalog entity", "policy": "delete" }, { "isResourced": true, "permission": "catalog
    entity", "policy": "update" }, { "isResourced": false, "permission": "catalog.location.read",
    "policy": "read" }, { "isResourced": false, "permission": "catalog.location.create",
    "policy": "create" }, { "isResourced": false, "permission": "catalog.location.delete",
    "policy": "delete" } ] }, ... ] ``` [GET] /api/permission/plugins/id:: Returns
    object with list plugin IDs: ```json [ { "ids": ["catalog", "permission"] } ]
    ``` [POST] /api/permission/plugins/id:: Add more plugins IDs defined in the request
    object. Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"]
    } ] ``` Returns a status code of 200 and JSON with actual object stored in the
    server: ```json [ { "ids": ["catalog", "permission", "scaffolder"] } ] ``` [DELETE]
    /api/permission/plugins/id:: Delete plugins IDs defined in the request object.
    Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"] }
    ] ``` Returns a status code of 200 and JSON with actual object stored in the server:
    ```json [ { "ids": ["catalog", "permission"] } ] ``` [NOTE] ---- In order to prevent
    an inconsistent state after a deployment restart, the REST API does not allow
    deletion of plugin IDs that were provided by using the application configuration.
    These ID values can only be removed through the configuration file. ---- ### Conditional
    policies The RBAC REST API supports the following endpoints for managing conditional
    policies in the Red Hat Developer Hub. [GET] /api/permission/plugins/condition-rules::
    Returns available conditional rule parameter schemas for the available plugins
    that are enabled in Developer Hub. ```json [ { "pluginId": "catalog", "rules":
    [ { "name": "HAS_ANNOTATION", "description": "Allow entities with the specified
    annotation", "resourceType": "catalog-entity", "paramsSchema": { "type": "object",
    "properties": { "annotation": { "type": "string", "description": "Name of the
    annotation to match on" }, "value": { "type": "string", "description": "Value
    of the annotation to match on" } }, "required": [ "annotation" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_LABEL",
    "description": "Allow entities with the specified label", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "label": { "type": "string",
    "description": "Name of the label to match on" } }, "required": [ "label" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_METADATA",
    "description": "Allow entities with the specified metadata subfield", "resourceType":
    "catalog-entity", "paramsSchema": { "type": "object", "properties": { "key": {
    "type": "string", "description": "Property within the entities metadata to match
    on" }, "value": { "type": "string", "description": "Value of the given property
    to match on" } }, "required": [ "key" ], "additionalProperties": false, "$schema":
    "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_SPEC", "description":
    "Allow entities with the specified spec subfield", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "key": { "type": "string",
    "description": "Property within the entities spec to match on" }, "value": { "type":
    "string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` [GET] /api/permission/roles/conditions/:id::
    Returns conditions for the specified ID. ```json { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ``` [GET] /api/permission/roles/conditions:: Returns
    list of all conditions for all roles. ```json [ { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ] ``` [POST] /api/permission/roles/conditions:: Creates
    a conditional policy for the specified role. ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog
    entity", "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } } } ``` ```json { "id": 1 } ``` [PUT] /permission/roles/conditions/:id:: Updates
    a condition policy for a specified ID. ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/test", "pluginId": "catalog", "resourceType": "catalog entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } },'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:15:16.780161'
    uuid: 217af377-e2af-4bba-8512-fa5ef98103ee
  response: The HAS_LABEL conditional rule is used to "Allow entities with the specified
    label". It applies to the "catalog-entity" resourceType and its parameter schema
    requires a string property named "label", which is described as the "Name of the
    label to match on".
  user_input: What is the function of the HAS_LABEL conditional rule?
- context:
  - '"read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } }, ] ``` [GET] /api/permission/policies/<kind>/<namespace>/<name>::
    Returns permission policies related to the specified entity reference. ```json
    [ { "entityReference": "role:default/test", "permission": "catalog-entity", "policy":
    "read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } } ] ``` [POST] /api/permission/policies::
    Creates a permission policy for a specified entity. ```json [ { "entityReference":
    "role:default/test", "permission": "catalog entity", "policy": "read", "effect":
    "allow" } ] ``` ``` 201 Created ``` [PUT] /api/permission/policies/<kind>/<namespace>/<name>::
    Updates a permission policy for a specified entity. The request body contains
    the oldPolicy and newPolicy objects: ```json { "oldPolicy": [ { "permission":
    "catalog entity", "policy": "read", "effect": "allow" }, { "permission": "catalog.entity.create",
    "policy": "create", "effect": "allow" } ], "newPolicy": [ { "permission": "catalog
    entity", "policy": "read", "effect": "deny" }, { "permission": "policy entity",
    "policy": "read", "effect": "allow" } ] } ``` ``` 200 ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>?permission={value1}&policy={value2}&effect={value3}::
    Deletes a permission policy added to the specified entity. ``` 204 No Content
    ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>:: Deletes all
    permission policies added to the specified entity. ``` 204 No Content ``` [GET]
    /api/permission/plugins/policies:: Returns permission policies for all static
    plugins. ```json [ { "pluginId": "catalog", "policies": [ { "isResourced": true,
    "permission": "catalog entity", "policy": "read" }, { "isResourced": false, "permission":
    "catalog.entity.create", "policy": "create" }, { "isResourced": true, "permission":
    "catalog entity", "policy": "delete" }, { "isResourced": true, "permission": "catalog
    entity", "policy": "update" }, { "isResourced": false, "permission": "catalog.location.read",
    "policy": "read" }, { "isResourced": false, "permission": "catalog.location.create",
    "policy": "create" }, { "isResourced": false, "permission": "catalog.location.delete",
    "policy": "delete" } ] }, ... ] ``` [GET] /api/permission/plugins/id:: Returns
    object with list plugin IDs: ```json [ { "ids": ["catalog", "permission"] } ]
    ``` [POST] /api/permission/plugins/id:: Add more plugins IDs defined in the request
    object. Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"]
    } ] ``` Returns a status code of 200 and JSON with actual object stored in the
    server: ```json [ { "ids": ["catalog", "permission", "scaffolder"] } ] ``` [DELETE]
    /api/permission/plugins/id:: Delete plugins IDs defined in the request object.
    Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"] }
    ] ``` Returns a status code of 200 and JSON with actual object stored in the server:
    ```json [ { "ids": ["catalog", "permission"] } ] ``` [NOTE] ---- In order to prevent
    an inconsistent state after a deployment restart, the REST API does not allow
    deletion of plugin IDs that were provided by using the application configuration.
    These ID values can only be removed through the configuration file. ---- ### Conditional
    policies The RBAC REST API supports the following endpoints for managing conditional
    policies in the Red Hat Developer Hub. [GET] /api/permission/plugins/condition-rules::
    Returns available conditional rule parameter schemas for the available plugins
    that are enabled in Developer Hub. ```json [ { "pluginId": "catalog", "rules":
    [ { "name": "HAS_ANNOTATION", "description": "Allow entities with the specified
    annotation", "resourceType": "catalog-entity", "paramsSchema": { "type": "object",
    "properties": { "annotation": { "type": "string", "description": "Name of the
    annotation to match on" }, "value": { "type": "string", "description": "Value
    of the annotation to match on" } }, "required": [ "annotation" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_LABEL",
    "description": "Allow entities with the specified label", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "label": { "type": "string",
    "description": "Name of the label to match on" } }, "required": [ "label" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_METADATA",
    "description": "Allow entities with the specified metadata subfield", "resourceType":
    "catalog-entity", "paramsSchema": { "type": "object", "properties": { "key": {
    "type": "string", "description": "Property within the entities metadata to match
    on" }, "value": { "type": "string", "description": "Value of the given property
    to match on" } }, "required": [ "key" ], "additionalProperties": false, "$schema":
    "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_SPEC", "description":
    "Allow entities with the specified spec subfield", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "key": { "type": "string",
    "description": "Property within the entities spec to match on" }, "value": { "type":
    "string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` [GET] /api/permission/roles/conditions/:id::
    Returns conditions for the specified ID. ```json { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ``` [GET] /api/permission/roles/conditions:: Returns
    list of all conditions for all roles. ```json [ { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ] ``` [POST] /api/permission/roles/conditions:: Creates
    a conditional policy for the specified role. ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog
    entity", "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } } } ``` ```json { "id": 1 } ``` [PUT] /permission/roles/conditions/:id:: Updates
    a condition policy for a specified ID. ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/test", "pluginId": "catalog", "resourceType": "catalog entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } },'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:15:28.046219'
    uuid: 74d3d113-bd4f-4db5-9c7e-f59910079559
  response: 'To add more plugin IDs, you can make a POST request to the `/api/permission/plugins/id`
    endpoint. The request requires an object in JSON format. For example, to add the
    "scaffolder" ID, the request object would be `[ { "ids": ["scaffolder"] } ]`.
    A successful request returns a status code of 200 and a JSON object with the updated
    list of IDs stored on the server, such as `[ { "ids": ["catalog", "permission",
    "scaffolder"] } ]`.'
  user_input: How do I add the scafolder plugin?
- context:
  - '"read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } }, ] ``` [GET] /api/permission/policies/<kind>/<namespace>/<name>::
    Returns permission policies related to the specified entity reference. ```json
    [ { "entityReference": "role:default/test", "permission": "catalog-entity", "policy":
    "read", "effect": "allow", "metadata": { "source": "csv-file" } }, { "entityReference":
    "role:default/test", "permission": "catalog.entity.create", "policy": "use", "effect":
    "allow", "metadata": { "source": "csv-file" } } ] ``` [POST] /api/permission/policies::
    Creates a permission policy for a specified entity. ```json [ { "entityReference":
    "role:default/test", "permission": "catalog entity", "policy": "read", "effect":
    "allow" } ] ``` ``` 201 Created ``` [PUT] /api/permission/policies/<kind>/<namespace>/<name>::
    Updates a permission policy for a specified entity. The request body contains
    the oldPolicy and newPolicy objects: ```json { "oldPolicy": [ { "permission":
    "catalog entity", "policy": "read", "effect": "allow" }, { "permission": "catalog.entity.create",
    "policy": "create", "effect": "allow" } ], "newPolicy": [ { "permission": "catalog
    entity", "policy": "read", "effect": "deny" }, { "permission": "policy entity",
    "policy": "read", "effect": "allow" } ] } ``` ``` 200 ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>?permission={value1}&policy={value2}&effect={value3}::
    Deletes a permission policy added to the specified entity. ``` 204 No Content
    ``` [DELETE] /api/permission/policies/<kind>/<namespace>/<name>:: Deletes all
    permission policies added to the specified entity. ``` 204 No Content ``` [GET]
    /api/permission/plugins/policies:: Returns permission policies for all static
    plugins. ```json [ { "pluginId": "catalog", "policies": [ { "isResourced": true,
    "permission": "catalog entity", "policy": "read" }, { "isResourced": false, "permission":
    "catalog.entity.create", "policy": "create" }, { "isResourced": true, "permission":
    "catalog entity", "policy": "delete" }, { "isResourced": true, "permission": "catalog
    entity", "policy": "update" }, { "isResourced": false, "permission": "catalog.location.read",
    "policy": "read" }, { "isResourced": false, "permission": "catalog.location.create",
    "policy": "create" }, { "isResourced": false, "permission": "catalog.location.delete",
    "policy": "delete" } ] }, ... ] ``` [GET] /api/permission/plugins/id:: Returns
    object with list plugin IDs: ```json [ { "ids": ["catalog", "permission"] } ]
    ``` [POST] /api/permission/plugins/id:: Add more plugins IDs defined in the request
    object. Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"]
    } ] ``` Returns a status code of 200 and JSON with actual object stored in the
    server: ```json [ { "ids": ["catalog", "permission", "scaffolder"] } ] ``` [DELETE]
    /api/permission/plugins/id:: Delete plugins IDs defined in the request object.
    Request Parameters: object in JSON format. ```json [ { "ids": ["scaffolder"] }
    ] ``` Returns a status code of 200 and JSON with actual object stored in the server:
    ```json [ { "ids": ["catalog", "permission"] } ] ``` [NOTE] ---- In order to prevent
    an inconsistent state after a deployment restart, the REST API does not allow
    deletion of plugin IDs that were provided by using the application configuration.
    These ID values can only be removed through the configuration file. ---- ### Conditional
    policies The RBAC REST API supports the following endpoints for managing conditional
    policies in the Red Hat Developer Hub. [GET] /api/permission/plugins/condition-rules::
    Returns available conditional rule parameter schemas for the available plugins
    that are enabled in Developer Hub. ```json [ { "pluginId": "catalog", "rules":
    [ { "name": "HAS_ANNOTATION", "description": "Allow entities with the specified
    annotation", "resourceType": "catalog-entity", "paramsSchema": { "type": "object",
    "properties": { "annotation": { "type": "string", "description": "Name of the
    annotation to match on" }, "value": { "type": "string", "description": "Value
    of the annotation to match on" } }, "required": [ "annotation" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_LABEL",
    "description": "Allow entities with the specified label", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "label": { "type": "string",
    "description": "Name of the label to match on" } }, "required": [ "label" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_METADATA",
    "description": "Allow entities with the specified metadata subfield", "resourceType":
    "catalog-entity", "paramsSchema": { "type": "object", "properties": { "key": {
    "type": "string", "description": "Property within the entities metadata to match
    on" }, "value": { "type": "string", "description": "Value of the given property
    to match on" } }, "required": [ "key" ], "additionalProperties": false, "$schema":
    "http://json-schema.org/draft-07/schema#" } }, { "name": "HAS_SPEC", "description":
    "Allow entities with the specified spec subfield", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "key": { "type": "string",
    "description": "Property within the entities spec to match on" }, "value": { "type":
    "string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` [GET] /api/permission/roles/conditions/:id::
    Returns conditions for the specified ID. ```json { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ``` [GET] /api/permission/roles/conditions:: Returns
    list of all conditions for all roles. ```json [ { "id": 1, "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog-entity", "params": { "claims": ["group:default/team-a"]
    } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": {
    "kinds": ["Group"] } } ] } } ] ``` [POST] /api/permission/roles/conditions:: Creates
    a conditional policy for the specified role. ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog
    entity", "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } } } ``` ```json { "id": 1 } ``` [PUT] /permission/roles/conditions/:id:: Updates
    a condition policy for a specified ID. ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/test", "pluginId": "catalog", "resourceType": "catalog entity",
    "permissionMapping": ["read"], "conditions": { "anyOf": [ { "rule": "IS_ENTITY_OWNER",
    "resourceType": "catalog entity", "params": { "claims": ["group:default/team a"]
    } },'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:15:37.158932'
    uuid: 4d0d2ec4-d36b-4315-ab6b-4117e829f818
  response: The HAS_METADATA conditional rule is designed to "Allow entities with
    the specified metadata subfield". It applies to the "catalog-entity" resource
    type and utilizes a parameter schema with a required "key" property, described
    as the "Property within the entities metadata to match on", and an optional "value"
    property, which is the "Value of the given property to match on".
  user_input: What is the purpose of the HAS_METADATA conditional rule within the
    RBAC REST API?
- context:
  - '{ "rule": "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds":
    ["Group"] } } ] } } ``` ``` 200 ``` [DELETE] /api/permission/roles/conditions/:id::
    Deletes a conditional policy for the specified ID. ``` 204 ``` ### User statistics
    The licensed-users-info-backend plugin exposes various REST API endpoints to retrieve
    data related to logged-in users. No additional configuration is required for the
    licensed-users-info-backend plugin. If the RBAC backend plugin is enabled, then
    an administrator role must be assigned to access the endpoints, as the endpoints
    are protected by the policy.entity.read permission. The base URL for user statistics
    endpoints is http://SERVER:PORT/api/licensed-users-info, such as http://localhost:7007/api/licensed-users-info.
    [GET] /users/quantity:: Returns the total number of logged-in users. ```bash curl
    X GET "http://localhost:7007/api/licensed users info/users/quantity" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json { "quantity":
    "2" } ``` [GET] /users:: Returns a list of logged-in users with their details.
    ```bash curl X GET "http://localhost:7007/api/licensed users info/users" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json [ { "userEntityRef":
    "user:default/dev", "lastTimeLogin": "Thu, 22 Aug 2024 16:27:41 GMT", "displayName":
    "John Leavy", "email": "dev@redhat.com" } ] ``` [GET] /users:: Returns a list
    of logged-in users in CSV format. ```bash curl X GET "http://localhost:7007/api/licensed
    users info/users" \ H "Content Type: text/csv" \ H "Authorization: Bearer $token"
    ``` ```csv userEntityRef,displayName,email,lastTimeLogin user:default/dev,John
    Leavy,dev@redhat.com,"Thu, 22 Aug 2024 16:27:41 GMT" ``` #'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:15:44.912208'
    uuid: 766a1720-9a3b-4a8d-b78f-c1bff6f91291
  response: When returning a list of logged-in users, the details provided for the
    user with the email "dev@redhat.com" are a "userEntityRef" of "user:default/dev",
    a "lastTimeLogin" of "Thu, 22 Aug 2024 16:27:41 GMT", and a "displayName" of "John
    Leavy".
  user_input: I am trying to get the users list from the API and I see this one user
    John Leavy with the email dev@redhat.com, what is all the information that the
    API gives me for this user from redhat.com?
- context:
  - '{ "rule": "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds":
    ["Group"] } } ] } } ``` ``` 200 ``` [DELETE] /api/permission/roles/conditions/:id::
    Deletes a conditional policy for the specified ID. ``` 204 ``` ### User statistics
    The licensed-users-info-backend plugin exposes various REST API endpoints to retrieve
    data related to logged-in users. No additional configuration is required for the
    licensed-users-info-backend plugin. If the RBAC backend plugin is enabled, then
    an administrator role must be assigned to access the endpoints, as the endpoints
    are protected by the policy.entity.read permission. The base URL for user statistics
    endpoints is http://SERVER:PORT/api/licensed-users-info, such as http://localhost:7007/api/licensed-users-info.
    [GET] /users/quantity:: Returns the total number of logged-in users. ```bash curl
    X GET "http://localhost:7007/api/licensed users info/users/quantity" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json { "quantity":
    "2" } ``` [GET] /users:: Returns a list of logged-in users with their details.
    ```bash curl X GET "http://localhost:7007/api/licensed users info/users" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json [ { "userEntityRef":
    "user:default/dev", "lastTimeLogin": "Thu, 22 Aug 2024 16:27:41 GMT", "displayName":
    "John Leavy", "email": "dev@redhat.com" } ] ``` [GET] /users:: Returns a list
    of logged-in users in CSV format. ```bash curl X GET "http://localhost:7007/api/licensed
    users info/users" \ H "Content Type: text/csv" \ H "Authorization: Bearer $token"
    ``` ```csv userEntityRef,displayName,email,lastTimeLogin user:default/dev,John
    Leavy,dev@redhat.com,"Thu, 22 Aug 2024 16:27:41 GMT" ``` #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:15:55.282740'
    uuid: e6df0ffb-8e0e-4253-ac39-e71aac52edeb
  response: The licensed-users-info-backend plugin is used to expose various REST
    API endpoints for retrieving data about logged-in users. No extra configuration
    is needed for it, but if the RBAC backend plugin is enabled, an administrator
    role is required to access the endpoints due to the policy.entity.read permission.
    The plugin's endpoints can provide the total quantity of logged-in users, a list
    of users with their details in JSON format, or a list of users in CSV format.
  user_input: what is the licensed-users-info-backend plugin for
- context:
  - '{ "rule": "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds":
    ["Group"] } } ] } } ``` ``` 200 ``` [DELETE] /api/permission/roles/conditions/:id::
    Deletes a conditional policy for the specified ID. ``` 204 ``` ### User statistics
    The licensed-users-info-backend plugin exposes various REST API endpoints to retrieve
    data related to logged-in users. No additional configuration is required for the
    licensed-users-info-backend plugin. If the RBAC backend plugin is enabled, then
    an administrator role must be assigned to access the endpoints, as the endpoints
    are protected by the policy.entity.read permission. The base URL for user statistics
    endpoints is http://SERVER:PORT/api/licensed-users-info, such as http://localhost:7007/api/licensed-users-info.
    [GET] /users/quantity:: Returns the total number of logged-in users. ```bash curl
    X GET "http://localhost:7007/api/licensed users info/users/quantity" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json { "quantity":
    "2" } ``` [GET] /users:: Returns a list of logged-in users with their details.
    ```bash curl X GET "http://localhost:7007/api/licensed users info/users" \ H "Content
    Type: application/json" \ H "Authorization: Bearer $token" ``` ```json [ { "userEntityRef":
    "user:default/dev", "lastTimeLogin": "Thu, 22 Aug 2024 16:27:41 GMT", "displayName":
    "John Leavy", "email": "dev@redhat.com" } ] ``` [GET] /users:: Returns a list
    of logged-in users in CSV format. ```bash curl X GET "http://localhost:7007/api/licensed
    users info/users" \ H "Content Type: text/csv" \ H "Authorization: Bearer $token"
    ``` ```csv userEntityRef,displayName,email,lastTimeLogin user:default/dev,John
    Leavy,dev@redhat.com,"Thu, 22 Aug 2024 16:27:41 GMT" ``` #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:03.115182'
    uuid: 0abe70be-f086-4b2f-83ae-0235631d8c5f
  response: If the RBAC backend plugin is enabled, an administrator role must be assigned
    to access the endpoints, as the endpoints are protected by the policy.entity.read
    permission.
  user_input: If the RBAC bakend plugin is enabled, what role is needed to acces the
    user statistics endpoints?
- context:
  - 'Managing authorizations by using external files To automate Red Hat Developer
    Hub maintenance, you can configure permissions and roles in external files, before
    starting Developer Hub. ## Defining authorizations in external files by using
    the Operator To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Backstage custom resource to mount in the Developer Hub filesystem
    your files from the rbac-policies config map: Backstage custom resource fragment
    ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application:
    extraFiles: mountPath: /opt/app root/src configMaps: name: rbac policies ``` 5.
    Update your Developer Hub app-config.yaml configuration file to use the rbac-policies.csv
    and rbac-conditional-policies.yaml external files: app-config.yaml file fragment
    ```yaml permission: enabled: true rbac: conditionalPoliciesFile: /opt/app root/src/rbac
    conditional policies.yaml policies csv file: /opt/app root/src/rbac policies.csv
    policyFileReload: true ``` ## Defining authorizations in external files by using
    Helm To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Developer Hub Backstage Helm chart to mount in the Developer
    Hub filesystem your files from the rbac-policies config map: 1. In the Developer
    Hub Helm Chart, go to Root Schema -> Backstage chart schema -> Backstage parameters
    -> Backstage container additional volume mounts. 2. Select Add Backstage container
    additional volume mounts and add the following values: mountPath:: /opt/app-root/src/rbac
    Name:: rbac-policies 3. Add the RBAC policy to the Backstage container additional
    volumes in the Developer Hub Helm Chart: name:: rbac-policies configMap:: defaultMode::
    420 name:: rbac-policies 5. Update your Developer Hub app-config.yaml configuration
    file to use the rbac-policies.csv and rbac-conditional-policies.yaml external
    files: app-config.yaml file fragment ```yaml permission: enabled: true rbac: conditionalPoliciesFile:
    /opt/app root/src/rbac conditional policies.yaml policies csv file: /opt/app root/src/rbac
    policies.csv policyFileReload: true ``` # Configuring guest access with RBAC UI
    Use guest access with the role-based access control (RBAC) front-end plugin to
    allow a user to test role and policy creation without the need to set up and configure
    an authentication provider. [NOTE] ---- Guest access is not recommended for production.
    ---- ## Configuring the RBAC backend plugin You can configure the RBAC backend
    plugin by updating the app-config.yaml file to enable the permission framework.
    You have installed the @backstage community/plugin rbac plugin in Developer Hub.
    For more information, see Configuring dynamic plugins. Update the app config.yaml
    file to enable the permission framework as shown: ```yaml permission enabled:
    true rbac: admin: users: name: user:default/guest pluginsWithPermission: catalog
    permission scaffolder ``` [NOTE] ---- The pluginsWithPermission section of the
    app-config.yaml file includes only three plugins by default. Update the section
    as needed to include any additional plugins that also incorporate permissions.
    ---- ## Setting up the guest authentication provider You can enable guest authentication
    and use it alongside the RBAC frontend plugin. You have installed the @backstage
    community/plugin rbac plugin in Developer Hub. For more information, see Configuring
    dynamic plugins. In the app config.yaml file, add the user entity reference to
    resolve and enable the dangerouslyAllowOutsideDevelopment option, as shown in
    the following example: ```yaml auth: environment: development providers: guest:
    userEntityRef: user:default/guest dangerouslyAllowOutsideDevelopment: true ```
    [NOTE] ---- You can use user:default/guest as the user entity reference to match
    the added user under the permission.rbac.admin.users section of the app-config.yaml
    file. ---- #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:12.739673'
    uuid: 03b8b999-5119-41af-9b07-fb2e58f44c87
  response: To automate Red Hat Developer Hub maintenance, you can configure permissions
    and roles in external files before starting Developer Hub, provided you have enabled
    the RBAC feature. The process involves defining policies in a `rbac-policies.csv`
    file and conditional policies in a `rbac-conditional-policies.yaml` file. These
    files are then uploaded to a config map named `rbac-policies` in your OpenShift
    Container Platform project using the `oc create configmap` command. Afterwards,
    you must update your configuration to mount the files from the config map into
    the Developer Hub filesystem. If using the Operator, you update the Backstage
    custom resource. If using Helm, you update the Developer Hub Backstage Helm chart.
    Finally, you update your `app-config.yaml` file to use these external files by
    specifying their paths in the `permission.rbac` section and setting `policyFileReload`
    to `true`.
  user_input: Red Hat Developer Hub automate authorizations with external files
- context:
  - 'Managing authorizations by using external files To automate Red Hat Developer
    Hub maintenance, you can configure permissions and roles in external files, before
    starting Developer Hub. ## Defining authorizations in external files by using
    the Operator To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Backstage custom resource to mount in the Developer Hub filesystem
    your files from the rbac-policies config map: Backstage custom resource fragment
    ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application:
    extraFiles: mountPath: /opt/app root/src configMaps: name: rbac policies ``` 5.
    Update your Developer Hub app-config.yaml configuration file to use the rbac-policies.csv
    and rbac-conditional-policies.yaml external files: app-config.yaml file fragment
    ```yaml permission: enabled: true rbac: conditionalPoliciesFile: /opt/app root/src/rbac
    conditional policies.yaml policies csv file: /opt/app root/src/rbac policies.csv
    policyFileReload: true ``` ## Defining authorizations in external files by using
    Helm To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Developer Hub Backstage Helm chart to mount in the Developer
    Hub filesystem your files from the rbac-policies config map: 1. In the Developer
    Hub Helm Chart, go to Root Schema -> Backstage chart schema -> Backstage parameters
    -> Backstage container additional volume mounts. 2. Select Add Backstage container
    additional volume mounts and add the following values: mountPath:: /opt/app-root/src/rbac
    Name:: rbac-policies 3. Add the RBAC policy to the Backstage container additional
    volumes in the Developer Hub Helm Chart: name:: rbac-policies configMap:: defaultMode::
    420 name:: rbac-policies 5. Update your Developer Hub app-config.yaml configuration
    file to use the rbac-policies.csv and rbac-conditional-policies.yaml external
    files: app-config.yaml file fragment ```yaml permission: enabled: true rbac: conditionalPoliciesFile:
    /opt/app root/src/rbac conditional policies.yaml policies csv file: /opt/app root/src/rbac
    policies.csv policyFileReload: true ``` # Configuring guest access with RBAC UI
    Use guest access with the role-based access control (RBAC) front-end plugin to
    allow a user to test role and policy creation without the need to set up and configure
    an authentication provider. [NOTE] ---- Guest access is not recommended for production.
    ---- ## Configuring the RBAC backend plugin You can configure the RBAC backend
    plugin by updating the app-config.yaml file to enable the permission framework.
    You have installed the @backstage community/plugin rbac plugin in Developer Hub.
    For more information, see Configuring dynamic plugins. Update the app config.yaml
    file to enable the permission framework as shown: ```yaml permission enabled:
    true rbac: admin: users: name: user:default/guest pluginsWithPermission: catalog
    permission scaffolder ``` [NOTE] ---- The pluginsWithPermission section of the
    app-config.yaml file includes only three plugins by default. Update the section
    as needed to include any additional plugins that also incorporate permissions.
    ---- ## Setting up the guest authentication provider You can enable guest authentication
    and use it alongside the RBAC frontend plugin. You have installed the @backstage
    community/plugin rbac plugin in Developer Hub. For more information, see Configuring
    dynamic plugins. In the app config.yaml file, add the user entity reference to
    resolve and enable the dangerouslyAllowOutsideDevelopment option, as shown in
    the following example: ```yaml auth: environment: development providers: guest:
    userEntityRef: user:default/guest dangerouslyAllowOutsideDevelopment: true ```
    [NOTE] ---- You can use user:default/guest as the user entity reference to match
    the added user under the permission.rbac.admin.users section of the app-config.yaml
    file. ---- #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:22.160020'
    uuid: f7ad11f2-6667-455b-b282-cd1018afd4d1
  response: "To automate Red Hat Developer Hub maintenance by defining permissions\
    \ and roles in external files using the Operator, you must first enable the RBAC\
    \ feature. The process involves preparing your files, uploading them to your OpenShift\
    \ Container Platform project, and configuring Developer Hub to use them. The steps\
    \ are as follows:\n\n1. Define your policies in a `rbac-policies.csv` file. To\
    \ define role permissions, use the format `p, <role_entity_reference>, <permission>,\
    \ <action>, <allow_or_deny>`. To assign a role to a group or user, use the format\
    \ `g, <group_or_user>, <role_entity_reference>`.\n\n2. Define your conditional\
    \ policies in a `rbac-conditional-policies.yaml` file using this format:\n```yaml\n\
    result: CONDITIONAL\nroleEntityRef: <role_entity_reference>\npluginId: <plugin_id>\n\
    permissionMapping:\n  read\n  update\n  delete\nconditions: <conditions>\n```\n\
    \n3. Upload both the `rbac-policies.csv` and `rbac-conditional-policies.yaml`\
    \ files to a config map named `rbac-policies` in your OpenShift Container Platform\
    \ project with the command: `$ oc create configmap rbac-policies \\ --from-file=rbac-policies.csv\
    \ \\ --from-file=rbac-conditional-policies.yaml`\n\n4. Update your Backstage custom\
    \ resource to mount the files from the `rbac-policies` config map into the Developer\
    \ Hub filesystem by adding the following fragment:\n```yaml\napiVersion: rhdh.redhat.com/v1alpha3\n\
    kind: Backstage\nspec:\n  application:\n    extraFiles:\n      mountPath: /opt/app\
    \ root/src\n      configMaps:\n        name: rbac policies\n```\n\n5. Update your\
    \ Developer Hub `app-config.yaml` configuration file to use the external files\
    \ with this configuration:\n```yaml\npermission:\n  enabled: true\n  rbac:\n \
    \   conditionalPoliciesFile: /opt/app root/src/rbac conditional policies.yaml\n\
    \    policies csv file: /opt/app root/src/rbac policies.csv\n    policyFileReload:\
    \ true\n```"
  user_input: For the Red Hat Developer Hub, how we can automate the maintenance by
    using external files for the permissions and roles, like what is the whole process
    for doing that with the Operator, i need to know all the steps like what files
    to make and what commands to run and what to put in the config files?
- context:
  - 'Managing authorizations by using external files To automate Red Hat Developer
    Hub maintenance, you can configure permissions and roles in external files, before
    starting Developer Hub. ## Defining authorizations in external files by using
    the Operator To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Backstage custom resource to mount in the Developer Hub filesystem
    your files from the rbac-policies config map: Backstage custom resource fragment
    ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage spec: application:
    extraFiles: mountPath: /opt/app root/src configMaps: name: rbac policies ``` 5.
    Update your Developer Hub app-config.yaml configuration file to use the rbac-policies.csv
    and rbac-conditional-policies.yaml external files: app-config.yaml file fragment
    ```yaml permission: enabled: true rbac: conditionalPoliciesFile: /opt/app root/src/rbac
    conditional policies.yaml policies csv file: /opt/app root/src/rbac policies.csv
    policyFileReload: true ``` ## Defining authorizations in external files by using
    Helm To automate Red Hat Developer Hub maintenance, you can define permissions
    and roles in external files, before starting Developer Hub. You need to prepare
    your files, upload them to your OpenShift Container Platform project, and configure
    Developer Hub to use the external files. You enabled the RBAC feature. 1. Define
    your policies in a rbac-policies.csv CSV file by using the following format: 1.
    Define role permissions: ```csv p, <role_entity_reference>, <permission>, <action>,
    <allow_or_deny> ``` <role_entity_reference>:: Role entity reference, such as:
    role:default/guest. <permission>:: Permission, such as: bulk.import, catalog.entity.read,
    or catalog.entity.refresh, or permission resource type, such as: bulk-import or
    catalog-entity. See: Permission policies reference. <action>:: Action type, such
    as: use, read, create, update, delete. <allow_or_deny>:: Access granted: allow
    or deny. 2. Assign the role to a group or a user: ```csv g, <group_or_user>, <role_entity_reference>
    ``` <group_or_user>:: Group, such as: user:default/mygroup, or user, such as:
    user:default/myuser. Sample rbac-policies.csv ```csv p, role:default/guests, catalog-entity,
    read, allow p, role:default/guests, catalog.entity.create, create, allow g, user:default/my-user,
    role:default/guests g, group:default/my-group, role:default/guests ``` 2. Define
    your conditional policies in a rbac-conditional-policies.yaml YAML file by using
    the following format: ```yaml result: CONDITIONAL roleEntityRef: <role_entity_reference>
    pluginId: <plugin_id> permissionMapping: read update delete conditions: <conditions>
    ``` See: Conditional policies reference. 3. Upload your rbac-policies.csv and
    rbac-conditional-policies.yaml files to a rbac-policies config map in your OpenShift
    Container Platform project containing Developer Hub. ```terminal $ oc create configmap
    rbac-policies \ --from-file=rbac-policies.csv \ --from-file=rbac-conditional-policies.yaml
    ``` 4. Update your Developer Hub Backstage Helm chart to mount in the Developer
    Hub filesystem your files from the rbac-policies config map: 1. In the Developer
    Hub Helm Chart, go to Root Schema -> Backstage chart schema -> Backstage parameters
    -> Backstage container additional volume mounts. 2. Select Add Backstage container
    additional volume mounts and add the following values: mountPath:: /opt/app-root/src/rbac
    Name:: rbac-policies 3. Add the RBAC policy to the Backstage container additional
    volumes in the Developer Hub Helm Chart: name:: rbac-policies configMap:: defaultMode::
    420 name:: rbac-policies 5. Update your Developer Hub app-config.yaml configuration
    file to use the rbac-policies.csv and rbac-conditional-policies.yaml external
    files: app-config.yaml file fragment ```yaml permission: enabled: true rbac: conditionalPoliciesFile:
    /opt/app root/src/rbac conditional policies.yaml policies csv file: /opt/app root/src/rbac
    policies.csv policyFileReload: true ``` # Configuring guest access with RBAC UI
    Use guest access with the role-based access control (RBAC) front-end plugin to
    allow a user to test role and policy creation without the need to set up and configure
    an authentication provider. [NOTE] ---- Guest access is not recommended for production.
    ---- ## Configuring the RBAC backend plugin You can configure the RBAC backend
    plugin by updating the app-config.yaml file to enable the permission framework.
    You have installed the @backstage community/plugin rbac plugin in Developer Hub.
    For more information, see Configuring dynamic plugins. Update the app config.yaml
    file to enable the permission framework as shown: ```yaml permission enabled:
    true rbac: admin: users: name: user:default/guest pluginsWithPermission: catalog
    permission scaffolder ``` [NOTE] ---- The pluginsWithPermission section of the
    app-config.yaml file includes only three plugins by default. Update the section
    as needed to include any additional plugins that also incorporate permissions.
    ---- ## Setting up the guest authentication provider You can enable guest authentication
    and use it alongside the RBAC frontend plugin. You have installed the @backstage
    community/plugin rbac plugin in Developer Hub. For more information, see Configuring
    dynamic plugins. In the app config.yaml file, add the user entity reference to
    resolve and enable the dangerouslyAllowOutsideDevelopment option, as shown in
    the following example: ```yaml auth: environment: development providers: guest:
    userEntityRef: user:default/guest dangerouslyAllowOutsideDevelopment: true ```
    [NOTE] ---- You can use user:default/guest as the user entity reference to match
    the added user under the permission.rbac.admin.users section of the app-config.yaml
    file. ---- #'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:30.789740'
    uuid: d535a09d-0af6-4f45-a770-aa1038f5e3cb
  response: To define authorizations in external files using the Operator, you first
    prepare your files by defining policies in a rbac-policies.csv file and conditional
    policies in a rbac-conditional-policies.yaml file. Next, you upload these files
    to a rbac-policies config map in your OpenShift Container Platform project. Then,
    you update your Backstage custom resource to mount the files from the config map
    into the Developer Hub filesystem. Finally, you update your Developer Hub app-config.yaml
    configuration file to use the external rbac-policies.csv and rbac-conditional-policies.yaml
    files.
  user_input: How are authorizations defined in external files using the Operator?
- context:
  - "Delegating role-based access controls (RBAC) access in Red Hat Developer Hub\
    \ An enterprise customer requires the ability to delegate role-based access control\
    \ (RBAC) responsibilities to other individuals in the organization. In this scenario,\
    \ you, as the administrator, can provide access to the RBAC plugin specifically\
    \ to designated users, such as team leads. Each team lead is then able to manage\
    \ permissions exclusively for users within their respective team or department,\
    \ without visibility into or control over permissions outside their assigned scope.\
    \ This approach allows team leads to manage access and permissions for their own\
    \ teams independently, while administrators maintain global oversight. In Red\
    \ Hat Developer Hub, you can delegate RBAC access using the multitenancy feature\
    \ of the RBAC plugin, specifically the IS_OWNER conditional rule. You can either\
    \ use the web UI or the RBAC backend API, depending on your preferred workflow\
    \ and level of automation: Use the web UI to create roles, assign users or groups,\
    \ define permissions, and apply ownership conditions through an intuitive interface.\
    \ Use the API for a more flexible and automatable approach, where you can programmatically\
    \ manage roles, permissions, and ownership conditions using authenticated curl\
    \ requests. By delegating RBAC access through either method, you can expect the\
    \ following outcomes: Team leads can manage RBAC settings for their teams independently.\
    \ Visibility of other users' or teams' permissions is restricted. Administrators\
    \ retain overarching control while delegating team specific access. Your RHDH\
    \ instance is running with the RBAC plugin installed and configured. You have\
    \ administrative access to RHDH. ## Delegating RBAC access in Red Hat Developer\
    \ Hub by using the web UI You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the web UI. 1. Log in to your RHDH instance with administrator\
    \ credentials. 2. Navigate to Administration \u2192 RBAC. 3. Click Create Role\
    \ and define a new role for team leads, such as role:default/team_lead. 4. In\
    \ the Members section, add the user or group, such as user:default/team_lead.\
    \ 5. Grant permissions required by team leads, such as: * policy.entity.create\
    \ to allow policy creation. * catalog-entity:read to allow catalog access. 6.\
    \ Apply conditions to limit access as follows: * Use the IS_OWNER rule to ensure\
    \ team leads can only manage resources they own. 7. Click Save to create the role\
    \ and apply changes. Log in as a team lead. Verify the following: RBAC UI is accessible.\
    \ Only users or roles related to their team are visible. No access to roles or\
    \ permissions outside their scope is granted. ## Delegating RBAC access in Red\
    \ Hat Developer Hub by using API You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the RBAC backend API. You have API access using curl or another\
    \ tool. 1. Create a new role designated for team leads using the RBAC backend\
    \ API: ```bash curl -X POST 'http://localhost:7007/api/permission/roles' \\ --header\
    \ \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\"\
    \ \\ --data '{ \"memberReferences\": [\"user:default/team_lead\"], \"name\": \"\
    role:default/team_lead\", \"metadata\": { \"description\": \"This is an example\
    \ team lead role\" } }' ``` 2. Allow team leads to read catalog entities and create\
    \ permissions in the RBAC plugin using the following API request: ```bash curl\
    \ -X POST 'http://localhost:7007/api/permission/policies' \\ --header \"Authorization:\
    \ Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\" \\ --data\
    \ '[ { \"entityReference\": \"role:default/team_lead\", \"permission\": \"policy.entity.create\"\
    , \"policy\": \"create\", \"effect\": \"allow\" }, { \"entityReference\": \"role:default/team_lead\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 3. To ensure team leads can only manage what they own, use the IS_OWNER\
    \ conditional rule as follows: ```bash curl -X POST 'http://localhost:7007/api/permission/roles/conditions'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"result\": \"CONDITIONAL\", \"pluginId\": \"\
    permission\", \"resourceType\": \"policy-entity\", \"conditions\": { \"rule\"\
    : \"IS_OWNER\", \"resourceType\": \"policy-entity\", \"params\": { \"owners\"\
    : [ \"user:default/team_lead\" ] } }, \"roleEntityRef\": \"role:default/team_lead\"\
    , \"permissionMapping\": [ \"read\", \"update\", \"delete\" ] }' ``` The previous\
    \ example of conditional policy limits visibility and control to only owned roles\
    \ and policies. 4. Log in to RHDH as team lead and verify the following: 1. Use\
    \ the following request and verify that you do not see any roles: Example curl\
    \ to retrieve roles visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` 2. Use the following\
    \ request to create a new role for their team: Example curl of team lead creating\
    \ a new role for their team with ownership assigned ```bash curl -X POST 'http://localhost:7007/api/permission/roles'\
    \ \\ --header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"memberReferences\": [\"user:default/team_member\"\
    ], \"name\": \"role:default/team_a\", \"metadata\": { \"description\": \"This\
    \ is an example team_a role\", \"owner\": \"user:default/team_lead\" } }' ```\
    \ [NOTE] ---- You can set the ownership during creation, but you can also update\
    \ the ownership at any time. ---- 3. Use the following request to assign a permission\
    \ policy to the new role: Example curl for granting read access to catalog entities\
    \ for the new role ```bash curl -X POST 'http://localhost:7007/api/permission/policies'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '[ { \"entityReference\": \"role:default/team_a\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 4. Use the following request to verify that only team-owned roles and\
    \ policies are visible: Example curl to retrieve roles and permission policies\
    \ visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" curl X GET 'http://localhost:7007/api/permission/policies'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` Log in as a team lead\
    \ and verify the following: The RBAC UI is accessible. Only the assigned users\
    \ or group is visible. Permissions outside the scoped team are not viewable or\
    \ editable. Log in as an administrator and verify that you retain full visibility\
    \ and control. # Permission policies reference Permission policies in Red Hat\
    \ Developer Hub are a set of rules to govern access to resources or functionalities.\
    \ These policies state the authorization level that is granted to users based\
    \ on their roles. The permission policies are implemented to maintain security\
    \ and confidentiality within a given environment. You can define the following\
    \ types of permissions in Developer Hub: resource type basic The distinction between\
    \ the two permission types depends on whether a permission includes a defined\
    \ resource"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:39.007116'
    uuid: 813dc15f-8f70-4e8f-8174-87b7cffc602c
  response: To delegate RBAC access using the RBAC backend API, you can follow these
    steps. First, create a new role for team leads by sending a POST request to 'http://localhost:7007/api/permission/roles'.
    Second, you must allow team leads to read catalog entities and create permissions
    by sending a POST request to 'http://localhost:7007/api/permission/policies' to
    grant permissions for 'policy.entity.create' and 'catalog-entity'. Finally, to
    ensure team leads can only manage what they own, you use the IS_OWNER conditional
    rule by sending a POST request to 'http://localhost:7007/api/permission/roles/conditions'.
    This conditional policy limits visibility and control to only owned roles and
    policies.
  user_input: so im trying to figure out how we can let our team leads manage their
    own peoples permissions cause right now its a big bottleneck, i see we can use
    the RBAC backend API for this which is good for automation, but what is the actual
    steps i need to do with the api to make it so a team lead can only see and manage
    their own teams stuff and not everyone elses?
- context:
  - "Delegating role-based access controls (RBAC) access in Red Hat Developer Hub\
    \ An enterprise customer requires the ability to delegate role-based access control\
    \ (RBAC) responsibilities to other individuals in the organization. In this scenario,\
    \ you, as the administrator, can provide access to the RBAC plugin specifically\
    \ to designated users, such as team leads. Each team lead is then able to manage\
    \ permissions exclusively for users within their respective team or department,\
    \ without visibility into or control over permissions outside their assigned scope.\
    \ This approach allows team leads to manage access and permissions for their own\
    \ teams independently, while administrators maintain global oversight. In Red\
    \ Hat Developer Hub, you can delegate RBAC access using the multitenancy feature\
    \ of the RBAC plugin, specifically the IS_OWNER conditional rule. You can either\
    \ use the web UI or the RBAC backend API, depending on your preferred workflow\
    \ and level of automation: Use the web UI to create roles, assign users or groups,\
    \ define permissions, and apply ownership conditions through an intuitive interface.\
    \ Use the API for a more flexible and automatable approach, where you can programmatically\
    \ manage roles, permissions, and ownership conditions using authenticated curl\
    \ requests. By delegating RBAC access through either method, you can expect the\
    \ following outcomes: Team leads can manage RBAC settings for their teams independently.\
    \ Visibility of other users' or teams' permissions is restricted. Administrators\
    \ retain overarching control while delegating team specific access. Your RHDH\
    \ instance is running with the RBAC plugin installed and configured. You have\
    \ administrative access to RHDH. ## Delegating RBAC access in Red Hat Developer\
    \ Hub by using the web UI You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the web UI. 1. Log in to your RHDH instance with administrator\
    \ credentials. 2. Navigate to Administration \u2192 RBAC. 3. Click Create Role\
    \ and define a new role for team leads, such as role:default/team_lead. 4. In\
    \ the Members section, add the user or group, such as user:default/team_lead.\
    \ 5. Grant permissions required by team leads, such as: * policy.entity.create\
    \ to allow policy creation. * catalog-entity:read to allow catalog access. 6.\
    \ Apply conditions to limit access as follows: * Use the IS_OWNER rule to ensure\
    \ team leads can only manage resources they own. 7. Click Save to create the role\
    \ and apply changes. Log in as a team lead. Verify the following: RBAC UI is accessible.\
    \ Only users or roles related to their team are visible. No access to roles or\
    \ permissions outside their scope is granted. ## Delegating RBAC access in Red\
    \ Hat Developer Hub by using API You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the RBAC backend API. You have API access using curl or another\
    \ tool. 1. Create a new role designated for team leads using the RBAC backend\
    \ API: ```bash curl -X POST 'http://localhost:7007/api/permission/roles' \\ --header\
    \ \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\"\
    \ \\ --data '{ \"memberReferences\": [\"user:default/team_lead\"], \"name\": \"\
    role:default/team_lead\", \"metadata\": { \"description\": \"This is an example\
    \ team lead role\" } }' ``` 2. Allow team leads to read catalog entities and create\
    \ permissions in the RBAC plugin using the following API request: ```bash curl\
    \ -X POST 'http://localhost:7007/api/permission/policies' \\ --header \"Authorization:\
    \ Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\" \\ --data\
    \ '[ { \"entityReference\": \"role:default/team_lead\", \"permission\": \"policy.entity.create\"\
    , \"policy\": \"create\", \"effect\": \"allow\" }, { \"entityReference\": \"role:default/team_lead\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 3. To ensure team leads can only manage what they own, use the IS_OWNER\
    \ conditional rule as follows: ```bash curl -X POST 'http://localhost:7007/api/permission/roles/conditions'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"result\": \"CONDITIONAL\", \"pluginId\": \"\
    permission\", \"resourceType\": \"policy-entity\", \"conditions\": { \"rule\"\
    : \"IS_OWNER\", \"resourceType\": \"policy-entity\", \"params\": { \"owners\"\
    : [ \"user:default/team_lead\" ] } }, \"roleEntityRef\": \"role:default/team_lead\"\
    , \"permissionMapping\": [ \"read\", \"update\", \"delete\" ] }' ``` The previous\
    \ example of conditional policy limits visibility and control to only owned roles\
    \ and policies. 4. Log in to RHDH as team lead and verify the following: 1. Use\
    \ the following request and verify that you do not see any roles: Example curl\
    \ to retrieve roles visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` 2. Use the following\
    \ request to create a new role for their team: Example curl of team lead creating\
    \ a new role for their team with ownership assigned ```bash curl -X POST 'http://localhost:7007/api/permission/roles'\
    \ \\ --header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"memberReferences\": [\"user:default/team_member\"\
    ], \"name\": \"role:default/team_a\", \"metadata\": { \"description\": \"This\
    \ is an example team_a role\", \"owner\": \"user:default/team_lead\" } }' ```\
    \ [NOTE] ---- You can set the ownership during creation, but you can also update\
    \ the ownership at any time. ---- 3. Use the following request to assign a permission\
    \ policy to the new role: Example curl for granting read access to catalog entities\
    \ for the new role ```bash curl -X POST 'http://localhost:7007/api/permission/policies'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '[ { \"entityReference\": \"role:default/team_a\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 4. Use the following request to verify that only team-owned roles and\
    \ policies are visible: Example curl to retrieve roles and permission policies\
    \ visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" curl X GET 'http://localhost:7007/api/permission/policies'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` Log in as a team lead\
    \ and verify the following: The RBAC UI is accessible. Only the assigned users\
    \ or group is visible. Permissions outside the scoped team are not viewable or\
    \ editable. Log in as an administrator and verify that you retain full visibility\
    \ and control. # Permission policies reference Permission policies in Red Hat\
    \ Developer Hub are a set of rules to govern access to resources or functionalities.\
    \ These policies state the authorization level that is granted to users based\
    \ on their roles. The permission policies are implemented to maintain security\
    \ and confidentiality within a given environment. You can define the following\
    \ types of permissions in Developer Hub: resource type basic The distinction between\
    \ the two permission types depends on whether a permission includes a defined\
    \ resource"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:47.285945'
    uuid: 0466bce2-30b7-4dc4-8cf6-74b5029590bf
  response: In Red Hat Developer Hub, you can delegate RBAC access using the multitenancy
    feature of the RBAC plugin, specifically the IS_OWNER conditional rule. You can
    use the IS_OWNER rule to ensure team leads can only manage resources they own.
    This conditional policy limits visibility and control to only owned roles and
    policies.
  user_input: Wht is the IS_OWNER rul for in RHDH?
- context:
  - "Delegating role-based access controls (RBAC) access in Red Hat Developer Hub\
    \ An enterprise customer requires the ability to delegate role-based access control\
    \ (RBAC) responsibilities to other individuals in the organization. In this scenario,\
    \ you, as the administrator, can provide access to the RBAC plugin specifically\
    \ to designated users, such as team leads. Each team lead is then able to manage\
    \ permissions exclusively for users within their respective team or department,\
    \ without visibility into or control over permissions outside their assigned scope.\
    \ This approach allows team leads to manage access and permissions for their own\
    \ teams independently, while administrators maintain global oversight. In Red\
    \ Hat Developer Hub, you can delegate RBAC access using the multitenancy feature\
    \ of the RBAC plugin, specifically the IS_OWNER conditional rule. You can either\
    \ use the web UI or the RBAC backend API, depending on your preferred workflow\
    \ and level of automation: Use the web UI to create roles, assign users or groups,\
    \ define permissions, and apply ownership conditions through an intuitive interface.\
    \ Use the API for a more flexible and automatable approach, where you can programmatically\
    \ manage roles, permissions, and ownership conditions using authenticated curl\
    \ requests. By delegating RBAC access through either method, you can expect the\
    \ following outcomes: Team leads can manage RBAC settings for their teams independently.\
    \ Visibility of other users' or teams' permissions is restricted. Administrators\
    \ retain overarching control while delegating team specific access. Your RHDH\
    \ instance is running with the RBAC plugin installed and configured. You have\
    \ administrative access to RHDH. ## Delegating RBAC access in Red Hat Developer\
    \ Hub by using the web UI You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the web UI. 1. Log in to your RHDH instance with administrator\
    \ credentials. 2. Navigate to Administration \u2192 RBAC. 3. Click Create Role\
    \ and define a new role for team leads, such as role:default/team_lead. 4. In\
    \ the Members section, add the user or group, such as user:default/team_lead.\
    \ 5. Grant permissions required by team leads, such as: * policy.entity.create\
    \ to allow policy creation. * catalog-entity:read to allow catalog access. 6.\
    \ Apply conditions to limit access as follows: * Use the IS_OWNER rule to ensure\
    \ team leads can only manage resources they own. 7. Click Save to create the role\
    \ and apply changes. Log in as a team lead. Verify the following: RBAC UI is accessible.\
    \ Only users or roles related to their team are visible. No access to roles or\
    \ permissions outside their scope is granted. ## Delegating RBAC access in Red\
    \ Hat Developer Hub by using API You can delegate the RBAC access in Red Hat Developer\
    \ Hub by using the RBAC backend API. You have API access using curl or another\
    \ tool. 1. Create a new role designated for team leads using the RBAC backend\
    \ API: ```bash curl -X POST 'http://localhost:7007/api/permission/roles' \\ --header\
    \ \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\"\
    \ \\ --data '{ \"memberReferences\": [\"user:default/team_lead\"], \"name\": \"\
    role:default/team_lead\", \"metadata\": { \"description\": \"This is an example\
    \ team lead role\" } }' ``` 2. Allow team leads to read catalog entities and create\
    \ permissions in the RBAC plugin using the following API request: ```bash curl\
    \ -X POST 'http://localhost:7007/api/permission/policies' \\ --header \"Authorization:\
    \ Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type: application/json\" \\ --data\
    \ '[ { \"entityReference\": \"role:default/team_lead\", \"permission\": \"policy.entity.create\"\
    , \"policy\": \"create\", \"effect\": \"allow\" }, { \"entityReference\": \"role:default/team_lead\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 3. To ensure team leads can only manage what they own, use the IS_OWNER\
    \ conditional rule as follows: ```bash curl -X POST 'http://localhost:7007/api/permission/roles/conditions'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"result\": \"CONDITIONAL\", \"pluginId\": \"\
    permission\", \"resourceType\": \"policy-entity\", \"conditions\": { \"rule\"\
    : \"IS_OWNER\", \"resourceType\": \"policy-entity\", \"params\": { \"owners\"\
    : [ \"user:default/team_lead\" ] } }, \"roleEntityRef\": \"role:default/team_lead\"\
    , \"permissionMapping\": [ \"read\", \"update\", \"delete\" ] }' ``` The previous\
    \ example of conditional policy limits visibility and control to only owned roles\
    \ and policies. 4. Log in to RHDH as team lead and verify the following: 1. Use\
    \ the following request and verify that you do not see any roles: Example curl\
    \ to retrieve roles visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` 2. Use the following\
    \ request to create a new role for their team: Example curl of team lead creating\
    \ a new role for their team with ownership assigned ```bash curl -X POST 'http://localhost:7007/api/permission/roles'\
    \ \\ --header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '{ \"memberReferences\": [\"user:default/team_member\"\
    ], \"name\": \"role:default/team_a\", \"metadata\": { \"description\": \"This\
    \ is an example team_a role\", \"owner\": \"user:default/team_lead\" } }' ```\
    \ [NOTE] ---- You can set the ownership during creation, but you can also update\
    \ the ownership at any time. ---- 3. Use the following request to assign a permission\
    \ policy to the new role: Example curl for granting read access to catalog entities\
    \ for the new role ```bash curl -X POST 'http://localhost:7007/api/permission/policies'\
    \ \\ --header \"Authorization: Bearer $ADMIN_TOKEN\" \\ --header \"Content-Type:\
    \ application/json\" \\ --data '[ { \"entityReference\": \"role:default/team_a\"\
    , \"permission\": \"catalog-entity\", \"policy\": \"read\", \"effect\": \"allow\"\
    \ } ]' ``` 4. Use the following request to verify that only team-owned roles and\
    \ policies are visible: Example curl to retrieve roles and permission policies\
    \ visible to the team lead ```bash curl X GET 'http://localhost:7007/api/permission/roles'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" curl X GET 'http://localhost:7007/api/permission/policies'\
    \ \\ header \"Authorization: Bearer $TEAM_LEAD_TOKEN\" ``` Log in as a team lead\
    \ and verify the following: The RBAC UI is accessible. Only the assigned users\
    \ or group is visible. Permissions outside the scoped team are not viewable or\
    \ editable. Log in as an administrator and verify that you retain full visibility\
    \ and control. # Permission policies reference Permission policies in Red Hat\
    \ Developer Hub are a set of rules to govern access to resources or functionalities.\
    \ These policies state the authorization level that is granted to users based\
    \ on their roles. The permission policies are implemented to maintain security\
    \ and confidentiality within a given environment. You can define the following\
    \ types of permissions in Developer Hub: resource type basic The distinction between\
    \ the two permission types depends on whether a permission includes a defined\
    \ resource"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:16:54.840121'
    uuid: 8cfacd8b-1564-4fbb-83f6-42fd9d6868d9
  response: In Red Hat Developer Hub, you can delegate RBAC access using the multitenancy
    feature of the RBAC plugin through two methods, depending on your preferred workflow
    and level of automation. You can either use the web UI to create roles, assign
    users or groups, define permissions, and apply ownership conditions through an
    intuitive interface, or you can use the RBAC backend API for a more flexible and
    automatable approach to programmatically manage these settings using authenticated
    curl requests.
  user_input: What methods does the RBAC plugin offer for delegating access controls
    in Red Hat Developer Hub?
- context:
  - "type. You can define the resource type permission using either the associated\
    \ resource type or the permission name as shown in the following example: ```csv\
    \ p, role:default/myrole, catalog.entity.read, read, allow g, user:default/myuser,\
    \ role:default/myrole p, role:default/another role, catalog entity, read, allow\
    \ g, user:default/another user, role:default/another role ``` You can define the\
    \ basic permission in Developer Hub using the permission name as shown in the\
    \ following example: ```csv p, role:default/myrole, catalog.entity.create, create,\
    \ allow g, user:default/myuser, role:default/myrole ``` Developer Hub supports\
    \ following permission policies: Catalog permissions:: Bulk import permission::\
    \ Scaffolder permissions:: RBAC permissions:: Kubernetes permissions:: OCM permissions::\
    \ Basic OCM permissions only restrict access to the cluster view, but they do\
    \ not prevent access to the Kubernetes clusters in the resource view. For more\
    \ effective permissions, consider applying a conditional policy to restrict access\
    \ to catalog entities that are of type kubernetes-cluster. Access restriction\
    \ is dependent on the set of permissions granted to a role. For example, if the\
    \ role had full permissions (read, update, and delete), then you must specify\
    \ all its permissions in the permissionMapping field. ```csv result: CONDITIONAL\
    \ roleEntityRef: 'role:default/<YOUR_ROLE>' pluginId: catalog resourceType: catalog\
    \ entity permissionMapping: read update delete conditions: not: rule: HAS_SPEC\
    \ resourceType: catalog entity params: key: type value: kubernetes cluster ```\
    \ Topology permissions:: Tekton permissions:: ArgoCD permissions:: Quay permissions::\
    \ # Conditional policies in Red Hat Developer Hub The permission framework in\
    \ Red Hat Developer Hub provides conditions, supported by the RBAC backend plugin\
    \ (backstage-plugin-rbac-backend). The conditions work as content filters for\
    \ the Developer Hub resources that are provided by the RBAC backend plugin. The\
    \ RBAC backend API stores conditions assigned to roles in the database. When you\
    \ request to access the frontend resources, the RBAC backend API searches for\
    \ the corresponding conditions and delegates them to the appropriate plugin using\
    \ its plugin ID. If you are assigned to multiple roles with different conditions,\
    \ then the RBAC backend merges the conditions using the anyOf criteria. Conditional\
    \ criteria:: A condition in Developer Hub is a simple condition with a rule and\
    \ parameters. However, a condition can also contain a parameter or an array of\
    \ parameters combined by conditional criteria. The supported conditional criteria\
    \ includes: * allOf: Ensures that all conditions within the array must be true\
    \ for the combined condition to be satisfied. * anyOf: Ensures that at least one\
    \ of the conditions within the array must be true for the combined condition to\
    \ be satisfied. * not: Ensures that the condition within it must not be true for\
    \ the combined condition to be satisfied. Conditional object:: The plugin specifies\
    \ the parameters supported for conditions. You can access the conditional object\
    \ schema from the RBAC API endpoint to understand how to construct a conditional\
    \ JSON object, which is then used by the RBAC backend plugin API. A conditional\
    \ object contains the following parameters: Conditional policy aliases:: The RBAC\
    \ backend plugin (backstage-plugin-rbac-backend) supports the use of aliases in\
    \ conditional policy rule parameters. The conditional policy aliases are dynamically\
    \ replaced with the corresponding values during policy evaluation. Each alias\
    \ in conditional policy is prefixed with a $ sign indicating its special function.\
    \ The supported conditional aliases include: * $currentUser: This alias is replaced\
    \ with the user entity reference for the user who requests access to the resource.\
    \ For example, if user Tom from the default namespace requests access, $currentUser\
    \ becomes user:default/tom. Example conditional policy object with $currentUser\
    \ alias: ```json { \"result\": \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\"\
    , \"pluginId\": \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\"\
    : [\"delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\"\
    : \"catalog entity\", \"params\": { \"claims\": [\"$currentUser\"] } } } ``` $ownerRefs:\
    \ This alias is replaced with ownership references, usually as an array that includes\
    \ the user entity reference and the user's parent group entity reference. For\
    \ example, for user Tom from team a, $ownerRefs becomes ['user:default/tom', 'group:default/team\
    \ a']. Example conditional policy object with $ownerRefs alias: ```json { \"result\"\
    : \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\", \"pluginId\"\
    : \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\": [\"\
    delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\":\
    \ \"catalog entity\", \"params\": { \"claims\": [\"$ownerRefs\"] } } } ``` ##\
    \ Enabling transitive parent groups By default, Red Hat Developer Hub does not\
    \ resolve indirect parent groups during authentication. In this case, with the\
    \ following group hierarchy, the user_alice user is only a member of the group_developers\
    \ group: ``` group_admin \u2514\u2500\u2500 group_developers \u2514\u2500\u2500\
    \ user_alice ``` To support multi-level group hierarchies when using the $ownerRefs\
    \ alias, you can configure Developer Hub to include indirect parent groups in\
    \ the user\u2019s ownership entities. In that case the user_alice user is a member\
    \ of both group_developers and group_admin groups. Enable the includeTransitiveGroupOwnership\
    \ option in your app config.yaml file. ```yaml includeTransitiveGroupOwnership:\
    \ true ``` ## Conditional policies reference You can access API endpoints for\
    \ conditional policies in Red Hat Developer Hub. For example, to retrieve the\
    \ available conditional rules, which can help you define these policies, you can\
    \ access the GET [api/plugins/condition-rules] endpoint. The api/plugins/condition-rules\
    \ returns the condition parameters schemas, for example: ```json [ { \"pluginId\"\
    : \"catalog\", \"rules\": [ { \"name\": \"HAS_ANNOTATION\", \"description\": \"\
    Allow entities with the specified annotation\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"annotation\":\
    \ { \"type\": \"string\", \"description\": \"Name of the annotation to match on\"\
    \ }, \"value\": { \"type\": \"string\", \"description\": \"Value of the annotation\
    \ to match on\" } }, \"required\": [ \"annotation\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_LABEL\", \"description\": \"Allow entities with the specified label\"\
    , \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\": \"object\"\
    , \"properties\": { \"label\": { \"type\": \"string\", \"description\": \"Name\
    \ of the label to match on\" } }, \"required\": [ \"label\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_METADATA\", \"description\": \"Allow entities with the specified metadata\
    \ subfield\", \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\"\
    : \"object\", \"properties\": { \"key\": { \"type\": \"string\", \"description\"\
    : \"Property within the entities metadata to match on\" }, \"value\": { \"type\"\
    : \"string\", \"description\": \"Value of the given property to match on\" } },\
    \ \"required\": [ \"key\" ], \"additionalProperties\": false, \"$schema\": \"\
    http://json-schema.org/draft-07/schema#\" } }, { \"name\": \"HAS_SPEC\", \"description\"\
    : \"Allow entities with the specified spec subfield\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"key\": { \"type\"\
    : \"string\", \"description\": \"Property within the entities spec to match on\"\
    \ }, \"value\": { \"type\":"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:17:05.221452'
    uuid: 2c0150c5-d606-4deb-b40b-de178d7de23c
  response: For more effective permissions, you should apply a conditional policy
    to restrict access to catalog entities that are of type kubernetes-cluster. This
    is recommended because Basic OCM permissions only restrict access to the cluster
    view and do not prevent access to the Kubernetes clusters in the resource view.
    An example conditional policy uses a "not" condition with the "HAS_SPEC" rule,
    targeting a resource type of "catalog entity" with parameters where the "key"
    is "type" and the "value" is "kubernetes cluster".
  user_input: How can I implement more effective permissions for Kubernetes clusters
    in Developer Hub?
- context:
  - "type. You can define the resource type permission using either the associated\
    \ resource type or the permission name as shown in the following example: ```csv\
    \ p, role:default/myrole, catalog.entity.read, read, allow g, user:default/myuser,\
    \ role:default/myrole p, role:default/another role, catalog entity, read, allow\
    \ g, user:default/another user, role:default/another role ``` You can define the\
    \ basic permission in Developer Hub using the permission name as shown in the\
    \ following example: ```csv p, role:default/myrole, catalog.entity.create, create,\
    \ allow g, user:default/myuser, role:default/myrole ``` Developer Hub supports\
    \ following permission policies: Catalog permissions:: Bulk import permission::\
    \ Scaffolder permissions:: RBAC permissions:: Kubernetes permissions:: OCM permissions::\
    \ Basic OCM permissions only restrict access to the cluster view, but they do\
    \ not prevent access to the Kubernetes clusters in the resource view. For more\
    \ effective permissions, consider applying a conditional policy to restrict access\
    \ to catalog entities that are of type kubernetes-cluster. Access restriction\
    \ is dependent on the set of permissions granted to a role. For example, if the\
    \ role had full permissions (read, update, and delete), then you must specify\
    \ all its permissions in the permissionMapping field. ```csv result: CONDITIONAL\
    \ roleEntityRef: 'role:default/<YOUR_ROLE>' pluginId: catalog resourceType: catalog\
    \ entity permissionMapping: read update delete conditions: not: rule: HAS_SPEC\
    \ resourceType: catalog entity params: key: type value: kubernetes cluster ```\
    \ Topology permissions:: Tekton permissions:: ArgoCD permissions:: Quay permissions::\
    \ # Conditional policies in Red Hat Developer Hub The permission framework in\
    \ Red Hat Developer Hub provides conditions, supported by the RBAC backend plugin\
    \ (backstage-plugin-rbac-backend). The conditions work as content filters for\
    \ the Developer Hub resources that are provided by the RBAC backend plugin. The\
    \ RBAC backend API stores conditions assigned to roles in the database. When you\
    \ request to access the frontend resources, the RBAC backend API searches for\
    \ the corresponding conditions and delegates them to the appropriate plugin using\
    \ its plugin ID. If you are assigned to multiple roles with different conditions,\
    \ then the RBAC backend merges the conditions using the anyOf criteria. Conditional\
    \ criteria:: A condition in Developer Hub is a simple condition with a rule and\
    \ parameters. However, a condition can also contain a parameter or an array of\
    \ parameters combined by conditional criteria. The supported conditional criteria\
    \ includes: * allOf: Ensures that all conditions within the array must be true\
    \ for the combined condition to be satisfied. * anyOf: Ensures that at least one\
    \ of the conditions within the array must be true for the combined condition to\
    \ be satisfied. * not: Ensures that the condition within it must not be true for\
    \ the combined condition to be satisfied. Conditional object:: The plugin specifies\
    \ the parameters supported for conditions. You can access the conditional object\
    \ schema from the RBAC API endpoint to understand how to construct a conditional\
    \ JSON object, which is then used by the RBAC backend plugin API. A conditional\
    \ object contains the following parameters: Conditional policy aliases:: The RBAC\
    \ backend plugin (backstage-plugin-rbac-backend) supports the use of aliases in\
    \ conditional policy rule parameters. The conditional policy aliases are dynamically\
    \ replaced with the corresponding values during policy evaluation. Each alias\
    \ in conditional policy is prefixed with a $ sign indicating its special function.\
    \ The supported conditional aliases include: * $currentUser: This alias is replaced\
    \ with the user entity reference for the user who requests access to the resource.\
    \ For example, if user Tom from the default namespace requests access, $currentUser\
    \ becomes user:default/tom. Example conditional policy object with $currentUser\
    \ alias: ```json { \"result\": \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\"\
    , \"pluginId\": \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\"\
    : [\"delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\"\
    : \"catalog entity\", \"params\": { \"claims\": [\"$currentUser\"] } } } ``` $ownerRefs:\
    \ This alias is replaced with ownership references, usually as an array that includes\
    \ the user entity reference and the user's parent group entity reference. For\
    \ example, for user Tom from team a, $ownerRefs becomes ['user:default/tom', 'group:default/team\
    \ a']. Example conditional policy object with $ownerRefs alias: ```json { \"result\"\
    : \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\", \"pluginId\"\
    : \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\": [\"\
    delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\":\
    \ \"catalog entity\", \"params\": { \"claims\": [\"$ownerRefs\"] } } } ``` ##\
    \ Enabling transitive parent groups By default, Red Hat Developer Hub does not\
    \ resolve indirect parent groups during authentication. In this case, with the\
    \ following group hierarchy, the user_alice user is only a member of the group_developers\
    \ group: ``` group_admin \u2514\u2500\u2500 group_developers \u2514\u2500\u2500\
    \ user_alice ``` To support multi-level group hierarchies when using the $ownerRefs\
    \ alias, you can configure Developer Hub to include indirect parent groups in\
    \ the user\u2019s ownership entities. In that case the user_alice user is a member\
    \ of both group_developers and group_admin groups. Enable the includeTransitiveGroupOwnership\
    \ option in your app config.yaml file. ```yaml includeTransitiveGroupOwnership:\
    \ true ``` ## Conditional policies reference You can access API endpoints for\
    \ conditional policies in Red Hat Developer Hub. For example, to retrieve the\
    \ available conditional rules, which can help you define these policies, you can\
    \ access the GET [api/plugins/condition-rules] endpoint. The api/plugins/condition-rules\
    \ returns the condition parameters schemas, for example: ```json [ { \"pluginId\"\
    : \"catalog\", \"rules\": [ { \"name\": \"HAS_ANNOTATION\", \"description\": \"\
    Allow entities with the specified annotation\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"annotation\":\
    \ { \"type\": \"string\", \"description\": \"Name of the annotation to match on\"\
    \ }, \"value\": { \"type\": \"string\", \"description\": \"Value of the annotation\
    \ to match on\" } }, \"required\": [ \"annotation\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_LABEL\", \"description\": \"Allow entities with the specified label\"\
    , \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\": \"object\"\
    , \"properties\": { \"label\": { \"type\": \"string\", \"description\": \"Name\
    \ of the label to match on\" } }, \"required\": [ \"label\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_METADATA\", \"description\": \"Allow entities with the specified metadata\
    \ subfield\", \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\"\
    : \"object\", \"properties\": { \"key\": { \"type\": \"string\", \"description\"\
    : \"Property within the entities metadata to match on\" }, \"value\": { \"type\"\
    : \"string\", \"description\": \"Value of the given property to match on\" } },\
    \ \"required\": [ \"key\" ], \"additionalProperties\": false, \"$schema\": \"\
    http://json-schema.org/draft-07/schema#\" } }, { \"name\": \"HAS_SPEC\", \"description\"\
    : \"Allow entities with the specified spec subfield\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"key\": { \"type\"\
    : \"string\", \"description\": \"Property within the entities spec to match on\"\
    \ }, \"value\": { \"type\":"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:17:15.052179'
    uuid: 6ef1901e-b8c7-4e3b-8c00-10df2644dab3
  response: 'Basic OCM permissions only restrict access to the cluster view and do
    not prevent access to the Kubernetes clusters in the resource view. For more effective
    permissions, you should apply a conditional policy to restrict access to catalog
    entities that are of type ''kubernetes-cluster''. The effectiveness of this restriction
    depends on the permissions granted to a role. For example, if a role has full
    permissions (read, update, and delete), you must specify all of its permissions
    in the permissionMapping field. An example of such a conditional policy is: ```csv

    result: CONDITIONAL

    roleEntityRef: ''role:default/<YOUR_ROLE>''

    pluginId: catalog

    resourceType: catalog entity

    permissionMapping:

    read

    update

    delete

    conditions:

    not:

    rule: HAS_SPEC

    resourceType: catalog entity

    params:

    key: type

    value: kubernetes cluster

    ```'
  user_input: How do I implement more effective OCM permissions in Developer Hub since
    the basic ones don't prevent access to Kubernetes clusters in the resource view?
- context:
  - "type. You can define the resource type permission using either the associated\
    \ resource type or the permission name as shown in the following example: ```csv\
    \ p, role:default/myrole, catalog.entity.read, read, allow g, user:default/myuser,\
    \ role:default/myrole p, role:default/another role, catalog entity, read, allow\
    \ g, user:default/another user, role:default/another role ``` You can define the\
    \ basic permission in Developer Hub using the permission name as shown in the\
    \ following example: ```csv p, role:default/myrole, catalog.entity.create, create,\
    \ allow g, user:default/myuser, role:default/myrole ``` Developer Hub supports\
    \ following permission policies: Catalog permissions:: Bulk import permission::\
    \ Scaffolder permissions:: RBAC permissions:: Kubernetes permissions:: OCM permissions::\
    \ Basic OCM permissions only restrict access to the cluster view, but they do\
    \ not prevent access to the Kubernetes clusters in the resource view. For more\
    \ effective permissions, consider applying a conditional policy to restrict access\
    \ to catalog entities that are of type kubernetes-cluster. Access restriction\
    \ is dependent on the set of permissions granted to a role. For example, if the\
    \ role had full permissions (read, update, and delete), then you must specify\
    \ all its permissions in the permissionMapping field. ```csv result: CONDITIONAL\
    \ roleEntityRef: 'role:default/<YOUR_ROLE>' pluginId: catalog resourceType: catalog\
    \ entity permissionMapping: read update delete conditions: not: rule: HAS_SPEC\
    \ resourceType: catalog entity params: key: type value: kubernetes cluster ```\
    \ Topology permissions:: Tekton permissions:: ArgoCD permissions:: Quay permissions::\
    \ # Conditional policies in Red Hat Developer Hub The permission framework in\
    \ Red Hat Developer Hub provides conditions, supported by the RBAC backend plugin\
    \ (backstage-plugin-rbac-backend). The conditions work as content filters for\
    \ the Developer Hub resources that are provided by the RBAC backend plugin. The\
    \ RBAC backend API stores conditions assigned to roles in the database. When you\
    \ request to access the frontend resources, the RBAC backend API searches for\
    \ the corresponding conditions and delegates them to the appropriate plugin using\
    \ its plugin ID. If you are assigned to multiple roles with different conditions,\
    \ then the RBAC backend merges the conditions using the anyOf criteria. Conditional\
    \ criteria:: A condition in Developer Hub is a simple condition with a rule and\
    \ parameters. However, a condition can also contain a parameter or an array of\
    \ parameters combined by conditional criteria. The supported conditional criteria\
    \ includes: * allOf: Ensures that all conditions within the array must be true\
    \ for the combined condition to be satisfied. * anyOf: Ensures that at least one\
    \ of the conditions within the array must be true for the combined condition to\
    \ be satisfied. * not: Ensures that the condition within it must not be true for\
    \ the combined condition to be satisfied. Conditional object:: The plugin specifies\
    \ the parameters supported for conditions. You can access the conditional object\
    \ schema from the RBAC API endpoint to understand how to construct a conditional\
    \ JSON object, which is then used by the RBAC backend plugin API. A conditional\
    \ object contains the following parameters: Conditional policy aliases:: The RBAC\
    \ backend plugin (backstage-plugin-rbac-backend) supports the use of aliases in\
    \ conditional policy rule parameters. The conditional policy aliases are dynamically\
    \ replaced with the corresponding values during policy evaluation. Each alias\
    \ in conditional policy is prefixed with a $ sign indicating its special function.\
    \ The supported conditional aliases include: * $currentUser: This alias is replaced\
    \ with the user entity reference for the user who requests access to the resource.\
    \ For example, if user Tom from the default namespace requests access, $currentUser\
    \ becomes user:default/tom. Example conditional policy object with $currentUser\
    \ alias: ```json { \"result\": \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\"\
    , \"pluginId\": \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\"\
    : [\"delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\"\
    : \"catalog entity\", \"params\": { \"claims\": [\"$currentUser\"] } } } ``` $ownerRefs:\
    \ This alias is replaced with ownership references, usually as an array that includes\
    \ the user entity reference and the user's parent group entity reference. For\
    \ example, for user Tom from team a, $ownerRefs becomes ['user:default/tom', 'group:default/team\
    \ a']. Example conditional policy object with $ownerRefs alias: ```json { \"result\"\
    : \"CONDITIONAL\", \"roleEntityRef\": \"role:default/developer\", \"pluginId\"\
    : \"catalog\", \"resourceType\": \"catalog entity\", \"permissionMapping\": [\"\
    delete\"], \"conditions\": { \"rule\": \"IS_ENTITY_OWNER\", \"resourceType\":\
    \ \"catalog entity\", \"params\": { \"claims\": [\"$ownerRefs\"] } } } ``` ##\
    \ Enabling transitive parent groups By default, Red Hat Developer Hub does not\
    \ resolve indirect parent groups during authentication. In this case, with the\
    \ following group hierarchy, the user_alice user is only a member of the group_developers\
    \ group: ``` group_admin \u2514\u2500\u2500 group_developers \u2514\u2500\u2500\
    \ user_alice ``` To support multi-level group hierarchies when using the $ownerRefs\
    \ alias, you can configure Developer Hub to include indirect parent groups in\
    \ the user\u2019s ownership entities. In that case the user_alice user is a member\
    \ of both group_developers and group_admin groups. Enable the includeTransitiveGroupOwnership\
    \ option in your app config.yaml file. ```yaml includeTransitiveGroupOwnership:\
    \ true ``` ## Conditional policies reference You can access API endpoints for\
    \ conditional policies in Red Hat Developer Hub. For example, to retrieve the\
    \ available conditional rules, which can help you define these policies, you can\
    \ access the GET [api/plugins/condition-rules] endpoint. The api/plugins/condition-rules\
    \ returns the condition parameters schemas, for example: ```json [ { \"pluginId\"\
    : \"catalog\", \"rules\": [ { \"name\": \"HAS_ANNOTATION\", \"description\": \"\
    Allow entities with the specified annotation\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"annotation\":\
    \ { \"type\": \"string\", \"description\": \"Name of the annotation to match on\"\
    \ }, \"value\": { \"type\": \"string\", \"description\": \"Value of the annotation\
    \ to match on\" } }, \"required\": [ \"annotation\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_LABEL\", \"description\": \"Allow entities with the specified label\"\
    , \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\": \"object\"\
    , \"properties\": { \"label\": { \"type\": \"string\", \"description\": \"Name\
    \ of the label to match on\" } }, \"required\": [ \"label\" ], \"additionalProperties\"\
    : false, \"$schema\": \"http://json-schema.org/draft-07/schema#\" } }, { \"name\"\
    : \"HAS_METADATA\", \"description\": \"Allow entities with the specified metadata\
    \ subfield\", \"resourceType\": \"catalog-entity\", \"paramsSchema\": { \"type\"\
    : \"object\", \"properties\": { \"key\": { \"type\": \"string\", \"description\"\
    : \"Property within the entities metadata to match on\" }, \"value\": { \"type\"\
    : \"string\", \"description\": \"Value of the given property to match on\" } },\
    \ \"required\": [ \"key\" ], \"additionalProperties\": false, \"$schema\": \"\
    http://json-schema.org/draft-07/schema#\" } }, { \"name\": \"HAS_SPEC\", \"description\"\
    : \"Allow entities with the specified spec subfield\", \"resourceType\": \"catalog-entity\"\
    , \"paramsSchema\": { \"type\": \"object\", \"properties\": { \"key\": { \"type\"\
    : \"string\", \"description\": \"Property within the entities spec to match on\"\
    \ }, \"value\": { \"type\":"
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:17:22.421872'
    uuid: 4d4d20fe-1ac8-404a-bb63-de15a437aba0
  response: Developer Hub supports ArgoCD permissions as one of its permission policies.
  user_input: I'm trying to figure out all the permissions for my devs and I see a
    bunch of policies supported by Developer Hub, like for Kubernetes and Scaffolder
    and stuff, but what about ArgoCD permissions, what kind of permission policies
    are supported for that specifically?
- context:
  - '"string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` The RBAC backend API constructs a condition
    JSON object based on the previous condition schema. ### Examples of conditional
    policies In Red Hat Developer Hub, you can define conditional policies with or
    without criteria. You can use the following examples to define the conditions
    based on your use case: A condition without criteria:: Consider a condition without
    criteria displaying catalogs only if user is a member of the owner group. To add
    this condition, you can use the catalog plugin schema IS_ENTITY_OWNER as follows:
    ```json { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params":
    { "claims": ["group:default/team a"] } } ``` In the previous example, the only
    conditional parameter used is claims, which contains a list of user or group entity
    references. You can apply the previous example condition to the RBAC REST API
    by adding additional parameters as follows: ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } } } ``` A condition
    with criteria:: Consider a condition with criteria, which displays catalogs only
    if user is a member of owner group OR displays list of all catalog user groups.
    To add the criteria, you can add another rule as IS_ENTITY_KIND in the condition
    as follows: ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog entity", "params": { "claims": ["group:default/team a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds": ["Group"]
    } } ] } ``` [NOTE] ---- Running conditions in parallel during creation is not
    supported. Therefore, consider defining nested conditional policies based on the
    available criteria. ---- ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": { "kinds": ["Group"]
    } } ], "not": { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params":
    { "kinds": ["Api"] } } } ``` You can apply the previous example condition to the
    RBAC REST API by adding additional parameters as follows: ```json { "result":
    "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType":
    "catalog entity", "permissionMapping": ["read"], "conditions": { "anyOf": [ {
    "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params": { "claims":
    ["group:default/team a"] } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog
    entity", "params": { "kinds": ["Group"] } } ] } } ``` The following examples can
    be used with Developer Hub plugins. These examples can help you determine how
    to define conditional policies: ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/developer", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["update", "delete"], "conditions": { "not": { "rule": "HAS_ANNOTATION",
    "resourceType": "catalog-entity", "params": { "annotation": "keycloak.org/realm",
    "value": "<YOUR_REALM>" } } } } ``` The previous example of Keycloak plugin prevents
    users in the role:default/developer from updating or deleting users that are ingested
    into the catalog from the Keycloak plugin. [NOTE] ---- In the previous example,
    the annotation keycloak.org/realm requires the value of <YOUR_REALM>. ---- ```json
    { "result": "CONDITIONAL", "roleEntityRef": "role:default/developer", "pluginId":
    "scaffolder", "resourceType": "scaffolder action", "permissionMapping": ["use"],
    "conditions": { "not": { "rule": "HAS_ACTION_ID", "resourceType": "scaffolder
    action", "params": { "actionId": "quay:create repository" } } } } ``` The previous
    example of Quay plugin prevents the role role:default/developer from using the
    Quay scaffolder action. Note that permissionMapping contains use, signifying that
    scaffolder-action resource type permission does not have a permission policy.
    # User statistics in Red Hat Developer Hub In Red Hat Developer Hub, the licensed-users-info-backend
    plugin provides statistical information about the logged-in users using the Web
    UI or REST API endpoints. The licensed-users-info-backend plugin enables administrators
    to monitor the number of active users on Developer Hub. Using this feature, organizations
    can compare their actual usage with the number of licenses they have purchased.
    Additionally, you can share the user metrics with Red Hat for transparency and
    accurate licensing. The licensed-users-info-backend plugin is enabled by default.
    This plugin enables a Download User List link at the bottom of the Administration
    -> RBAC tab. ## Downloading active users list in Red Hat Developer Hub You can
    download the list of users in CSV format using the Developer Hub web interface.
    RBAC plugins (@backstage community/plugin rbac and @backstage community/plugin
    rbac backend) must be enabled in Red Hat Developer Hub. An administrator role
    must be assigned. 1. In Red Hat Developer Hub, navigate to Administration and
    select the RBAC tab. 2. At the bottom of the RBAC page, click Download User List.
    3. Optional: Modify the file name in the Save as field and click Save. 4. To access
    the downloaded users list, go to the Downloads folder on your local machine and
    open the CSV file.'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:17:32.047178'
    uuid: 3b981675-2ff1-4f64-9669-f23d3d5b83b7
  response: 'The IS_ENTITY_OWNER condition is used to "Allow entities owned by a specified
    claim" and its resourceType is "catalog-entity". The paramsSchema for this rule
    requires a "claims" property, which is an array of strings described as a "List
    of claims to match at least one on within ownedBy". The claims parameter contains
    a list of user or group entity references. An example of this condition is as
    follows: { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params":
    { "claims": ["group:default/team a"] } }.'
  user_input: I am looking at the RBAC conditions for my developer platform and I
    need to understand how the IS_ENTITY_OWNER rule is working, what are the params
    for it to allow entities owned by a specified claim and can you show me a json
    example of how to use it?
- context:
  - '"string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` The RBAC backend API constructs a condition
    JSON object based on the previous condition schema. ### Examples of conditional
    policies In Red Hat Developer Hub, you can define conditional policies with or
    without criteria. You can use the following examples to define the conditions
    based on your use case: A condition without criteria:: Consider a condition without
    criteria displaying catalogs only if user is a member of the owner group. To add
    this condition, you can use the catalog plugin schema IS_ENTITY_OWNER as follows:
    ```json { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params":
    { "claims": ["group:default/team a"] } } ``` In the previous example, the only
    conditional parameter used is claims, which contains a list of user or group entity
    references. You can apply the previous example condition to the RBAC REST API
    by adding additional parameters as follows: ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } } } ``` A condition
    with criteria:: Consider a condition with criteria, which displays catalogs only
    if user is a member of owner group OR displays list of all catalog user groups.
    To add the criteria, you can add another rule as IS_ENTITY_KIND in the condition
    as follows: ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog entity", "params": { "claims": ["group:default/team a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds": ["Group"]
    } } ] } ``` [NOTE] ---- Running conditions in parallel during creation is not
    supported. Therefore, consider defining nested conditional policies based on the
    available criteria. ---- ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": { "kinds": ["Group"]
    } } ], "not": { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params":
    { "kinds": ["Api"] } } } ``` You can apply the previous example condition to the
    RBAC REST API by adding additional parameters as follows: ```json { "result":
    "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType":
    "catalog entity", "permissionMapping": ["read"], "conditions": { "anyOf": [ {
    "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params": { "claims":
    ["group:default/team a"] } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog
    entity", "params": { "kinds": ["Group"] } } ] } } ``` The following examples can
    be used with Developer Hub plugins. These examples can help you determine how
    to define conditional policies: ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/developer", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["update", "delete"], "conditions": { "not": { "rule": "HAS_ANNOTATION",
    "resourceType": "catalog-entity", "params": { "annotation": "keycloak.org/realm",
    "value": "<YOUR_REALM>" } } } } ``` The previous example of Keycloak plugin prevents
    users in the role:default/developer from updating or deleting users that are ingested
    into the catalog from the Keycloak plugin. [NOTE] ---- In the previous example,
    the annotation keycloak.org/realm requires the value of <YOUR_REALM>. ---- ```json
    { "result": "CONDITIONAL", "roleEntityRef": "role:default/developer", "pluginId":
    "scaffolder", "resourceType": "scaffolder action", "permissionMapping": ["use"],
    "conditions": { "not": { "rule": "HAS_ACTION_ID", "resourceType": "scaffolder
    action", "params": { "actionId": "quay:create repository" } } } } ``` The previous
    example of Quay plugin prevents the role role:default/developer from using the
    Quay scaffolder action. Note that permissionMapping contains use, signifying that
    scaffolder-action resource type permission does not have a permission policy.
    # User statistics in Red Hat Developer Hub In Red Hat Developer Hub, the licensed-users-info-backend
    plugin provides statistical information about the logged-in users using the Web
    UI or REST API endpoints. The licensed-users-info-backend plugin enables administrators
    to monitor the number of active users on Developer Hub. Using this feature, organizations
    can compare their actual usage with the number of licenses they have purchased.
    Additionally, you can share the user metrics with Red Hat for transparency and
    accurate licensing. The licensed-users-info-backend plugin is enabled by default.
    This plugin enables a Download User List link at the bottom of the Administration
    -> RBAC tab. ## Downloading active users list in Red Hat Developer Hub You can
    download the list of users in CSV format using the Developer Hub web interface.
    RBAC plugins (@backstage community/plugin rbac and @backstage community/plugin
    rbac backend) must be enabled in Red Hat Developer Hub. An administrator role
    must be assigned. 1. In Red Hat Developer Hub, navigate to Administration and
    select the RBAC tab. 2. At the bottom of the RBAC page, click Download User List.
    3. Optional: Modify the file name in the Save as field and click Save. 4. To access
    the downloaded users list, go to the Downloads folder on your local machine and
    open the CSV file.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:17:40.241543'
    uuid: 205841a1-800e-408b-86c4-f71db75c2898
  response: In Red Hat Developer Hub, the licensed-users-info-backend plugin provides
    statistical information about logged-in users through the Web UI or REST API endpoints.
    This plugin enables administrators to monitor the number of active users, which
    allows organizations to compare their usage with the number of licenses they have
    purchased and share these metrics with Red Hat. An administrator can download
    a list of active users in CSV format by navigating to the Administration -> RBAC
    tab and clicking the "Download User List" link at the bottom of the page.
  user_input: As an administrator, what functionality does Red Hat Developer Hub provide
    for monitoring active users and managing licensing?
- context:
  - '"string", "description": "Value of the given property to match on" } }, "required":
    [ "key" ], "additionalProperties": false, "$schema": "http://json-schema.org/draft-07/schema#"
    } }, { "name": "IS_ENTITY_KIND", "description": "Allow entities matching a specified
    kind", "resourceType": "catalog-entity", "paramsSchema": { "type": "object", "properties":
    { "kinds": { "type": "array", "items": { "type": "string" }, "description": "List
    of kinds to match at least one of" } }, "required": [ "kinds" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } }, { "name": "IS_ENTITY_OWNER",
    "description": "Allow entities owned by a specified claim", "resourceType": "catalog-entity",
    "paramsSchema": { "type": "object", "properties": { "claims": { "type": "array",
    "items": { "type": "string" }, "description": "List of claims to match at least
    one on within ownedBy" } }, "required": [ "claims" ], "additionalProperties":
    false, "$schema": "http://json-schema.org/draft-07/schema#" } } ] } ... <another
    plugin condition parameter schemas> ] ``` The RBAC backend API constructs a condition
    JSON object based on the previous condition schema. ### Examples of conditional
    policies In Red Hat Developer Hub, you can define conditional policies with or
    without criteria. You can use the following examples to define the conditions
    based on your use case: A condition without criteria:: Consider a condition without
    criteria displaying catalogs only if user is a member of the owner group. To add
    this condition, you can use the catalog plugin schema IS_ENTITY_OWNER as follows:
    ```json { "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params":
    { "claims": ["group:default/team a"] } } ``` In the previous example, the only
    conditional parameter used is claims, which contains a list of user or group entity
    references. You can apply the previous example condition to the RBAC REST API
    by adding additional parameters as follows: ```json { "result": "CONDITIONAL",
    "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["read"], "conditions": { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } } } ``` A condition
    with criteria:: Consider a condition with criteria, which displays catalogs only
    if user is a member of owner group OR displays list of all catalog user groups.
    To add the criteria, you can add another rule as IS_ENTITY_KIND in the condition
    as follows: ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog entity", "params": { "claims": ["group:default/team a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog entity", "params": { "kinds": ["Group"]
    } } ] } ``` [NOTE] ---- Running conditions in parallel during creation is not
    supported. Therefore, consider defining nested conditional policies based on the
    available criteria. ---- ```json { "anyOf": [ { "rule": "IS_ENTITY_OWNER", "resourceType":
    "catalog-entity", "params": { "claims": ["group:default/team-a"] } }, { "rule":
    "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params": { "kinds": ["Group"]
    } } ], "not": { "rule": "IS_ENTITY_KIND", "resourceType": "catalog-entity", "params":
    { "kinds": ["Api"] } } } ``` You can apply the previous example condition to the
    RBAC REST API by adding additional parameters as follows: ```json { "result":
    "CONDITIONAL", "roleEntityRef": "role:default/test", "pluginId": "catalog", "resourceType":
    "catalog entity", "permissionMapping": ["read"], "conditions": { "anyOf": [ {
    "rule": "IS_ENTITY_OWNER", "resourceType": "catalog entity", "params": { "claims":
    ["group:default/team a"] } }, { "rule": "IS_ENTITY_KIND", "resourceType": "catalog
    entity", "params": { "kinds": ["Group"] } } ] } } ``` The following examples can
    be used with Developer Hub plugins. These examples can help you determine how
    to define conditional policies: ```json { "result": "CONDITIONAL", "roleEntityRef":
    "role:default/developer", "pluginId": "catalog", "resourceType": "catalog-entity",
    "permissionMapping": ["update", "delete"], "conditions": { "not": { "rule": "HAS_ANNOTATION",
    "resourceType": "catalog-entity", "params": { "annotation": "keycloak.org/realm",
    "value": "<YOUR_REALM>" } } } } ``` The previous example of Keycloak plugin prevents
    users in the role:default/developer from updating or deleting users that are ingested
    into the catalog from the Keycloak plugin. [NOTE] ---- In the previous example,
    the annotation keycloak.org/realm requires the value of <YOUR_REALM>. ---- ```json
    { "result": "CONDITIONAL", "roleEntityRef": "role:default/developer", "pluginId":
    "scaffolder", "resourceType": "scaffolder action", "permissionMapping": ["use"],
    "conditions": { "not": { "rule": "HAS_ACTION_ID", "resourceType": "scaffolder
    action", "params": { "actionId": "quay:create repository" } } } } ``` The previous
    example of Quay plugin prevents the role role:default/developer from using the
    Quay scaffolder action. Note that permissionMapping contains use, signifying that
    scaffolder-action resource type permission does not have a permission policy.
    # User statistics in Red Hat Developer Hub In Red Hat Developer Hub, the licensed-users-info-backend
    plugin provides statistical information about the logged-in users using the Web
    UI or REST API endpoints. The licensed-users-info-backend plugin enables administrators
    to monitor the number of active users on Developer Hub. Using this feature, organizations
    can compare their actual usage with the number of licenses they have purchased.
    Additionally, you can share the user metrics with Red Hat for transparency and
    accurate licensing. The licensed-users-info-backend plugin is enabled by default.
    This plugin enables a Download User List link at the bottom of the Administration
    -> RBAC tab. ## Downloading active users list in Red Hat Developer Hub You can
    download the list of users in CSV format using the Developer Hub web interface.
    RBAC plugins (@backstage community/plugin rbac and @backstage community/plugin
    rbac backend) must be enabled in Red Hat Developer Hub. An administrator role
    must be assigned. 1. In Red Hat Developer Hub, navigate to Administration and
    select the RBAC tab. 2. At the bottom of the RBAC page, click Download User List.
    3. Optional: Modify the file name in the Save as field and click Save. 4. To access
    the downloaded users list, go to the Downloads folder on your local machine and
    open the CSV file.'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:17:50.685333'
    uuid: e37311dc-ac2e-44ef-aca4-101e46e4b532
  response: In Red Hat Developer Hub, the licensed-users-info-backend plugin provides
    statistical information about logged-in users, which allows organizations to compare
    their actual usage with the number of licenses they have purchased. To download
    the list of active users in CSV format, you must have an administrator role and
    have the RBAC plugins enabled. In the Developer Hub web interface, navigate to
    Administration and select the RBAC tab. At the bottom of the page, click Download
    User List. You can then save the file, which will be accessible in the Downloads
    folder on your local machine.
  user_input: how i can get the users list from Red Hat for see how many license we
    use?
- context:
  - '# Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service (AKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Microsoft Azure
    Kubernetes Service (AKS) using either the Operator or Helm chart. # Installing
    Developer Hub on Microsoft Azure Kubernetes Service (AKS) by using the Operator
    To benefit from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On AKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Microsoft Azure Kubernetes
    Service (AKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Microsoft Azure Kubernetes Service (AKS):
    The Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> 1. Create the rhdh-operator namespace to contain the
    Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:17:59.612742'
    uuid: 7166d8b6-1184-445f-9640-2216b14f9083
  response: 'To install the Red Hat Developer Hub Operator on Microsoft Azure Kubernetes
    Service (AKS) using the OLM framework, you must have the kubectl CLI installed
    on your local environment, your system must meet the sizing requirements for Red
    Hat Developer Hub, you must have installed the Operator Lifecycle Manager (OLM),
    and you need your credentials for the Red Hat Container Registry. The installation
    steps are as follows: 1. Create the rhdh-operator namespace. 2. Create a pull
    secret using your Red Hat credentials. 3. Create a catalog source containing the
    Red Hat operators. 4. Create an operator group to manage subscriptions. 5. Create
    a subscription to install the Red Hat Developer Hub Operator. 6. Wait until the
    Operator deployment finishes. 7. Include your pull secret name in the Operator
    deployment manifest to avoid ImagePullBackOff errors.'
  user_input: What are the prerequisits and steps for installing the Red Hat Developer
    Hub Opertor on AKS using the OLM framwork?
- context:
  - '# Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service (AKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Microsoft Azure
    Kubernetes Service (AKS) using either the Operator or Helm chart. # Installing
    Developer Hub on Microsoft Azure Kubernetes Service (AKS) by using the Operator
    To benefit from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On AKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Microsoft Azure Kubernetes
    Service (AKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Microsoft Azure Kubernetes Service (AKS):
    The Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> 1. Create the rhdh-operator namespace to contain the
    Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:18:08.836527'
    uuid: e850511d-0315-4b03-945f-c5a627df3c72
  response: To install Red Hat Developer Hub using its Operator on Microsoft Azure
    Kubernetes Service (AKS), the Operator Lifecycle Manager (OLM) framework is necessary
    to benefit from over-the-air updates and catalogs. The Red Hat Container Registry,
    which contains the distribution of the Red Hat Developer Hub Operator, is based
    on the OLM framework. Unlike OpenShift-based installations, the OLM framework
    is not built into AKS and therefore must be installed as a prerequisite.
  user_input: Since AKS doesn't have it built-in, what's the main reason we need the
    Operater Lifecyle Manager (OLM) for our Red Hat Developer Hub installation?
- context:
  - '# Installing Red Hat Developer Hub on Microsoft Azure Kubernetes Service (AKS)
    Red Hat Developer Hub (RHDH) is an enterprise-grade platform for building developer
    portals. Administrative users can configure roles, permissions, and other settings
    to enable other authorized users to deploy a RHDH instance on Microsoft Azure
    Kubernetes Service (AKS) using either the Operator or Helm chart. # Installing
    Developer Hub on Microsoft Azure Kubernetes Service (AKS) by using the Operator
    To benefit from over-the-air updates and catalogs provided by Operator-based applications
    distributed with the Operator Lifecycle Manager (OLM) framework, consider installing
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator distributed
    in the Red Hat Container Registry. On AKS, the most notable differences over an
    OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes. For clarity,
    the content is broken down in sections highlighting these platform-specific additional
    steps. ## Installing the Developer Hub Operator on Microsoft Azure Kubernetes
    Service (AKS) by using the OLM framework The Red Hat Container Registry (registry.redhat.io),
    based on the Operator Lifecycle Manager (OLM) framework, contains a distribution
    of the Red Hat Developer Hub Operator, aimed at managing your Red Hat Developer
    Hub instance lifecycle. However, on Microsoft Azure Kubernetes Service (AKS):
    The Operator Lifecycle Manager (OLM) framework and the Red Hat Container Registry
    are not built in. The Red Hat Container Registry pull secret is not managed globally.
    Therefore, install the OLM framework, the Red Hat Container Registry, and provision
    your Red Hat Container Registry pull secret to install Developer Hub Operator.
    You have installed the kubectl CLI on your local environment. Your system meets
    the sizing requirements for Red Hat Developer Hub. You have installed the Operator
    Lifecycle Manager (OLM). Your credentials to the Red Hat Container Registry: <redhat_user_name>
    <redhat_password> <email> 1. Create the rhdh-operator namespace to contain the
    Red Hat Developer Hub Operator: ```terminal $ kubectl create namespace rhdh-operator
    ``` 2. Create a pull secret using your Red Hat credentials to pull the container
    images from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n rhdh operator create secret docker registry rhdh pull secret \ docker
    server=registry.redhat.io \ docker username=<redhat_user_name> \ docker password=<redhat_password>
    \ docker email=<email> ``` 3. Create a catalog source that contains the Red Hat
    operators: ```terminal $ cat <<EOF | kubectl -n rhdh-operator apply -f - apiVersion:
    operators.coreos.com/v1alpha1 kind: CatalogSource metadata: name: redhat-catalog
    spec: sourceType: grpc image: registry.redhat.io/redhat/redhat-operator-index:v4.19
    secrets: - "rhdh-pull-secret" displayName: Red Hat Operators EOF ``` 4. Create
    an operator group to manage your operator subscriptions: ```terminal $ cat <<EOF
    | kubectl apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1 kind:
    OperatorGroup metadata: name: rhdh-operator-group EOF ``` 5. Create a subscription
    to install the Red Hat Developer Hub Operator: ```terminal $ cat <<EOF | kubectl
    apply -n rhdh-operator -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription
    metadata: name: rhdh namespace: rhdh-operator spec: channel: fast installPlanApproval:
    Automatic name: rhdh source: redhat-catalog sourceNamespace: rhdh-operator startingCSV:
    rhdh-operator.v1.8.0 EOF ``` 6. To wait until the Operator deployment finishes
    to be able to run the next step, run: ```terminal until kubectl -n rhdh-operator
    get deployment rhdh-operator &>/dev/null; do echo -n . sleep 3 done echo "RHDH
    Operator Deployment created" ``` 7. Include your pull secret name in the Operator
    deployment manifest, to avoid ImagePullBackOff errors: ```terminal $ kubectl n
    rhdh operator patch deployment \ rhdh operator - patch ''{"spec":{"template":{"spec":{"imagePullSecrets":[{"name":"rhdh
    pull secret"}]}}}}'' \ type=merge ``` Verify the deployment name: ```terminal
    $ kubectl get deployment n rhdh operator ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:18:18.634480'
    uuid: 28ea6f5a-d71d-4a2c-8841-df39e60cef15
  response: 'On Microsoft Azure Kubernetes Service (AKS), the most notable differences
    over an OpenShift-based installation are: The OLM framework and the Red Hat Container
    Registry are not built in. The Red Hat Container Registry pull secret is not managed
    globally. To expose the application, Ingresses replace OpenShift Routes.'
  user_input: what different for Microsoft Azure Kubernetes Service (AKS) install?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Microsoft Azure Kubernetes Service (AKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your AKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ##'
  metadata:
    classification:
      category: rbac
      datetime: '2025-12-10T16:18:29.113467'
    uuid: 09fe6d2b-4e99-467a-b8d8-6546aecd8521
  response: 'To enable Role-based access control (RBAC) and set up an administrator,
    you must modify two custom configuration files. First, in your custom `app-config.yaml`
    file, you need to enable permissions and enter your policy administrator''s name
    under the `permission` section. The configuration should be set as follows: `permission:
    enabled: true` with the admin user specified under `rbac: admin: users:`. Second,
    since the RBAC plugin is disabled by default, you must enable it in your custom
    `dynamic-plugins.yaml` file by setting `disabled: false` for the package `''./dynamic
    plugins/dist/backstage community plugin rbac''`.'
  user_input: What are the specific steps and configuration file modifications required
    to enable and configure an administrator for Role-based access control (RBAC)
    in a custom Red Hat Developer Hub deployment?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Microsoft Azure Kubernetes Service (AKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your AKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:18:40.612888'
    uuid: 55e2acd5-1905-4e3a-a2b0-5201e57625a1
  response: By using the Kubernetes CLI ('kubectl'), you gain access to the Kubernetes
    cluster for your Developer Hub instance. To provision your configuration, you
    first create a namespace like `<my-rhdh-project>` using the command `$ oc create
    namespace my-rhdh-project`. Then, you provision your `app-config.yaml` and `dynamic-plugins.yaml`
    files into config maps with the commands `$ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project` and `$ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project`.
    Lastly, you provision your `secrets.txt` file to a secret named `my-rhdh-secrets`
    using `$ oc create secret generic my-rhdh-secrets --from-file=secrets.txt --namespace=my-rhdh-project`.
    Alternatively, the config maps and secret can be created using the web console.
  user_input: How do I use the Kubernets CLI to provisoin the custom config maps and
    secrets for my Developer Hub instance?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Microsoft Azure Kubernetes Service (AKS) before running Red Hat Developer
    Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip this step
    to run Developer Hub with the default config map and secret. Your changes on this
    configuration might get reverted on Developer Hub restart. ---- By using the Kubernetes
    CLI (''kubectl''), you have access, with developer permissions, to the Kubernetes
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. 1. For a production environment, start with the following setup: app-config.yaml
    ```yaml app: title: <Red Hat Developer Hub> branding: fullLogo: ${BASE64_EMBEDDED_FULL_LOGO}
    fullLogoWidth: 110px iconLogo: ${BASE64_EMBEDDED_ICON_LOGO} backend: cache: store:
    redis connection: ${REDIS_CONNECTION} techdocs: cache: ttl: 3600000 catalog: providers:
    <enter_your_provider_configuration> integrations: <enter_your_integrations_configuration>
    permission: enabled: true rbac: admin: users: - name: user:default/<your_policy_administrator_name>
    pluginsWithPermission: - catalog - scaffolder - permission ``` Most fields use
    environment variables that you defined in secrets in the previous step. app::
    title:: Enter your Developer Hub instance display name, such as <Red Hat Developer
    Hub>. branding:: Set your custom logo. Optionally, customize the width of the
    branding logo by changing value for the fullLogoWidth field. The following units
    are supported: integer, px, em, rem, percentage. backend:: cache:: Enable the
    plugins assets cache. techdocs:: cache:: Enable the Techdocs cache. catalog::
    provider:: Enter your catalog provider configuration. integrations:: Enter your
    repository discovery configuration. permissions:: Enable Role-based access control.
    Enter your policy administrator name. 2. Additionally, provision users and enable
    authentication with your external identity provider. 3. Author your custom dynamic-plugins.yaml
    file to enable plugins. By default, Developer Hub enables a minimal plugin set,
    and disables plugins that require configuration or secrets, such as the GitHub
    repository discovery plugin and the Role-based access control (RBAC) plugin. Enable
    the GitHub repository discovery and the RBAC features: dynamic.plugins.yaml ```yaml
    includes: dynamic plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage
    plugin catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your AKS cluster. 1. Create the <my-rhdh-project> {namespace} aimed at
    containing your Developer Hub instance. ```terminal $ oc create namespace my-rhdh-project
    ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml files respectively
    to the my-rhdh-app-config, and dynamic-plugins-rhdh config maps in the <my-rhdh-project>
    project. ```terminal $ oc create configmap my-rhdh-app-config --from-file=app-config.yaml
    --namespace=my-rhdh-project $ oc create configmap dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml
    --namespace=my-rhdh-project ``` Alternatively, create the config maps by using
    the web console. 3. Provision your secrets.txt file to the my-rhdh-secrets secret
    in the <my-rhdh-project> project. ```terminal $ oc create secret generic my-rhdh-secrets
    --from-file=secrets.txt --namespace=my-rhdh-project ``` Alternatively, create
    the secret by using the web console. Provision your PostgreSQL database secrets
    Provision your dynamic plugins config map Provision your RBAC policies config
    map ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:18:49.459597'
    uuid: 45e02f8a-548a-4bf1-a064-1f77a8a1bd2e
  response: On Red Hat OpenShift Container Platform, you can skip the step of provisioning
    your custom Red Hat Developer Hub config maps and secrets to run Developer Hub
    with the default config map and secret.
  user_input: What step can be skipped when configuring Red Hat Developer Hub on Red
    Hat OpenShift Container Platform?
- context:
  - 'Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Microsoft Azure Kubernetes Service (AKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on AKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:19:00.008762'
    uuid: d06fa6cd-65b5-4183-bb76-44d233834383
  response: On Microsoft Azure Kubernetes Service (AKS), the Red Hat Container Registry
    pull-secret is not managed globally, so you must add it to your Red Hat Developer
    Hub instance namespace. First, create a pull secret using your Red Hat credentials
    for registry.redhat.io with the `kubectl create secret docker-registry` command.
    After that, to enable pulling the images, you must add the image pull secret to
    the default service account in the namespace by using the `kubectl patch serviceaccount`
    command.
  user_input: How do I provison a pull secret on AKS?
- context:
  - 'Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Microsoft Azure Kubernetes Service (AKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on AKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:19:09.017518'
    uuid: 819411c3-7f5a-4831-9bd5-8d51f98dfdc4
  response: 'To create a pull secret using your Red Hat credentials for the Red Hat
    Container Registry, use the following command: `$ kubectl n {my rhdh namespace}
    create secret docker registry my rhdh pull secret \ docker server=registry.redhat.io
    \ docker username=<redhat_user_name> \ docker password=<redhat_password> \ docker
    email=<email>`.'
  user_input: kubectl command to create a docker registry secret for Red Hat
- context:
  - 'Provision your Red Hat Container Registry pull secret to your Red Hat Developer
    Hub instance namespace On Microsoft Azure Kubernetes Service (AKS), the Red Hat
    Container Registry pull-secret is not managed globally. Therefore add your pull-secret
    in your Red Hat Developer Hub instance namespace. Your credentials to the Red
    Hat Container Registry: <redhat_user_name> <redhat_password> <email> You created
    the {my rhdh project} namespace on AKS to host your Developer Hub instance. 1.
    Create a pull secret using your Red Hat credentials to pull the container images
    from the protected Red Hat Container Registry (registry.redhat.io): ```terminal
    $ kubectl n {my rhdh namespace} create secret docker registry my rhdh pull secret
    \ docker server=registry.redhat.io \ docker username=<redhat_user_name> \ docker
    password=<redhat_password> \ docker email=<email> ``` 2. To enable pulling Developer
    Hub images from the Red Hat Container Registry, add the image pull secret in the
    default service account within the namespace where the Developer Hub instance
    is being deployed: ```terminal $ kubectl patch serviceaccount default \ -p ''{"imagePullSecrets":
    [{"name": "my-rhdh-pull-secret"}]}'' \ -n {my-rhdh-namespace} ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:19:21.668207'
    uuid: 46c9c4fc-326c-4702-aaa7-03b9fff55d31
  response: On Microsoft Azure Kubernetes Service (AKS), the Red Hat Container Registry
    pull-secret is not managed globally and must be added to your Red Hat Developer
    Hub instance namespace. The first step is to create a docker-registry secret using
    your Red Hat credentials for registry.redhat.io. The second step is to add this
    image pull secret to the default service account within the namespace where the
    Developer Hub instance is being deployed, which enables the pulling of Developer
    Hub images from the Red Hat Container Registry.
  user_input: What is the standard procedure for provisioning a Red Hat Container
    Registry pull secret for a Red Hat Developer Hub instance on Microsoft Azure Kubernetes
    Service?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the AKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:19:33.766952'
    uuid: db214c67-0f94-4524-97c7-8c4eda1f5496
  response: To run Red Hat Developer Hub with your custom configuration, you use the
    Red Hat Developer Hub Operator. You must create a Backstage custom resource (CR)
    in a YAML file that mounts files from your custom config maps and injects environment
    variables from your custom secrets. After authoring the CR, you apply it using
    the command "oc apply -f my-rhdh-custom-resource.yaml -n my-rhdh-project" to start
    or update your Developer Hub instance.
  user_input: How do I run Red Hat Developer Hub with a custom configuration?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the AKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:19:46.907239'
    uuid: ca889582-fa56-46c0-aae4-7740b40fb8d6
  response: To use the Red Hat Developer Hub Operator with a custom configuration,
    the primary method is to create a Backstage custom resource (CR). This CR is authored
    in a YAML file and is designed to mount files provisioned in your custom config
    maps and inject environment variables provisioned in your custom secrets. Once
    authored, you apply the Backstage CR using the Kubernetes CLI to start or update
    your Developer Hub instance.
  user_input: What is the primary method for customizing a Red Hat Developer Hub instance
    using the Developer Hub Operator?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the Kubernetes CLI (''kubectl''), you have access,
    with developer permissions, to the AKS cluster aimed at containing your Developer
    Hub instance. Your administrator has installed the Red Hat Developer Hub Operator
    in the cluster. You have provisioned your custom config maps and secrets in your
    <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:19:57.334216'
    uuid: 8d8592dc-f64c-4245-94fa-bb59f306d941
  response: To use the Red Hat Developer Hub Operator with a custom configuration,
    you must create a Backstage custom resource (CR). This CR is designed to mount
    files provisioned in your custom config maps and inject environment variables
    from your custom secrets. You author this CR in a file named `my-rhdh-custom-resource.yaml`
    and then apply it using the command `oc apply - filename=my rhdh custom resource.yaml
    - namespace=my rhdh project` to start or update your Developer Hub instance.
  user_input: how to use Developer Hub Operator for custom configuration
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Microsoft Azure
    Kubernetes Service (AKS) On Microsoft Azure Kubernetes Service (AKS), to expose
    your Red Hat Developer Hub instance, Kubernetes ingresses replace OpenShift Container
    Platform routes. The Red Hat Developer Hub operator does not create ingresses.
    Therefore, to access your Developer Hub instance via a domain name, create the
    required ingresses on AKS and point your domain name to it. You have installed
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator. 1. Create an
    Ingress manifest file, named rhdh-ingress.yaml, specifying your Developer Hub
    service name as follows: ```yaml apiVersion: networking.k8s.io/v1 kind: Ingress
    metadata: name: my rhdh ingress namespace: my rhdh project spec: ingressClassName:
    webapprouting.kubernetes.azure.com rules: http: paths: path: / pathType: Prefix
    backend: service: name: my rhdh custom resource port: name: http backend ``` 2.
    To deploy the created Ingress, run the following command: ```terminal $ kubectl
    n my rhdh project apply f rhdh ingress.yaml ``` 1. Access the deployed Developer
    Hub using the URL: https://<app_address>, where <app_address> is the Ingress address
    obtained earlier (for example, https://108.141.70.228). # Deploying Developer
    Hub on AKS with the Helm chart You can deploy your Developer Hub application on
    Azure Kubernetes Service (AKS) to access a comprehensive solution for building,
    testing, and deploying applications. You have a Microsoft Azure account with active
    subscription. You have installed the Azure CLI. You have installed the kubectl
    CLI. You are logged into your cluster using kubectl, and have developer or admin
    permissions. You have installed Helm 3 or the latest. Make sure that your system
    meets the minimum sizing requirements. See Sizing requirements for Red Hat Developer
    Hub. Permissions issue: Developer Hub containers might encounter permission related
    errors, such as Permission denied when attempting certain operations. This error
    can be addressed by adjusting the fsGroup in the PodSpec.securityContext. Ingress
    configuration: In AKS, configuring ingress is essential for accessing the installed
    Developer Hub instance. Accessing the Developer Hub instance requires enabling
    the Routing add on, an NGINX based Ingress Controller, using the following command:
    ```terminal az aks approuting enable --resource-group <your_ResourceGroup> --name
    <your_ClusterName> ``` [TIP] ---- You might need to install the Azure CLI extension
    aks-preview. If the extension is not installed automatically, you might need to
    install it manually using the following command: ```terminal az extension add
    - upgrade n aks preview - allow preview true ``` ---- [NOTE] ---- After you install
    the Ingress Controller, the app-routing-system namespace with the Ingress Controller
    will be deployed in your cluster. Note the address of your Developer Hub application
    from the installed Ingress Controller (for example, 108.141.70.228) for later
    access to the Developer Hub application, later referenced as <app_address>. ```terminal
    kubectl get svc nginx --namespace app-routing-system -o jsonpath=''{.status.loadBalancer.ingress[0].ip}''
    ``` ---- * Namespace management: You can create a dedicated namespace for Developer
    Hub deployment in AKS using the following command: ```terminal kubectl create
    namespace <your_namespace> ``` 1. Log in to AKS by running the following command:
    ```terminal az login [- tenant=<optional_directory_name>] ``` 2. Create a resource
    group by running the following command: ```terminal az group create - name <resource_group_name>
    - location <location> ``` [TIP] ---- You can list available regions by running
    the following command: ```terminal az account list locations o table ``` ----
    3. Create an AKS cluster by running the following command: ```terminal az aks
    create \ resource group <resource_group_name> \ name <cluster_name> \ enable managed
    identity \ generate ssh keys ``` You can refer to --help for additional options.
    4. Connect to your cluster by running the following command: ```terminal az aks
    get credentials - resource group <resource_group_name> - name <cluster_name> ```
    The previous command configures the Kubernetes client and sets the current context
    in the kubeconfig to point to your AKS cluster. 5. Open terminal and run the following
    command to add the Helm chart repository: ```terminal helm repo add openshift
    helm charts https://charts.openshift.io/ ``` 6. Create and activate the <my-rhdh-project>
    namespace: ```terminal DEPLOYMENT_NAME=<redhat developer hub> NAMESPACE=<rhdh>
    kubectl create namespace ${NAMESPACE} kubectl config set context - current - namespace=${NAMESPACE}
    ``` 7. Create a pull secret, which is used to pull the Developer Hub images from
    the Red Hat Container Registry, by running the following command: ```terminal
    kubectl -n $NAMESPACE create secret docker-registry rhdh-pull-secret \ --docker-server=registry.redhat.io
    \ --docker-username=<redhat_user_name> \ --docker-password=<redhat_password> \
    --docker-email=<email> ``` 8. Create a file named values.yaml using the following
    template: ```yaml global: host: <app_address> route: enabled: false upstream:
    ingress: enabled: true className: webapprouting.kubernetes.azure.com host: backstage:
    image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql:
    image: pullSecrets: rhdh pull secret primary: podSecurityContext: enabled: true
    fsGroup: 3000 volumePermissions: enabled: true ``` 9. To install Developer Hub
    by using the Helm chart, run the following command: ```terminal helm n $NAMESPACE
    install f values.yaml $DEPLOYMENT_NAME openshift helm charts/redhat developer
    hub - version 1.8.0 ``` 10. Verify the deployment status: ```terminal kubectl
    get deploy $DEPLOYMENT_NAME n $NAMESPACE ``` 11. Configure your Developer Hub
    Helm chart instance with the Developer Hub database password and router base URL
    values from your cluster: ```terminal PASSWORD=$(kubectl get secret redhat developer
    hub postgresql o jsonpath="{.data.password}" | base64 d) CLUSTER_ROUTER_BASE=$(kubectl
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/^[^.]
    \.//'') helm upgrade $DEPLOYMENT_NAME i "https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 12. Display the running
    Developer Hub instance URL, by running the following command: ```terminal echo
    "https://$DEPLOYMENT_NAME $NAMESPACE.$CLUSTER_ROUTER_BASE" ``` Open the running
    Developer Hub instance URL in your browser to use Developer Hub. To upgrade the
    deployment, run the following command: ```terminal helm upgrade $DEPLOYMENT_NAME
    i https://github.com/openshift helm charts/charts/releases/download/redhat redhat
    developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` To delete the deployment,
    run the following command: ```terminal helm n $NAMESPACE delete $DEPLOYMENT_NAME
    ```'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:20:08.217906'
    uuid: 27de64cd-773c-4b02-9912-9306a83866a5
  response: On Microsoft Azure Kubernetes Service (AKS), Kubernetes ingresses are
    used to replace OpenShift Container Platform routes for exposing your Red Hat
    Developer Hub instance. Because the Red Hat Developer Hub operator does not create
    these ingresses, you must manually create the required ingresses on AKS and point
    your domain name to them in order to access your Developer Hub instance.
  user_input: what replaces OpenShift Container Platform routes for exposing a Developer
    Hub instance on AKS
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Microsoft Azure
    Kubernetes Service (AKS) On Microsoft Azure Kubernetes Service (AKS), to expose
    your Red Hat Developer Hub instance, Kubernetes ingresses replace OpenShift Container
    Platform routes. The Red Hat Developer Hub operator does not create ingresses.
    Therefore, to access your Developer Hub instance via a domain name, create the
    required ingresses on AKS and point your domain name to it. You have installed
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator. 1. Create an
    Ingress manifest file, named rhdh-ingress.yaml, specifying your Developer Hub
    service name as follows: ```yaml apiVersion: networking.k8s.io/v1 kind: Ingress
    metadata: name: my rhdh ingress namespace: my rhdh project spec: ingressClassName:
    webapprouting.kubernetes.azure.com rules: http: paths: path: / pathType: Prefix
    backend: service: name: my rhdh custom resource port: name: http backend ``` 2.
    To deploy the created Ingress, run the following command: ```terminal $ kubectl
    n my rhdh project apply f rhdh ingress.yaml ``` 1. Access the deployed Developer
    Hub using the URL: https://<app_address>, where <app_address> is the Ingress address
    obtained earlier (for example, https://108.141.70.228). # Deploying Developer
    Hub on AKS with the Helm chart You can deploy your Developer Hub application on
    Azure Kubernetes Service (AKS) to access a comprehensive solution for building,
    testing, and deploying applications. You have a Microsoft Azure account with active
    subscription. You have installed the Azure CLI. You have installed the kubectl
    CLI. You are logged into your cluster using kubectl, and have developer or admin
    permissions. You have installed Helm 3 or the latest. Make sure that your system
    meets the minimum sizing requirements. See Sizing requirements for Red Hat Developer
    Hub. Permissions issue: Developer Hub containers might encounter permission related
    errors, such as Permission denied when attempting certain operations. This error
    can be addressed by adjusting the fsGroup in the PodSpec.securityContext. Ingress
    configuration: In AKS, configuring ingress is essential for accessing the installed
    Developer Hub instance. Accessing the Developer Hub instance requires enabling
    the Routing add on, an NGINX based Ingress Controller, using the following command:
    ```terminal az aks approuting enable --resource-group <your_ResourceGroup> --name
    <your_ClusterName> ``` [TIP] ---- You might need to install the Azure CLI extension
    aks-preview. If the extension is not installed automatically, you might need to
    install it manually using the following command: ```terminal az extension add
    - upgrade n aks preview - allow preview true ``` ---- [NOTE] ---- After you install
    the Ingress Controller, the app-routing-system namespace with the Ingress Controller
    will be deployed in your cluster. Note the address of your Developer Hub application
    from the installed Ingress Controller (for example, 108.141.70.228) for later
    access to the Developer Hub application, later referenced as <app_address>. ```terminal
    kubectl get svc nginx --namespace app-routing-system -o jsonpath=''{.status.loadBalancer.ingress[0].ip}''
    ``` ---- * Namespace management: You can create a dedicated namespace for Developer
    Hub deployment in AKS using the following command: ```terminal kubectl create
    namespace <your_namespace> ``` 1. Log in to AKS by running the following command:
    ```terminal az login [- tenant=<optional_directory_name>] ``` 2. Create a resource
    group by running the following command: ```terminal az group create - name <resource_group_name>
    - location <location> ``` [TIP] ---- You can list available regions by running
    the following command: ```terminal az account list locations o table ``` ----
    3. Create an AKS cluster by running the following command: ```terminal az aks
    create \ resource group <resource_group_name> \ name <cluster_name> \ enable managed
    identity \ generate ssh keys ``` You can refer to --help for additional options.
    4. Connect to your cluster by running the following command: ```terminal az aks
    get credentials - resource group <resource_group_name> - name <cluster_name> ```
    The previous command configures the Kubernetes client and sets the current context
    in the kubeconfig to point to your AKS cluster. 5. Open terminal and run the following
    command to add the Helm chart repository: ```terminal helm repo add openshift
    helm charts https://charts.openshift.io/ ``` 6. Create and activate the <my-rhdh-project>
    namespace: ```terminal DEPLOYMENT_NAME=<redhat developer hub> NAMESPACE=<rhdh>
    kubectl create namespace ${NAMESPACE} kubectl config set context - current - namespace=${NAMESPACE}
    ``` 7. Create a pull secret, which is used to pull the Developer Hub images from
    the Red Hat Container Registry, by running the following command: ```terminal
    kubectl -n $NAMESPACE create secret docker-registry rhdh-pull-secret \ --docker-server=registry.redhat.io
    \ --docker-username=<redhat_user_name> \ --docker-password=<redhat_password> \
    --docker-email=<email> ``` 8. Create a file named values.yaml using the following
    template: ```yaml global: host: <app_address> route: enabled: false upstream:
    ingress: enabled: true className: webapprouting.kubernetes.azure.com host: backstage:
    image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql:
    image: pullSecrets: rhdh pull secret primary: podSecurityContext: enabled: true
    fsGroup: 3000 volumePermissions: enabled: true ``` 9. To install Developer Hub
    by using the Helm chart, run the following command: ```terminal helm n $NAMESPACE
    install f values.yaml $DEPLOYMENT_NAME openshift helm charts/redhat developer
    hub - version 1.8.0 ``` 10. Verify the deployment status: ```terminal kubectl
    get deploy $DEPLOYMENT_NAME n $NAMESPACE ``` 11. Configure your Developer Hub
    Helm chart instance with the Developer Hub database password and router base URL
    values from your cluster: ```terminal PASSWORD=$(kubectl get secret redhat developer
    hub postgresql o jsonpath="{.data.password}" | base64 d) CLUSTER_ROUTER_BASE=$(kubectl
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/^[^.]
    \.//'') helm upgrade $DEPLOYMENT_NAME i "https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 12. Display the running
    Developer Hub instance URL, by running the following command: ```terminal echo
    "https://$DEPLOYMENT_NAME $NAMESPACE.$CLUSTER_ROUTER_BASE" ``` Open the running
    Developer Hub instance URL in your browser to use Developer Hub. To upgrade the
    deployment, run the following command: ```terminal helm upgrade $DEPLOYMENT_NAME
    i https://github.com/openshift helm charts/charts/releases/download/redhat redhat
    developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` To delete the deployment,
    run the following command: ```terminal helm n $NAMESPACE delete $DEPLOYMENT_NAME
    ```'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:20:18.448111'
    uuid: 31220b4c-950f-4165-a850-aacfc52d573b
  response: 'On Azure Kubernetes Service (AKS), configuring ingress is essential for
    accessing the installed Developer Hub instance. This requires enabling the Routing
    add-on, which is an NGINX based Ingress Controller, by using the command: `az
    aks approuting enable --resource-group <your_ResourceGroup> --name <your_ClusterName>`.
    After this is installed, the app-routing-system namespace containing the Ingress
    Controller will be deployed in the cluster.'
  user_input: According to the deployment guide, what is the required procedure for
    enabling the NGINX-based Ingress Controller to ensure the Developer Hub instance
    is accessible on Azure Kubernetes Service?
- context:
  - 'Exposing your operator-based Red Hat Developer Hub instance on Microsoft Azure
    Kubernetes Service (AKS) On Microsoft Azure Kubernetes Service (AKS), to expose
    your Red Hat Developer Hub instance, Kubernetes ingresses replace OpenShift Container
    Platform routes. The Red Hat Developer Hub operator does not create ingresses.
    Therefore, to access your Developer Hub instance via a domain name, create the
    required ingresses on AKS and point your domain name to it. You have installed
    Red Hat Developer Hub by using the Red Hat Developer Hub Operator. 1. Create an
    Ingress manifest file, named rhdh-ingress.yaml, specifying your Developer Hub
    service name as follows: ```yaml apiVersion: networking.k8s.io/v1 kind: Ingress
    metadata: name: my rhdh ingress namespace: my rhdh project spec: ingressClassName:
    webapprouting.kubernetes.azure.com rules: http: paths: path: / pathType: Prefix
    backend: service: name: my rhdh custom resource port: name: http backend ``` 2.
    To deploy the created Ingress, run the following command: ```terminal $ kubectl
    n my rhdh project apply f rhdh ingress.yaml ``` 1. Access the deployed Developer
    Hub using the URL: https://<app_address>, where <app_address> is the Ingress address
    obtained earlier (for example, https://108.141.70.228). # Deploying Developer
    Hub on AKS with the Helm chart You can deploy your Developer Hub application on
    Azure Kubernetes Service (AKS) to access a comprehensive solution for building,
    testing, and deploying applications. You have a Microsoft Azure account with active
    subscription. You have installed the Azure CLI. You have installed the kubectl
    CLI. You are logged into your cluster using kubectl, and have developer or admin
    permissions. You have installed Helm 3 or the latest. Make sure that your system
    meets the minimum sizing requirements. See Sizing requirements for Red Hat Developer
    Hub. Permissions issue: Developer Hub containers might encounter permission related
    errors, such as Permission denied when attempting certain operations. This error
    can be addressed by adjusting the fsGroup in the PodSpec.securityContext. Ingress
    configuration: In AKS, configuring ingress is essential for accessing the installed
    Developer Hub instance. Accessing the Developer Hub instance requires enabling
    the Routing add on, an NGINX based Ingress Controller, using the following command:
    ```terminal az aks approuting enable --resource-group <your_ResourceGroup> --name
    <your_ClusterName> ``` [TIP] ---- You might need to install the Azure CLI extension
    aks-preview. If the extension is not installed automatically, you might need to
    install it manually using the following command: ```terminal az extension add
    - upgrade n aks preview - allow preview true ``` ---- [NOTE] ---- After you install
    the Ingress Controller, the app-routing-system namespace with the Ingress Controller
    will be deployed in your cluster. Note the address of your Developer Hub application
    from the installed Ingress Controller (for example, 108.141.70.228) for later
    access to the Developer Hub application, later referenced as <app_address>. ```terminal
    kubectl get svc nginx --namespace app-routing-system -o jsonpath=''{.status.loadBalancer.ingress[0].ip}''
    ``` ---- * Namespace management: You can create a dedicated namespace for Developer
    Hub deployment in AKS using the following command: ```terminal kubectl create
    namespace <your_namespace> ``` 1. Log in to AKS by running the following command:
    ```terminal az login [- tenant=<optional_directory_name>] ``` 2. Create a resource
    group by running the following command: ```terminal az group create - name <resource_group_name>
    - location <location> ``` [TIP] ---- You can list available regions by running
    the following command: ```terminal az account list locations o table ``` ----
    3. Create an AKS cluster by running the following command: ```terminal az aks
    create \ resource group <resource_group_name> \ name <cluster_name> \ enable managed
    identity \ generate ssh keys ``` You can refer to --help for additional options.
    4. Connect to your cluster by running the following command: ```terminal az aks
    get credentials - resource group <resource_group_name> - name <cluster_name> ```
    The previous command configures the Kubernetes client and sets the current context
    in the kubeconfig to point to your AKS cluster. 5. Open terminal and run the following
    command to add the Helm chart repository: ```terminal helm repo add openshift
    helm charts https://charts.openshift.io/ ``` 6. Create and activate the <my-rhdh-project>
    namespace: ```terminal DEPLOYMENT_NAME=<redhat developer hub> NAMESPACE=<rhdh>
    kubectl create namespace ${NAMESPACE} kubectl config set context - current - namespace=${NAMESPACE}
    ``` 7. Create a pull secret, which is used to pull the Developer Hub images from
    the Red Hat Container Registry, by running the following command: ```terminal
    kubectl -n $NAMESPACE create secret docker-registry rhdh-pull-secret \ --docker-server=registry.redhat.io
    \ --docker-username=<redhat_user_name> \ --docker-password=<redhat_password> \
    --docker-email=<email> ``` 8. Create a file named values.yaml using the following
    template: ```yaml global: host: <app_address> route: enabled: false upstream:
    ingress: enabled: true className: webapprouting.kubernetes.azure.com host: backstage:
    image: pullSecrets: rhdh pull secret podSecurityContext: fsGroup: 3000 postgresql:
    image: pullSecrets: rhdh pull secret primary: podSecurityContext: enabled: true
    fsGroup: 3000 volumePermissions: enabled: true ``` 9. To install Developer Hub
    by using the Helm chart, run the following command: ```terminal helm n $NAMESPACE
    install f values.yaml $DEPLOYMENT_NAME openshift helm charts/redhat developer
    hub - version 1.8.0 ``` 10. Verify the deployment status: ```terminal kubectl
    get deploy $DEPLOYMENT_NAME n $NAMESPACE ``` 11. Configure your Developer Hub
    Helm chart instance with the Developer Hub database password and router base URL
    values from your cluster: ```terminal PASSWORD=$(kubectl get secret redhat developer
    hub postgresql o jsonpath="{.data.password}" | base64 d) CLUSTER_ROUTER_BASE=$(kubectl
    get route console n openshift console o=jsonpath=''{.spec.host}'' | sed ''s/^[^.]
    \.//'') helm upgrade $DEPLOYMENT_NAME i "https://github.com/openshift helm charts/charts/releases/download/redhat
    redhat developer hub 1.8.0/redhat developer hub 1.8.0.tgz" \ set global.clusterRouterBase="$CLUSTER_ROUTER_BASE"
    \ set global.postgresql.auth.password="$PASSWORD" ``` 12. Display the running
    Developer Hub instance URL, by running the following command: ```terminal echo
    "https://$DEPLOYMENT_NAME $NAMESPACE.$CLUSTER_ROUTER_BASE" ``` Open the running
    Developer Hub instance URL in your browser to use Developer Hub. To upgrade the
    deployment, run the following command: ```terminal helm upgrade $DEPLOYMENT_NAME
    i https://github.com/openshift helm charts/charts/releases/download/redhat redhat
    developer hub 1.8.0/redhat developer hub 1.8.0.tgz ``` To delete the deployment,
    run the following command: ```terminal helm n $NAMESPACE delete $DEPLOYMENT_NAME
    ```'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:20:27.455410'
    uuid: af0376b3-b506-497a-ba49-41889fafd91c
  response: On Microsoft Azure Kubernetes Service (AKS), to expose your Red Hat Developer
    Hub instance, Kubernetes ingresses replace OpenShift Container Platform routes.
    The Red Hat Developer Hub operator does not create ingresses, so to access your
    Developer Hub instance via a domain name, you must create the required ingresses
    on AKS and point your domain name to it.
  user_input: what replaces OpenShift Container Platform routes on AKS
- context:
  - '# Upgrading Red Hat Developer Hub # Upgrading the Red Hat Developer Hub Operator
    If you use the Operator to deploy your Red Hat Developer Hub instance, then an
    administrator can use the OpenShift Container Platform web console to upgrade
    the Operator to a later version. OpenShift Container Platform is currently supported
    from version 4.16 to 4.19. See also the Red Hat Developer Hub Life Cycle. You
    are logged in as an administrator on the OpenShift Container Platform web console.
    You have installed the Red Hat Developer Hub Operator. You have configured the
    appropriate roles and permissions within your project to create or access an application.
    For more information, see the Red Hat OpenShift Container Platform documentation
    on Building applications. 1. In the Administrator perspective of the OpenShift
    Container Platform web console, click Operators > Installed Operators. 2. On the
    Installed Operators page, click Red Hat Developer Hub Operator. 3. On the Red
    Hat Developer Hub Operator page, click the Subscription tab. 4. From the Upgrade
    status field on the Subscription details page, click Upgrade available. [NOTE]
    ---- If there is no upgrade available, the Upgrade status field value is Up to
    date. ---- 5. On the InstallPlan details page, click Preview InstallPlan > Approve.
    [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must manually
    update the plugin configuration after approval to avoid a failed deployment. For
    more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console #  OpenShift Container Platform
    web console to upgrade the Operator to a later version. OpenShift Container Platform
    is currently supported from version 4.16 to 4.19. See also the Red Hat Developer
    Hub Life Cycle. You are logged in as an administrator on the OpenShift Container
    Platform web console. You have installed the Red Hat Developer Hub Operator. You
    have configured the appropriate roles and permissions within your project to create
    or access an application. For more information, see the Red Hat OpenShift Container
    Platform documentation on Building applications. 1. In the Administrator perspective
    of the OpenShift Container Platform web console, click Operators > Installed Operators.
    2. On the Installed Operators page, click Red Hat Developer Hub Operator. 3. On
    the Red Hat Developer Hub Operator page, click the Subscription tab. 4. From the
    Upgrade status field on the Subscription details page, click Upgrade available.
    [NOTE] ---- If there is no upgrade available, the Upgrade status field value is
    Up to date. ---- 5. On the InstallPlan details page, click Preview InstallPlan
    > Approve. [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must
    manually update the plugin configuration after approval to avoid a failed deployment.
    For more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console # Upgrading the Red Hat Developer
    Hub Helm Chart You can upgrade to a later version of Red Hat Developer Hub in
    OpenShift Container Platform by using either the web console or the CLI. OpenShift
    Container Platform web console 1. In the Developer perspective, click Helm to
    open the Helm Releases tab. 2. Click the overflow menu on the Helm release that
    you want to use and select Upgrade. 3. On the Upgrade Helm Release page, select
    the version of Developer Hub that you want to upgrade to from the chart version
    drop down list. 4. Click Upgrade. [NOTE] ---- It might take a few minutes to delete
    the resources in the older versions and to start the newer versions of the Developer
    Hub pods. ---- 5. Close all open Developer Hub web pages, and log in again to
    verify that the upgrade was successful. *'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:20:37.147102'
    uuid: b52cfbc3-d0a7-40a5-b7be-007c7d29d510
  response: 'An administrator can upgrade the Red Hat Developer Hub Operator using
    the OpenShift Container Platform web console by following these steps: 1. In the
    Administrator perspective, navigate to Operators > Installed Operators. 2. Select
    the Red Hat Developer Hub Operator. 3. Click on the Subscription tab. 4. In the
    Upgrade status field, click "Upgrade available". If no upgrade is available, this
    field will show "Up to date". 5. On the InstallPlan details page, click "Preview
    InstallPlan > Approve". After these steps, the Upgrade status will show as "Up
    to date". It is important to note that if you are using the Orchestrator plugin
    1.7, you must manually update the plugin configuration after approval to prevent
    a failed deployment.'
  user_input: What is the procedure for upgrading the Red Hat Developer Hub Operator
    through the OpenShift Container Platform web console?
- context:
  - '# Upgrading Red Hat Developer Hub # Upgrading the Red Hat Developer Hub Operator
    If you use the Operator to deploy your Red Hat Developer Hub instance, then an
    administrator can use the OpenShift Container Platform web console to upgrade
    the Operator to a later version. OpenShift Container Platform is currently supported
    from version 4.16 to 4.19. See also the Red Hat Developer Hub Life Cycle. You
    are logged in as an administrator on the OpenShift Container Platform web console.
    You have installed the Red Hat Developer Hub Operator. You have configured the
    appropriate roles and permissions within your project to create or access an application.
    For more information, see the Red Hat OpenShift Container Platform documentation
    on Building applications. 1. In the Administrator perspective of the OpenShift
    Container Platform web console, click Operators > Installed Operators. 2. On the
    Installed Operators page, click Red Hat Developer Hub Operator. 3. On the Red
    Hat Developer Hub Operator page, click the Subscription tab. 4. From the Upgrade
    status field on the Subscription details page, click Upgrade available. [NOTE]
    ---- If there is no upgrade available, the Upgrade status field value is Up to
    date. ---- 5. On the InstallPlan details page, click Preview InstallPlan > Approve.
    [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must manually
    update the plugin configuration after approval to avoid a failed deployment. For
    more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console #  OpenShift Container Platform
    web console to upgrade the Operator to a later version. OpenShift Container Platform
    is currently supported from version 4.16 to 4.19. See also the Red Hat Developer
    Hub Life Cycle. You are logged in as an administrator on the OpenShift Container
    Platform web console. You have installed the Red Hat Developer Hub Operator. You
    have configured the appropriate roles and permissions within your project to create
    or access an application. For more information, see the Red Hat OpenShift Container
    Platform documentation on Building applications. 1. In the Administrator perspective
    of the OpenShift Container Platform web console, click Operators > Installed Operators.
    2. On the Installed Operators page, click Red Hat Developer Hub Operator. 3. On
    the Red Hat Developer Hub Operator page, click the Subscription tab. 4. From the
    Upgrade status field on the Subscription details page, click Upgrade available.
    [NOTE] ---- If there is no upgrade available, the Upgrade status field value is
    Up to date. ---- 5. On the InstallPlan details page, click Preview InstallPlan
    > Approve. [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must
    manually update the plugin configuration after approval to avoid a failed deployment.
    For more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console # Upgrading the Red Hat Developer
    Hub Helm Chart You can upgrade to a later version of Red Hat Developer Hub in
    OpenShift Container Platform by using either the web console or the CLI. OpenShift
    Container Platform web console 1. In the Developer perspective, click Helm to
    open the Helm Releases tab. 2. Click the overflow menu on the Helm release that
    you want to use and select Upgrade. 3. On the Upgrade Helm Release page, select
    the version of Developer Hub that you want to upgrade to from the chart version
    drop down list. 4. Click Upgrade. [NOTE] ---- It might take a few minutes to delete
    the resources in the older versions and to start the newer versions of the Developer
    Hub pods. ---- 5. Close all open Developer Hub web pages, and log in again to
    verify that the upgrade was successful. *'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:20:45.793034'
    uuid: fb0458d7-be37-4a22-8703-79d5d137d930
  response: You can upgrade the Red Hat Developer Hub Operator using the OpenShift
    Container Platform web console. Alternatively, you can upgrade the Red Hat Developer
    Hub Helm Chart in OpenShift Container Platform by using either the web console
    or the CLI.
  user_input: What methods are available for upgrading the Red Hat Developer Hub?
- context:
  - '# Upgrading Red Hat Developer Hub # Upgrading the Red Hat Developer Hub Operator
    If you use the Operator to deploy your Red Hat Developer Hub instance, then an
    administrator can use the OpenShift Container Platform web console to upgrade
    the Operator to a later version. OpenShift Container Platform is currently supported
    from version 4.16 to 4.19. See also the Red Hat Developer Hub Life Cycle. You
    are logged in as an administrator on the OpenShift Container Platform web console.
    You have installed the Red Hat Developer Hub Operator. You have configured the
    appropriate roles and permissions within your project to create or access an application.
    For more information, see the Red Hat OpenShift Container Platform documentation
    on Building applications. 1. In the Administrator perspective of the OpenShift
    Container Platform web console, click Operators > Installed Operators. 2. On the
    Installed Operators page, click Red Hat Developer Hub Operator. 3. On the Red
    Hat Developer Hub Operator page, click the Subscription tab. 4. From the Upgrade
    status field on the Subscription details page, click Upgrade available. [NOTE]
    ---- If there is no upgrade available, the Upgrade status field value is Up to
    date. ---- 5. On the InstallPlan details page, click Preview InstallPlan > Approve.
    [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must manually
    update the plugin configuration after approval to avoid a failed deployment. For
    more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console #  OpenShift Container Platform
    web console to upgrade the Operator to a later version. OpenShift Container Platform
    is currently supported from version 4.16 to 4.19. See also the Red Hat Developer
    Hub Life Cycle. You are logged in as an administrator on the OpenShift Container
    Platform web console. You have installed the Red Hat Developer Hub Operator. You
    have configured the appropriate roles and permissions within your project to create
    or access an application. For more information, see the Red Hat OpenShift Container
    Platform documentation on Building applications. 1. In the Administrator perspective
    of the OpenShift Container Platform web console, click Operators > Installed Operators.
    2. On the Installed Operators page, click Red Hat Developer Hub Operator. 3. On
    the Red Hat Developer Hub Operator page, click the Subscription tab. 4. From the
    Upgrade status field on the Subscription details page, click Upgrade available.
    [NOTE] ---- If there is no upgrade available, the Upgrade status field value is
    Up to date. ---- 5. On the InstallPlan details page, click Preview InstallPlan
    > Approve. [IMPORTANT] ---- If you are on the Orchestrator plugin 1.7, you must
    manually update the plugin configuration after approval to avoid a failed deployment.
    For more information, see Upgrading the Orchestrator plugin from 1.7 to 1.8. ----
    The Upgrade status field value on the Subscription details page is Up to date.
    Installing Red Hat Developer Hub on OpenShift Container Platform with the Operator
    Installing from OperatorHub by using the web console # Upgrading the Red Hat Developer
    Hub Helm Chart You can upgrade to a later version of Red Hat Developer Hub in
    OpenShift Container Platform by using either the web console or the CLI. OpenShift
    Container Platform web console 1. In the Developer perspective, click Helm to
    open the Helm Releases tab. 2. Click the overflow menu on the Helm release that
    you want to use and select Upgrade. 3. On the Upgrade Helm Release page, select
    the version of Developer Hub that you want to upgrade to from the chart version
    drop down list. 4. Click Upgrade. [NOTE] ---- It might take a few minutes to delete
    the resources in the older versions and to start the newer versions of the Developer
    Hub pods. ---- 5. Close all open Developer Hub web pages, and log in again to
    verify that the upgrade was successful. *'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:20:57.082997'
    uuid: 8f56b6d7-372d-45c2-b54d-eac04f231d6a
  response: OpenShift Container Platform is currently supported from version 4.16
    to 4.19.
  user_input: what versions OpenShift Container Platform supported?
- context:
  - 'OpenShift Container Platform CLI 1. Log in to the OpenShift Container Platform
    cluster as the cluster administrator and switch to the project or namespace in
    which Developer Hub was installed. ```terminal oc login u <user> p <password>
    https://api.<HOSTNAME>:6443 oc project my rhdh project ``` 2. For a new version
    of the Developer Hub Helm chart, run the following upgrade command: ```terminal
    helm upgrade i rhdh f new values.yml \ openshift helm charts/redhat developer
    hub - version 1.8.0 ``` [NOTE] ---- You can also provide extra values to the chart
    by creating a new-values.yml file on your workstation with values that override
    the attributes in the installed chart or by adding new attributes. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:21:04.826642'
    uuid: df446d2e-81c5-4c4a-ad2c-fdf8467639cc
  response: 'To upgrade, you must first log in to the OpenShift Container Platform
    cluster as the cluster administrator and switch to the project where Developer
    Hub was installed using the commands "oc login u <user> p <password> https://api.<HOSTNAME>:6443"
    and "oc project my rhdh project". After that, for a new version of the Developer
    Hub Helm chart, you run the upgrade command: "helm upgrade i rhdh f new values.yml
    \\ openshift helm charts/redhat developer hub - version 1.8.0". You can provide
    extra values to the chart by creating a new-values.yml file on your workstation
    with values that override the attributes in the installed chart or by adding new
    attributes.'
  user_input: I'm trying to figure out the upgrade process for the Red Hat Developer
    Hub, like when a new version of the Helm chart is out, what is the exact commands
    I need to run, and also how can I provide some extra values to the chart, is there
    a file I can make for that?
- context:
  - 'OpenShift Container Platform CLI 1. Log in to the OpenShift Container Platform
    cluster as the cluster administrator and switch to the project or namespace in
    which Developer Hub was installed. ```terminal oc login u <user> p <password>
    https://api.<HOSTNAME>:6443 oc project my rhdh project ``` 2. For a new version
    of the Developer Hub Helm chart, run the following upgrade command: ```terminal
    helm upgrade i rhdh f new values.yml \ openshift helm charts/redhat developer
    hub - version 1.8.0 ``` [NOTE] ---- You can also provide extra values to the chart
    by creating a new-values.yml file on your workstation with values that override
    the attributes in the installed chart or by adding new attributes. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:21:12.816150'
    uuid: a0e6bc3e-ff4b-4064-89fb-b48dd6bfecf8
  response: 'To upgrade to a new version of the Developer Hub Helm chart, you must
    run the command: `helm upgrade i rhdh f new values.yml \ openshift helm charts/redhat
    developer hub - version 1.8.0`. You can provide extra values to the chart by creating
    a `new-values.yml` file on your workstation with values that override the attributes
    in the installed chart or by adding new attributes.'
  user_input: What is the specific Helm command for upgrading the Developer Hub, and
    how can I introduce custom values during the upgrade process?
- context:
  - 'OpenShift Container Platform CLI 1. Log in to the OpenShift Container Platform
    cluster as the cluster administrator and switch to the project or namespace in
    which Developer Hub was installed. ```terminal oc login u <user> p <password>
    https://api.<HOSTNAME>:6443 oc project my rhdh project ``` 2. For a new version
    of the Developer Hub Helm chart, run the following upgrade command: ```terminal
    helm upgrade i rhdh f new values.yml \ openshift helm charts/redhat developer
    hub - version 1.8.0 ``` [NOTE] ---- You can also provide extra values to the chart
    by creating a new-values.yml file on your workstation with values that override
    the attributes in the installed chart or by adding new attributes. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:21:22.843484'
    uuid: 796aa004-5129-49ea-8722-bb08b77064a2
  response: 'First, log in to the OpenShift Container Platform cluster as the cluster
    administrator and switch to the project or namespace where Developer Hub was installed.
    Then, for a new version of the Developer Hub Helm chart, run the following command:
    `helm upgrade i rhdh f new values.yml \ openshift helm charts/redhat developer
    hub - version 1.8.0`. You can also provide extra values by creating a new-values.yml
    file with values that override or add new attributes to the installed chart.'
  user_input: how i upgrade rhdh?
- context:
  - '# Authentication in Red Hat Developer Hub # Understanding authentication and
    user provisioning Learn about the authentication process from creating user and
    group entities in the software catalog to user sign-in, and how authentication
    and catalog plugins enable each step. Understanding this process is essential
    for successfully configuring your Developer Hub instance, securing access through
    authorization, and enabling features that rely on synchronized user and group
    data. To fully enable catalog features, provision user and group data from the
    Identity Provider to the Developer Hub software catalog. Catalog provider plugins
    handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- # Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ## Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ## Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. # Authenticating
    with Red Hat Build of Keycloak (RHBK) ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:21:29.969004'
    uuid: 699322ed-3520-43e4-a76c-6aba1744cba4
  response: When a user tries to access Red Hat Developer Hub, the hub redirects them
    to a configured authentication provider, such as Microsoft Azure. As the external
    Identity Provider (IdP), Microsoft Azure is responsible for authenticating the
    user. After a successful authentication, the Developer Hub authentication plugin
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub.
  user_input: How does Red Hat Developer Hub handle the authentication process using
    Microsoft Azure?
- context:
  - '# Authentication in Red Hat Developer Hub # Understanding authentication and
    user provisioning Learn about the authentication process from creating user and
    group entities in the software catalog to user sign-in, and how authentication
    and catalog plugins enable each step. Understanding this process is essential
    for successfully configuring your Developer Hub instance, securing access through
    authorization, and enabling features that rely on synchronized user and group
    data. To fully enable catalog features, provision user and group data from the
    Identity Provider to the Developer Hub software catalog. Catalog provider plugins
    handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- # Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ## Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ## Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. # Authenticating
    with Red Hat Build of Keycloak (RHBK) ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:21:39.817682'
    uuid: 39d2d8ee-6702-4e64-8b70-727fd9033f1a
  response: In Red Hat Developer Hub, an external Identity Provider (IdP) is responsible
    for authenticating the user. When a user attempts to access Developer Hub, they
    are redirected to a configured authentication provider like Red Hat Build of Keycloak
    (RHBK), GitHub, or Microsoft Azure. The IdP is also the source for provisioning
    user and group data into the Developer Hub software catalog via catalog provider
    plugins. This one-way synchronization ensures the catalog accurately reflects
    the users and groups in your organization, which is necessary for features that
    rely on understanding entity ownership and relationships.
  user_input: what is the role of an Identity Provider in Red Hat Developer Hub
- context:
  - '# Authentication in Red Hat Developer Hub # Understanding authentication and
    user provisioning Learn about the authentication process from creating user and
    group entities in the software catalog to user sign-in, and how authentication
    and catalog plugins enable each step. Understanding this process is essential
    for successfully configuring your Developer Hub instance, securing access through
    authorization, and enabling features that rely on synchronized user and group
    data. To fully enable catalog features, provision user and group data from the
    Identity Provider to the Developer Hub software catalog. Catalog provider plugins
    handle this task asynchronously. These plugins query the Identity Provider (IdP)
    for relevant user and group information, and create or update corresponding entities
    in the Developer Hub catalog. Scheduled provisioning ensures that the catalog
    accurately reflects the users and groups in your organization. When a user attempts
    to access Developer Hub, Developer Hub redirects them to a configured authentication
    provider, such as Red Hat Build of Keycloak (RHBK), GitHub, or Microsoft Azure.
    This external IdP is responsible for authenticating the user. On successful authentication,
    the Developer Hub authentication plugin, configured in your app-config.yaml file,
    processes the response from the IdP, resolves the identity in the Developer Hub
    software catalog, and establishes a user session within Developer Hub. Configuring
    authentication and user provisioning is critical for several reasons. Securing
    your Developer Hub instance by ensuring only authenticated users can gain access.
    Enabling authorization by allowing you to define access controls based on user
    and group memberships synchronized from your IdP. Provisioning user and group
    data to the catalog is necessary for various catalog features that rely on understanding
    entity ownership and relationships between users, groups, and software components.
    [IMPORTANT] ---- Without this provisioning step, features such as displaying who
    owns a catalog entity might not function correctly. ---- [TIP] ---- To explore
    Developer Hub features in a non-production environment, you can: * To use Developer
    Hub without external IdP, enable the guest user to skip configuring authentication
    and authorization, log in as the guest user, and access all Developer Hub features.
    * To use Developer Hub without authorization policies and features relying on
    the software catalog, you can enable the dangerouslyAllowSignInWithoutUserInCatalog
    resolver option. This setting bypasses the check requiring a user to be in the
    catalog but still enforces authentication. ---- [IMPORTANT] ---- Developer Hub
    uses a one-way synchronization model, where user and group data flow from your
    Identity Provider to the Developer Hub software catalog. As a result, deleting
    users or groups manually through the Developer Hub Web UI or REST API might be
    ineffective or cause inconsistencies, since Developer Hub will create those entities
    again during the next import. ---- # Authenticating with the Guest user For trial
    or non-production environments, you can enable guest access to skip configuring
    authentication and authorization and explore Developer Hub features. ## Authenticating
    with the Guest user on an Operator-based installation For trial or non-production
    environments installed by using the Red Hat Developer Hub Operator, you can enable
    guest access to skip configuring authentication and authorization and explore
    Developer Hub features. You added a custom Developer Hub application configuration,
    and have enough permissions to change it. You use the Red Hat Developer Hub Operator
    to run Developer Hub. Add the following content to the app config.yaml file: ```yaml
    auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. ## Authenticating
    with the Guest user on a Helm-based installation For trial or non-production environments
    installed by using the Red Hat Developer Hub Helm chart, you can enable guest
    access to skip configuring authentication and authorization and explore Developer
    Hub features. You added a custom Developer Hub application configuration, and
    have enough permissions to change it. You use the Red Hat Developer Hub Helm chart
    to run Developer Hub. Add following content to your Red Hat Developer Hub Helm
    Chart: ```yaml upstream: backstage: appConfig: app: baseUrl: ''https://{{ include
    "janus idp.hostname" . }}'' auth: environment: development providers: guest: dangerouslyAllowOutsideDevelopment:
    true ``` 1. Go to the Developer Hub login page. 2. To log in with the Guest user
    account, click Enter in the Guest tile. 3. In the Developer Hub Settings page,
    your profile name is Guest. 4. You can use Developer Hub features. # Authenticating
    with Red Hat Build of Keycloak (RHBK) ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:21:48.031067'
    uuid: 8cef678a-4b35-4142-8957-bc1e26fd9f01
  response: In the Red Hat Developer Hub authentication process, GitHub can be used
    as a configured authentication provider, which is an external Identity Provider
    (IdP). When a user tries to access Developer Hub, the system redirects them to
    the provider, such as GitHub, which is then responsible for authenticating the
    user. After a successful authentication, the Developer Hub authentication plugin
    processes the response from the IdP to resolve the user's identity in the software
    catalog and establish a session.
  user_input: What is the specific function of GitHub within the authentication workflow
    for Red Hat Developer Hub?
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK), with optional
    steps Authenticate users with Red Hat Build of Keycloak (RHBK), by provisioning
    the users and groups from RHBK to the Developer Hub software catalog, and configuring
    the OpenID Connect (OIDC) authentication provider in Red Hat Developer Hub. You
    added a custom Developer Hub application configuration, and have enough permissions
    to change it. You have enough permissions in RHSSO to create and manage a realm
    and a client. [TIP] ---- Alternatively, ask your RHBK administrator to prepare
    in RHBK the required realm and client. ---- 1. Register your Developer Hub app
    in RHBK: 1. Use an existing realm, or create a realm, with a distinctive Name
    such as <my_realm>. Save the value for the next step: * RHBK realm base URL, such
    as: <your_rhbk_URL>/realms/<your_realm>. 2. To register your Developer Hub in
    RHBK, in the created realm, secure the first application, with: 1. Client ID:
    A distinctive client ID, such as <RHDH>. 2. Valid redirect URIs: Set to the OIDC
    handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame. 3.
    Go to the Credentials tab and copy the Client secret. 4. Save the values for the
    next step: * Client ID * Client Secret 3. To prepare for the verification steps,
    in the same realm, get the credential information for an existing user or create
    a user. Save the user credential information for the verification steps. 2. Add
    your RHSSO credentials to Developer Hub, by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. 5. Optional: Add optional fields to the keycloackOrg catalog
    provider section in your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    userQuerySize: 100 groupQuerySize: 100 schedule: frequency: { hours: 1 } timeout:
    { minutes: 50 } initialDelay: { seconds: 15} ``` userQuerySize:: Enter the user
    count to query simultaneously. Default value: 100. groupQuerySize:: Enter the
    group count to query simultaneously. Default value: 100. schedule:: frequency::
    Enter the schedule frequency. Supports cron, ISO duration, and "human duration"
    as used in code. timeout:: Enter the timeout for the user provisioning job. Supports
    ISO duration and "human duration" as used in code. initialDelay:: Enter the initial
    delay to wait for before starting the user provisioning job. Supports ISO duration
    and "human duration" as used in code. 6. Enable the RHBK authentication provider,
    by adding the OIDC provider section in your app-config.yaml file: ```yaml auth:
    environment: production providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt:
    auto signInPage: oidc ``` environment: production:: Mark the environment as production
    to hide the Guest login in the Developer Hub home page. metadataUrl, clientId,
    clientSecret:: Configure the OIDC provider with your secrets. prompt:: Enter auto
    to allow the identity provider to automatically determine whether to prompt for
    credentials or bypass the login redirect if an active RHSSO session exists. The
    identity provider defaults to none, which assumes that you are already logged
    in. Sign-in requests without an active session are rejected. signInPage:: Enter
    oidc to enable the OIDC provider as default sign-in provider. 7. Optional: Add
    optional fields to the OIDC authentication provider section in your app-config.yaml
    file: ```yaml auth: providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} callbackUrl:
    ${KEYCLOAK_CALLBACK_URL} tokenEndpointAuthMethod: ${KEYCLOAK_TOKEN_ENDPOINT_METHOD}
    tokenSignedResponseAlg: ${KEYCLOAK_SIGNED_RESPONSE_ALG} additionalScopes: ${KEYCLOAK_SCOPE}
    signIn: resolvers: - resolver: oidcSubClaimMatchingKeycloakUserId - resolver:
    preferredUsernameMatchingUserEntityName - resolver: emailMatchingUserEntityProfileEmail
    - resolver: emailLocalPartMatchingUserEntityName dangerouslyAllowSignInWithoutUserInCatalog:
    true sessionDuration: { hours: 24 } backstageTokenExpiration: { minutes: _<user_defined_value>_
    } signInPage: oidc ``` callbackUrl:: RHBK callback URL. tokenEndpointAuthMethod::
    Enter your token endpoint authentication method. tokenSignedResponseAlg:: Token
    signed response algorithm. additionalScopes:: Enter additional RHBK scopes to
    request for during the authentication flow. signIn:: resolvers:: After successful
    authentication, the user signing in must be resolved to an existing user in the
    Developer Hub catalog. To best match users securely for your use case, consider
    configuring a specific resolver. Enter the resolver list to override the default
    resolver: oidcSubClaimMatchingKeycloakUserId. Available values: oidcSubClaimMatchingKeycloakUserId::
    Matches the user with the immutable sub parameter from OIDC to the RHBK user ID.
    Consider using this resolver for enhanced security. emailLocalPartMatchingUserEntityName::
    Matches the email local part with the user entity name. emailMatchingUserEntityProfileEmail::
    Matches the email with the user entity profile email. preferredUsernameMatchingUserEntityName::
    Matches the preferred username with the user entity name. The authentication provider
    tries each sign-in resolver in order until it succeeds, and fails if none succeed.
    [WARNING] ---- In production mode, configure only one resolver to make sure users
    are securely matched. ---- dangerouslyAllowSignInWithoutUserInCatalog: true::
    Configure the sign-in resolver to bypass the user provisioning requirement in
    the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable the dangerouslyAllowSignInWithoutUserInCatalog option. ---- sessionDuration::
    Lifespan of the user session. Enter a duration in ms library format (such as ''24h'',
    ''2 days''), ISO duration, or "human duration" as used in code. backstageTokenExpiration::
    Enter a value to modify the Developer Hub token expiration from its default value
    of one hour. It refers to the validity of short-term cryptographic tokens,'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:21:56.997790'
    uuid: b141b196-1536-46da-86a3-3c09cd7d3b76
  response: 'To register your Developer Hub app in Red Hat Build of Keycloak (RHBK),
    you need to save the following values for the next steps: the RHBK realm base
    URL, a distinctive Client ID, the Client secret from the Credentials tab, and
    the credential information for an existing or newly created user for verification.'
  user_input: what info i need from RHBK?
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK), with optional
    steps Authenticate users with Red Hat Build of Keycloak (RHBK), by provisioning
    the users and groups from RHBK to the Developer Hub software catalog, and configuring
    the OpenID Connect (OIDC) authentication provider in Red Hat Developer Hub. You
    added a custom Developer Hub application configuration, and have enough permissions
    to change it. You have enough permissions in RHSSO to create and manage a realm
    and a client. [TIP] ---- Alternatively, ask your RHBK administrator to prepare
    in RHBK the required realm and client. ---- 1. Register your Developer Hub app
    in RHBK: 1. Use an existing realm, or create a realm, with a distinctive Name
    such as <my_realm>. Save the value for the next step: * RHBK realm base URL, such
    as: <your_rhbk_URL>/realms/<your_realm>. 2. To register your Developer Hub in
    RHBK, in the created realm, secure the first application, with: 1. Client ID:
    A distinctive client ID, such as <RHDH>. 2. Valid redirect URIs: Set to the OIDC
    handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame. 3.
    Go to the Credentials tab and copy the Client secret. 4. Save the values for the
    next step: * Client ID * Client Secret 3. To prepare for the verification steps,
    in the same realm, get the credential information for an existing user or create
    a user. Save the user credential information for the verification steps. 2. Add
    your RHSSO credentials to Developer Hub, by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. 5. Optional: Add optional fields to the keycloackOrg catalog
    provider section in your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    userQuerySize: 100 groupQuerySize: 100 schedule: frequency: { hours: 1 } timeout:
    { minutes: 50 } initialDelay: { seconds: 15} ``` userQuerySize:: Enter the user
    count to query simultaneously. Default value: 100. groupQuerySize:: Enter the
    group count to query simultaneously. Default value: 100. schedule:: frequency::
    Enter the schedule frequency. Supports cron, ISO duration, and "human duration"
    as used in code. timeout:: Enter the timeout for the user provisioning job. Supports
    ISO duration and "human duration" as used in code. initialDelay:: Enter the initial
    delay to wait for before starting the user provisioning job. Supports ISO duration
    and "human duration" as used in code. 6. Enable the RHBK authentication provider,
    by adding the OIDC provider section in your app-config.yaml file: ```yaml auth:
    environment: production providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt:
    auto signInPage: oidc ``` environment: production:: Mark the environment as production
    to hide the Guest login in the Developer Hub home page. metadataUrl, clientId,
    clientSecret:: Configure the OIDC provider with your secrets. prompt:: Enter auto
    to allow the identity provider to automatically determine whether to prompt for
    credentials or bypass the login redirect if an active RHSSO session exists. The
    identity provider defaults to none, which assumes that you are already logged
    in. Sign-in requests without an active session are rejected. signInPage:: Enter
    oidc to enable the OIDC provider as default sign-in provider. 7. Optional: Add
    optional fields to the OIDC authentication provider section in your app-config.yaml
    file: ```yaml auth: providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} callbackUrl:
    ${KEYCLOAK_CALLBACK_URL} tokenEndpointAuthMethod: ${KEYCLOAK_TOKEN_ENDPOINT_METHOD}
    tokenSignedResponseAlg: ${KEYCLOAK_SIGNED_RESPONSE_ALG} additionalScopes: ${KEYCLOAK_SCOPE}
    signIn: resolvers: - resolver: oidcSubClaimMatchingKeycloakUserId - resolver:
    preferredUsernameMatchingUserEntityName - resolver: emailMatchingUserEntityProfileEmail
    - resolver: emailLocalPartMatchingUserEntityName dangerouslyAllowSignInWithoutUserInCatalog:
    true sessionDuration: { hours: 24 } backstageTokenExpiration: { minutes: _<user_defined_value>_
    } signInPage: oidc ``` callbackUrl:: RHBK callback URL. tokenEndpointAuthMethod::
    Enter your token endpoint authentication method. tokenSignedResponseAlg:: Token
    signed response algorithm. additionalScopes:: Enter additional RHBK scopes to
    request for during the authentication flow. signIn:: resolvers:: After successful
    authentication, the user signing in must be resolved to an existing user in the
    Developer Hub catalog. To best match users securely for your use case, consider
    configuring a specific resolver. Enter the resolver list to override the default
    resolver: oidcSubClaimMatchingKeycloakUserId. Available values: oidcSubClaimMatchingKeycloakUserId::
    Matches the user with the immutable sub parameter from OIDC to the RHBK user ID.
    Consider using this resolver for enhanced security. emailLocalPartMatchingUserEntityName::
    Matches the email local part with the user entity name. emailMatchingUserEntityProfileEmail::
    Matches the email with the user entity profile email. preferredUsernameMatchingUserEntityName::
    Matches the preferred username with the user entity name. The authentication provider
    tries each sign-in resolver in order until it succeeds, and fails if none succeed.
    [WARNING] ---- In production mode, configure only one resolver to make sure users
    are securely matched. ---- dangerouslyAllowSignInWithoutUserInCatalog: true::
    Configure the sign-in resolver to bypass the user provisioning requirement in
    the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable the dangerouslyAllowSignInWithoutUserInCatalog option. ---- sessionDuration::
    Lifespan of the user session. Enter a duration in ms library format (such as ''24h'',
    ''2 days''), ISO duration, or "human duration" as used in code. backstageTokenExpiration::
    Enter a value to modify the Developer Hub token expiration from its default value
    of one hour. It refers to the validity of short-term cryptographic tokens,'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:22:05.174466'
    uuid: 0158d614-c6e6-4f5d-9b24-3ad1fd8c05da
  response: To configure user authentication with Red Hat Developer Hub, you must
    have sufficient permissions in RHSSO to create and manage a realm and a client.
    As an alternative, you can request that your RHBK administrator prepare the necessary
    realm and client in RHBK.
  user_input: What permissions are required in RHSSO to configure user authentication
    for Developer Hub?
- context:
  - 'Enabling user authentication with Red Hat Build of Keycloak (RHBK), with optional
    steps Authenticate users with Red Hat Build of Keycloak (RHBK), by provisioning
    the users and groups from RHBK to the Developer Hub software catalog, and configuring
    the OpenID Connect (OIDC) authentication provider in Red Hat Developer Hub. You
    added a custom Developer Hub application configuration, and have enough permissions
    to change it. You have enough permissions in RHSSO to create and manage a realm
    and a client. [TIP] ---- Alternatively, ask your RHBK administrator to prepare
    in RHBK the required realm and client. ---- 1. Register your Developer Hub app
    in RHBK: 1. Use an existing realm, or create a realm, with a distinctive Name
    such as <my_realm>. Save the value for the next step: * RHBK realm base URL, such
    as: <your_rhbk_URL>/realms/<your_realm>. 2. To register your Developer Hub in
    RHBK, in the created realm, secure the first application, with: 1. Client ID:
    A distinctive client ID, such as <RHDH>. 2. Valid redirect URIs: Set to the OIDC
    handler URL: https://<my_developer_hub_domain>/api/auth/oidc/handler/frame. 3.
    Go to the Credentials tab and copy the Client secret. 4. Save the values for the
    next step: * Client ID * Client Secret 3. To prepare for the verification steps,
    in the same realm, get the credential information for an existing user or create
    a user. Save the user credential information for the verification steps. 2. Add
    your RHSSO credentials to Developer Hub, by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. KEYCLOAK_CLIENT_ID::
    Enter the saved Client ID. KEYCLOAK_CLIENT_SECRET:: Enter the saved Client Secret.
    KEYCLOAK_BASE_URL:: Enter the saved RHBK realm base URL. KEYCLOAK_REALM:: Enter
    the realm name to provision users. KEYCLOAK_LOGIN_REALM:: Enter the realm name
    to authenticate users. 3. Enable the Keycloak catalog provider plugin in your
    dynamic-plugins.yaml file. The plugin is named after RHBK upstream project. This
    plugin imports RHBK users and groups to the Developer Hub software catalog. ```yaml
    plugins: package: ''./dynamic plugins/dist/backstage community plugin catalog
    backend module keycloak dynamic'' disabled: false ``` 4. Enable provisioning RHBK
    users and groups to the Developer Hub software catalog, by adding the catalog.providers.keycloakOrg
    section to your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    ``` baseUrl:: Enter your RHBK server URL, defined earlier. clientId:: Enter your
    Developer Hub application client ID in RHBK, defined earlier. clientSecret:: Enter
    your Developer Hub application client secret in RHBK, defined earlier. realm::
    Enter the realm name to provision users. loginRealm:: Enter the realm name to
    authenticate users. 5. Optional: Add optional fields to the keycloackOrg catalog
    provider section in your app-config.yaml file: ```yaml catalog: providers: keycloakOrg:
    default: baseUrl: ${KEYCLOAK_BASE_URL} clientId: ${KEYCLOAK_CLIENT_ID} clientSecret:
    ${KEYCLOAK_CLIENT_SECRET} realm: ${KEYCLOAK_REALM} loginRealm: ${KEYCLOAK_LOGIN_REALM}
    userQuerySize: 100 groupQuerySize: 100 schedule: frequency: { hours: 1 } timeout:
    { minutes: 50 } initialDelay: { seconds: 15} ``` userQuerySize:: Enter the user
    count to query simultaneously. Default value: 100. groupQuerySize:: Enter the
    group count to query simultaneously. Default value: 100. schedule:: frequency::
    Enter the schedule frequency. Supports cron, ISO duration, and "human duration"
    as used in code. timeout:: Enter the timeout for the user provisioning job. Supports
    ISO duration and "human duration" as used in code. initialDelay:: Enter the initial
    delay to wait for before starting the user provisioning job. Supports ISO duration
    and "human duration" as used in code. 6. Enable the RHBK authentication provider,
    by adding the OIDC provider section in your app-config.yaml file: ```yaml auth:
    environment: production providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} prompt:
    auto signInPage: oidc ``` environment: production:: Mark the environment as production
    to hide the Guest login in the Developer Hub home page. metadataUrl, clientId,
    clientSecret:: Configure the OIDC provider with your secrets. prompt:: Enter auto
    to allow the identity provider to automatically determine whether to prompt for
    credentials or bypass the login redirect if an active RHSSO session exists. The
    identity provider defaults to none, which assumes that you are already logged
    in. Sign-in requests without an active session are rejected. signInPage:: Enter
    oidc to enable the OIDC provider as default sign-in provider. 7. Optional: Add
    optional fields to the OIDC authentication provider section in your app-config.yaml
    file: ```yaml auth: providers: oidc: production: metadataUrl: ${KEYCLOAK_BASE_URL}
    clientId: ${KEYCLOAK_CLIENT_ID} clientSecret: ${KEYCLOAK_CLIENT_SECRET} callbackUrl:
    ${KEYCLOAK_CALLBACK_URL} tokenEndpointAuthMethod: ${KEYCLOAK_TOKEN_ENDPOINT_METHOD}
    tokenSignedResponseAlg: ${KEYCLOAK_SIGNED_RESPONSE_ALG} additionalScopes: ${KEYCLOAK_SCOPE}
    signIn: resolvers: - resolver: oidcSubClaimMatchingKeycloakUserId - resolver:
    preferredUsernameMatchingUserEntityName - resolver: emailMatchingUserEntityProfileEmail
    - resolver: emailLocalPartMatchingUserEntityName dangerouslyAllowSignInWithoutUserInCatalog:
    true sessionDuration: { hours: 24 } backstageTokenExpiration: { minutes: _<user_defined_value>_
    } signInPage: oidc ``` callbackUrl:: RHBK callback URL. tokenEndpointAuthMethod::
    Enter your token endpoint authentication method. tokenSignedResponseAlg:: Token
    signed response algorithm. additionalScopes:: Enter additional RHBK scopes to
    request for during the authentication flow. signIn:: resolvers:: After successful
    authentication, the user signing in must be resolved to an existing user in the
    Developer Hub catalog. To best match users securely for your use case, consider
    configuring a specific resolver. Enter the resolver list to override the default
    resolver: oidcSubClaimMatchingKeycloakUserId. Available values: oidcSubClaimMatchingKeycloakUserId::
    Matches the user with the immutable sub parameter from OIDC to the RHBK user ID.
    Consider using this resolver for enhanced security. emailLocalPartMatchingUserEntityName::
    Matches the email local part with the user entity name. emailMatchingUserEntityProfileEmail::
    Matches the email with the user entity profile email. preferredUsernameMatchingUserEntityName::
    Matches the preferred username with the user entity name. The authentication provider
    tries each sign-in resolver in order until it succeeds, and fails if none succeed.
    [WARNING] ---- In production mode, configure only one resolver to make sure users
    are securely matched. ---- dangerouslyAllowSignInWithoutUserInCatalog: true::
    Configure the sign-in resolver to bypass the user provisioning requirement in
    the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable the dangerouslyAllowSignInWithoutUserInCatalog option. ---- sessionDuration::
    Lifespan of the user session. Enter a duration in ms library format (such as ''24h'',
    ''2 days''), ISO duration, or "human duration" as used in code. backstageTokenExpiration::
    Enter a value to modify the Developer Hub token expiration from its default value
    of one hour. It refers to the validity of short-term cryptographic tokens,'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:22:14.947971'
    uuid: 86c8afca-9b51-4415-afd1-2b676ffe296d
  response: "You can add optional fields to the OIDC authentication provider section\
    \ in your app-config.yaml file to configure session duration and token expiration.\
    \ The `sessionDuration` field defines the lifespan of the user session and accepts\
    \ values in ms library format (such as '24h', '2 days'), ISO duration, or \"human\
    \ duration\". The `backstageTokenExpiration` field is used to modify the Developer\
    \ Hub token expiration from its default value of one hour, and it refers to the\
    \ validity of short-term cryptographic tokens. An example snippet for the `app-config.yaml`\
    \ file is: ```yaml\nauth:\n providers:\n oidc:\n production:\n ...\n sessionDuration:\
    \ { hours: 24 }\n backstageTokenExpiration: { minutes: _<user_defined_value>_\
    \ }\n ...\n```"
  user_input: how to configure backstage token expiration and session duration for
    Red Hat Developer Hub OIDC authentication provider using the app-config.yaml file
- context:
  - 'Enabling user provisioning with LDAP When Red Hat Build of Keycloak (RHBK) depends
    on Lightweight Directory Access Protocol (LDAP) to resolve user and group identities,
    you can opt to provision users and groups from LDAP directly to the Red Hat Developer
    Hub software catalog, rather than using the RHBK provisioning mechanism. You have
    configured authentication with Red Hat Build of Keycloak (RHBK). You have collected
    the required LDAP credentials: LDAP URL:: Your LDAP server URL, such as ldaps://ds.example.net.
    Bind dn:: Your bind distinguished name, such as cn=admin,OU=Users,DC=rhdh,DC=test
    LDAP secret:: Your LDAP secret. Recommended: LDAP certificates and keys:: To use
    a secure LDAP connexion (ldaps://): you stored your LDAP certificates and keys
    respectively in the ldap_certs.pem and ldap_keys.pem files. [WARNING] ---- In
    production mode, use a secure LDAP connexion. ---- 1. Enter your LDAP credentials
    to Developer Hub, by adding the LDAP_SECRET environment variable to your Developer
    Hub secrets. ``` $ oc patch secret my-rhdh-secrets --patch ''{"stringData": {
    "LDAP_SECRET": "<ldap_secret>" }}'' ``` <ldap_secret>:: Enter your LDAP secret.
    2. Recommended: To use a secure LDAP connection (ldaps://), add your LDAP certificates
    and keys files to a {a-platform-generic} secret. ``` $ oc create secret generic
    my-rhdh-ldap-secrets \ --from-file=./ldap_certs.pem \ --from-file=./ldap_keys.pem
    ``` 3. Enable the LDAP catalog provider plugin in your dynamic-plugins.yaml file.
    ```yaml plugins: package: ''./dynamic plugins/dist/backstage plugin catalog backend
    module ldap dynamic'' disabled: false ``` 4. Enable provisioning GitHub users
    and groups to the Developer Hub software catalog, by adding the LDAP catalog provider
    section to your app-config.yaml file: 1. Optional: Remove other catalog providers,
    by removing the other catalog providers section. 2. Enter the mandatory fields:
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    schedule: frequency: PT1H timeout: PT15M ``` target:: Enter your LDAP server URL,
    such as ldaps://ds.example.net. bind:: Enter your service account informations:
    dn:: Enter your service account distinguished name (DN), such as cn=admin,OU=Users,DC=rhdh,DC=test
    secret:: Enter the name of the variable containing your LDAP secret: ${LDAP_SECRET}.
    users:: Enter information about how to find your users: dn:: Enter the DN containing
    the user information. options:: filter:: Enter your filter, such as (uid=*) to
    provision to the RHDH software catalog only users with an existing uid. groups::
    Enter information about how to find your groups: dn:: Enter the DN containing
    the group information. schedule:: Enter your schedule information: frequency::
    Enter your schedule frequency, in the cron, ISO duration, or "human duration"
    format. timeout:: Enter your schedule timeout, in the ISO duration or "human duration"
    format. initialDelay:: Enter your schedule initial delay, in the ISO duration
    or "human duration" format. 3. Optional: To change how Developer Hub maps LDAP
    user fields to the software catalog, enter optional maps and set fields. ```yaml
    catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind: dn:
    cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH Local,DC=rhdh,DC=test
    options: filter: (uid= ) map: rdn: uid name: uid description: {} displayName:
    cn email: mail picture: {} memberOf: memberOf set: metadata.customField: ''hello''
    groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test schedule: frequency: PT1H
    timeout: PT15M ``` rdn:: To change the default value: uid, enter the relative
    distinguished name of each entry. name:: To change the default value: uid, enter
    the LDAP field to map to the RHDH metadata.name field. description:: To set a
    value, enter the LDAP field to map to the RHDH metadata.description field. displayName::
    To change the default value: cn, enter the LDAP field to map to the RHDH metadata.displayName
    field. email:: To change the default value: mail, enter the LDAP field to map
    to the RHDH spec.profile.email field. picture:: To set a value, enter the LDAP
    field to map to the RHDH spec.profile.picture field. memberOf:: To change the
    default value: memberOf, enter the LDAP field to map to the RHDH spec.memberOf
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 4. Optional: To change
    how Developer Hub maps LDAP group fields to the software catalog, enter optional
    groups.maps fields. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    map: rdn: uid name: uid description: {} displayName: cn email: mail picture: {}
    memberOf: memberOf members: member type: groupType set: metadata.customField:
    ''hello'' schedule: frequency: PT1H timeout: PT15M ``` rdn:: To change the default
    value: cn, enter the relative distinguished name of each entry. name:: To change
    the default value: cn, enter the LDAP field to map to the RHDH metadata.name field.
    description:: To set a value, enter the LDAP field to map to the RHDH metadata.description
    field. displayName:: To change the default value: cn, enter the LDAP field to
    map to the RHDH metadata.displayName field. email:: To change the default value:
    mail, enter the LDAP field to map to the RHDH spec.profile.email field. picture::
    To set a value, enter the LDAP field to map to the RHDH spec.profile.picture field.
    memberOf:: To change the default value: memberOf, enter the LDAP field to map
    to the RHDH spec.memberOf field. members:: To change the default value: member,
    enter the LDAP field to map to the RHDH spec.children field. type:: To change
    the default value: groupType, enter the LDAP field to map to the RHDH spec.type
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 5. Recommended: To use
    a secure LDAP connection (ldaps://), enter optional tls fields. Optional tls fields
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: ldapOrg: default:
    tls: rejectUnauthorized: true keys: ''/path/to/keys.pem'' certs: ''/path/to/certs.pem''
    ``` rejectUnauthorized:: Set to false to allow self-signed certificates [WARNING]
    ---- This option is not recommended for production. ---- keys:: Enter a file containing
    private keys in PEM format certs:: Enter a file containing cert chains in PEM
    format 6. Optional: Enter configuration for vendor-specific attributes to set
    custom attribute names for distinguished names (DN) and universally unique identifiers
    (UUID) in LDAP directories. Default values are defined per supported vendor and
    automatically'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:22:29.490610'
    uuid: 5f9a6539-4708-4f50-8a4a-b1211f2179ed
  response: "To enable user provisioning with LDAP directly to the Red Hat Developer\
    \ Hub software catalog, you must first collect the required LDAP credentials,\
    \ including the LDAP server URL, the bind distinguished name (dn), and the LDAP\
    \ secret. The next steps involve adding your LDAP credentials to Developer Hub\
    \ by patching the secrets with the LDAP_SECRET environment variable, and then\
    \ enabling the LDAP catalog provider plugin in your dynamic-plugins.yaml file.\
    \ Finally, you must add the LDAP catalog provider section to your app-config.yaml\
    \ file with the following mandatory fields: \n- **target**: Your LDAP server URL.\
    \ \n- **bind**: Contains your service account information, specifically the `dn`\
    \ (distinguished name) and `secret` (the variable name for your LDAP secret, e.g.,\
    \ ${LDAP_SECRET}). \n- **users**: Contains information on how to find users, including\
    \ the `dn` (the distinguished name containing user information) and an `options.filter`\
    \ to specify which users to provision. \n- **groups**: Contains the `dn` for the\
    \ location of group information. \n- **schedule**: Includes schedule information\
    \ such as `frequency` and `timeout` for the provisioning process."
  user_input: As a Platform Engineering Lead tasked with standardizing our development
    environment, could you provide a comprehensive overview of the mandatory configuration
    steps and specific YAML parameters required to enable user and group provisioning
    from our LDAP server directly into the Red Hat Developer Hub software catalog?
- context:
  - 'Enabling user provisioning with LDAP When Red Hat Build of Keycloak (RHBK) depends
    on Lightweight Directory Access Protocol (LDAP) to resolve user and group identities,
    you can opt to provision users and groups from LDAP directly to the Red Hat Developer
    Hub software catalog, rather than using the RHBK provisioning mechanism. You have
    configured authentication with Red Hat Build of Keycloak (RHBK). You have collected
    the required LDAP credentials: LDAP URL:: Your LDAP server URL, such as ldaps://ds.example.net.
    Bind dn:: Your bind distinguished name, such as cn=admin,OU=Users,DC=rhdh,DC=test
    LDAP secret:: Your LDAP secret. Recommended: LDAP certificates and keys:: To use
    a secure LDAP connexion (ldaps://): you stored your LDAP certificates and keys
    respectively in the ldap_certs.pem and ldap_keys.pem files. [WARNING] ---- In
    production mode, use a secure LDAP connexion. ---- 1. Enter your LDAP credentials
    to Developer Hub, by adding the LDAP_SECRET environment variable to your Developer
    Hub secrets. ``` $ oc patch secret my-rhdh-secrets --patch ''{"stringData": {
    "LDAP_SECRET": "<ldap_secret>" }}'' ``` <ldap_secret>:: Enter your LDAP secret.
    2. Recommended: To use a secure LDAP connection (ldaps://), add your LDAP certificates
    and keys files to a {a-platform-generic} secret. ``` $ oc create secret generic
    my-rhdh-ldap-secrets \ --from-file=./ldap_certs.pem \ --from-file=./ldap_keys.pem
    ``` 3. Enable the LDAP catalog provider plugin in your dynamic-plugins.yaml file.
    ```yaml plugins: package: ''./dynamic plugins/dist/backstage plugin catalog backend
    module ldap dynamic'' disabled: false ``` 4. Enable provisioning GitHub users
    and groups to the Developer Hub software catalog, by adding the LDAP catalog provider
    section to your app-config.yaml file: 1. Optional: Remove other catalog providers,
    by removing the other catalog providers section. 2. Enter the mandatory fields:
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    schedule: frequency: PT1H timeout: PT15M ``` target:: Enter your LDAP server URL,
    such as ldaps://ds.example.net. bind:: Enter your service account informations:
    dn:: Enter your service account distinguished name (DN), such as cn=admin,OU=Users,DC=rhdh,DC=test
    secret:: Enter the name of the variable containing your LDAP secret: ${LDAP_SECRET}.
    users:: Enter information about how to find your users: dn:: Enter the DN containing
    the user information. options:: filter:: Enter your filter, such as (uid=*) to
    provision to the RHDH software catalog only users with an existing uid. groups::
    Enter information about how to find your groups: dn:: Enter the DN containing
    the group information. schedule:: Enter your schedule information: frequency::
    Enter your schedule frequency, in the cron, ISO duration, or "human duration"
    format. timeout:: Enter your schedule timeout, in the ISO duration or "human duration"
    format. initialDelay:: Enter your schedule initial delay, in the ISO duration
    or "human duration" format. 3. Optional: To change how Developer Hub maps LDAP
    user fields to the software catalog, enter optional maps and set fields. ```yaml
    catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind: dn:
    cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH Local,DC=rhdh,DC=test
    options: filter: (uid= ) map: rdn: uid name: uid description: {} displayName:
    cn email: mail picture: {} memberOf: memberOf set: metadata.customField: ''hello''
    groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test schedule: frequency: PT1H
    timeout: PT15M ``` rdn:: To change the default value: uid, enter the relative
    distinguished name of each entry. name:: To change the default value: uid, enter
    the LDAP field to map to the RHDH metadata.name field. description:: To set a
    value, enter the LDAP field to map to the RHDH metadata.description field. displayName::
    To change the default value: cn, enter the LDAP field to map to the RHDH metadata.displayName
    field. email:: To change the default value: mail, enter the LDAP field to map
    to the RHDH spec.profile.email field. picture:: To set a value, enter the LDAP
    field to map to the RHDH spec.profile.picture field. memberOf:: To change the
    default value: memberOf, enter the LDAP field to map to the RHDH spec.memberOf
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 4. Optional: To change
    how Developer Hub maps LDAP group fields to the software catalog, enter optional
    groups.maps fields. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    map: rdn: uid name: uid description: {} displayName: cn email: mail picture: {}
    memberOf: memberOf members: member type: groupType set: metadata.customField:
    ''hello'' schedule: frequency: PT1H timeout: PT15M ``` rdn:: To change the default
    value: cn, enter the relative distinguished name of each entry. name:: To change
    the default value: cn, enter the LDAP field to map to the RHDH metadata.name field.
    description:: To set a value, enter the LDAP field to map to the RHDH metadata.description
    field. displayName:: To change the default value: cn, enter the LDAP field to
    map to the RHDH metadata.displayName field. email:: To change the default value:
    mail, enter the LDAP field to map to the RHDH spec.profile.email field. picture::
    To set a value, enter the LDAP field to map to the RHDH spec.profile.picture field.
    memberOf:: To change the default value: memberOf, enter the LDAP field to map
    to the RHDH spec.memberOf field. members:: To change the default value: member,
    enter the LDAP field to map to the RHDH spec.children field. type:: To change
    the default value: groupType, enter the LDAP field to map to the RHDH spec.type
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 5. Recommended: To use
    a secure LDAP connection (ldaps://), enter optional tls fields. Optional tls fields
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: ldapOrg: default:
    tls: rejectUnauthorized: true keys: ''/path/to/keys.pem'' certs: ''/path/to/certs.pem''
    ``` rejectUnauthorized:: Set to false to allow self-signed certificates [WARNING]
    ---- This option is not recommended for production. ---- keys:: Enter a file containing
    private keys in PEM format certs:: Enter a file containing cert chains in PEM
    format 6. Optional: Enter configuration for vendor-specific attributes to set
    custom attribute names for distinguished names (DN) and universally unique identifiers
    (UUID) in LDAP directories. Default values are defined per supported vendor and
    automatically'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:22:41.485476'
    uuid: ccbf5d90-079b-4ba3-a230-75c439508c85
  response: "To enable user provisioning from LDAP directly to the Red Hat Developer\
    \ Hub software catalog, you must first have authentication with Red Hat Build\
    \ of Keycloak (RHBK) configured and possess the required LDAP credentials. The\
    \ process is as follows:\n\n1.  **Enter LDAP Credentials**: Add your LDAP secret\
    \ to the Developer Hub secrets by patching the secret with the `LDAP_SECRET` environment\
    \ variable using the command: `$ oc patch secret my-rhdh-secrets --patch '{\\\"\
    stringData\\\": { \\\"LDAP_SECRET\\\": \\\"<ldap_secret>\\\" }}'`.\n\n2.  **Enable\
    \ the LDAP Plugin**: In your `dynamic-plugins.yaml` file, enable the LDAP catalog\
    \ provider plugin by setting `disabled: false` for the package `'./dynamic plugins/dist/backstage\
    \ plugin catalog backend module ldap dynamic'`.\n\n3.  **Configure `app-config.yaml`**:\
    \ Add the LDAP catalog provider section to your `app-config.yaml` file with the\
    \ following mandatory fields:\n    *   `target`: Your LDAP server URL (e.g., `ldaps://ds.example.net`).\n\
    \    *   `bind`: Contains your service account information, including `dn` (distinguished\
    \ name) and `secret` (the variable name `${LDAP_SECRET}`).\n    *   `users`: Specifies\
    \ how to find users, requiring a `dn` for the location of user information and\
    \ an optional `filter` under `options`.\n    *   `groups`: Specifies how to find\
    \ groups, requiring a `dn` for the location of group information.\n    *   `schedule`:\
    \ Defines the provisioning schedule with `frequency` and `timeout`.\n\nAdditionally,\
    \ for secure LDAP connections (ldaps://), it is recommended to create a secret\
    \ containing your LDAP certificates and keys and to configure optional `tls` fields\
    \ in the `app-config.yaml` file. You can also optionally customize how Developer\
    \ Hub maps LDAP user and group fields to the software catalog."
  user_input: As a Platform Engineering Lead tasked with integrating our existing
    identity management systems, could you provide a comprehensive, step-by-step guide
    on how to configure the Red Hat Developer Hub to provision users and groups directly
    from an LDAP directory into its software catalog, detailing the necessary credential
    management, plugin activation, and the mandatory fields required in the `app-config.yaml`
    file?
- context:
  - 'Enabling user provisioning with LDAP When Red Hat Build of Keycloak (RHBK) depends
    on Lightweight Directory Access Protocol (LDAP) to resolve user and group identities,
    you can opt to provision users and groups from LDAP directly to the Red Hat Developer
    Hub software catalog, rather than using the RHBK provisioning mechanism. You have
    configured authentication with Red Hat Build of Keycloak (RHBK). You have collected
    the required LDAP credentials: LDAP URL:: Your LDAP server URL, such as ldaps://ds.example.net.
    Bind dn:: Your bind distinguished name, such as cn=admin,OU=Users,DC=rhdh,DC=test
    LDAP secret:: Your LDAP secret. Recommended: LDAP certificates and keys:: To use
    a secure LDAP connexion (ldaps://): you stored your LDAP certificates and keys
    respectively in the ldap_certs.pem and ldap_keys.pem files. [WARNING] ---- In
    production mode, use a secure LDAP connexion. ---- 1. Enter your LDAP credentials
    to Developer Hub, by adding the LDAP_SECRET environment variable to your Developer
    Hub secrets. ``` $ oc patch secret my-rhdh-secrets --patch ''{"stringData": {
    "LDAP_SECRET": "<ldap_secret>" }}'' ``` <ldap_secret>:: Enter your LDAP secret.
    2. Recommended: To use a secure LDAP connection (ldaps://), add your LDAP certificates
    and keys files to a {a-platform-generic} secret. ``` $ oc create secret generic
    my-rhdh-ldap-secrets \ --from-file=./ldap_certs.pem \ --from-file=./ldap_keys.pem
    ``` 3. Enable the LDAP catalog provider plugin in your dynamic-plugins.yaml file.
    ```yaml plugins: package: ''./dynamic plugins/dist/backstage plugin catalog backend
    module ldap dynamic'' disabled: false ``` 4. Enable provisioning GitHub users
    and groups to the Developer Hub software catalog, by adding the LDAP catalog provider
    section to your app-config.yaml file: 1. Optional: Remove other catalog providers,
    by removing the other catalog providers section. 2. Enter the mandatory fields:
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    schedule: frequency: PT1H timeout: PT15M ``` target:: Enter your LDAP server URL,
    such as ldaps://ds.example.net. bind:: Enter your service account informations:
    dn:: Enter your service account distinguished name (DN), such as cn=admin,OU=Users,DC=rhdh,DC=test
    secret:: Enter the name of the variable containing your LDAP secret: ${LDAP_SECRET}.
    users:: Enter information about how to find your users: dn:: Enter the DN containing
    the user information. options:: filter:: Enter your filter, such as (uid=*) to
    provision to the RHDH software catalog only users with an existing uid. groups::
    Enter information about how to find your groups: dn:: Enter the DN containing
    the group information. schedule:: Enter your schedule information: frequency::
    Enter your schedule frequency, in the cron, ISO duration, or "human duration"
    format. timeout:: Enter your schedule timeout, in the ISO duration or "human duration"
    format. initialDelay:: Enter your schedule initial delay, in the ISO duration
    or "human duration" format. 3. Optional: To change how Developer Hub maps LDAP
    user fields to the software catalog, enter optional maps and set fields. ```yaml
    catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind: dn:
    cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH Local,DC=rhdh,DC=test
    options: filter: (uid= ) map: rdn: uid name: uid description: {} displayName:
    cn email: mail picture: {} memberOf: memberOf set: metadata.customField: ''hello''
    groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test schedule: frequency: PT1H
    timeout: PT15M ``` rdn:: To change the default value: uid, enter the relative
    distinguished name of each entry. name:: To change the default value: uid, enter
    the LDAP field to map to the RHDH metadata.name field. description:: To set a
    value, enter the LDAP field to map to the RHDH metadata.description field. displayName::
    To change the default value: cn, enter the LDAP field to map to the RHDH metadata.displayName
    field. email:: To change the default value: mail, enter the LDAP field to map
    to the RHDH spec.profile.email field. picture:: To set a value, enter the LDAP
    field to map to the RHDH spec.profile.picture field. memberOf:: To change the
    default value: memberOf, enter the LDAP field to map to the RHDH spec.memberOf
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 4. Optional: To change
    how Developer Hub maps LDAP group fields to the software catalog, enter optional
    groups.maps fields. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: dn: OU=Users,OU=RHDH
    Local,DC=rhdh,DC=test options: filter: (uid= ) groups: dn: OU=Groups,OU=RHDH Local,DC=rhdh,DC=test
    map: rdn: uid name: uid description: {} displayName: cn email: mail picture: {}
    memberOf: memberOf members: member type: groupType set: metadata.customField:
    ''hello'' schedule: frequency: PT1H timeout: PT15M ``` rdn:: To change the default
    value: cn, enter the relative distinguished name of each entry. name:: To change
    the default value: cn, enter the LDAP field to map to the RHDH metadata.name field.
    description:: To set a value, enter the LDAP field to map to the RHDH metadata.description
    field. displayName:: To change the default value: cn, enter the LDAP field to
    map to the RHDH metadata.displayName field. email:: To change the default value:
    mail, enter the LDAP field to map to the RHDH spec.profile.email field. picture::
    To set a value, enter the LDAP field to map to the RHDH spec.profile.picture field.
    memberOf:: To change the default value: memberOf, enter the LDAP field to map
    to the RHDH spec.memberOf field. members:: To change the default value: member,
    enter the LDAP field to map to the RHDH spec.children field. type:: To change
    the default value: groupType, enter the LDAP field to map to the RHDH spec.type
    field. set:: To set a value, enter the hard coded JSON to apply to the entities
    after ingestion, such as metadata.customField: ''hello''. 5. Recommended: To use
    a secure LDAP connection (ldaps://), enter optional tls fields. Optional tls fields
    ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net bind:
    dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: ldapOrg: default:
    tls: rejectUnauthorized: true keys: ''/path/to/keys.pem'' certs: ''/path/to/certs.pem''
    ``` rejectUnauthorized:: Set to false to allow self-signed certificates [WARNING]
    ---- This option is not recommended for production. ---- keys:: Enter a file containing
    private keys in PEM format certs:: Enter a file containing cert chains in PEM
    format 6. Optional: Enter configuration for vendor-specific attributes to set
    custom attribute names for distinguished names (DN) and universally unique identifiers
    (UUID) in LDAP directories. Default values are defined per supported vendor and
    automatically'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:23:00.679454'
    uuid: 013c6bc2-e3fc-4225-a858-4cd7cf8ace5f
  response: To provision users and groups from LDAP directly to the Red Hat Developer
    Hub software catalog, you must first add the LDAP_SECRET environment variable
    to your Developer Hub secrets. For a secure connection, it is recommended to add
    your LDAP certificates and keys to a secret. Next, you must enable the LDAP catalog
    provider plugin in your dynamic-plugins.yaml file. Finally, you enable provisioning
    by adding the LDAP catalog provider section to your app-config.yaml file, where
    you will enter mandatory fields such as the target LDAP server URL, bind information,
    the secret variable, and the distinguished names (DN) for your users and groups.
  user_input: how do i provison users from ldap to Red Hat Developer Hub?
- context:
  - 'not to the session duration. The expiration value must be set between 10 minutes
    and 24 hours. [WARNING] ---- If multiple valid refresh tokens are issued due to
    frequent refresh token requests, older tokens will remain valid until they expire.
    Enhance security and prevent potential misuse of older tokens by enabling a refresh
    token rotation strategy in your RHBK realm. 1. From the Configure section of the
    navigation menu, click Realm Settings. 2. From the Realm Settings page, click
    the Tokens tab. 3. From the Refresh tokens section of the Tokens tab, toggle the
    Revoke Refresh Token to the Enabled position. ---- 1. To verify user and group
    provisioning, check the console logs. Successful synchronization example: ```
    2025-06-27T16:02:34.647Z catalog info Read 5 Keycloak users and 3 Keycloak groups
    in 0.4 seconds. Committing... class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:23:11.999203'
    uuid: cf7a300a-269a-4692-a9e4-5c16c5dd9ca7
  response: 'To enhance security and prevent potential misuse of older tokens, you
    must enable a refresh token rotation strategy in your RHBK realm. The procedure
    is as follows: First, from the Configure section of the navigation menu, click
    Realm Settings. Next, from the Realm Settings page, click the Tokens tab. Finally,
    from the Refresh tokens section of the Tokens tab, toggle the Revoke Refresh Token
    to the Enabled position.'
  user_input: Considering the security risk that arises when multiple valid refresh
    tokens are issued and older tokens remain valid until expiration, what is the
    precise, step-by-step procedure within our Keycloak-based RHBK realm to enable
    a refresh token rotation strategy and prevent the potential misuse of these older
    tokens?
- context:
  - 'not to the session duration. The expiration value must be set between 10 minutes
    and 24 hours. [WARNING] ---- If multiple valid refresh tokens are issued due to
    frequent refresh token requests, older tokens will remain valid until they expire.
    Enhance security and prevent potential misuse of older tokens by enabling a refresh
    token rotation strategy in your RHBK realm. 1. From the Configure section of the
    navigation menu, click Realm Settings. 2. From the Realm Settings page, click
    the Tokens tab. 3. From the Refresh tokens section of the Tokens tab, toggle the
    Revoke Refresh Token to the Enabled position. ---- 1. To verify user and group
    provisioning, check the console logs. Successful synchronization example: ```
    2025-06-27T16:02:34.647Z catalog info Read 5 Keycloak users and 3 Keycloak groups
    in 0.4 seconds. Committing... class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:23:19.169585'
    uuid: fc1b0938-8ead-4c96-b5fd-074d346825c5
  response: To verify RHBK user authentication, you need to go to the Developer Hub
    login page. On that page, you should see that it displays "Sign in using OIDC"
    and that the Guest user sign-in is disabled. After confirming this, you can log
    in with OIDC by using the saved Username and Password values.
  user_input: I'm trying to figure out how we can verify the RHBK user authentication
    is working right, specifically with the OIDC integration, what is the process
    for checking that the sign-in page is configured correctly and that a user can
    actually log in using their OIDC credentials?
- context:
  - 'not to the session duration. The expiration value must be set between 10 minutes
    and 24 hours. [WARNING] ---- If multiple valid refresh tokens are issued due to
    frequent refresh token requests, older tokens will remain valid until they expire.
    Enhance security and prevent potential misuse of older tokens by enabling a refresh
    token rotation strategy in your RHBK realm. 1. From the Configure section of the
    navigation menu, click Realm Settings. 2. From the Realm Settings page, click
    the Tokens tab. 3. From the Refresh tokens section of the Tokens tab, toggle the
    Revoke Refresh Token to the Enabled position. ---- 1. To verify user and group
    provisioning, check the console logs. Successful synchronization example: ```
    2025-06-27T16:02:34.647Z catalog info Read 5 Keycloak users and 3 Keycloak groups
    in 0.4 seconds. Committing... class="KeycloakOrgEntityProvider" taskId="KeycloakOrgEntityProvider:default:refresh"
    taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82" trace_id="606f80a9ce00d1c86800718c4522f7c6"
    span_id="7ebc2a254a546e90" trace_flags="01" 2025-06-27T16:02:34.650Z catalog info
    Committed 5 Keycloak users and 3 Keycloak groups in 0.0 seconds. class="KeycloakOrgEntityProvider"
    taskId="KeycloakOrgEntityProvider:default:refresh" taskInstanceId="db55c34b-46b3-402b-b12f-2fbc48498e82"
    trace_id="606f80a9ce00d1c86800718c4522f7c6" span_id="7ebc2a254a546e90" trace_flags="01"
    ``` 2. To verify RHBK user authentication: 1. Go to the Developer Hub login page.
    2. Your Developer Hub sign-in page displays Sign in using OIDC and the Guest user
    sign-in is disabled. 3. Log in with OIDC by using the saved Username and Password
    values. ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:23:26.357970'
    uuid: de24641b-9151-4e14-b6be-51d31f453e18
  response: To verify RHBK user authentication, you must first go to the Developer
    Hub login page. On that page, you should see that it displays "Sign in using OIDC"
    and that the Guest user sign-in is disabled. The final step is to log in with
    OIDC by using the saved Username and Password values.
  user_input: After setting up my Red Hat Developer Hub environment, what are the
    specific steps I need to follow to verify that the RHBK user authentication with
    OIDC is working as expected?
- context:
  - 'detected. ```yaml catalog: providers: ldapOrg: default: vendor: dnAttributeName:
    customDN uuidAttributeName: customUUID ``` dnAttributeName:: Enter the attribute
    name that holds the distinguished name (DN) for an entry. uuidAttributeName::
    Enter the attribute name that holds a universal unique identifier (UUID) for an
    entry. 7. Optional: Enter low level users and groups configuration in the options
    subsection. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: options: scope:
    sub filter: (uid= ) attributes: cn uid description paged: pageSize: 500 groups:
    options: scope: sub filter: (cn= ) attributes: cn uid description paged: pageSize:
    500 pagePause: true ``` scope:: To change the default value: one, enter how deep
    the search should go within the directory tree: * base to search only the base
    DN. * one to search one level below the base DN. * sub to search all descendant
    entries. filter:: To change the default value: (objectclass=*), enter your LDAP
    filter. With the default mapping: * For users, enter (uid=*) to make sure only
    users with valid uid field is synced, since users without uid will cause error
    and ingestion fails. * For groups, enter (cn=*) [TIP] ---- When you change the
    mapping, also update the filter. ---- attributes:: To change the default value:
    all attributes [''*'', ''+''], enter the array of attribute names to import from
    LDAP. paged:: Enter a value to enable paged results. pageSize:: Enter a value
    to set the results page size, such as 500. pagePause:: Enter true to tell the
    client to wait for the asynchronous results of the next page, when the page limit
    has been reached. 5. Recommended: To use a secure LDAP connection (ldaps://),
    mount your LDAP certificates and keys files in your Developer Hub deployment,
    by editing your Backstage custom resource. ``` kind: Backstage spec: application:
    extraFiles: mountPath: /opt/ldap secrets secrets: name: my rhdh database database
    secrets key: ldap certs.pem, ldap keys.pem ``` To verify user and group provisioning,
    check the console logs. Successful synchronization example: ```json 2025-10-15T20:45:49.072Z
    catalog info Read 4 LDAP users and 6 LDAP groups in 0.3 seconds. Committing...
    class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh" taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952"
    trace_id="6a318e2eadba84e20df773948668aa4c" span_id="cbec568cb6e64985" trace_flags="01"
    2025-10-15T20:45:49.075Z catalog info Committed 4 LDAP users and 6 LDAP groups
    in 0.0 seconds. class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh"
    taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952" trace_id="6a318e2eadba84e20df773948668aa4c"
    span_id="cbec568cb6e64985" trace_flags="01" ``` ## Creating a custom transformer
    to provision users from Red Hat Build of Keycloak (RHBK) to the software catalog
    Customize how Red Hat Developer Hub provisions users and groups to Red Hat Developer
    Hub software catalog entities, by creating a backend module that uses the keycloakTransformerExtensionPoint
    to offer custom user and group transformers for the Keycloak backend. You have
    enabled provisioning users from Red Hat Build of Keycloak (RHBK) to the software
    catalog. 1. Create a new backend module with the yarn new command. 2. Add your
    custom user and group transformers to the keycloakTransformerExtensionPoint. The
    following is an example plugins/<module_name>/src/module.ts file defining the
    backend module: ```javascript import { GroupTransformer, keycloakTransformerExtensionPoint,
    UserTransformer, } from ''@backstage community/plugin catalog backend module keycloak'';
    const customGroupTransformer: GroupTransformer = async ( entity, // entity output
    from default parser realm, // Keycloak realm name groups, // Keycloak group representation
    ) => { /* apply transformations */ return entity; }; const customUserTransformer:
    UserTransformer = async ( entity, // entity output from default parser user, //
    Keycloak user representation realm, // Keycloak realm name groups, // Keycloak
    group representation ) => { /* apply transformations */ return entity; }; export
    const keycloakBackendModuleTransformer = createBackendModule({ pluginId: ''catalog'',
    moduleId: ''keycloak-transformer'', register(reg) { reg.registerInit({ deps: {
    keycloak: keycloakTransformerExtensionPoint, }, async init({ keycloak }) { keycloak.setUserTransformer(customUserTransformer);
    keycloak.setGroupTransformer(customGroupTransformer); /* highlight-add-end */
    }, }); }, }); ``` [IMPORTANT] ---- Set the module''s pluginId to catalog to match
    the pluginId of the keycloak-backend; otherwise, the module fails to initialize.
    ---- 3. Install this new backend module into your Developer Hub backend. ```javascript
    backend.add(import(backstage plugin catalog backend module keycloak transformer))
    ``` Developer Hub imports the users and groups each time when started. Check the
    console logs to verify the synchronization result. Successful synchronization
    example: ```json {"class":"KeycloakOrgEntityProvider","level":"info","message":"Read
    3 Keycloak users and 2 Keycloak groups in 1.5 seconds. Committing...","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} {"class":"KeycloakOrgEntityProvider","level":"info","message":"Committed
    3 Keycloak users and 2 Keycloak groups in 0.0 seconds.","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} ``` After the first import is complete, go to the Catalog page and
    select User to view the list of users. When you select a user, you see the information
    imported from RHBK. You can select a group, view the list, and access or review
    the information imported from RHBK. You can log in with an RHBK account. # Enabling
    authentication with GitHub ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:23:37.744730'
    uuid: 133f9ff2-9341-4f14-9634-32700ce6bfd2
  response: To use a secure LDAP connection (ldaps://), you must mount your LDAP certificate
    and key files in your Developer Hub deployment by editing your Backstage custom
    resource. This involves adding an `extraFiles` section with a `mountPath` and
    specifying the secret name and keys. For low-level configuration of users and
    groups, you can define an `options` subsection. Within this, the `scope` option
    controls the search depth in the directory tree, with possible values being 'base'
    (only the base DN), 'one' (one level below), or 'sub' (all descendant entries).
    The `filter` option allows you to specify an LDAP filter; for users, it is recommended
    to use `(uid=*)` to ensure only users with a valid uid are synced, and for groups,
    `(cn=*)`. To enable paged results, you can enter a value for `paged`, set the
    `pageSize` (e.g., 500), and set `pagePause` to `true` to make the client wait
    for the next page of results. You can verify the provisioning by checking the
    console logs for a successful synchronization message, such as "Read 4 LDAP users
    and 6 LDAP groups in 0.3 seconds. Committing...".
  user_input: What are the detailed steps for configuring secure LDAP user and group
    provisioning in a Backstage instance, including mounting certificates and setting
    up specific options like search scope, filters, and paged results?
- context:
  - 'detected. ```yaml catalog: providers: ldapOrg: default: vendor: dnAttributeName:
    customDN uuidAttributeName: customUUID ``` dnAttributeName:: Enter the attribute
    name that holds the distinguished name (DN) for an entry. uuidAttributeName::
    Enter the attribute name that holds a universal unique identifier (UUID) for an
    entry. 7. Optional: Enter low level users and groups configuration in the options
    subsection. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: options: scope:
    sub filter: (uid= ) attributes: cn uid description paged: pageSize: 500 groups:
    options: scope: sub filter: (cn= ) attributes: cn uid description paged: pageSize:
    500 pagePause: true ``` scope:: To change the default value: one, enter how deep
    the search should go within the directory tree: * base to search only the base
    DN. * one to search one level below the base DN. * sub to search all descendant
    entries. filter:: To change the default value: (objectclass=*), enter your LDAP
    filter. With the default mapping: * For users, enter (uid=*) to make sure only
    users with valid uid field is synced, since users without uid will cause error
    and ingestion fails. * For groups, enter (cn=*) [TIP] ---- When you change the
    mapping, also update the filter. ---- attributes:: To change the default value:
    all attributes [''*'', ''+''], enter the array of attribute names to import from
    LDAP. paged:: Enter a value to enable paged results. pageSize:: Enter a value
    to set the results page size, such as 500. pagePause:: Enter true to tell the
    client to wait for the asynchronous results of the next page, when the page limit
    has been reached. 5. Recommended: To use a secure LDAP connection (ldaps://),
    mount your LDAP certificates and keys files in your Developer Hub deployment,
    by editing your Backstage custom resource. ``` kind: Backstage spec: application:
    extraFiles: mountPath: /opt/ldap secrets secrets: name: my rhdh database database
    secrets key: ldap certs.pem, ldap keys.pem ``` To verify user and group provisioning,
    check the console logs. Successful synchronization example: ```json 2025-10-15T20:45:49.072Z
    catalog info Read 4 LDAP users and 6 LDAP groups in 0.3 seconds. Committing...
    class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh" taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952"
    trace_id="6a318e2eadba84e20df773948668aa4c" span_id="cbec568cb6e64985" trace_flags="01"
    2025-10-15T20:45:49.075Z catalog info Committed 4 LDAP users and 6 LDAP groups
    in 0.0 seconds. class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh"
    taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952" trace_id="6a318e2eadba84e20df773948668aa4c"
    span_id="cbec568cb6e64985" trace_flags="01" ``` ## Creating a custom transformer
    to provision users from Red Hat Build of Keycloak (RHBK) to the software catalog
    Customize how Red Hat Developer Hub provisions users and groups to Red Hat Developer
    Hub software catalog entities, by creating a backend module that uses the keycloakTransformerExtensionPoint
    to offer custom user and group transformers for the Keycloak backend. You have
    enabled provisioning users from Red Hat Build of Keycloak (RHBK) to the software
    catalog. 1. Create a new backend module with the yarn new command. 2. Add your
    custom user and group transformers to the keycloakTransformerExtensionPoint. The
    following is an example plugins/<module_name>/src/module.ts file defining the
    backend module: ```javascript import { GroupTransformer, keycloakTransformerExtensionPoint,
    UserTransformer, } from ''@backstage community/plugin catalog backend module keycloak'';
    const customGroupTransformer: GroupTransformer = async ( entity, // entity output
    from default parser realm, // Keycloak realm name groups, // Keycloak group representation
    ) => { /* apply transformations */ return entity; }; const customUserTransformer:
    UserTransformer = async ( entity, // entity output from default parser user, //
    Keycloak user representation realm, // Keycloak realm name groups, // Keycloak
    group representation ) => { /* apply transformations */ return entity; }; export
    const keycloakBackendModuleTransformer = createBackendModule({ pluginId: ''catalog'',
    moduleId: ''keycloak-transformer'', register(reg) { reg.registerInit({ deps: {
    keycloak: keycloakTransformerExtensionPoint, }, async init({ keycloak }) { keycloak.setUserTransformer(customUserTransformer);
    keycloak.setGroupTransformer(customGroupTransformer); /* highlight-add-end */
    }, }); }, }); ``` [IMPORTANT] ---- Set the module''s pluginId to catalog to match
    the pluginId of the keycloak-backend; otherwise, the module fails to initialize.
    ---- 3. Install this new backend module into your Developer Hub backend. ```javascript
    backend.add(import(backstage plugin catalog backend module keycloak transformer))
    ``` Developer Hub imports the users and groups each time when started. Check the
    console logs to verify the synchronization result. Successful synchronization
    example: ```json {"class":"KeycloakOrgEntityProvider","level":"info","message":"Read
    3 Keycloak users and 2 Keycloak groups in 1.5 seconds. Committing...","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} {"class":"KeycloakOrgEntityProvider","level":"info","message":"Committed
    3 Keycloak users and 2 Keycloak groups in 0.0 seconds.","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} ``` After the first import is complete, go to the Catalog page and
    select User to view the list of users. When you select a user, you see the information
    imported from RHBK. You can select a group, view the list, and access or review
    the information imported from RHBK. You can log in with an RHBK account. # Enabling
    authentication with GitHub ##'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:24:17.145496'
    uuid: 81b985ea-a29c-485d-bd6c-6249d3aaa6c8
  response: To customize how Red Hat Developer Hub provisions users and groups from
    Red Hat Build of Keycloak (RHBK), you can create a backend module that uses the
    keycloakTransformerExtensionPoint. First, create a new backend module with the
    'yarn new' command. Then, add your custom user and group transformers to the keycloakTransformerExtensionPoint.
    The module's pluginId must be set to 'catalog' to match the pluginId of the keycloak-backend,
    otherwise the module will fail to initialize. Finally, you must install this new
    backend module into your Developer Hub backend.
  user_input: how i customize user provision in Red Hat Developer Hub from keycloak?
- context:
  - 'detected. ```yaml catalog: providers: ldapOrg: default: vendor: dnAttributeName:
    customDN uuidAttributeName: customUUID ``` dnAttributeName:: Enter the attribute
    name that holds the distinguished name (DN) for an entry. uuidAttributeName::
    Enter the attribute name that holds a universal unique identifier (UUID) for an
    entry. 7. Optional: Enter low level users and groups configuration in the options
    subsection. ```yaml catalog: providers: ldapOrg: default: target: ldaps://ds.example.net
    bind: dn: cn=admin,ou=Users,dc=rhdh secret: ${LDAP_SECRET} users: options: scope:
    sub filter: (uid= ) attributes: cn uid description paged: pageSize: 500 groups:
    options: scope: sub filter: (cn= ) attributes: cn uid description paged: pageSize:
    500 pagePause: true ``` scope:: To change the default value: one, enter how deep
    the search should go within the directory tree: * base to search only the base
    DN. * one to search one level below the base DN. * sub to search all descendant
    entries. filter:: To change the default value: (objectclass=*), enter your LDAP
    filter. With the default mapping: * For users, enter (uid=*) to make sure only
    users with valid uid field is synced, since users without uid will cause error
    and ingestion fails. * For groups, enter (cn=*) [TIP] ---- When you change the
    mapping, also update the filter. ---- attributes:: To change the default value:
    all attributes [''*'', ''+''], enter the array of attribute names to import from
    LDAP. paged:: Enter a value to enable paged results. pageSize:: Enter a value
    to set the results page size, such as 500. pagePause:: Enter true to tell the
    client to wait for the asynchronous results of the next page, when the page limit
    has been reached. 5. Recommended: To use a secure LDAP connection (ldaps://),
    mount your LDAP certificates and keys files in your Developer Hub deployment,
    by editing your Backstage custom resource. ``` kind: Backstage spec: application:
    extraFiles: mountPath: /opt/ldap secrets secrets: name: my rhdh database database
    secrets key: ldap certs.pem, ldap keys.pem ``` To verify user and group provisioning,
    check the console logs. Successful synchronization example: ```json 2025-10-15T20:45:49.072Z
    catalog info Read 4 LDAP users and 6 LDAP groups in 0.3 seconds. Committing...
    class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh" taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952"
    trace_id="6a318e2eadba84e20df773948668aa4c" span_id="cbec568cb6e64985" trace_flags="01"
    2025-10-15T20:45:49.075Z catalog info Committed 4 LDAP users and 6 LDAP groups
    in 0.0 seconds. class="LdapOrgEntityProvider" taskId="LdapOrgEntityProvider:default:refresh"
    taskInstanceId="9bb48fd5-2f55-4096-9fd0-61cee6679952" trace_id="6a318e2eadba84e20df773948668aa4c"
    span_id="cbec568cb6e64985" trace_flags="01" ``` ## Creating a custom transformer
    to provision users from Red Hat Build of Keycloak (RHBK) to the software catalog
    Customize how Red Hat Developer Hub provisions users and groups to Red Hat Developer
    Hub software catalog entities, by creating a backend module that uses the keycloakTransformerExtensionPoint
    to offer custom user and group transformers for the Keycloak backend. You have
    enabled provisioning users from Red Hat Build of Keycloak (RHBK) to the software
    catalog. 1. Create a new backend module with the yarn new command. 2. Add your
    custom user and group transformers to the keycloakTransformerExtensionPoint. The
    following is an example plugins/<module_name>/src/module.ts file defining the
    backend module: ```javascript import { GroupTransformer, keycloakTransformerExtensionPoint,
    UserTransformer, } from ''@backstage community/plugin catalog backend module keycloak'';
    const customGroupTransformer: GroupTransformer = async ( entity, // entity output
    from default parser realm, // Keycloak realm name groups, // Keycloak group representation
    ) => { /* apply transformations */ return entity; }; const customUserTransformer:
    UserTransformer = async ( entity, // entity output from default parser user, //
    Keycloak user representation realm, // Keycloak realm name groups, // Keycloak
    group representation ) => { /* apply transformations */ return entity; }; export
    const keycloakBackendModuleTransformer = createBackendModule({ pluginId: ''catalog'',
    moduleId: ''keycloak-transformer'', register(reg) { reg.registerInit({ deps: {
    keycloak: keycloakTransformerExtensionPoint, }, async init({ keycloak }) { keycloak.setUserTransformer(customUserTransformer);
    keycloak.setGroupTransformer(customGroupTransformer); /* highlight-add-end */
    }, }); }, }); ``` [IMPORTANT] ---- Set the module''s pluginId to catalog to match
    the pluginId of the keycloak-backend; otherwise, the module fails to initialize.
    ---- 3. Install this new backend module into your Developer Hub backend. ```javascript
    backend.add(import(backstage plugin catalog backend module keycloak transformer))
    ``` Developer Hub imports the users and groups each time when started. Check the
    console logs to verify the synchronization result. Successful synchronization
    example: ```json {"class":"KeycloakOrgEntityProvider","level":"info","message":"Read
    3 Keycloak users and 2 Keycloak groups in 1.5 seconds. Committing...","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} {"class":"KeycloakOrgEntityProvider","level":"info","message":"Committed
    3 Keycloak users and 2 Keycloak groups in 0.0 seconds.","plugin":"catalog","service":"backstage","taskId":"KeycloakOrgEntityProvider:default:refresh","taskInstanceId":"bf0467ff-8ac4-4702-911c-380270e44dea","timestamp":"2024-09-25
    13:58:04"} ``` After the first import is complete, go to the Catalog page and
    select User to view the list of users. When you select a user, you see the information
    imported from RHBK. You can select a group, view the list, and access or review
    the information imported from RHBK. You can log in with an RHBK account. # Enabling
    authentication with GitHub ##'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T16:24:27.468934'
    uuid: a0fc66bc-633e-4917-b615-8b8fe71c1fb4
  response: 'To customize how Red Hat Developer Hub provisions users and groups from
    Red Hat Build of Keycloak (RHBK) to the software catalog, you must create a backend
    module that utilizes the keycloakTransformerExtensionPoint. The process is as
    follows: First, create a new backend module with the ''yarn new'' command. Second,
    add your custom user and group transformers to the keycloakTransformerExtensionPoint.
    You can define a ''customUserTransformer'' and a ''customGroupTransformer'' and
    then register them in the module''s initialization with ''keycloak.setUserTransformer(customUserTransformer);''
    and ''keycloak.setGroupTransformer(customGroupTransformer);''. It is important
    that the module''s ''pluginId'' is set to ''catalog'' to match the ''keycloak-backend''
    plugin, or the module will fail to initialize. Finally, install the new backend
    module into your Developer Hub backend by adding the following line: ''backend.add(import(backstage
    plugin catalog backend module keycloak transformer))''.'
  user_input: How do i custmize the way users and groups from RHBK are provisined
    into the Red Hat Devloper Hub software catalog?
- context:
  - 'Enabling user authentication with GitHub, with optional steps Authenticate users
    with GitHub by provisioning the users and groups from GitHub to the Developer
    Hub software catalog, and configuring the GitHub authentication provider in Red
    Hat Developer Hub. You have enough permissions in GitHub to create and manage
    a GitHub App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare
    the required GitHub App. ---- * You have added a custom Developer Hub application
    configuration, and have enough permissions to change it. 1. Allow Developer Hub
    to authenticate with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub
    App instead of an OAuth app to use fine-grained permissions, use short-lived tokens,
    scale with the number of installations by avoiding rate limits, and have a more
    transparent integration by avoiding to request user input. ---- 1. Register a
    GitHub App with the following configuration: GitHub App name:: Enter a unique
    name identifying your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage
    URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>. Authorization
    callback URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and groups to the Developer Hub software catalog. ```yaml plugins: package:
    ''./dynamic plugins/dist/backstage plugin catalog backend module github org dynamic''
    disabled: false ``` 4. Enable provisioning GitHub users and groups to the Developer
    Hub software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. 1. Optional: Add optional
    fields to the GitHub authentication provider section in your app-config.yaml file:
    ```yaml auth: environment: production providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} callbackUrl: <your_intermediate_service_url/handler>
    sessionDuration: { hours: 24 } signIn: resolvers: - resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: github ``` callbackUrl::
    Enter the callback URL that GitHub uses when initiating an OAuth flow, such as:
    <your_intermediate_service_url/handler>. Define it when Developer Hub is not the
    immediate receiver, such as in cases when you use one OAuth app for many Developer
    Hub instances. sessionDuration:: Enter the user session lifespan, in ms library
    format (such as ''24h'', ''2 days''), ISO duration, or "human duration". signIn::
    resolvers:: After successful authentication, Developer Hub resolves the user signing
    in to an existing user in the Developer Hub catalog. Configure a specific resolver
    to best match users securely for your use case.. Enter the resolver list to override
    the default resolver: usernameMatchingUserEntityName. The authentication provider
    tries each sign-in resolver in order until it succeeds. If none of the attempts
    succeed, the sign-in fails. [WARNING] ---- In production mode, configure only
    one resolver to make sure users are securely matched. ---- resolver:: Enter the
    sign-in resolver name. Available resolvers: * usernameMatchingUserEntityName *
    preferredUsernameMatchingUserEntityName * emailMatchingUserEntityProfileEmail
    dangerouslyAllowSignInWithoutUserInCatalog:: Enter true to configure the sign-in
    resolver to bypass the user provisioning requirement in the Developer Hub software
    catalog. [WARNING] ---- In production more, do not enable dangerouslyAllowSignInWithoutUserInCatalog.
    ---- 1. Verify user and group provisioning by checking the console logs. Successful
    synchronization example: ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with GitHub
    as an auxiliary authentication provider If your primary authentication provider
    is not GitHub, users might lack the permissions needed for templates or plugins
    that require GitHub access. The recommended solution is to configure GitHub as
    an auxiliary authentication provider. This approach uses the primary provider
    for user identity management and the auxiliary provider to grant the necessary
    GitHub permissions, without re-resolving the user&#8217;s identity. Give users
    access to these features by configuring GitHub as an auxiliary authentication
    provider. You have enough permissions in GitHub to create and manage a GitHub
    App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:24:45.268961'
    uuid: fe0dd9ee-341b-4764-a4dd-438a79b30418
  response: When verifying user and group provisioning, the console logs identify
    the service as "backstage". This is related to enabling the GitHub catalog provider
    plugin to import GitHub users and groups into the Developer Hub software catalog.
    The configuration for this in the dynamic-plugins.yaml file specifies the package
    path as './dynamic plugins/dist/backstage plugin catalog backend module github
    org dynamic'.
  user_input: why the logs say service is backstage when im setting up github auth?
    what that mean for the catalog?
- context:
  - 'Enabling user authentication with GitHub, with optional steps Authenticate users
    with GitHub by provisioning the users and groups from GitHub to the Developer
    Hub software catalog, and configuring the GitHub authentication provider in Red
    Hat Developer Hub. You have enough permissions in GitHub to create and manage
    a GitHub App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare
    the required GitHub App. ---- * You have added a custom Developer Hub application
    configuration, and have enough permissions to change it. 1. Allow Developer Hub
    to authenticate with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub
    App instead of an OAuth app to use fine-grained permissions, use short-lived tokens,
    scale with the number of installations by avoiding rate limits, and have a more
    transparent integration by avoiding to request user input. ---- 1. Register a
    GitHub App with the following configuration: GitHub App name:: Enter a unique
    name identifying your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage
    URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>. Authorization
    callback URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and groups to the Developer Hub software catalog. ```yaml plugins: package:
    ''./dynamic plugins/dist/backstage plugin catalog backend module github org dynamic''
    disabled: false ``` 4. Enable provisioning GitHub users and groups to the Developer
    Hub software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. 1. Optional: Add optional
    fields to the GitHub authentication provider section in your app-config.yaml file:
    ```yaml auth: environment: production providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} callbackUrl: <your_intermediate_service_url/handler>
    sessionDuration: { hours: 24 } signIn: resolvers: - resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: github ``` callbackUrl::
    Enter the callback URL that GitHub uses when initiating an OAuth flow, such as:
    <your_intermediate_service_url/handler>. Define it when Developer Hub is not the
    immediate receiver, such as in cases when you use one OAuth app for many Developer
    Hub instances. sessionDuration:: Enter the user session lifespan, in ms library
    format (such as ''24h'', ''2 days''), ISO duration, or "human duration". signIn::
    resolvers:: After successful authentication, Developer Hub resolves the user signing
    in to an existing user in the Developer Hub catalog. Configure a specific resolver
    to best match users securely for your use case.. Enter the resolver list to override
    the default resolver: usernameMatchingUserEntityName. The authentication provider
    tries each sign-in resolver in order until it succeeds. If none of the attempts
    succeed, the sign-in fails. [WARNING] ---- In production mode, configure only
    one resolver to make sure users are securely matched. ---- resolver:: Enter the
    sign-in resolver name. Available resolvers: * usernameMatchingUserEntityName *
    preferredUsernameMatchingUserEntityName * emailMatchingUserEntityProfileEmail
    dangerouslyAllowSignInWithoutUserInCatalog:: Enter true to configure the sign-in
    resolver to bypass the user provisioning requirement in the Developer Hub software
    catalog. [WARNING] ---- In production more, do not enable dangerouslyAllowSignInWithoutUserInCatalog.
    ---- 1. Verify user and group provisioning by checking the console logs. Successful
    synchronization example: ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with GitHub
    as an auxiliary authentication provider If your primary authentication provider
    is not GitHub, users might lack the permissions needed for templates or plugins
    that require GitHub access. The recommended solution is to configure GitHub as
    an auxiliary authentication provider. This approach uses the primary provider
    for user identity management and the auxiliary provider to grant the necessary
    GitHub permissions, without re-resolving the user&#8217;s identity. Give users
    access to these features by configuring GitHub as an auxiliary authentication
    provider. You have enough permissions in GitHub to create and manage a GitHub
    App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:24:54.258772'
    uuid: e0a8fdab-fbc1-49a0-a603-eca020b37043
  response: To enable user authentication with GitHub in Red Hat Developer Hub, you
    must first create a GitHub App with a unique name, your Developer Hub URL as the
    Homepage URL, and your Developer Hub authentication backend URL as the Authorization
    callback URL, while enabling Read-only access to Members for Organization permissions.
    After generating and saving the Client ID and Client secret, you add these credentials,
    along with your GITHUB_URL and GITHUB_ORG, to your Developer Hub secrets. You
    must then enable the GitHub catalog provider plugin in your dynamic-plugins.yaml
    file. Following this, you enable provisioning of GitHub users and groups by adding
    the GitHub catalog provider section to your app-config.yaml file. The final step
    is to enable the GitHub authentication provider by adding its section to your
    app-config.yaml file, which includes the clientId, clientSecret, and sets the
    signInPage to github.
  user_input: how do i enable github auth in Red Hat Develper Hub?
- context:
  - 'Enabling user authentication with GitHub, with optional steps Authenticate users
    with GitHub by provisioning the users and groups from GitHub to the Developer
    Hub software catalog, and configuring the GitHub authentication provider in Red
    Hat Developer Hub. You have enough permissions in GitHub to create and manage
    a GitHub App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare
    the required GitHub App. ---- * You have added a custom Developer Hub application
    configuration, and have enough permissions to change it. 1. Allow Developer Hub
    to authenticate with GitHub, by creating a GitHub App. [NOTE] ---- Use a GitHub
    App instead of an OAuth app to use fine-grained permissions, use short-lived tokens,
    scale with the number of installations by avoiding rate limits, and have a more
    transparent integration by avoiding to request user input. ---- 1. Register a
    GitHub App with the following configuration: GitHub App name:: Enter a unique
    name identifying your GitHub App, such as authenticating-with-rhdh-<GUID>. Homepage
    URL:: Enter your Developer Hub URL: https://<my_developer_hub_domain>. Authorization
    callback URL:: Enter your Developer Hub authentication backend URL: https://<my_developer_hub_domain>/api/auth/github/handler/frame.
    Webhook:: Clear "Active". Organization permissions:: Enable Read-only access to
    Members. Where can this GitHub App be installed?:: Select Only on this account.
    2. In the General -> Clients secrets section, click Generate a new client secret.
    3. In the Install App tab, choose an account to install your GitHub App on. 4.
    Save the following values for the next step: * Client ID * Client secret 2. Add
    your GitHub credentials to Developer Hub by adding the following key/value pairs
    to your Developer Hub secrets. You can use these secrets in the Developer Hub
    configuration files by using their environment variable name. GITHUB_CLIENT_ID::
    Enter the saved Client ID. GITHUB_CLIENT_SECRET:: Enter the saved Client Secret.
    GITHUB_URL:: Enter the GitHub host domain: github.com. GITHUB_ORG:: Enter your
    GitHub organization name, such as <your_github_organization_name>. 3. Enable the
    GitHub catalog provider plugin in your dynamic-plugins.yaml file to import GitHub
    users and groups to the Developer Hub software catalog. ```yaml plugins: package:
    ''./dynamic plugins/dist/backstage plugin catalog backend module github org dynamic''
    disabled: false ``` 4. Enable provisioning GitHub users and groups to the Developer
    Hub software catalog by adding the GitHub catalog provider section to your app-config.yaml
    file: ```yaml catalog: providers: githubOrg: id: githuborg githubUrl: "${GITHUB_URL}"
    orgs: [ "${GITHUB_ORG}" ] schedule: frequency: minutes: 30 initialDelay: seconds:
    15 timeout: minutes: 15 ``` id:: Enter a stable identifier for this provider,
    such as githuborg. Entities from this provider are associated with this identifier.
    Therefore, do not to change the identifier over time since that might lead to
    orphaned entities or conflicts. githubUrl:: Enter the configured secret variable
    name: ${GITHUB_URL}. orgs:: Enter the configured secret variable name: ${GITHUB_ORG}.
    schedule.frequency:: Enter your schedule frequency, in the cron, ISO duration,
    or "human duration" format. schedule.timeout:: Enter your schedule timeout, in
    the ISO duration or "human duration" format. schedule.initialDelay:: Enter your
    schedule initial delay, in the ISO duration or "human duration" format. 1. Enable
    the GitHub authentication provider, by adding the GitHub authentication provider
    section to your app-config.yaml file: ```yaml auth: environment: production providers:
    github: production: clientId: ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET}
    signInPage: github ``` environment:: Enter production to disable the Guest login
    option in the Developer Hub login page. clientId:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_ID}. clientSecret:: Enter the configured secret
    variable name: ${GITHUB_CLIENT_SECRET}. signInPage:: Enter github to enable the
    GitHub provider as your Developer Hub sign-in provider. 1. Optional: Add optional
    fields to the GitHub authentication provider section in your app-config.yaml file:
    ```yaml auth: environment: production providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} callbackUrl: <your_intermediate_service_url/handler>
    sessionDuration: { hours: 24 } signIn: resolvers: - resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: github ``` callbackUrl::
    Enter the callback URL that GitHub uses when initiating an OAuth flow, such as:
    <your_intermediate_service_url/handler>. Define it when Developer Hub is not the
    immediate receiver, such as in cases when you use one OAuth app for many Developer
    Hub instances. sessionDuration:: Enter the user session lifespan, in ms library
    format (such as ''24h'', ''2 days''), ISO duration, or "human duration". signIn::
    resolvers:: After successful authentication, Developer Hub resolves the user signing
    in to an existing user in the Developer Hub catalog. Configure a specific resolver
    to best match users securely for your use case.. Enter the resolver list to override
    the default resolver: usernameMatchingUserEntityName. The authentication provider
    tries each sign-in resolver in order until it succeeds. If none of the attempts
    succeed, the sign-in fails. [WARNING] ---- In production mode, configure only
    one resolver to make sure users are securely matched. ---- resolver:: Enter the
    sign-in resolver name. Available resolvers: * usernameMatchingUserEntityName *
    preferredUsernameMatchingUserEntityName * emailMatchingUserEntityProfileEmail
    dangerouslyAllowSignInWithoutUserInCatalog:: Enter true to configure the sign-in
    resolver to bypass the user provisioning requirement in the Developer Hub software
    catalog. [WARNING] ---- In production more, do not enable dangerouslyAllowSignInWithoutUserInCatalog.
    ---- 1. Verify user and group provisioning by checking the console logs. Successful
    synchronization example: ```json {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Reading
    GitHub users and teams for org: rhdh-dast","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:58"} {"class":"GithubMultiOrgEntityProvider","level":"info","message":"Read
    7 GitHub users and 2 GitHub groups in 0.4 seconds. Committing...","plugin":"catalog","service":"backstage","target":"https://github.com","taskId":"GithubMultiOrgEntityProvider:githuborg:refresh","taskInstanceId":"801b3c6c-167f-473b-b43e-e0b4b780c384","timestamp":"2024-09-09
    23:55:59"} ``` 2. To verify GitHub authentication: 1. Go to the Developer Hub
    login page. 2. Your Developer Hub sign-in page displays Sign in using GitHub and
    the Guest user sign-in is disabled. 3. Log in with a GitHub account. Integrating
    Red Hat Developer Hub with GitHub ## Enabling user authentication with GitHub
    as an auxiliary authentication provider If your primary authentication provider
    is not GitHub, users might lack the permissions needed for templates or plugins
    that require GitHub access. The recommended solution is to configure GitHub as
    an auxiliary authentication provider. This approach uses the primary provider
    for user identity management and the auxiliary provider to grant the necessary
    GitHub permissions, without re-resolving the user&#8217;s identity. Give users
    access to these features by configuring GitHub as an auxiliary authentication
    provider. You have enough permissions in GitHub to create and manage a GitHub
    App. [TIP] ---- Alternatively, ask your GitHub administrator to prepare the required
    GitHub App. ---- * You have added a custom Developer Hub application configuration,
    and have enough'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:25:04.342995'
    uuid: f9f11bd2-e75e-4af0-be76-772c2ee339e9
  response: "To enable user authentication with GitHub in Red Hat Developer Hub, you\
    \ must follow these steps: \n1. Create a GitHub App with a unique name, your Developer\
    \ Hub URL as the Homepage URL, and `https://<my_developer_hub_domain>/api/auth/github/handler/frame`\
    \ as the Authorization callback URL. Set Organization permissions to \"Read-only\
    \ access to Members\" and install it on your account. Generate and save the Client\
    \ ID and Client secret.\n2. Add your GitHub credentials to Developer Hub secrets\
    \ using the keys GITHUB_CLIENT_ID, GITHUB_CLIENT_SECRET, GITHUB_URL, and GITHUB_ORG.\n\
    3. Enable the GitHub catalog provider plugin in your `dynamic-plugins.yaml` file\
    \ to import users and groups.\n4. Configure the provisioning of GitHub users and\
    \ groups in your `app-config.yaml` file by adding a `githubOrg` provider under\
    \ `catalog`, specifying the `id`, `githubUrl`, `orgs`, and `schedule`.\n5. Enable\
    \ the GitHub authentication provider in your `app-config.yaml` file by adding\
    \ a `github` section under `auth.providers`, setting the `environment` to `production`,\
    \ and configuring the `clientId` and `clientSecret` with the secret variables.\n\
    6. Optionally, add fields like `callbackUrl`, `sessionDuration`, and `signIn`\
    \ resolvers to the GitHub authentication provider section in `app-config.yaml`.\n\
    7. Verify the setup by checking console logs for successful synchronization and\
    \ confirming the Developer Hub login page shows the \"Sign in using GitHub\" option."
  user_input: What are the detailed steps for enabling user authentication with GitHub
    in Red Hat Developer Hub, including creating a GitHub App and configuring the
    necessary YAML files?
- context:
  - 'Enabling user authentication with Microsoft Azure, with optional steps Authenticate
    users with Microsoft Azure by provisioning the users and groups from Azure to
    the Developer Hub software catalog, and configuring the Azure authentication provider
    in Red Hat Developer Hub. You have the permission to register an application in
    Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the required
    Azure application. ---- * You added a custom Developer Hub application configuration,
    and have enough permissions to change it. * Your Developer Hub backend can access
    the following hosts: login.microsoftonline.com:: The Microsoft Azure authorization
    server, which enables the authentication flow. graph.microsoft.com:: The server
    for retrieving organization data, including user and group data, to import into
    the Developer Hub catalog. 1. Register your Developer Hub app in Azure, by using
    the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2. Optional:
    If you have access to multiple tenants, use the Settings icon in the top menu
    to switch to the tenant in which you want to register the application from the
    Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. 5. Optional: Add optional
    fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: authority: https://login.microsoftonline.com/
    queryMode: advanced user: expand: manager filter: accountEnabled eq true and userType
    eq ''member'' loadPhotos: true select: [''id'', ''displayName'', ''description'']
    userGroupMember: filter: "displayName eq ''Backstage Users''" search: ''"description:One"
    AND ("displayName:Video" OR "displayName:Drive")'' group: expand: member filter:
    securityEnabled eq false and mailEnabled eq true and groupTypes/any(c:c+eq+''Unified'')
    search: ''"description:One" AND ("displayName:Video" OR "displayName:Drive")''
    select: [''id'', ''displayName'', ''description''] ``` authority:: Enter your
    Azure authority URL if it is different from the default: https://login.microsoftonline.com.
    queryMode:: Enter advanced when the default basic query mode is insufficient for
    your queries to the Microsoft Graph API. See Microsoft Azure advanced queries.
    user:: Add this section to configure optional user query parameters. expand::
    Enter your expansion parameter to include the expanded resource or collection
    referenced by a single relationship (navigation property) in your results. A single
    request can expand only one relationship. See Microsoft Graph query expand parameter.
    You can combine this parameter with userGroupMember.filter or user.filter. filter::
    Enter your user filter. See Microsoft Graph API and Microsoft Graph API query
    filter parameters syntax. This parameter and userGroupMember.filter are mutually
    exclusive, specify only one. loadPhotos:: Developer Hub loads photos by default.
    Enter false to avoid loading user photos. select:: Enter the Microsoft Graph resource
    type list to retrieve. userGroupMember:: Add this section to use group membership
    to get users. filter:: Enter your filter to filter groups and fetch their members.
    This parameter and user.filter are mutually exclusive, specify only one. search::
    Enter your search query to search for groups and fetch their members. This parameter
    and user.filter are mutually exclusive, specify only one. group:: Enter your configuration
    to get groups. expand:: Enter your expansion parameter to include the expanded
    resource or collection referenced by a single relationship (navigation property)
    in your results. A single request can expand only one relationship. See Customize
    Microsoft Graph responses with query parameters. You can combine this parameter
    with user.filter or userGroupMember.filter. filter:: Enter your group filter parameter.
    See Microsoft Graph API query group syntax. search:: Enter your group search'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:25:18.911944'
    uuid: 4c1a6245-9ed4-427b-867b-99ec8e2fac70
  response: "To enable provisioning of Azure users and groups to the Developer Hub\
    \ software catalog, you must add the Microsoft Graph catalog provider section\
    \ to your app-config.yaml file. The required configuration includes:\n\n*   `target`:\
    \ The MSGraph API endpoint, typically https://graph.microsoft.com/v1.0.\n*   `tenantId`:\
    \ The configured secret variable name, ${MICROSOFT_TENANT_ID}.\n*   `clientId`:\
    \ The configured secret variable name, ${MICROSOFT_CLIENT_ID}.\n*   `clientSecret`:\
    \ The configured secret variable name, ${MICROSOFT_CLIENT_SECRET}.\n*   `schedule`:\
    \ This includes `frequency`, `timeout`, and `initialDelay` to define the schedule\
    \ for user provisioning.\n\nAdditionally, you can add several optional fields\
    \ to the Microsoft authentication provider section in your app-config.yaml file:\n\
    \n*   `authority`: Your Azure authority URL if it differs from the default.\n\
    *   `queryMode`: Set to 'advanced' if the basic query mode is insufficient.\n\
    *   `user`: A section for optional user query parameters, including:\n    *  \
    \ `expand`: To include an expanded resource or collection.\n    *   `filter`:\
    \ To specify a user filter.\n    *   `loadPhotos`: Set to 'false' to avoid loading\
    \ user photos.\n    *   `select`: To list the Microsoft Graph resource types to\
    \ retrieve.\n*   `userGroupMember`: A section to get users based on group membership,\
    \ with options for `filter` or `search`.\n*   `group`: A section to configure\
    \ how groups are retrieved, with options for `expand`, `filter`, and `search`."
  user_input: I'm tryin to set up user provisoning from Azure in Developer Hub, and
    I'm stuck on the app-config.yaml file. Wht are all the required configuraton settings
    I need to add in the Microsoft Graph catalog provider sectoin of the app-config.yaml
    file, and can you also list out some of the optional fields I could add to customize
    the user and group queries?
- context:
  - 'Enabling user authentication with Microsoft Azure, with optional steps Authenticate
    users with Microsoft Azure by provisioning the users and groups from Azure to
    the Developer Hub software catalog, and configuring the Azure authentication provider
    in Red Hat Developer Hub. You have the permission to register an application in
    Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the required
    Azure application. ---- * You added a custom Developer Hub application configuration,
    and have enough permissions to change it. * Your Developer Hub backend can access
    the following hosts: login.microsoftonline.com:: The Microsoft Azure authorization
    server, which enables the authentication flow. graph.microsoft.com:: The server
    for retrieving organization data, including user and group data, to import into
    the Developer Hub catalog. 1. Register your Developer Hub app in Azure, by using
    the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2. Optional:
    If you have access to multiple tenants, use the Settings icon in the top menu
    to switch to the tenant in which you want to register the application from the
    Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. 5. Optional: Add optional
    fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: authority: https://login.microsoftonline.com/
    queryMode: advanced user: expand: manager filter: accountEnabled eq true and userType
    eq ''member'' loadPhotos: true select: [''id'', ''displayName'', ''description'']
    userGroupMember: filter: "displayName eq ''Backstage Users''" search: ''"description:One"
    AND ("displayName:Video" OR "displayName:Drive")'' group: expand: member filter:
    securityEnabled eq false and mailEnabled eq true and groupTypes/any(c:c+eq+''Unified'')
    search: ''"description:One" AND ("displayName:Video" OR "displayName:Drive")''
    select: [''id'', ''displayName'', ''description''] ``` authority:: Enter your
    Azure authority URL if it is different from the default: https://login.microsoftonline.com.
    queryMode:: Enter advanced when the default basic query mode is insufficient for
    your queries to the Microsoft Graph API. See Microsoft Azure advanced queries.
    user:: Add this section to configure optional user query parameters. expand::
    Enter your expansion parameter to include the expanded resource or collection
    referenced by a single relationship (navigation property) in your results. A single
    request can expand only one relationship. See Microsoft Graph query expand parameter.
    You can combine this parameter with userGroupMember.filter or user.filter. filter::
    Enter your user filter. See Microsoft Graph API and Microsoft Graph API query
    filter parameters syntax. This parameter and userGroupMember.filter are mutually
    exclusive, specify only one. loadPhotos:: Developer Hub loads photos by default.
    Enter false to avoid loading user photos. select:: Enter the Microsoft Graph resource
    type list to retrieve. userGroupMember:: Add this section to use group membership
    to get users. filter:: Enter your filter to filter groups and fetch their members.
    This parameter and user.filter are mutually exclusive, specify only one. search::
    Enter your search query to search for groups and fetch their members. This parameter
    and user.filter are mutually exclusive, specify only one. group:: Enter your configuration
    to get groups. expand:: Enter your expansion parameter to include the expanded
    resource or collection referenced by a single relationship (navigation property)
    in your results. A single request can expand only one relationship. See Customize
    Microsoft Graph responses with query parameters. You can combine this parameter
    with user.filter or userGroupMember.filter. filter:: Enter your group filter parameter.
    See Microsoft Graph API query group syntax. search:: Enter your group search'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:25:27.270172'
    uuid: 5c9b9ad1-7fb9-4a6f-a911-ba48abfea141
  response: 'After signing in to the Microsoft Entra admin center, you can optionally
    switch to the tenant where you want to register the application. Then, browse
    to Applications > App registrations and create a New registration with the following
    configuration: provide a name for the application, select "Accounts in this organizational
    directory only" for Supported account types, and for the Redirect URI, select
    the Web platform and enter the URL "https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame".
    Next, on the API permissions page, add a permission for Microsoft Graph, selecting
    Application Permissions for "GroupMember.Read.All" and "User.Read.All", and Delegated
    Permissions for "User.Read", "email", "offline_access", "openid", and "profile".
    Following that, on the Certificates & secrets page, go to the Client secrets tab
    and create a New client secret. Finally, you must save the Directory (tenant)
    ID, Application (client) ID, and Application (client) Secret ID for the next step.'
  user_input: I'm trying to get our Developer Hub app set up with Azure authentication,
    can you tell me what are all the specific steps I need to do inside the Microsft
    Entra admin center after I sign in to get the app registration done correctly?
- context:
  - 'Enabling user authentication with Microsoft Azure, with optional steps Authenticate
    users with Microsoft Azure by provisioning the users and groups from Azure to
    the Developer Hub software catalog, and configuring the Azure authentication provider
    in Red Hat Developer Hub. You have the permission to register an application in
    Azure. [TIP] ---- Alternatively, ask your Azure administrator to prepare the required
    Azure application. ---- * You added a custom Developer Hub application configuration,
    and have enough permissions to change it. * Your Developer Hub backend can access
    the following hosts: login.microsoftonline.com:: The Microsoft Azure authorization
    server, which enables the authentication flow. graph.microsoft.com:: The server
    for retrieving organization data, including user and group data, to import into
    the Developer Hub catalog. 1. Register your Developer Hub app in Azure, by using
    the Azure portal. 1. Sign in to the Microsoft Entra admin center. 2. Optional:
    If you have access to multiple tenants, use the Settings icon in the top menu
    to switch to the tenant in which you want to register the application from the
    Directories + subscriptions menu. 3. Browse to Applications > App registrations,
    and create a New registration with the configuration: Name:: Enter a name to identify
    your application in Azure, such as {my-product-app-name-in-azure}. Supported account
    types:: Select Accounts in this organizational directory only. Redirect URI::
    Select a platform:: Select Web. URL:: Enter the backend authentication URI set
    in Developer Hub: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame
    4. On the Applications > App registrations > {my-product-app-name-in-azure} >
    Manage > API permissions page, Add a Permission, Microsoft Graph, select the following
    permissions: Application Permissions:: GroupMember.Read.All, User.Read.All:: Enter
    permissions that enable provisioning user and groups to the Developer Hub software
    catalog. Optional: Grant admin consent for these permissions. Even if your company
    does not require admin consent, consider doing so as it means users do not need
    to individually consent the first time they access Developer Hub. Delegated Permissions::
    User.Read, email, offline_access, openid, profile:: Enter permissions that enable
    authenticating users. Optional: Enter optional custom scopes for the Microsoft
    Graph API that you define both here and in your app-config.yaml Developer Hub
    configuration file. 5. On the Applications > App registrations > {my-product-app-name-in-azure}
    > Manage > Certificates & secrets page, in the Client secrets tab, create a New
    client secret. 6. Save the following values for the next step: * Directory (tenant)
    ID * Application (client) ID * Application (client) Secret ID 2. Add your Azure
    credentials to Developer Hub, by adding the following key/value pairs to your
    Developer Hub secrets: MICROSOFT_TENANT_ID:: Enter your saved Directory (tenant)
    ID. MICROSOFT_CLIENT_ID:: Enter your saved Application (client) ID. MICROSOFT_CLIENT_SECRET::
    Enter your saved Application (client) secret. 3. Enable the Microsoft Graph catalog
    provider plugin in your dynamic-plugins.yaml file. This plugin imports Azure users
    and groups to the Developer Hub software catalog. ```yaml plugins: package: ''./dynamic
    plugins/dist/backstage plugin catalog backend module msgraph dynamic'' disabled:
    false ``` 4. Enable provisioning Azure users and groups to the Developer Hub software
    catalog, by adding the Microsoft Graph catalog provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: target: https://graph.microsoft.com/v1.0
    tenantId: ${MICROSOFT_TENANT_ID} clientId: ${MICROSOFT_CLIENT_ID} clientSecret:
    ${MICROSOFT_CLIENT_SECRET} schedule: frequency: hours: 1 timeout: minutes: 50
    initialDelay: minutes: 50 ``` target:: Enter https://graph.microsoft.com/v1.0
    to define the MSGraph API endpoint the provider is connecting to. You might change
    this parameter to use a different version, such as the beta endpoint. tenandId::
    Enter the configured secret variable name: ${MICROSOFT_TENANT_ID}. clientId::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret::
    Enter the configured secret variable name: ${MICROSOFT_CLIENT_SECRET}. schedule::
    frequency:: Enter the schedule frequency in the cron, ISO duration, or human duration
    format. In a large organization, user provisioning might take a long time, therefore
    avoid using a low value. timeout:: Enter the schedule timeout in the ISO duration
    or human duration format. In a large organization, user provisioning might take
    a long time, therefore avoid using a low value. initialDelay:: Enter the schedule
    initial delay in the ISO duration or human duration format. 5. Optional: Add optional
    fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml catalog: providers: microsoftGraphOrg: providerId: authority: https://login.microsoftonline.com/
    queryMode: advanced user: expand: manager filter: accountEnabled eq true and userType
    eq ''member'' loadPhotos: true select: [''id'', ''displayName'', ''description'']
    userGroupMember: filter: "displayName eq ''Backstage Users''" search: ''"description:One"
    AND ("displayName:Video" OR "displayName:Drive")'' group: expand: member filter:
    securityEnabled eq false and mailEnabled eq true and groupTypes/any(c:c+eq+''Unified'')
    search: ''"description:One" AND ("displayName:Video" OR "displayName:Drive")''
    select: [''id'', ''displayName'', ''description''] ``` authority:: Enter your
    Azure authority URL if it is different from the default: https://login.microsoftonline.com.
    queryMode:: Enter advanced when the default basic query mode is insufficient for
    your queries to the Microsoft Graph API. See Microsoft Azure advanced queries.
    user:: Add this section to configure optional user query parameters. expand::
    Enter your expansion parameter to include the expanded resource or collection
    referenced by a single relationship (navigation property) in your results. A single
    request can expand only one relationship. See Microsoft Graph query expand parameter.
    You can combine this parameter with userGroupMember.filter or user.filter. filter::
    Enter your user filter. See Microsoft Graph API and Microsoft Graph API query
    filter parameters syntax. This parameter and userGroupMember.filter are mutually
    exclusive, specify only one. loadPhotos:: Developer Hub loads photos by default.
    Enter false to avoid loading user photos. select:: Enter the Microsoft Graph resource
    type list to retrieve. userGroupMember:: Add this section to use group membership
    to get users. filter:: Enter your filter to filter groups and fetch their members.
    This parameter and user.filter are mutually exclusive, specify only one. search::
    Enter your search query to search for groups and fetch their members. This parameter
    and user.filter are mutually exclusive, specify only one. group:: Enter your configuration
    to get groups. expand:: Enter your expansion parameter to include the expanded
    resource or collection referenced by a single relationship (navigation property)
    in your results. A single request can expand only one relationship. See Customize
    Microsoft Graph responses with query parameters. You can combine this parameter
    with user.filter or userGroupMember.filter. filter:: Enter your group filter parameter.
    See Microsoft Graph API query group syntax. search:: Enter your group search'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:25:40.422816'
    uuid: 88cccd2e-1dd9-413a-9cf7-ce3d3e1971bd
  response: 'To enable user authentication with Microsoft Azure, you must first register
    your Developer Hub application in the Azure portal. Sign in to the Microsoft Entra
    admin center, navigate to "Applications > App registrations", and create a "New
    registration". Configure it with a name, set "Supported account types" to "Accounts
    in this organizational directory only", and for the "Redirect URI", select the
    "Web" platform and enter the URL: https://<my_developer_hub_domain>/api/auth/microsoft/handler/frame.
    Next, on the "API permissions" page for your app, add permissions for Microsoft
    Graph. For "Application Permissions", add "GroupMember.Read.All" and "User.Read.All".
    For "Delegated Permissions", add "User.Read", "email", "offline_access", "openid",
    and "profile". Then, on the "Certificates & secrets" page, create a "New client
    secret" and save the "Directory (tenant) ID", "Application (client) ID", and the
    client secret value. After obtaining these credentials, add them to your Developer
    Hub secrets with the keys MICROSOFT_TENANT_ID, MICROSOFT_CLIENT_ID, and MICROSOFT_CLIENT_SECRET.
    You must also enable the Microsoft Graph catalog provider plugin in your dynamic-plugins.yaml
    file by ensuring the package ''./dynamic plugins/dist/backstage plugin catalog
    backend module msgraph dynamic'' is not disabled. Finally, in your app-config.yaml
    file, enable provisioning by adding the Microsoft Graph catalog provider section
    with the target set to https://graph.microsoft.com/v1.0 and the tenantId, clientId,
    and clientSecret configured to use the secret variables you just set (${MICROSOFT_TENANT_ID},
    ${MICROSOFT_CLIENT_ID}, ${MICROSOFT_CLIENT_SECRET}).'
  user_input: I'm tryin to setup our Developer Hub to sync with our company's Azure
    AD for user authntication and to get our users and groups into the software catalog,
    but I'm a bit lost. Can someone outline all the nessessary steps, like what exactlly
    do I need to register in the Azure portal, what API permisions are required, and
    what are the specific key/value pairs I need to put in my secrets and the app-config.yaml
    file to get the Microsoft Graph provider workin correctly?
- context:
  - 'permissions to change it. * You have configured a primary authentication provider
    to provision user and group identities to the Red Hat Developer Hub software catalog,
    and establish Developer Hub user sessions. 1. Add the auth.providers.github section
    to your app-config.yaml file: ```yaml auth: providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} disableIdentityResolution:
    true ``` where: clientId:: Enter the configured secret variable name: ${GITHUB_CLIENT_ID}.
    clientSecret:: Enter the configured secret variable name: ${GITHUB_CLIENT_SECRET}.
    disableIdentityResolution:: Enter true to skip user identity resolution for this
    provider to enable sign-in from an auxiliary authentication provider. [WARNING]
    ---- Do not enable this setting on the primary authentication provider you plan
    on using for sign-in and identity management. ---- 1. Go to the Developer Hub
    login page. 2. Log in with your primary authentication provider account. 3. In
    the top user menu, go to Settings > Authentication Providers. 4. In the GitHub
    line, click the Sign in button and log in. 5. In the GitHub line, the button displays
    Sign out. Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:25:52.297100'
    uuid: 5ee58dc4-9d29-489b-a7a6-ceb408c5e134
  response: 'For the clientId, you must enter the configured secret variable name:
    ${GITHUB_CLIENT_ID}.'
  user_input: I'm trying to configure the GitHub provider, what value am I suposed
    to use for the clintId in the app-config.yaml?
- context:
  - 'permissions to change it. * You have configured a primary authentication provider
    to provision user and group identities to the Red Hat Developer Hub software catalog,
    and establish Developer Hub user sessions. 1. Add the auth.providers.github section
    to your app-config.yaml file: ```yaml auth: providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} disableIdentityResolution:
    true ``` where: clientId:: Enter the configured secret variable name: ${GITHUB_CLIENT_ID}.
    clientSecret:: Enter the configured secret variable name: ${GITHUB_CLIENT_SECRET}.
    disableIdentityResolution:: Enter true to skip user identity resolution for this
    provider to enable sign-in from an auxiliary authentication provider. [WARNING]
    ---- Do not enable this setting on the primary authentication provider you plan
    on using for sign-in and identity management. ---- 1. Go to the Developer Hub
    login page. 2. Log in with your primary authentication provider account. 3. In
    the top user menu, go to Settings > Authentication Providers. 4. In the GitHub
    line, click the Sign in button and log in. 5. In the GitHub line, the button displays
    Sign out. Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:26:08.434709'
    uuid: c372b794-ba4d-4ccb-9882-6e49fce1ac2e
  response: For the clientSecret parameter, you must enter the configured secret variable
    name, which is ${GITHUB_CLIENT_SECRET}.
  user_input: When configuring the GitHub authentication provider in the app-config.yaml
    file, what specific value should be entered for the clientSecret parameter?
- context:
  - 'permissions to change it. * You have configured a primary authentication provider
    to provision user and group identities to the Red Hat Developer Hub software catalog,
    and establish Developer Hub user sessions. 1. Add the auth.providers.github section
    to your app-config.yaml file: ```yaml auth: providers: github: production: clientId:
    ${GITHUB_CLIENT_ID} clientSecret: ${GITHUB_CLIENT_SECRET} disableIdentityResolution:
    true ``` where: clientId:: Enter the configured secret variable name: ${GITHUB_CLIENT_ID}.
    clientSecret:: Enter the configured secret variable name: ${GITHUB_CLIENT_SECRET}.
    disableIdentityResolution:: Enter true to skip user identity resolution for this
    provider to enable sign-in from an auxiliary authentication provider. [WARNING]
    ---- Do not enable this setting on the primary authentication provider you plan
    on using for sign-in and identity management. ---- 1. Go to the Developer Hub
    login page. 2. Log in with your primary authentication provider account. 3. In
    the top user menu, go to Settings > Authentication Providers. 4. In the GitHub
    line, click the Sign in button and log in. 5. In the GitHub line, the button displays
    Sign out. Integrating Red Hat Developer Hub with GitHub #'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:26:17.630078'
    uuid: 916395d5-8553-4405-a51d-35e890e1d78e
  response: "To configure GitHub as an auxiliary authentication provider, you must\
    \ first have a primary authentication provider configured. Then, add the `auth.providers.github`\
    \ section to your `app-config.yaml` file as follows: \n```yaml\nauth:\n  providers:\n\
    \    github:\n      production:\n        clientId: ${GITHUB_CLIENT_ID}\n     \
    \   clientSecret: ${GITHUB_CLIENT_SECRET}\n        disableIdentityResolution:\
    \ true\n```\nIn this configuration, `clientId` and `clientSecret` are the configured\
    \ secret variable names. The `disableIdentityResolution` field should be set to\
    \ `true` to skip user identity resolution, which is necessary for an auxiliary\
    \ provider. It is warned not to enable this setting on the primary authentication\
    \ provider. After configuration, the user login process is: 1. Go to the Developer\
    \ Hub login page and log in with the primary authentication provider account.\
    \ 2. Navigate to Settings > Authentication Providers in the top user menu. 3.\
    \ Find the GitHub line and click the \"Sign in\" button to log in. The button\
    \ will then display \"Sign out\"."
  user_input: What are the specific configuration steps in the app-config.yaml file
    for adding GitHub as an auxiliary authentication provider in Red Hat Developer
    Hub, and what is the subsequent user login process?
- context:
  - 'parameter. See Microsoft Graph API query search parameter. select:: Enter the
    Microsoft Graph resource type list to retrieve. 6. Enable Azure authentication,
    by adding the Microsoft authentication provider to your app-config.yaml file content:
    ```yaml auth: environment: production providers: microsoft: production: clientId:
    ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID}
    signInPage: microsoft ``` environment:: Enter production to disable the Guest
    login option in the Developer Hub login page. clientId:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured
    secret variable name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to
    set the Azure provider as your Developer Hub sign-in provider. 7. Optional: Add
    optional fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml auth: environment: production providers: microsoft: production:
    clientId: ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId:
    ${MICROSOFT_TENANT_ID} domainHint: ${MICROSOFT_TENANT_ID} additionalScopes: Mail.Send
    sessionDuration: hours: 24 signIn: resolvers: resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: microsoft ``` domainHint::
    * Leave this parameter empty, or enter the tenant ID when your application registration
    is single-tenant. * Leave this parameter empty when your application registration
    is multi-tenant. * Enter the tenant ID to reduce login friction for users with
    accounts in multiple tenants, by automatically filtering out accounts from other
    tenants. For more information, see Home Realm Discovery. additionalScopes:: Enter
    the list of additional scopes to add scopes for the application registration.
    The default and mandatory value lists following scopes: * openid * offline_access
    * profile * email * User.Read sessionDuration:: Lifespan of the user session.
    Enter a duration in ms library (such as ''24h'', ''2 days''), ISO duration, or
    "human duration" format. signIn.resolvers:: After successful authentication, Developer
    Hub resolves the user signing in to an existing user in the Developer Hub catalog.
    To best match users securely for your use case, consider configuring a specific
    resolver. Enter the resolver list to override the default resolver: userIdMatchingUserEntityAnnotation.
    The authentication provider tries each sign-in resolver in order until it succeeds,
    and fails if none succeed. [WARNING] ---- In production mode, configure only one
    resolver to make sure users are securely matched. ---- resolver:: Enter the sign-in
    resolver name. Available resolvers: emailMatchingUserEntityAnnotation:: Use this
    resolver to look up the user by matching their Microsoft email to the email entity
    annotation. emailLocalPartMatchingUserEntityName:: Use this resolver to look up
    the user by matching their Microsoft email user name to the user entity name.
    emailMatchingUserEntityProfileEmail:: Use this resolver to look up the user by
    matching their Microsoft email to the user entity profile email. dangerouslyAllowSignInWithoutUserInCatalog::
    Enter true to configure the sign-in resolver to bypass the user provisioning requirement
    in the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable dangerouslyAllowSignInWithoutUserInCatalog. ---- 1. To verify user and
    group provisioning, check the console logs for MicrosoftGraphOrgEntityProvider
    events. Successful synchronization example: ``` 2025-06-23T13:37:55.804Z catalog
    info Read 9 msgraph users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Troubleshooting authentication issues Learn how to troubleshoot
    authentication issues. ## Reducing the size of issued tokens By default, the authentication
    backend issues user identity tokens with ownership references of the user in the
    ent claim of the JSON Web Token (JWT) payload. This makes it easier for consumers
    of the token to resolve ownership of the user. However, depending on the structure
    of your organization and how you resolve ownership claims, the tokens can grow
    large and cause HTTP errors that prevent you from accessing parts of RHDH. Use
    the omitIdentityTokenOwnershipClaim flag to remove the ent claim from tokens and
    reduce their size. 1. In the app-config.yaml file, set omitIdentityTokenOwnershipClaim
    to true as follows: ```yaml auth: omitIdentityTokenOwnershipClaim: true ```'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:26:28.341993'
    uuid: beb6c49b-35b9-4762-89d7-ab2973ea72c1
  response: 'To enable Microsoft authentication, you must add the Microsoft authentication
    provider to your `app-config.yaml` file. The mandatory configuration includes
    setting `environment` to `production` to disable the Guest login option. You must
    also provide the `clientId`, `clientSecret`, and `tenantId` using their configured
    secret variable names (${MICROSOFT_CLIENT_ID}, ${MICROSOFT_CLIENT_SECRET}, ${MICROSOFT_TENANT_ID}).
    Additionally, `signInPage` must be set to `microsoft` to designate the Azure provider
    as the sign-in provider for Developer Hub.


    Optionally, you can add several other fields. The `domainHint` can be left empty
    or set to the tenant ID to reduce login friction for users with accounts in multiple
    tenants. The `additionalScopes` field allows you to add a list of extra scopes
    for the application registration, beyond the default and mandatory scopes of `openid`,
    `offline_access`, `profile`, `email`, and `User.Read`. You can set the `sessionDuration`
    to define the lifespan of a user session. The `signIn.resolvers` section can be
    used to override the default resolver for matching an authenticated user to a
    user in the Developer Hub catalog; available resolvers include `emailMatchingUserEntityAnnotation`,
    `emailLocalPartMatchingUserEntityName`, and `emailMatchingUserEntityProfileEmail`.
    Finally, the `dangerouslyAllowSignInWithoutUserInCatalog` parameter can be set
    to `true` to bypass the user provisioning requirement, though this is not recommended
    for production environments.'
  user_input: As a Platform Engineer configuring Red Hat Developer Hub, could you
    please provide a comprehensive breakdown of all the mandatory and optional parameters
    required in the `app-config.yaml` file to properly set up the Microsoft authentication
    provider, including a description of what each parameter controls?
- context:
  - 'parameter. See Microsoft Graph API query search parameter. select:: Enter the
    Microsoft Graph resource type list to retrieve. 6. Enable Azure authentication,
    by adding the Microsoft authentication provider to your app-config.yaml file content:
    ```yaml auth: environment: production providers: microsoft: production: clientId:
    ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID}
    signInPage: microsoft ``` environment:: Enter production to disable the Guest
    login option in the Developer Hub login page. clientId:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured
    secret variable name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to
    set the Azure provider as your Developer Hub sign-in provider. 7. Optional: Add
    optional fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml auth: environment: production providers: microsoft: production:
    clientId: ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId:
    ${MICROSOFT_TENANT_ID} domainHint: ${MICROSOFT_TENANT_ID} additionalScopes: Mail.Send
    sessionDuration: hours: 24 signIn: resolvers: resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: microsoft ``` domainHint::
    * Leave this parameter empty, or enter the tenant ID when your application registration
    is single-tenant. * Leave this parameter empty when your application registration
    is multi-tenant. * Enter the tenant ID to reduce login friction for users with
    accounts in multiple tenants, by automatically filtering out accounts from other
    tenants. For more information, see Home Realm Discovery. additionalScopes:: Enter
    the list of additional scopes to add scopes for the application registration.
    The default and mandatory value lists following scopes: * openid * offline_access
    * profile * email * User.Read sessionDuration:: Lifespan of the user session.
    Enter a duration in ms library (such as ''24h'', ''2 days''), ISO duration, or
    "human duration" format. signIn.resolvers:: After successful authentication, Developer
    Hub resolves the user signing in to an existing user in the Developer Hub catalog.
    To best match users securely for your use case, consider configuring a specific
    resolver. Enter the resolver list to override the default resolver: userIdMatchingUserEntityAnnotation.
    The authentication provider tries each sign-in resolver in order until it succeeds,
    and fails if none succeed. [WARNING] ---- In production mode, configure only one
    resolver to make sure users are securely matched. ---- resolver:: Enter the sign-in
    resolver name. Available resolvers: emailMatchingUserEntityAnnotation:: Use this
    resolver to look up the user by matching their Microsoft email to the email entity
    annotation. emailLocalPartMatchingUserEntityName:: Use this resolver to look up
    the user by matching their Microsoft email user name to the user entity name.
    emailMatchingUserEntityProfileEmail:: Use this resolver to look up the user by
    matching their Microsoft email to the user entity profile email. dangerouslyAllowSignInWithoutUserInCatalog::
    Enter true to configure the sign-in resolver to bypass the user provisioning requirement
    in the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable dangerouslyAllowSignInWithoutUserInCatalog. ---- 1. To verify user and
    group provisioning, check the console logs for MicrosoftGraphOrgEntityProvider
    events. Successful synchronization example: ``` 2025-06-23T13:37:55.804Z catalog
    info Read 9 msgraph users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Troubleshooting authentication issues Learn how to troubleshoot
    authentication issues. ## Reducing the size of issued tokens By default, the authentication
    backend issues user identity tokens with ownership references of the user in the
    ent claim of the JSON Web Token (JWT) payload. This makes it easier for consumers
    of the token to resolve ownership of the user. However, depending on the structure
    of your organization and how you resolve ownership claims, the tokens can grow
    large and cause HTTP errors that prevent you from accessing parts of RHDH. Use
    the omitIdentityTokenOwnershipClaim flag to remove the ent claim from tokens and
    reduce their size. 1. In the app-config.yaml file, set omitIdentityTokenOwnershipClaim
    to true as follows: ```yaml auth: omitIdentityTokenOwnershipClaim: true ```'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:26:36.285250'
    uuid: 0900eef3-c14c-4229-b9cd-85a246d2cd9f
  response: The authentication backend issues user identity tokens with ownership
    references in the 'ent' claim of the JSON Web Token (JWT) payload, which can cause
    tokens to grow large and result in HTTP errors. To reduce the size of the tokens,
    you can use the 'omitIdentityTokenOwnershipClaim' flag to remove the 'ent' claim.
    In your app-config.yaml file, set 'omitIdentityTokenOwnershipClaim' to true under
    the 'auth' section.
  user_input: My users are getting HTTP erors when they try to access some parts of
    RHDH, and I think its becuase the JSON Web Token payload is geting too big. Is
    there a way to remove the ownership claims or something to reduce the tokin size?
- context:
  - 'parameter. See Microsoft Graph API query search parameter. select:: Enter the
    Microsoft Graph resource type list to retrieve. 6. Enable Azure authentication,
    by adding the Microsoft authentication provider to your app-config.yaml file content:
    ```yaml auth: environment: production providers: microsoft: production: clientId:
    ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId: ${MICROSOFT_TENANT_ID}
    signInPage: microsoft ``` environment:: Enter production to disable the Guest
    login option in the Developer Hub login page. clientId:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_ID}. clientSecret:: Enter the configured
    secret variable name: ${MICROSOFT_CLIENT_SECRET}. tenantId:: Enter the configured
    secret variable name: ${MICROSOFT_TENANT_ID}. signInPage:: Enter microsoft to
    set the Azure provider as your Developer Hub sign-in provider. 7. Optional: Add
    optional fields to the Microsoft authentication provider section in your app-config.yaml
    file: ```yaml auth: environment: production providers: microsoft: production:
    clientId: ${MICROSOFT_CLIENT_ID} clientSecret: ${MICROSOFT_CLIENT_SECRET} tenantId:
    ${MICROSOFT_TENANT_ID} domainHint: ${MICROSOFT_TENANT_ID} additionalScopes: Mail.Send
    sessionDuration: hours: 24 signIn: resolvers: resolver: usernameMatchingUserEntityName
    dangerouslyAllowSignInWithoutUserInCatalog: true signInPage: microsoft ``` domainHint::
    * Leave this parameter empty, or enter the tenant ID when your application registration
    is single-tenant. * Leave this parameter empty when your application registration
    is multi-tenant. * Enter the tenant ID to reduce login friction for users with
    accounts in multiple tenants, by automatically filtering out accounts from other
    tenants. For more information, see Home Realm Discovery. additionalScopes:: Enter
    the list of additional scopes to add scopes for the application registration.
    The default and mandatory value lists following scopes: * openid * offline_access
    * profile * email * User.Read sessionDuration:: Lifespan of the user session.
    Enter a duration in ms library (such as ''24h'', ''2 days''), ISO duration, or
    "human duration" format. signIn.resolvers:: After successful authentication, Developer
    Hub resolves the user signing in to an existing user in the Developer Hub catalog.
    To best match users securely for your use case, consider configuring a specific
    resolver. Enter the resolver list to override the default resolver: userIdMatchingUserEntityAnnotation.
    The authentication provider tries each sign-in resolver in order until it succeeds,
    and fails if none succeed. [WARNING] ---- In production mode, configure only one
    resolver to make sure users are securely matched. ---- resolver:: Enter the sign-in
    resolver name. Available resolvers: emailMatchingUserEntityAnnotation:: Use this
    resolver to look up the user by matching their Microsoft email to the email entity
    annotation. emailLocalPartMatchingUserEntityName:: Use this resolver to look up
    the user by matching their Microsoft email user name to the user entity name.
    emailMatchingUserEntityProfileEmail:: Use this resolver to look up the user by
    matching their Microsoft email to the user entity profile email. dangerouslyAllowSignInWithoutUserInCatalog::
    Enter true to configure the sign-in resolver to bypass the user provisioning requirement
    in the Developer Hub software catalog. [WARNING] ---- In production mode, do not
    enable dangerouslyAllowSignInWithoutUserInCatalog. ---- 1. To verify user and
    group provisioning, check the console logs for MicrosoftGraphOrgEntityProvider
    events. Successful synchronization example: ``` 2025-06-23T13:37:55.804Z catalog
    info Read 9 msgraph users and 3 msgraph groups in 1.5 seconds. Committing... class="MicrosoftGraphOrgEntityProvider"
    taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh" taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959"
    trace_id="e4c633659cffd6b1529afa55a5bfbad7" span_id="76affd0420e8baa6" trace_flags="01"
    2025-06-23T13:37:55.811Z catalog info Committed 9 msgraph users and 3 msgraph
    groups in 0.0 seconds. class="MicrosoftGraphOrgEntityProvider" taskId="MicrosoftGraphOrgEntityProvider:providerId:refresh"
    taskInstanceId="e104a116-6481-4ceb-9bc4-0f8f9581f959" trace_id="e4c633659cffd6b1529afa55a5bfbad7"
    span_id="76affd0420e8baa6" trace_flags="01" ``` 2. To verify Azure user authentication:
    1. Go to the Developer Hub login page. 2. Your Developer Hub sign-in page displays
    Sign in using Microsoft and the Guest user sign-in is disabled. 3. Log in with
    an Azure account. # Troubleshooting authentication issues Learn how to troubleshoot
    authentication issues. ## Reducing the size of issued tokens By default, the authentication
    backend issues user identity tokens with ownership references of the user in the
    ent claim of the JSON Web Token (JWT) payload. This makes it easier for consumers
    of the token to resolve ownership of the user. However, depending on the structure
    of your organization and how you resolve ownership claims, the tokens can grow
    large and cause HTTP errors that prevent you from accessing parts of RHDH. Use
    the omitIdentityTokenOwnershipClaim flag to remove the ent claim from tokens and
    reduce their size. 1. In the app-config.yaml file, set omitIdentityTokenOwnershipClaim
    to true as follows: ```yaml auth: omitIdentityTokenOwnershipClaim: true ```'
  metadata:
    classification:
      category: authentication
      datetime: '2025-12-10T16:26:46.629470'
    uuid: 8ded8f24-e5cb-4b7f-9233-8a3e5feae7ea
  response: To reduce login friction for users with accounts in multiple tenants,
    you can use the "domainHint" parameter by entering the tenant ID. This automatically
    filters out accounts from other tenants. The context also specifies that for a
    single-tenant application registration, you can either leave this parameter empty
    or enter the tenant ID, and for a multi-tenant application registration, you should
    leave the parameter empty. For more information, the documentation refers to Home
    Realm Discovery.
  user_input: How can I configure the domainHint parameter for Home Realm Discovery
    to reduce login friction for users who have accounts in multiple tenants when
    setting up the Microsoft authentication provider?
- context:
  - "# Using dynamic plugins in Red Hat Developer Hub # Using Ansible plug-ins for\
    \ Red Hat Developer Hub Ansible plug-ins for Red Hat Developer Hub deliver an\
    \ Ansible-specific portal experience with curated learning paths, push-button\
    \ content creation, integrated development tools, and other opinionated resources.\
    \ [IMPORTANT] ---- The Ansible plug-ins are a Technology Preview feature only.\
    \ Technology Preview features are not supported with Red Hat production service\
    \ level agreements (SLAs), might not be functionally complete, and Red Hat does\
    \ not recommend using them for production. These features provide early access\
    \ to upcoming product features, enabling customers to test functionality and provide\
    \ feedback during the development process. ---- Technology Preview Features Scope\
    \ Red Hat Developer Support Policy Using Ansible plug ins for Red Hat Developer\
    \ Hub # Using the Argo CD plugin You can use the Argo CD plugin to visualize the\
    \ Continuous Delivery (CD) workflows in OpenShift GitOps. This plugin provides\
    \ a visual overview of the application\u2019s status, deployment details, commit\
    \ message, author of the commit, container image promoted to environment and deployment\
    \ history. You have enabled the Argo CD plugin in Red Hat Developer Hub RHDH.\
    \ 1. Select the Catalog tab and choose the component that you want to use. 2.\
    \ Select the CD tab to view insights into deployments managed by Argo CD. ![CD\
    \ tab Argo CD] 3. Select an appropriate card to view the deployment details (for\
    \ example, commit message, author name, and deployment history). ![Sidebar] 1.\
    \ Click the link icon () to open the deployment details in Argo CD. 4. Select\
    \ the Overview tab and navigate to the Deployment summary section to review the\
    \ summary of your application's deployment across namespaces. Additionally, select\
    \ an appropriate Argo CD app to open the deployment details in Argo CD, or select\
    \ a commit ID from the Revision column to review the changes in GitLab or GitHub.\
    \ ![Deployment summary] Installing and viewing plugins in Red Hat Developer Hub\
    \ # Using the JFrog Artifactory plugin The JFrog Artifactory plugin displays information\
    \ about your container images within the Jfrog Artifactory registry. [IMPORTANT]\
    \ ---- The JFrog Artifactory plugin is a Technology Preview feature only. Technology\
    \ Preview features are not supported with Red Hat production service level agreements\
    \ (SLAs), might not be functionally complete, and Red Hat does not recommend using\
    \ them for production. These features provide early access to upcoming product\
    \ features, enabling customers to test functionality and provide feedback during\
    \ the development process. For more information on Red Hat Technology Preview\
    \ features, see Technology Preview Features Scope. Additional detail on how Red\
    \ Hat provides support for bundled community dynamic plugins is available on the\
    \ Red Hat Developer Support Policy page. ---- Your Developer Hub application is\
    \ installed and running. You have enabled the JFrog Artifactory plugin. 1. Open\
    \ your Developer Hub application and select a component from the Catalog page.\
    \ 2. Go to the Image Registry tab. The Image Registry tab contains a list of container\
    \ images within your Jfrog Artifactory repository and related information, such\
    \ as Version, Repositories, Manifest, Modified, and Size. ![image-registry-tab-jfrog-artifactory]\
    \ #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:26:55.068285'
    uuid: 69797a8d-ed5d-4150-b85c-4e5d8e3b91d7
  response: The JFrog Artifactory plugin is a Technology Preview feature only and
    is not recommended for production use. It displays information about your container
    images within the Jfrog Artifactory registry. To see this information, you must
    first open your Developer Hub application and select a component from the Catalog
    page. Then, go to the Image Registry tab, which contains a list of container images
    from your Jfrog Artifactory repository and related information, such as Version,
    Repositories, Manifest, Modified, and Size.
  user_input: I enabled the JFrog Artifactory plugin in my Developer Hub but i dont
    know what it do, can you tell me what information this plugin is supposed to be
    showing me and where do i find it at?
- context:
  - "# Using dynamic plugins in Red Hat Developer Hub # Using Ansible plug-ins for\
    \ Red Hat Developer Hub Ansible plug-ins for Red Hat Developer Hub deliver an\
    \ Ansible-specific portal experience with curated learning paths, push-button\
    \ content creation, integrated development tools, and other opinionated resources.\
    \ [IMPORTANT] ---- The Ansible plug-ins are a Technology Preview feature only.\
    \ Technology Preview features are not supported with Red Hat production service\
    \ level agreements (SLAs), might not be functionally complete, and Red Hat does\
    \ not recommend using them for production. These features provide early access\
    \ to upcoming product features, enabling customers to test functionality and provide\
    \ feedback during the development process. ---- Technology Preview Features Scope\
    \ Red Hat Developer Support Policy Using Ansible plug ins for Red Hat Developer\
    \ Hub # Using the Argo CD plugin You can use the Argo CD plugin to visualize the\
    \ Continuous Delivery (CD) workflows in OpenShift GitOps. This plugin provides\
    \ a visual overview of the application\u2019s status, deployment details, commit\
    \ message, author of the commit, container image promoted to environment and deployment\
    \ history. You have enabled the Argo CD plugin in Red Hat Developer Hub RHDH.\
    \ 1. Select the Catalog tab and choose the component that you want to use. 2.\
    \ Select the CD tab to view insights into deployments managed by Argo CD. ![CD\
    \ tab Argo CD] 3. Select an appropriate card to view the deployment details (for\
    \ example, commit message, author name, and deployment history). ![Sidebar] 1.\
    \ Click the link icon () to open the deployment details in Argo CD. 4. Select\
    \ the Overview tab and navigate to the Deployment summary section to review the\
    \ summary of your application's deployment across namespaces. Additionally, select\
    \ an appropriate Argo CD app to open the deployment details in Argo CD, or select\
    \ a commit ID from the Revision column to review the changes in GitLab or GitHub.\
    \ ![Deployment summary] Installing and viewing plugins in Red Hat Developer Hub\
    \ # Using the JFrog Artifactory plugin The JFrog Artifactory plugin displays information\
    \ about your container images within the Jfrog Artifactory registry. [IMPORTANT]\
    \ ---- The JFrog Artifactory plugin is a Technology Preview feature only. Technology\
    \ Preview features are not supported with Red Hat production service level agreements\
    \ (SLAs), might not be functionally complete, and Red Hat does not recommend using\
    \ them for production. These features provide early access to upcoming product\
    \ features, enabling customers to test functionality and provide feedback during\
    \ the development process. For more information on Red Hat Technology Preview\
    \ features, see Technology Preview Features Scope. Additional detail on how Red\
    \ Hat provides support for bundled community dynamic plugins is available on the\
    \ Red Hat Developer Support Policy page. ---- Your Developer Hub application is\
    \ installed and running. You have enabled the JFrog Artifactory plugin. 1. Open\
    \ your Developer Hub application and select a component from the Catalog page.\
    \ 2. Go to the Image Registry tab. The Image Registry tab contains a list of container\
    \ images within your Jfrog Artifactory repository and related information, such\
    \ as Version, Repositories, Manifest, Modified, and Size. ![image-registry-tab-jfrog-artifactory]\
    \ #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:27:02.132514'
    uuid: 82187bde-2518-4db3-a698-805d4b028d7a
  response: "Red Hat Developer Hub has Ansible plug-ins that provide an Ansible-specific\
    \ portal experience with curated learning paths and integrated development tools.\
    \ It also has an Argo CD plugin to visualize Continuous Delivery (CD) workflows,\
    \ showing an application\u2019s status, deployment details, and history. Additionally,\
    \ there is a JFrog Artifactory plugin that displays information about container\
    \ images from the Jfrog Artifactory registry, such as Version, Repositories, and\
    \ Size. Both the Ansible and JFrog Artifactory plugins are noted as being Technology\
    \ Preview features."
  user_input: what plugns are in red hat devloper hub?
- context:
  - "# Using dynamic plugins in Red Hat Developer Hub # Using Ansible plug-ins for\
    \ Red Hat Developer Hub Ansible plug-ins for Red Hat Developer Hub deliver an\
    \ Ansible-specific portal experience with curated learning paths, push-button\
    \ content creation, integrated development tools, and other opinionated resources.\
    \ [IMPORTANT] ---- The Ansible plug-ins are a Technology Preview feature only.\
    \ Technology Preview features are not supported with Red Hat production service\
    \ level agreements (SLAs), might not be functionally complete, and Red Hat does\
    \ not recommend using them for production. These features provide early access\
    \ to upcoming product features, enabling customers to test functionality and provide\
    \ feedback during the development process. ---- Technology Preview Features Scope\
    \ Red Hat Developer Support Policy Using Ansible plug ins for Red Hat Developer\
    \ Hub # Using the Argo CD plugin You can use the Argo CD plugin to visualize the\
    \ Continuous Delivery (CD) workflows in OpenShift GitOps. This plugin provides\
    \ a visual overview of the application\u2019s status, deployment details, commit\
    \ message, author of the commit, container image promoted to environment and deployment\
    \ history. You have enabled the Argo CD plugin in Red Hat Developer Hub RHDH.\
    \ 1. Select the Catalog tab and choose the component that you want to use. 2.\
    \ Select the CD tab to view insights into deployments managed by Argo CD. ![CD\
    \ tab Argo CD] 3. Select an appropriate card to view the deployment details (for\
    \ example, commit message, author name, and deployment history). ![Sidebar] 1.\
    \ Click the link icon () to open the deployment details in Argo CD. 4. Select\
    \ the Overview tab and navigate to the Deployment summary section to review the\
    \ summary of your application's deployment across namespaces. Additionally, select\
    \ an appropriate Argo CD app to open the deployment details in Argo CD, or select\
    \ a commit ID from the Revision column to review the changes in GitLab or GitHub.\
    \ ![Deployment summary] Installing and viewing plugins in Red Hat Developer Hub\
    \ # Using the JFrog Artifactory plugin The JFrog Artifactory plugin displays information\
    \ about your container images within the Jfrog Artifactory registry. [IMPORTANT]\
    \ ---- The JFrog Artifactory plugin is a Technology Preview feature only. Technology\
    \ Preview features are not supported with Red Hat production service level agreements\
    \ (SLAs), might not be functionally complete, and Red Hat does not recommend using\
    \ them for production. These features provide early access to upcoming product\
    \ features, enabling customers to test functionality and provide feedback during\
    \ the development process. For more information on Red Hat Technology Preview\
    \ features, see Technology Preview Features Scope. Additional detail on how Red\
    \ Hat provides support for bundled community dynamic plugins is available on the\
    \ Red Hat Developer Support Policy page. ---- Your Developer Hub application is\
    \ installed and running. You have enabled the JFrog Artifactory plugin. 1. Open\
    \ your Developer Hub application and select a component from the Catalog page.\
    \ 2. Go to the Image Registry tab. The Image Registry tab contains a list of container\
    \ images within your Jfrog Artifactory repository and related information, such\
    \ as Version, Repositories, Manifest, Modified, and Size. ![image-registry-tab-jfrog-artifactory]\
    \ #"
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:27:09.977899'
    uuid: d485bc28-3448-48d5-9a84-828239115132
  response: Ansible plug-ins for Red Hat Developer Hub deliver an Ansible-specific
    portal experience with curated learning paths, push-button content creation, integrated
    development tools, and other opinionated resources. However, the Ansible plug-ins
    are a Technology Preview feature only. Technology Preview features are not supported
    with Red Hat production service level agreements (SLAs), might not be functionally
    complete, and Red Hat does not recommend using them for production. The purpose
    of these features is to provide early access to upcoming product features, which
    enables customers to test functionality and provide feedback during the development
    process.
  user_input: Given my responsibility for building a stable and unified developer
    platform, I am interested in the potential benefits of integrating the Ansible
    plug-ins into our Red Hat Developer Hub. Could you please provide a comprehensive
    overview of the features they offer and, more importantly, clarify their current
    support status and any associated limitations for enterprise production environments?
- context:
  - 'Using Keycloak The Keycloak backend plugin, which integrates Keycloak into Developer
    Hub, has the following capabilities: Synchronization of Keycloak users in a realm.
    Synchronization of Keycloak groups and their users in a realm. ## Importing users
    and groups in Developer Hub using the Keycloak plugin After configuring the plugin
    successfully, the plugin imports the users and groups each time when started.
    [NOTE] ---- If you set up a schedule, users and groups will also be imported.
    ---- 1. in Red Hat Developer Hub, go to the Catalog page. 2. Select User from
    the entity type filter to display the list of imported users. 3. Browse the list
    of users displayed on the page. 4. Select a user to view detailed information
    imported from Keycloak. 5. To view groups, select Group from the entity type filter.
    6. Browse the list of groups shown on the page. 7. From the list of groups, select
    a group to view the information imported from Keycloak. #'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:27:22.162421'
    uuid: 1121a9b8-9556-4b62-a840-8f138335fa16
  response: The Keycloak backend plugin integrates with Developer Hub to provide synchronization
    of Keycloak users in a realm, as well as synchronization of Keycloak groups and
    their users in a realm. After configuration, the plugin imports users and groups
    each time it starts, and can also be scheduled to do so. Once imported, you can
    view the list of users and groups on the Catalog page by selecting the appropriate
    entity type filter. Selecting a specific user or group allows you to view the
    detailed information that was imported from Keycloak.
  user_input: According to the documentation, what are the specific capabilities of
    the Keycloak plugin for managing users and groups within the Developer Hub?
- context:
  - 'Using Keycloak The Keycloak backend plugin, which integrates Keycloak into Developer
    Hub, has the following capabilities: Synchronization of Keycloak users in a realm.
    Synchronization of Keycloak groups and their users in a realm. ## Importing users
    and groups in Developer Hub using the Keycloak plugin After configuring the plugin
    successfully, the plugin imports the users and groups each time when started.
    [NOTE] ---- If you set up a schedule, users and groups will also be imported.
    ---- 1. in Red Hat Developer Hub, go to the Catalog page. 2. Select User from
    the entity type filter to display the list of imported users. 3. Browse the list
    of users displayed on the page. 4. Select a user to view detailed information
    imported from Keycloak. 5. To view groups, select Group from the entity type filter.
    6. Browse the list of groups shown on the page. 7. From the list of groups, select
    a group to view the information imported from Keycloak. #'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T16:27:32.097696'
    uuid: 5adb0bd3-b8bd-4ab1-893e-bd42cb0e8b57
  response: After the Keycloak plugin imports users and groups, you can view them
    by first going to the Catalog page in Red Hat Developer Hub. To see the list of
    imported users, select 'User' from the entity type filter and browse the list.
    You can select a user to view their detailed information. To view groups, select
    'Group' from the entity type filter. You can then browse the list of groups and
    select a specific group to view the information that was imported from Keycloak.
  user_input: After integrating the Keycloak plugin, what is the step-by-step process
    to find and view the synchronized users and groups within the Red Hat Developer
    Hub catalog?
- context:
  - 'Using Keycloak The Keycloak backend plugin, which integrates Keycloak into Developer
    Hub, has the following capabilities: Synchronization of Keycloak users in a realm.
    Synchronization of Keycloak groups and their users in a realm. ## Importing users
    and groups in Developer Hub using the Keycloak plugin After configuring the plugin
    successfully, the plugin imports the users and groups each time when started.
    [NOTE] ---- If you set up a schedule, users and groups will also be imported.
    ---- 1. in Red Hat Developer Hub, go to the Catalog page. 2. Select User from
    the entity type filter to display the list of imported users. 3. Browse the list
    of users displayed on the page. 4. Select a user to view detailed information
    imported from Keycloak. 5. To view groups, select Group from the entity type filter.
    6. Browse the list of groups shown on the page. 7. From the list of groups, select
    a group to view the information imported from Keycloak. #'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T16:27:40.901330'
    uuid: 1edf1684-f338-4d89-8124-0e573bc1baac
  response: To see users in Red Hat Developer Hub, go to the Catalog page and select
    User from the entity type filter to display the list of imported users. You can
    then browse the list of users on the page and select a user to view detailed information
    imported from Keycloak.
  user_input: how i see users in Developer Hub?
- context:
  - 'Using the Nexus Repository Manager plugin The Nexus Repository Manager plugin
    displays the information about your build artifacts in your Developer Hub application.
    The build artifacts are available in the Nexus Repository Manager. [IMPORTANT]
    ---- The Nexus Repository Manager plugin is a Technology Preview feature only.
    Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- The Nexus Repository Manager
    is a front-end plugin that enables you to view the information about build artifacts.
    Your Developer Hub application is installed and running. You have installed the
    Nexus Repository Manager plugin. 1. Open your Developer Hub application and select
    a component from the Catalog page. 2. Go to the BUILD ARTIFACTS tab. The BUILD
    ARTIFACTS tab contains a list of build artifacts and related information, such
    as VERSION, REPOSITORY, REPOSITORY TYPE, MANIFEST, MODIFIED, and SIZE. ![nexus-repository-manager-tab]
    # Using the Tekton plugin You can use the Tekton plugin to visualize the results
    of CI/CD pipeline runs on your Kubernetes or OpenShift clusters. The plugin allows
    users to visually see high level status of all associated tasks in the pipeline
    for their applications. You can use the Tekton front-end plugin to view PipelineRun
    resources. You have installed the Red Hat Developer Hub (RHDH). You have installed
    the Tekton plugin. For the installation process, see Installing and configuring
    the Tekton plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the CI tab. The CI tab displays the list of PipelineRun
    resources associated with a Kubernetes cluster. The list contains pipeline run
    details, such as NAME, VULNERABILITIES, STATUS, TASK STATUS, STARTED, and DURATION.
    ![ci-cd-tab-tekton] 3. Click the expand row button besides PipelineRun name in
    the list to view the PipelineRun visualization. The pipeline run resource includes
    tasks to complete. When you hover the mouse pointer on a task card, you can view
    the steps to complete that particular task. ![ci-cd-tab-tekton] # Using the Topology
    plugin Topology is a front-end plugin that enables you to view the workloads as
    nodes that power any service on the Kubernetes cluster. ## Enabling users to use
    the Topology plugin The Topology plugin is defining additional permissions. When
    Authorization in Red Hat Developer Hub is enabled, to enable users to use the
    Topology plugin, grant them: The kubernetes.clusters.read and kubernetes.resources.read,
    read permissions to view the Topology panel. The kubernetes.proxy use permission
    to view the pod logs. The catalog entity read permission to view the Red Hat Developer
    Hub software catalog items. You are managing Authorization in Red Hat Developer
    Hub by using external files. Add the following permission policies to your rbac
    policy.csv file to create a topology viewer role that has access to the Topology
    plugin features, and add the role to the users requiring this authorization: ```
    g, user:default/<YOUR_USERNAME>, role:default/topology-viewer p, role:default/topology-viewer,
    kubernetes.clusters.read, read, allow 1 p, role:default/topology-viewer, kubernetes.resources.read,
    read, allow 1 p, role:default/topology-viewer, kubernetes.proxy, use, allow 2
    p, role:default/topology-viewer, catalog-entity, read, allow 3 ``` Grants the
    user the ability to see the Topology panel. Grants the user the ability to view
    the pod logs. Grants the user the ability to see the catalog item. ## Using the
    Topology plugin Your Red Hat Developer Hub instance is installed and running.
    You have installed the Topology plugin. You have enabled the users to use the
    Topology plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the TOPOLOGY tab and you can view the workloads such as
    deployments or pods as nodes. ![topology-user-1] 3. Select a node and a pop-up
    appears on the right side that contains two tabs: Details and Resources. The Details
    and Resources tabs contain the associated information and resources for the node.
    ![topology-user-2] 4. Click the Open URL button on the top of a node. ![topology-user-3]
    Click the Open URL button to access the associated Ingresses and run your application
    in a new tab.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:27:50.603279'
    uuid: 32d0bd74-f932-4c9d-837f-7d0d271090aa
  response: After selecting a component from the Catalog page in the Red Hat Developer
    Hub application, users can access information from several plugins. In the "BUILD
    ARTIFACTS" tab, provided by the Nexus Repository Manager plugin, they can see
    a list of build artifacts with details such as VERSION, REPOSITORY, REPOSITORY
    TYPE, MANIFEST, MODIFIED, and SIZE. In the "CI" tab, the Tekton plugin displays
    a list of PipelineRun resources with information including NAME, VULNERABILITIES,
    STATUS, TASK STATUS, STARTED, and DURATION; users can also expand a row to view
    a visualization of the PipelineRun and hover over tasks to see their steps. Finally,
    in the "TOPOLOGY" tab, the Topology plugin allows users to view workloads like
    deployments or pods as nodes. Selecting a node brings up a pop-up with "Details"
    and "Resources" tabs, and clicking the "Open URL" button on a node lets the user
    access associated Ingresses and run the application in a new tab.
  user_input: I'm trying to understand for my team, with this Red Hat Developer Hub,
    what are all the things they can actually do and see inside it, like when they
    look at a component in the catalog what information is showed to them from those
    plugins like the one for build artifacts and the CI tab and that topology thing?
- context:
  - 'Using the Nexus Repository Manager plugin The Nexus Repository Manager plugin
    displays the information about your build artifacts in your Developer Hub application.
    The build artifacts are available in the Nexus Repository Manager. [IMPORTANT]
    ---- The Nexus Repository Manager plugin is a Technology Preview feature only.
    Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- The Nexus Repository Manager
    is a front-end plugin that enables you to view the information about build artifacts.
    Your Developer Hub application is installed and running. You have installed the
    Nexus Repository Manager plugin. 1. Open your Developer Hub application and select
    a component from the Catalog page. 2. Go to the BUILD ARTIFACTS tab. The BUILD
    ARTIFACTS tab contains a list of build artifacts and related information, such
    as VERSION, REPOSITORY, REPOSITORY TYPE, MANIFEST, MODIFIED, and SIZE. ![nexus-repository-manager-tab]
    # Using the Tekton plugin You can use the Tekton plugin to visualize the results
    of CI/CD pipeline runs on your Kubernetes or OpenShift clusters. The plugin allows
    users to visually see high level status of all associated tasks in the pipeline
    for their applications. You can use the Tekton front-end plugin to view PipelineRun
    resources. You have installed the Red Hat Developer Hub (RHDH). You have installed
    the Tekton plugin. For the installation process, see Installing and configuring
    the Tekton plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the CI tab. The CI tab displays the list of PipelineRun
    resources associated with a Kubernetes cluster. The list contains pipeline run
    details, such as NAME, VULNERABILITIES, STATUS, TASK STATUS, STARTED, and DURATION.
    ![ci-cd-tab-tekton] 3. Click the expand row button besides PipelineRun name in
    the list to view the PipelineRun visualization. The pipeline run resource includes
    tasks to complete. When you hover the mouse pointer on a task card, you can view
    the steps to complete that particular task. ![ci-cd-tab-tekton] # Using the Topology
    plugin Topology is a front-end plugin that enables you to view the workloads as
    nodes that power any service on the Kubernetes cluster. ## Enabling users to use
    the Topology plugin The Topology plugin is defining additional permissions. When
    Authorization in Red Hat Developer Hub is enabled, to enable users to use the
    Topology plugin, grant them: The kubernetes.clusters.read and kubernetes.resources.read,
    read permissions to view the Topology panel. The kubernetes.proxy use permission
    to view the pod logs. The catalog entity read permission to view the Red Hat Developer
    Hub software catalog items. You are managing Authorization in Red Hat Developer
    Hub by using external files. Add the following permission policies to your rbac
    policy.csv file to create a topology viewer role that has access to the Topology
    plugin features, and add the role to the users requiring this authorization: ```
    g, user:default/<YOUR_USERNAME>, role:default/topology-viewer p, role:default/topology-viewer,
    kubernetes.clusters.read, read, allow 1 p, role:default/topology-viewer, kubernetes.resources.read,
    read, allow 1 p, role:default/topology-viewer, kubernetes.proxy, use, allow 2
    p, role:default/topology-viewer, catalog-entity, read, allow 3 ``` Grants the
    user the ability to see the Topology panel. Grants the user the ability to view
    the pod logs. Grants the user the ability to see the catalog item. ## Using the
    Topology plugin Your Red Hat Developer Hub instance is installed and running.
    You have installed the Topology plugin. You have enabled the users to use the
    Topology plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the TOPOLOGY tab and you can view the workloads such as
    deployments or pods as nodes. ![topology-user-1] 3. Select a node and a pop-up
    appears on the right side that contains two tabs: Details and Resources. The Details
    and Resources tabs contain the associated information and resources for the node.
    ![topology-user-2] 4. Click the Open URL button on the top of a node. ![topology-user-3]
    Click the Open URL button to access the associated Ingresses and run your application
    in a new tab.'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:28:02.609051'
    uuid: 454e5146-2c85-4320-8f04-e45958c3ec6c
  response: You can use the Tekton plugin to visualize the results of CI/CD pipeline
    runs on your OpenShift clusters. The plugin allows users to visually see the high
    level status of all associated tasks in the pipeline for their applications. To
    view them, open your Red Hat Developer Hub (RHDH) application, select a component
    from the Catalog page, and go to the CI tab. The CI tab displays the list of PipelineRun
    resources, and you can click the expand row button to view the PipelineRun visualization.
  user_input: How can I use the Tekton plugn to see the CI/CD pipeline runs for my
    aplications on an OpenShift cluster?
- context:
  - 'Using the Nexus Repository Manager plugin The Nexus Repository Manager plugin
    displays the information about your build artifacts in your Developer Hub application.
    The build artifacts are available in the Nexus Repository Manager. [IMPORTANT]
    ---- The Nexus Repository Manager plugin is a Technology Preview feature only.
    Technology Preview features are not supported with Red Hat production service
    level agreements (SLAs), might not be functionally complete, and Red Hat does
    not recommend using them for production. These features provide early access to
    upcoming product features, enabling customers to test functionality and provide
    feedback during the development process. For more information on Red Hat Technology
    Preview features, see Technology Preview Features Scope. Additional detail on
    how Red Hat provides support for bundled community dynamic plugins is available
    on the Red Hat Developer Support Policy page. ---- The Nexus Repository Manager
    is a front-end plugin that enables you to view the information about build artifacts.
    Your Developer Hub application is installed and running. You have installed the
    Nexus Repository Manager plugin. 1. Open your Developer Hub application and select
    a component from the Catalog page. 2. Go to the BUILD ARTIFACTS tab. The BUILD
    ARTIFACTS tab contains a list of build artifacts and related information, such
    as VERSION, REPOSITORY, REPOSITORY TYPE, MANIFEST, MODIFIED, and SIZE. ![nexus-repository-manager-tab]
    # Using the Tekton plugin You can use the Tekton plugin to visualize the results
    of CI/CD pipeline runs on your Kubernetes or OpenShift clusters. The plugin allows
    users to visually see high level status of all associated tasks in the pipeline
    for their applications. You can use the Tekton front-end plugin to view PipelineRun
    resources. You have installed the Red Hat Developer Hub (RHDH). You have installed
    the Tekton plugin. For the installation process, see Installing and configuring
    the Tekton plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the CI tab. The CI tab displays the list of PipelineRun
    resources associated with a Kubernetes cluster. The list contains pipeline run
    details, such as NAME, VULNERABILITIES, STATUS, TASK STATUS, STARTED, and DURATION.
    ![ci-cd-tab-tekton] 3. Click the expand row button besides PipelineRun name in
    the list to view the PipelineRun visualization. The pipeline run resource includes
    tasks to complete. When you hover the mouse pointer on a task card, you can view
    the steps to complete that particular task. ![ci-cd-tab-tekton] # Using the Topology
    plugin Topology is a front-end plugin that enables you to view the workloads as
    nodes that power any service on the Kubernetes cluster. ## Enabling users to use
    the Topology plugin The Topology plugin is defining additional permissions. When
    Authorization in Red Hat Developer Hub is enabled, to enable users to use the
    Topology plugin, grant them: The kubernetes.clusters.read and kubernetes.resources.read,
    read permissions to view the Topology panel. The kubernetes.proxy use permission
    to view the pod logs. The catalog entity read permission to view the Red Hat Developer
    Hub software catalog items. You are managing Authorization in Red Hat Developer
    Hub by using external files. Add the following permission policies to your rbac
    policy.csv file to create a topology viewer role that has access to the Topology
    plugin features, and add the role to the users requiring this authorization: ```
    g, user:default/<YOUR_USERNAME>, role:default/topology-viewer p, role:default/topology-viewer,
    kubernetes.clusters.read, read, allow 1 p, role:default/topology-viewer, kubernetes.resources.read,
    read, allow 1 p, role:default/topology-viewer, kubernetes.proxy, use, allow 2
    p, role:default/topology-viewer, catalog-entity, read, allow 3 ``` Grants the
    user the ability to see the Topology panel. Grants the user the ability to view
    the pod logs. Grants the user the ability to see the catalog item. ## Using the
    Topology plugin Your Red Hat Developer Hub instance is installed and running.
    You have installed the Topology plugin. You have enabled the users to use the
    Topology plugin. 1. Open your RHDH application and select a component from the
    Catalog page. 2. Go to the TOPOLOGY tab and you can view the workloads such as
    deployments or pods as nodes. ![topology-user-1] 3. Select a node and a pop-up
    appears on the right side that contains two tabs: Details and Resources. The Details
    and Resources tabs contain the associated information and resources for the node.
    ![topology-user-2] 4. Click the Open URL button on the top of a node. ![topology-user-3]
    Click the Open URL button to access the associated Ingresses and run your application
    in a new tab.'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:28:11.401684'
    uuid: 46fd5b47-6c3a-4448-b220-fe37ebccb7f0
  response: To view build artifacts in your Developer Hub application, you can use
    the Nexus Repository Manager plugin. After selecting a component from the Catalog
    page, navigate to the BUILD ARTIFACTS tab, which lists artifacts with details
    like VERSION, REPOSITORY, and SIZE. Note that this plugin is a Technology Preview
    feature and is not recommended for production. To visualize CI/CD pipeline runs,
    you can use the Tekton plugin. In a component's CI tab, you can see a list of
    PipelineRun resources with details such as NAME, STATUS, and DURATION. You can
    also expand a row to view a visualization of the pipeline run and its tasks.
  user_input: How can I use the Developer Hub to view build artifacts and CI/CD pipeline
    runs?
- context:
  - '# Configuring Red Hat Developer Hub Learn how to configure Red Hat Developer
    Hub (RHDH) for production to work in your IT ecosystem by adding custom config
    maps and secrets. # Provisioning and using your custom Red Hat Developer Hub configuration
    To configure Red Hat Developer Hub, use these methods, which are widely used to
    configure a Red Hat OpenShift Container Platform application: Use config maps
    to mount files and directories. Use secrets to inject environment variables. Learn
    to apply these methods to Developer Hub: 1. Provision your custom config maps
    and secrets to OpenShift Container Platform. 2. Use your selected deployment method
    to mount the config maps and inject the secrets: * Use the Red Hat Developer Hub
    operator to deploy Developer Hub. * Use the Red Hat Developer Hub Helm chart to
    deploy Developer Hub. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:28:22.785294'
    uuid: 9cc151c0-c3ea-467c-9d80-0d46c333ee8d
  response: To configure Red Hat Developer Hub for production on a Red Hat OpenShift
    Container Platform application, you can use config maps to mount files and directories
    and use secrets to inject environment variables. The process involves first provisioning
    your custom config maps and secrets to OpenShift Container Platform, and then
    using your selected deployment method, such as the Red Hat Developer Hub operator
    or Helm chart, to mount the config maps and inject the secrets.
  user_input: So my team is trying to get Red Hat Developer Hub working in our production
    IT ecosystem on the Red Hat OpenShift Container Platform, what are the methods
    you use for that, like how do you provision the custom configs and secrets and
    stuff?
- context:
  - '# Configuring Red Hat Developer Hub Learn how to configure Red Hat Developer
    Hub (RHDH) for production to work in your IT ecosystem by adding custom config
    maps and secrets. # Provisioning and using your custom Red Hat Developer Hub configuration
    To configure Red Hat Developer Hub, use these methods, which are widely used to
    configure a Red Hat OpenShift Container Platform application: Use config maps
    to mount files and directories. Use secrets to inject environment variables. Learn
    to apply these methods to Developer Hub: 1. Provision your custom config maps
    and secrets to OpenShift Container Platform. 2. Use your selected deployment method
    to mount the config maps and inject the secrets: * Use the Red Hat Developer Hub
    operator to deploy Developer Hub. * Use the Red Hat Developer Hub Helm chart to
    deploy Developer Hub. ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:28:44.320416'
    uuid: 79536af2-133d-4f91-875d-c70054aea2e7
  response: The Red Hat Developer Hub Helm chart is a deployment method used to deploy
    Developer Hub. It is utilized to mount custom config maps and inject secrets as
    part of the configuration process.
  user_input: What is the specified function of the Red Hat Developer Hub Helm chart
    in the context of application configuration?
- context:
  - '# Configuring Red Hat Developer Hub Learn how to configure Red Hat Developer
    Hub (RHDH) for production to work in your IT ecosystem by adding custom config
    maps and secrets. # Provisioning and using your custom Red Hat Developer Hub configuration
    To configure Red Hat Developer Hub, use these methods, which are widely used to
    configure a Red Hat OpenShift Container Platform application: Use config maps
    to mount files and directories. Use secrets to inject environment variables. Learn
    to apply these methods to Developer Hub: 1. Provision your custom config maps
    and secrets to OpenShift Container Platform. 2. Use your selected deployment method
    to mount the config maps and inject the secrets: * Use the Red Hat Developer Hub
    operator to deploy Developer Hub. * Use the Red Hat Developer Hub Helm chart to
    deploy Developer Hub. ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:28:56.057540'
    uuid: 8c4e6700-78f4-404c-9b70-95f2f076fcc5
  response: 'To configure Red Hat Developer Hub, you can use config maps to mount
    files and directories and use secrets to inject environment variables. The process
    involves two main steps: first, provision your custom config maps and secrets
    to OpenShift Container Platform. Second, use your selected deployment method to
    mount the config maps and inject the secrets. The deployment methods mentioned
    are using either the Red Hat Developer Hub operator or the Red Hat Developer Hub
    Helm chart.'
  user_input: what are the recommended methods for configuring a production instance
    of Red Hat Developer Hub in an OpenShift environment using custom config maps
    and secrets
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Red Hat OpenShift Container Platform (RHOCP) before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the OpenShift CLI (oc), you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. * To prepare a deployment with the Red Hat Developer Hub Operator on OpenShift
    Container Platform, you can start with an empty file. * To prepare a deployment
    with the Red Hat Developer Hub Helm chart, or on Kubernetes, enter the Developer
    Hub base URL in the relevant fields in your app-config.yaml file to ensure proper
    functionality of Developer Hub. The base URL is what a Developer Hub user sees
    in their browser when accessing Developer Hub. The relevant fields are baseUrl
    in the app and backend sections, and origin in the backend.cors subsection: Configuring
    the baseUrl in app-config.yaml ```yaml app: title: Red Hat Developer Hub baseUrl:
    https://<my_developer_hub_domain> backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://<my_developer_hub_domain>
    cors: origin: https://<my_developer_hub_domain> ``` * Optionally, enter your configuration
    such as: * Authentication in Red Hat Developer Hub. * Authorization in Red Hat
    Developer Hub. * Customization. * Configure your OpenShift Container Platform
    integration. 3. Author your custom dynamic-plugins.yaml file to enable plugins.
    By default, Developer Hub enables a minimal plugin set, and disables plugins that
    require configuration or secrets, such as the GitHub repository discovery plugin
    and the Role-based access control (RBAC) plugin. Enable the GitHub repository
    discovery and the RBAC features: dynamic.plugins.yaml ```yaml includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your OpenShift Container Platform cluster. 1. Create the <my-rhdh-project>
    {namespace} aimed at containing your Developer Hub instance. ```terminal $ oc
    create namespace my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. Provision your PostgreSQL database secrets Provision your dynamic
    plugins config map Provision your RBAC policies config map ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:29:08.453053'
    uuid: 123b0d60-30c7-4beb-adbd-86b1086d0116
  response: To provision your custom Red Hat Developer Hub configuration, you must
    first store your secrets as environment variables in an OpenShift Container Platform
    secret by collecting them in a secrets.txt file. Next, you need to author a custom
    app-config.yaml file, which is the main Developer Hub configuration file, and
    a custom dynamic-plugins.yaml file to enable plugins. After creating these files,
    you provision them to your OpenShift Container Platform cluster by creating a
    namespace, then creating config maps from your app-config.yaml and dynamic-plugins.yaml
    files, and finally creating a secret from your secrets.txt file within that project
    namespace.
  user_input: so im trying to get this Red Hat Developer Hub thing setup for my team
    and the docs are a bit much, can you tell me what all the steps is for provisioning
    the custom config like what files do i need to make and how do i get them into
    openshift for the Red Hat Developer Hub?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Red Hat OpenShift Container Platform (RHOCP) before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the OpenShift CLI (oc), you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. * To prepare a deployment with the Red Hat Developer Hub Operator on OpenShift
    Container Platform, you can start with an empty file. * To prepare a deployment
    with the Red Hat Developer Hub Helm chart, or on Kubernetes, enter the Developer
    Hub base URL in the relevant fields in your app-config.yaml file to ensure proper
    functionality of Developer Hub. The base URL is what a Developer Hub user sees
    in their browser when accessing Developer Hub. The relevant fields are baseUrl
    in the app and backend sections, and origin in the backend.cors subsection: Configuring
    the baseUrl in app-config.yaml ```yaml app: title: Red Hat Developer Hub baseUrl:
    https://<my_developer_hub_domain> backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://<my_developer_hub_domain>
    cors: origin: https://<my_developer_hub_domain> ``` * Optionally, enter your configuration
    such as: * Authentication in Red Hat Developer Hub. * Authorization in Red Hat
    Developer Hub. * Customization. * Configure your OpenShift Container Platform
    integration. 3. Author your custom dynamic-plugins.yaml file to enable plugins.
    By default, Developer Hub enables a minimal plugin set, and disables plugins that
    require configuration or secrets, such as the GitHub repository discovery plugin
    and the Role-based access control (RBAC) plugin. Enable the GitHub repository
    discovery and the RBAC features: dynamic.plugins.yaml ```yaml includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your OpenShift Container Platform cluster. 1. Create the <my-rhdh-project>
    {namespace} aimed at containing your Developer Hub instance. ```terminal $ oc
    create namespace my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. Provision your PostgreSQL database secrets Provision your dynamic
    plugins config map Provision your RBAC policies config map ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:29:19.999814'
    uuid: ec3e33a4-2e8b-41f5-972a-cb2e409fe948
  response: 'By default, Developer Hub disables plugins that require configuration
    or secrets, such as the GitHub repository discovery plugin. To enable the GitHub
    repository discovery feature, you must author a custom dynamic-plugins.yaml file.
    In this file, under the plugins section, you must specify the package ''./dynamic
    plugins/dist/backstage plugin catalog backend module github'' and set ''disabled:
    false''.'
  user_input: how i make github work?
- context:
  - 'Provisioning your custom Red Hat Developer Hub configuration To configure Red
    Hat Developer Hub, provision your custom Red Hat Developer Hub config maps and
    secrets to Red Hat OpenShift Container Platform (RHOCP) before running Red Hat
    Developer Hub. [TIP] ---- On Red Hat OpenShift Container Platform, you can skip
    this step to run Developer Hub with the default config map and secret. Your changes
    on this configuration might get reverted on Developer Hub restart. ---- By using
    the OpenShift CLI (oc), you have access, with developer permissions, to the OpenShift
    cluster aimed at containing your Developer Hub instance. 1. For security, store
    your secrets as environment variables values in an OpenShift Container Platform
    secret, rather than in clear text in your configuration files. Collect all your
    secrets in the secrets.txt file, with one secret per line in KEY=value form. *
    Enter your authentication secrets. 2. Author your custom app-config.yaml file.
    This is the main Developer Hub configuration file. You need a custom app-config.yaml
    file to avoid the Developer Hub installer to revert user edits during upgrades.
    When your custom app-config.yaml file is empty, Developer Hub is using default
    values. * To prepare a deployment with the Red Hat Developer Hub Operator on OpenShift
    Container Platform, you can start with an empty file. * To prepare a deployment
    with the Red Hat Developer Hub Helm chart, or on Kubernetes, enter the Developer
    Hub base URL in the relevant fields in your app-config.yaml file to ensure proper
    functionality of Developer Hub. The base URL is what a Developer Hub user sees
    in their browser when accessing Developer Hub. The relevant fields are baseUrl
    in the app and backend sections, and origin in the backend.cors subsection: Configuring
    the baseUrl in app-config.yaml ```yaml app: title: Red Hat Developer Hub baseUrl:
    https://<my_developer_hub_domain> backend: auth: externalAccess: - type: legacy
    options: subject: legacy-default-config secret: "${BACKEND_SECRET}" baseUrl: https://<my_developer_hub_domain>
    cors: origin: https://<my_developer_hub_domain> ``` * Optionally, enter your configuration
    such as: * Authentication in Red Hat Developer Hub. * Authorization in Red Hat
    Developer Hub. * Customization. * Configure your OpenShift Container Platform
    integration. 3. Author your custom dynamic-plugins.yaml file to enable plugins.
    By default, Developer Hub enables a minimal plugin set, and disables plugins that
    require configuration or secrets, such as the GitHub repository discovery plugin
    and the Role-based access control (RBAC) plugin. Enable the GitHub repository
    discovery and the RBAC features: dynamic.plugins.yaml ```yaml includes: dynamic
    plugins.default.yaml plugins: package: ./dynamic plugins/dist/backstage plugin
    catalog backend module github disabled: false package: ./dynamic plugins/dist/backstage
    community plugin rbac disabled: false ``` 4. Provision your custom configuration
    files to your OpenShift Container Platform cluster. 1. Create the <my-rhdh-project>
    {namespace} aimed at containing your Developer Hub instance. ```terminal $ oc
    create namespace my-rhdh-project ``` 2. Provision your app-config.yaml and dynamic-plugins.yaml
    files respectively to the my-rhdh-app-config, and dynamic-plugins-rhdh config
    maps in the <my-rhdh-project> project. ```terminal $ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project $ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project
    ``` Alternatively, create the config maps by using the web console. 3. Provision
    your secrets.txt file to the my-rhdh-secrets secret in the <my-rhdh-project> project.
    ```terminal $ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project ``` Alternatively, create the secret by using the
    web console. Provision your PostgreSQL database secrets Provision your dynamic
    plugins config map Provision your RBAC policies config map ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:29:32.074262'
    uuid: d83d812c-b43d-4fd5-b7e4-aa06f087c79f
  response: 'To provision your custom configuration files to your OpenShift Container
    Platform cluster using the OpenShift CLI, you first create the namespace for your
    Developer Hub instance with the command: `$ oc create namespace my-rhdh-project`.
    Next, you provision your `app-config.yaml` and `dynamic-plugins.yaml` files to
    their respective config maps using these commands: `$ oc create configmap my-rhdh-app-config
    --from-file=app-config.yaml --namespace=my-rhdh-project` and `$ oc create configmap
    dynamic-plugins-rhdh --from-file=dynamic-plugins.yaml --namespace=my-rhdh-project`.
    Lastly, you provision your `secrets.txt` file to the `my-rhdh-secrets` secret
    with this command: `$ oc create secret generic my-rhdh-secrets --from-file=secrets.txt
    --namespace=my-rhdh-project`. As an alternative, the config maps and secret can
    also be created using the web console.'
  user_input: I'm trying to provision our custom config files for Developer Hub, what
    are the specific OpenShift CLI comands I need to run to create the namespace,
    the config maps for app-config.yaml and dynamic-plugins.yaml, and the secret for
    secrets.txt?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the OpenShift CLI (oc), you have access, with
    developer permissions, to the OpenShift Container Platform cluster aimed at containing
    your Developer Hub instance. Your administrator has installed the Red Hat Developer
    Hub Operator in the cluster. You have provisioned your custom config maps and
    secrets in your <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ### Injecting extra files and environment variables into Backstage
    containers The mountPath field specifies the location where a ConfigMap or Secret
    is mounted. The behavior of the mount, whether it includes or excludes a subPath,
    depends on the specification of the key or mountPath fields. If key and mountPath
    are not specified: Each key or value is mounted as a filename or content with
    a subPath. If key is specified with or without mountPath: The specified key or
    value is mounted with a subPath. If only mountPath is specified: A directory containing
    all the keys or values is mounted without a subPath. If the containers field is
    not specified: The volume mounts only to the backstage backend container. By default,
    files mount only to the backstage backend container. You can also specify other
    targets, including a list of containers by name (such as dynamic plugin install
    or selectcustom sidecars) or select all containers in the Backstage Pod. [NOTE]
    ---- * OpenShift Container Platform does not automatically update a volume mounted
    with subPath. By default, the RHDH Operator monitors these ConfigMaps or Secrets
    and refreshes the RHDH Pod when changes occur. * For security purposes, Red Hat
    Developer Hub does not give the Operator Service Account read access to Secrets.
    As a result, mounting files from Secrets without specifying both mountPath and
    key is not supported. ---- 1. Apply the configuration to your Backstage custom
    resource (CR). The following code block is an example: ```yaml spec: application:
    extraFiles: mountPath: _<default_mount_path>_ configMaps: name: _<configmap_name_all_entries>_
    name: _<configmap_name_single_key>_ key: _<specific_file_key>_ containers: " "
    name: _<configmap_name_custom_path>_ mountPath: _<custom_cm_mount_path>_ containers:
    backstage backend install dynamic plugins secrets: name: _<secret_name_single_key>_
    key: _<specific_secret_key>_ containers: install dynamic plugins name: _<secret_name_custom_path>_
    mountPath: _<custom_secret_mount_path>_ pvcs: name: _<pvc_name_default_path>_
    name: _<pvc_name_custom_path>_ mountPath: _<custom_pvc_mount_path>_ extraEnvs:
    configMaps: name: _<configmap_name_env_var>_ key: _<env_var_key>_ containers:
    " " secrets: name: _<secret_name_all_envs>_ envs: name: _<static_env_var_name>_
    value: "_<static_env_var_value>_" containers: install dynamic plugins ``` where:
    spec.application.extraFiles.mountPath:: Specifies the default base mount path
    for files if no specific mountPath is set for a resource (for example, /<default_mount_path>).
    spec.application.extraFiles.configMaps.name:: Mounts all entries from <configmap_name_all_entries>
    to the default mount path. spec.application.extraFiles.configMaps.key:: Mounts
    **only the specified key (for example, <specific_file_key>.txt) from the ConfigMap.
    spec.application.extraFiles.configMaps.containers:: Targets all containers ("*")
    for mounting. spec.application.extraFiles.configMaps.mountPath:: Overrides the
    default and mounts all ConfigMap entries as a directory at the specified path
    (for example, /<custom_cm_mount_path>). spec.application.extraFiles.secrets.key::
    Mounts only a specific key from the Secret. spec.application.extraFiles.secrets.mountPath::
    Overrides the default and mounts all Secret entries as a directory at the specified
    path (for example, /<custom_secret_mount_path>). spec.application.extraFiles.pvcs.name::
    Mounts the PVC to the default mount path, appending the PVC name (for example,
    /<default_mount_path>/<pvc_name_default_path>). spec.application.extraFiles.pvcs.mountPath::
    Overrides the default and mounts the PVC to the specified'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:29:41.427598'
    uuid: c7d74d05-0b20-4a6f-a58a-490d6252f25e
  response: 'To use the Developer Hub Operator to run Red Hat Developer Hub with your
    custom configuration, you must create a Backstage custom resource (CR) that mounts
    files from your custom config maps and injects environment variables from your
    custom secrets. First, you author your Backstage CR in a my-rhdh-custom-resource.yaml
    file. After that, you apply the CR to start or update your Developer Hub instance
    using the command: `$ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project`.'
  user_input: how i use Red Hat Developer Hub with my config?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the OpenShift CLI (oc), you have access, with
    developer permissions, to the OpenShift Container Platform cluster aimed at containing
    your Developer Hub instance. Your administrator has installed the Red Hat Developer
    Hub Operator in the cluster. You have provisioned your custom config maps and
    secrets in your <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ### Injecting extra files and environment variables into Backstage
    containers The mountPath field specifies the location where a ConfigMap or Secret
    is mounted. The behavior of the mount, whether it includes or excludes a subPath,
    depends on the specification of the key or mountPath fields. If key and mountPath
    are not specified: Each key or value is mounted as a filename or content with
    a subPath. If key is specified with or without mountPath: The specified key or
    value is mounted with a subPath. If only mountPath is specified: A directory containing
    all the keys or values is mounted without a subPath. If the containers field is
    not specified: The volume mounts only to the backstage backend container. By default,
    files mount only to the backstage backend container. You can also specify other
    targets, including a list of containers by name (such as dynamic plugin install
    or selectcustom sidecars) or select all containers in the Backstage Pod. [NOTE]
    ---- * OpenShift Container Platform does not automatically update a volume mounted
    with subPath. By default, the RHDH Operator monitors these ConfigMaps or Secrets
    and refreshes the RHDH Pod when changes occur. * For security purposes, Red Hat
    Developer Hub does not give the Operator Service Account read access to Secrets.
    As a result, mounting files from Secrets without specifying both mountPath and
    key is not supported. ---- 1. Apply the configuration to your Backstage custom
    resource (CR). The following code block is an example: ```yaml spec: application:
    extraFiles: mountPath: _<default_mount_path>_ configMaps: name: _<configmap_name_all_entries>_
    name: _<configmap_name_single_key>_ key: _<specific_file_key>_ containers: " "
    name: _<configmap_name_custom_path>_ mountPath: _<custom_cm_mount_path>_ containers:
    backstage backend install dynamic plugins secrets: name: _<secret_name_single_key>_
    key: _<specific_secret_key>_ containers: install dynamic plugins name: _<secret_name_custom_path>_
    mountPath: _<custom_secret_mount_path>_ pvcs: name: _<pvc_name_default_path>_
    name: _<pvc_name_custom_path>_ mountPath: _<custom_pvc_mount_path>_ extraEnvs:
    configMaps: name: _<configmap_name_env_var>_ key: _<env_var_key>_ containers:
    " " secrets: name: _<secret_name_all_envs>_ envs: name: _<static_env_var_name>_
    value: "_<static_env_var_value>_" containers: install dynamic plugins ``` where:
    spec.application.extraFiles.mountPath:: Specifies the default base mount path
    for files if no specific mountPath is set for a resource (for example, /<default_mount_path>).
    spec.application.extraFiles.configMaps.name:: Mounts all entries from <configmap_name_all_entries>
    to the default mount path. spec.application.extraFiles.configMaps.key:: Mounts
    **only the specified key (for example, <specific_file_key>.txt) from the ConfigMap.
    spec.application.extraFiles.configMaps.containers:: Targets all containers ("*")
    for mounting. spec.application.extraFiles.configMaps.mountPath:: Overrides the
    default and mounts all ConfigMap entries as a directory at the specified path
    (for example, /<custom_cm_mount_path>). spec.application.extraFiles.secrets.key::
    Mounts only a specific key from the Secret. spec.application.extraFiles.secrets.mountPath::
    Overrides the default and mounts all Secret entries as a directory at the specified
    path (for example, /<custom_secret_mount_path>). spec.application.extraFiles.pvcs.name::
    Mounts the PVC to the default mount path, appending the PVC name (for example,
    /<default_mount_path>/<pvc_name_default_path>). spec.application.extraFiles.pvcs.mountPath::
    Overrides the default and mounts the PVC to the specified'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:29:50.937136'
    uuid: 1bddaf0f-eec1-48d1-a8cd-a2f59fc381c0
  response: To use an external PostgreSQL database with Red Hat Developer Hub, you
    must first disable the local database generation by setting `spec.database.enableLocalDb`
    to `false` in your Backstage custom resource. Next, you must inject the environment
    variables for the database by adding your secret's name, such as `my-rhdh-database-secrets`,
    to the list under `spec.application.extraEnvs.secrets`. Finally, to mount the
    necessary certificate files, you need to configure the `spec.application.extraFiles.secrets`
    section by providing the secret name, for example `my-rhdh-database-certificates-secrets`,
    and a list of the keys for the files to be mounted, such as `postgres-crt.pem`,
    `postgres-ca.pem`, and `postgres-key.key`.
  user_input: As a Platform Engineering Lead tasked with integrating our existing
    infrastructure, what are the precise configuration steps within the Backstage
    custom resource required to connect the Red Hat Developer Hub to an external PostgreSQL
    database, including how to disable the local database and properly inject the
    necessary database secrets and certificate files?
- context:
  - 'Using the Red Hat Developer Hub Operator to run Developer Hub with your custom
    configuration To use the Developer Hub Operator to run Red Hat Developer Hub with
    your custom configuration, create your Backstage custom resource (CR) that: Mounts
    files provisioned in your custom config maps. Injects environment variables provisioned
    in your custom secrets. By using the OpenShift CLI (oc), you have access, with
    developer permissions, to the OpenShift Container Platform cluster aimed at containing
    your Developer Hub instance. Your administrator has installed the Red Hat Developer
    Hub Operator in the cluster. You have provisioned your custom config maps and
    secrets in your <my rhdh project> project. 1. Author your Backstage CR in a my-rhdh-custom-resource.yaml
    file to use your custom config maps and secrets. Minimal my rhdh custom resource.yaml
    custom resource example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: my rhdh custom resource spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config extraEnvs: secrets: name:
    <my_product_secrets> extraFiles: mountPath: /opt/app root/src route: enabled:
    true database: enableLocalDb: true ``` my-rhdh-custom-resource.yaml custom resource
    example with dynamic plugins and RBAC policies config maps, and external PostgreSQL
    database secrets: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <my rhdh custom resource> spec: application: appConfig: mountPath:
    /opt/app root/src configMaps: name: my rhdh app config name: rbac policies dynamicPluginsConfigMapName:
    dynamic plugins rhdh extraEnvs: secrets: name: <my_product_secrets> name: my rhdh
    database secrets extraFiles: mountPath: /opt/app root/src secrets: name: my rhdh
    database certificates secrets key: postgres crt.pem, postgres ca.pem, postgres
    key.key route: enabled: true database: enableLocalDb: false ``` Mandatory fields::
    No fields are mandatory. You can create an empty Backstage CR and run Developer
    Hub with the default configuration. Optional fields:: spec.application.appConfig.configMaps::
    Enter your config map name list. Mount files in the my-rhdh-app-config config
    map: ```yaml spec: application: appConfig: mountPath: /opt/app root/src configMaps:
    name: my rhdh app config ``` Mount files in the my-rhdh-app-config and rbac-policies
    config maps: ```yaml spec: application: appConfig: mountPath: /opt/app root/src
    configMaps: name: my rhdh app config name: rbac policies ``` spec.application.extraEnvs.envs::
    Optionally, enter your additional environment variables that are not secrets,
    such as your proxy environment variables. Inject your HTTP_PROXY, HTTPS_PROXY
    and NO_PROXY environment variables: ```yaml spec: application: extraEnvs: envs:
    name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY value:
    ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org'' ```
    spec.application.extraEnvs.secrets:: Enter your environment variables secret name
    list. Inject the environment variables in your Red Hat Developer Hub secret: ```yaml
    spec: application: extraEnvs: secrets: name: <my_product_secrets> ``` Inject the
    environment variables in the Red Hat Developer Hub and my-rhdh-database-secrets
    secrets: ```yaml spec: application: extraEnvs: secrets: name: <my_product_secrets>
    name: my rhdh database secrets ``` [NOTE] ---- <my_product_secrets> is your preferred
    Developer Hub secret name, specifying the identifier for your secret configuration
    within Developer Hub. ---- spec.application.extraFiles.secrets:: Enter your certificates
    files secret name and files list. Mount the postgres-crt.pem, postgres-ca.pem,
    and postgres-key.key files contained in the my-rhdh-database-certificates-secrets
    secret: ```yaml spec: application: extraFiles: mountPath: /opt/app root/src secrets:
    name: my rhdh database certificates secrets key: postgres crt.pem, postgres ca.pem,
    postgres key.key ``` spec.database.enableLocalDb:: Enable or disable the local
    PostgreSQL database. Disable the local PostgreSQL database generation to use an
    external postgreSQL database: ```yaml spec: database: enableLocalDb: false ```
    On a development environment, use the local PostgreSQL database: ```yaml spec:
    database: enableLocalDb: true ``` spec.deployment:: Optionally, enter your deployment
    configuration. 2. Apply your Backstage CR to start or update your Developer Hub
    instance: ```terminal $ oc apply - filename=my rhdh custom resource.yaml - namespace=my
    rhdh project ``` ### Injecting extra files and environment variables into Backstage
    containers The mountPath field specifies the location where a ConfigMap or Secret
    is mounted. The behavior of the mount, whether it includes or excludes a subPath,
    depends on the specification of the key or mountPath fields. If key and mountPath
    are not specified: Each key or value is mounted as a filename or content with
    a subPath. If key is specified with or without mountPath: The specified key or
    value is mounted with a subPath. If only mountPath is specified: A directory containing
    all the keys or values is mounted without a subPath. If the containers field is
    not specified: The volume mounts only to the backstage backend container. By default,
    files mount only to the backstage backend container. You can also specify other
    targets, including a list of containers by name (such as dynamic plugin install
    or selectcustom sidecars) or select all containers in the Backstage Pod. [NOTE]
    ---- * OpenShift Container Platform does not automatically update a volume mounted
    with subPath. By default, the RHDH Operator monitors these ConfigMaps or Secrets
    and refreshes the RHDH Pod when changes occur. * For security purposes, Red Hat
    Developer Hub does not give the Operator Service Account read access to Secrets.
    As a result, mounting files from Secrets without specifying both mountPath and
    key is not supported. ---- 1. Apply the configuration to your Backstage custom
    resource (CR). The following code block is an example: ```yaml spec: application:
    extraFiles: mountPath: _<default_mount_path>_ configMaps: name: _<configmap_name_all_entries>_
    name: _<configmap_name_single_key>_ key: _<specific_file_key>_ containers: " "
    name: _<configmap_name_custom_path>_ mountPath: _<custom_cm_mount_path>_ containers:
    backstage backend install dynamic plugins secrets: name: _<secret_name_single_key>_
    key: _<specific_secret_key>_ containers: install dynamic plugins name: _<secret_name_custom_path>_
    mountPath: _<custom_secret_mount_path>_ pvcs: name: _<pvc_name_default_path>_
    name: _<pvc_name_custom_path>_ mountPath: _<custom_pvc_mount_path>_ extraEnvs:
    configMaps: name: _<configmap_name_env_var>_ key: _<env_var_key>_ containers:
    " " secrets: name: _<secret_name_all_envs>_ envs: name: _<static_env_var_name>_
    value: "_<static_env_var_value>_" containers: install dynamic plugins ``` where:
    spec.application.extraFiles.mountPath:: Specifies the default base mount path
    for files if no specific mountPath is set for a resource (for example, /<default_mount_path>).
    spec.application.extraFiles.configMaps.name:: Mounts all entries from <configmap_name_all_entries>
    to the default mount path. spec.application.extraFiles.configMaps.key:: Mounts
    **only the specified key (for example, <specific_file_key>.txt) from the ConfigMap.
    spec.application.extraFiles.configMaps.containers:: Targets all containers ("*")
    for mounting. spec.application.extraFiles.configMaps.mountPath:: Overrides the
    default and mounts all ConfigMap entries as a directory at the specified path
    (for example, /<custom_cm_mount_path>). spec.application.extraFiles.secrets.key::
    Mounts only a specific key from the Secret. spec.application.extraFiles.secrets.mountPath::
    Overrides the default and mounts all Secret entries as a directory at the specified
    path (for example, /<custom_secret_mount_path>). spec.application.extraFiles.pvcs.name::
    Mounts the PVC to the default mount path, appending the PVC name (for example,
    /<default_mount_path>/<pvc_name_default_path>). spec.application.extraFiles.pvcs.mountPath::
    Overrides the default and mounts the PVC to the specified'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:30:02.645096'
    uuid: 5b6b003e-9425-4bca-add6-17aa8d956294
  response: "To run Red Hat Developer Hub with a custom configuration, you create\
    \ a Backstage custom resource (CR) that mounts files from config maps, injects\
    \ environment variables from secrets, and can be configured for an external database.\
    \ \n\n1.  **Mounting Files from Config Maps**: You can mount files provisioned\
    \ in your custom config maps using the `spec.application.appConfig.configMaps`\
    \ field in your Backstage CR. For example, to mount files from a config map named\
    \ `my-rhdh-app-config`, you would use the following configuration:\n    ```yaml\n\
    \    spec:\n      application:\n        appConfig:\n          mountPath: /opt/app-root/src\n\
    \          configMaps:\n            - name: my-rhdh-app-config\n    ```\n    You\
    \ can also mount files from multiple config maps, such as `my-rhdh-app-config`\
    \ and `rbac-policies`, by listing them under `configMaps`.\n\n2.  **Injecting\
    \ Environment Variables from Secrets**: To inject environment variables, you use\
    \ the `spec.application.extraEnvs.secrets` field and provide a list of your secret\
    \ names. For instance, to inject variables from a secret named `<my_product_secrets>`,\
    \ the configuration would be:\n    ```yaml\n    spec:\n      application:\n  \
    \      extraEnvs:\n          secrets:\n            - name: <my_product_secrets>\n\
    \    ```\n    To use multiple secrets, such as `<my_product_secrets>` and `my-rhdh-database-secrets`,\
    \ you can list them both.\n\n3.  **Managing External Database Configurations**:\
    \ To use an external PostgreSQL database, you must disable the local one by setting\
    \ `spec.database.enableLocalDb` to `false`. You would then inject the necessary\
    \ database secrets and mount certificate files. An example configuration for an\
    \ external database involves:\n    *   Disabling the local database: `spec.database.enableLocalDb:\
    \ false`\n    *   Injecting database secrets via `extraEnvs`: `secrets: - name:\
    \ my-rhdh-database-secrets`\n    *   Mounting database certificate files from\
    \ a secret using `extraFiles`: \n        ```yaml\n        spec:\n          application:\n\
    \            extraFiles:\n              mountPath: /opt/app-root/src\n       \
    \       secrets:\n                - name: my-rhdh-database-certificates-secrets\n\
    \                  key: [postgres-crt.pem, postgres-ca.pem, postgres-key.key]\n\
    \        ```\nAfter authoring your `my-rhdh-custom-resource.yaml` file with these\
    \ configurations, you apply it using the `oc apply` command to start or update\
    \ your Developer Hub instance."
  user_input: Could you provide a comprehensive explanation of the various methods
    available for customizing a Red Hat Developer Hub instance by authoring a Backstage
    custom resource, specifically detailing how to mount files from config maps, inject
    environment variables from secrets, and manage external database configurations?
- context:
  - 'Using the Red Hat Developer Hub Helm chart to run Developer Hub with your custom
    configuration You can use the Red Hat Developer Hub Helm chart to add a custom
    application configuration file to your OpenShift Container Platform instance.
    By using the OpenShift Container Platform web console, you have access with developer
    permissions, to an OpenShift Container Platform project named <my rhdh project>,
    aimed at containing your Developer Hub instance. You have uploaded your custom
    configuration files and secrets in your <my rhdh project> project. 1. Configure
    Helm to use your custom configuration files in Developer Hub. 1. Go to the Helm
    tab to see the list of Helm releases. 2. Click the overflow menu on the Helm release
    that you want to use and select Upgrade. 3. Use the YAML view to edit the Helm
    configuration. 4. Set the value of the upstream.backstage.extraAppConfig.configMapRef
    and upstream.backstage.extraAppConfig.filename parameters as follows: Helm configuration
    excerpt ```yaml upstream: backstage: extraAppConfig: configMapRef: my rhdh app
    config filename: app config.yaml ``` 5. Click Upgrade. Install Developer Hub by
    using Helm. !:previouscontext: # Red Hat Developer Hub default configuration You
    can deploy a standard Red Hat Developer Hub (RHDH) instance, understand the structure,
    and tailor RHDH instance to meet your needs. ## Red Hat Developer Hub default
    configuration guide The Red Hat Developer Hub (RHDH) Operator creates a set of
    Kubernetes resources to deploy and manage a Backstage instance. The default configuration
    for these default resources is defined at the Operator level and can be customized
    for a specific instance using the Backstage Custom Resource (CR). This approach
    provides a clear starting point while offering flexibility to tailor each deployment.
    The default configuration is stored in a ConfigMap named rhdh-default-config located
    in the rhdh-operator namespace on OpenShift. This ConfigMap contains the YAML
    manifests that define the foundational structure of the RHDH instance. You can
    create a basic RHDH instance by applying an empty Backstage Custom Resource as
    follows: ```yaml apiVersion: backstage.redhat.com/v1alpha4 kind: Backstage metadata:
    name: my rhdh instance namespace: rhdh ``` The Operator automatically creates
    the following resources in the specified RHDH namespace by default based on the
    default configuration: [NOTE] ---- {cr-name} is the name of the Backstage Custom
    Resource, for example ''my-rhdh-instance'' in the above example. ---- ## Automated
    Operator features You can use the Operator to automate several key processes to
    effectively configure your Backstage application. ### Metadata generation The
    Operator automatically generates specific metadata values for all default resources
    at runtime to ensure your Backstage application functions properly. For all the
    default resources, metadata.name is generated according to the rules defined in
    the Default Configuration files, particularly the Resource name column. For example,
    Backstage Custom Resource (CR) named mybackstage creates Kubernetes Deployment
    resource called backstage-mybackstage. The following metadata is generated for
    each resource: deployment.yaml spec.selector.matchLabels[rhdh.redhat.com/app]
    = backstage {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    {cr name} service.yaml spec.selector[rhdh.redhat.com/app] = backstage {cr name}
    db statefulset.yaml spec.selector.matchLabels[rhdh.redhat.com/app] = backstage
    psql {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    psql {cr name} db service.yaml spec.selector[rhdh.redhat.com/app] = backstage
    psql {cr name} ### Multiple resources You can define and create multiple resources
    of the same type in a single YAML file. This is applicable to any resource type
    that is a list in the resource table. To define multiple resources, use the ---
    delimiter to separate each resource definition. For example, adding the following
    code snip to pvcs.yaml creates two PersistentVolumeClaims (PVCs) called backstage-{cr-name}-myclaim1
    and backstage-{cr-name}-myclaim2 and mounts them to the Backstage container accordingly.
    ```yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim1 ...
    -- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim2 ... ```
    ### Default base URLs The Operator automatically sets the base URLs for your Backstage
    application in the default app-config ConfigMap known as backstage-appconfig-{CR_name}.
    The Operator does so based on your Route parameters and the OpenShift cluster
    ingress domain. The Operator follows these rules to set the base URLs for your
    application: If the cluster is not OpenShift, the Operator makes no changes. If
    you explicitly set the spec.application.route.enabled field in your Custom Resource
    (CR) to false, no changes are made. If you define spec.application.route.host
    in the Backstage CR, the base URLs are set to https://<spec.application.route.host>.
    If you specify the spec.application.route.subdomain in the Backstage CR, the base
    URLs are set to https://<spec.application.route.subdomain>.<cluster_ingress_domain>.
    If no custom host or subdomain is provided, the Operator sets the base URLs to
    https://backstage <cr_name> <namespace>.<cluster_ingress_domain>, which is the
    default domain for the created Route resource. The Operator updates the following
    base URLs in the default app-config ConfigMap: app.baseUrl backend.baseUrl backend.cors.origin
    [NOTE] ---- You can perform these actions on a best-effort basis and only on OpenShift.
    During an error or on non-OpenShift clusters, you can still override these defaults
    by providing a custom app-config ConfigMap. ---- ## Mounts for default Secrets
    and Persistent Volume Claims (PVCs) You can use annotations to configure mount
    paths and specify containers for Secrets and Persistent Volume Claims (PVCs) that
    are attached to the Operator default resources in your Red Hat Developer Hub deployment.
    This method is specific for default objects, for instance, the Backstage Deployment
    that the Operator manages. ### Configuring mount paths for default Secrets and
    Persistent Volume Claims (PVCs) By default, the mount path is /opt/app-root/src.
    To specify a different path, add the rhdh.redhat.com/mount-path annotation to
    your resource. 1. To specify a PVC mount path, add the rhdh.redhat.com/mount-path
    annotation to your configuration file as shown in the following example: Example
    specifying the PVC mount path ```yaml apiVersion: v1 kind: PersistentVolumeClaim
    metadata: name: <my_claim> # Specifies the PVC to mount annotations: # Specifies
    which mount path the PVC mounts to (in this case, /mount/path/from/annotation
    directory) rhdh.redhat.com/mount-path: /mount/path/from/annotation ``` 2. To specify
    a Secret mount path, add the rhdh.redhat.com/mount-path annotation to your configuration
    file as shown in the following example: Example specifying where the Secret mounts
    ```yaml apiVersion: v1 kind: Secret metadata: name: <my_secret> # Specifies the
    Secret name annotations: rhdh.redhat.com/mount-path: /mount/path/from/annotation
    ``` ### Mounting Secrets and PVCs to specific containers By default, Secrets and
    PVCs mount only to the Red Hat Developer Hub backstage-backend container. You
    can add the rhdh.redhat.com/containers'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:30:14.460921'
    uuid: 2911995b-c0bb-4036-a2ed-a287d2922881
  response: You can use the Operator to automate several key processes to effectively
    configure your Backstage application. The Operator automatically generates specific
    metadata values for all default resources at runtime to ensure your application
    functions properly. For instance, a Backstage Custom Resource (CR) named mybackstage
    creates a Kubernetes Deployment resource called backstage-mybackstage. Additionally,
    the Operator automatically sets the base URLs for your Backstage application in
    the default app-config ConfigMap, based on your Route parameters and the OpenShift
    cluster ingress domain.
  user_input: how operator help configure Backstage?
- context:
  - 'Using the Red Hat Developer Hub Helm chart to run Developer Hub with your custom
    configuration You can use the Red Hat Developer Hub Helm chart to add a custom
    application configuration file to your OpenShift Container Platform instance.
    By using the OpenShift Container Platform web console, you have access with developer
    permissions, to an OpenShift Container Platform project named <my rhdh project>,
    aimed at containing your Developer Hub instance. You have uploaded your custom
    configuration files and secrets in your <my rhdh project> project. 1. Configure
    Helm to use your custom configuration files in Developer Hub. 1. Go to the Helm
    tab to see the list of Helm releases. 2. Click the overflow menu on the Helm release
    that you want to use and select Upgrade. 3. Use the YAML view to edit the Helm
    configuration. 4. Set the value of the upstream.backstage.extraAppConfig.configMapRef
    and upstream.backstage.extraAppConfig.filename parameters as follows: Helm configuration
    excerpt ```yaml upstream: backstage: extraAppConfig: configMapRef: my rhdh app
    config filename: app config.yaml ``` 5. Click Upgrade. Install Developer Hub by
    using Helm. !:previouscontext: # Red Hat Developer Hub default configuration You
    can deploy a standard Red Hat Developer Hub (RHDH) instance, understand the structure,
    and tailor RHDH instance to meet your needs. ## Red Hat Developer Hub default
    configuration guide The Red Hat Developer Hub (RHDH) Operator creates a set of
    Kubernetes resources to deploy and manage a Backstage instance. The default configuration
    for these default resources is defined at the Operator level and can be customized
    for a specific instance using the Backstage Custom Resource (CR). This approach
    provides a clear starting point while offering flexibility to tailor each deployment.
    The default configuration is stored in a ConfigMap named rhdh-default-config located
    in the rhdh-operator namespace on OpenShift. This ConfigMap contains the YAML
    manifests that define the foundational structure of the RHDH instance. You can
    create a basic RHDH instance by applying an empty Backstage Custom Resource as
    follows: ```yaml apiVersion: backstage.redhat.com/v1alpha4 kind: Backstage metadata:
    name: my rhdh instance namespace: rhdh ``` The Operator automatically creates
    the following resources in the specified RHDH namespace by default based on the
    default configuration: [NOTE] ---- {cr-name} is the name of the Backstage Custom
    Resource, for example ''my-rhdh-instance'' in the above example. ---- ## Automated
    Operator features You can use the Operator to automate several key processes to
    effectively configure your Backstage application. ### Metadata generation The
    Operator automatically generates specific metadata values for all default resources
    at runtime to ensure your Backstage application functions properly. For all the
    default resources, metadata.name is generated according to the rules defined in
    the Default Configuration files, particularly the Resource name column. For example,
    Backstage Custom Resource (CR) named mybackstage creates Kubernetes Deployment
    resource called backstage-mybackstage. The following metadata is generated for
    each resource: deployment.yaml spec.selector.matchLabels[rhdh.redhat.com/app]
    = backstage {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    {cr name} service.yaml spec.selector[rhdh.redhat.com/app] = backstage {cr name}
    db statefulset.yaml spec.selector.matchLabels[rhdh.redhat.com/app] = backstage
    psql {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    psql {cr name} db service.yaml spec.selector[rhdh.redhat.com/app] = backstage
    psql {cr name} ### Multiple resources You can define and create multiple resources
    of the same type in a single YAML file. This is applicable to any resource type
    that is a list in the resource table. To define multiple resources, use the ---
    delimiter to separate each resource definition. For example, adding the following
    code snip to pvcs.yaml creates two PersistentVolumeClaims (PVCs) called backstage-{cr-name}-myclaim1
    and backstage-{cr-name}-myclaim2 and mounts them to the Backstage container accordingly.
    ```yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim1 ...
    -- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim2 ... ```
    ### Default base URLs The Operator automatically sets the base URLs for your Backstage
    application in the default app-config ConfigMap known as backstage-appconfig-{CR_name}.
    The Operator does so based on your Route parameters and the OpenShift cluster
    ingress domain. The Operator follows these rules to set the base URLs for your
    application: If the cluster is not OpenShift, the Operator makes no changes. If
    you explicitly set the spec.application.route.enabled field in your Custom Resource
    (CR) to false, no changes are made. If you define spec.application.route.host
    in the Backstage CR, the base URLs are set to https://<spec.application.route.host>.
    If you specify the spec.application.route.subdomain in the Backstage CR, the base
    URLs are set to https://<spec.application.route.subdomain>.<cluster_ingress_domain>.
    If no custom host or subdomain is provided, the Operator sets the base URLs to
    https://backstage <cr_name> <namespace>.<cluster_ingress_domain>, which is the
    default domain for the created Route resource. The Operator updates the following
    base URLs in the default app-config ConfigMap: app.baseUrl backend.baseUrl backend.cors.origin
    [NOTE] ---- You can perform these actions on a best-effort basis and only on OpenShift.
    During an error or on non-OpenShift clusters, you can still override these defaults
    by providing a custom app-config ConfigMap. ---- ## Mounts for default Secrets
    and Persistent Volume Claims (PVCs) You can use annotations to configure mount
    paths and specify containers for Secrets and Persistent Volume Claims (PVCs) that
    are attached to the Operator default resources in your Red Hat Developer Hub deployment.
    This method is specific for default objects, for instance, the Backstage Deployment
    that the Operator manages. ### Configuring mount paths for default Secrets and
    Persistent Volume Claims (PVCs) By default, the mount path is /opt/app-root/src.
    To specify a different path, add the rhdh.redhat.com/mount-path annotation to
    your resource. 1. To specify a PVC mount path, add the rhdh.redhat.com/mount-path
    annotation to your configuration file as shown in the following example: Example
    specifying the PVC mount path ```yaml apiVersion: v1 kind: PersistentVolumeClaim
    metadata: name: <my_claim> # Specifies the PVC to mount annotations: # Specifies
    which mount path the PVC mounts to (in this case, /mount/path/from/annotation
    directory) rhdh.redhat.com/mount-path: /mount/path/from/annotation ``` 2. To specify
    a Secret mount path, add the rhdh.redhat.com/mount-path annotation to your configuration
    file as shown in the following example: Example specifying where the Secret mounts
    ```yaml apiVersion: v1 kind: Secret metadata: name: <my_secret> # Specifies the
    Secret name annotations: rhdh.redhat.com/mount-path: /mount/path/from/annotation
    ``` ### Mounting Secrets and PVCs to specific containers By default, Secrets and
    PVCs mount only to the Red Hat Developer Hub backstage-backend container. You
    can add the rhdh.redhat.com/containers'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:30:25.330624'
    uuid: eae52ffd-182a-4136-a407-79783ebf7306
  response: To use the Red Hat Developer Hub Helm chart with a custom configuration
    file, you must first upload your custom configuration files and secrets to your
    OpenShift Container Platform project. Then, navigate to the Helm tab to view the
    list of Helm releases. Click the overflow menu on the release you want to use
    and select Upgrade. Use the YAML view to edit the Helm configuration, setting
    the values for the `upstream.backstage.extraAppConfig.configMapRef` and `upstream.backstage.extraAppConfig.filename`
    parameters. An example configuration sets `configMapRef` to `my rhdh app config`
    and `filename` to `app config.yaml`. After setting these parameters, click Upgrade.
  user_input: how i use Helm for custom config file?
- context:
  - 'Using the Red Hat Developer Hub Helm chart to run Developer Hub with your custom
    configuration You can use the Red Hat Developer Hub Helm chart to add a custom
    application configuration file to your OpenShift Container Platform instance.
    By using the OpenShift Container Platform web console, you have access with developer
    permissions, to an OpenShift Container Platform project named <my rhdh project>,
    aimed at containing your Developer Hub instance. You have uploaded your custom
    configuration files and secrets in your <my rhdh project> project. 1. Configure
    Helm to use your custom configuration files in Developer Hub. 1. Go to the Helm
    tab to see the list of Helm releases. 2. Click the overflow menu on the Helm release
    that you want to use and select Upgrade. 3. Use the YAML view to edit the Helm
    configuration. 4. Set the value of the upstream.backstage.extraAppConfig.configMapRef
    and upstream.backstage.extraAppConfig.filename parameters as follows: Helm configuration
    excerpt ```yaml upstream: backstage: extraAppConfig: configMapRef: my rhdh app
    config filename: app config.yaml ``` 5. Click Upgrade. Install Developer Hub by
    using Helm. !:previouscontext: # Red Hat Developer Hub default configuration You
    can deploy a standard Red Hat Developer Hub (RHDH) instance, understand the structure,
    and tailor RHDH instance to meet your needs. ## Red Hat Developer Hub default
    configuration guide The Red Hat Developer Hub (RHDH) Operator creates a set of
    Kubernetes resources to deploy and manage a Backstage instance. The default configuration
    for these default resources is defined at the Operator level and can be customized
    for a specific instance using the Backstage Custom Resource (CR). This approach
    provides a clear starting point while offering flexibility to tailor each deployment.
    The default configuration is stored in a ConfigMap named rhdh-default-config located
    in the rhdh-operator namespace on OpenShift. This ConfigMap contains the YAML
    manifests that define the foundational structure of the RHDH instance. You can
    create a basic RHDH instance by applying an empty Backstage Custom Resource as
    follows: ```yaml apiVersion: backstage.redhat.com/v1alpha4 kind: Backstage metadata:
    name: my rhdh instance namespace: rhdh ``` The Operator automatically creates
    the following resources in the specified RHDH namespace by default based on the
    default configuration: [NOTE] ---- {cr-name} is the name of the Backstage Custom
    Resource, for example ''my-rhdh-instance'' in the above example. ---- ## Automated
    Operator features You can use the Operator to automate several key processes to
    effectively configure your Backstage application. ### Metadata generation The
    Operator automatically generates specific metadata values for all default resources
    at runtime to ensure your Backstage application functions properly. For all the
    default resources, metadata.name is generated according to the rules defined in
    the Default Configuration files, particularly the Resource name column. For example,
    Backstage Custom Resource (CR) named mybackstage creates Kubernetes Deployment
    resource called backstage-mybackstage. The following metadata is generated for
    each resource: deployment.yaml spec.selector.matchLabels[rhdh.redhat.com/app]
    = backstage {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    {cr name} service.yaml spec.selector[rhdh.redhat.com/app] = backstage {cr name}
    db statefulset.yaml spec.selector.matchLabels[rhdh.redhat.com/app] = backstage
    psql {cr name} spec.template.metadata.labels[rhdh.redhat.com/app] = backstage
    psql {cr name} db service.yaml spec.selector[rhdh.redhat.com/app] = backstage
    psql {cr name} ### Multiple resources You can define and create multiple resources
    of the same type in a single YAML file. This is applicable to any resource type
    that is a list in the resource table. To define multiple resources, use the ---
    delimiter to separate each resource definition. For example, adding the following
    code snip to pvcs.yaml creates two PersistentVolumeClaims (PVCs) called backstage-{cr-name}-myclaim1
    and backstage-{cr-name}-myclaim2 and mounts them to the Backstage container accordingly.
    ```yaml apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim1 ...
    -- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: myclaim2 ... ```
    ### Default base URLs The Operator automatically sets the base URLs for your Backstage
    application in the default app-config ConfigMap known as backstage-appconfig-{CR_name}.
    The Operator does so based on your Route parameters and the OpenShift cluster
    ingress domain. The Operator follows these rules to set the base URLs for your
    application: If the cluster is not OpenShift, the Operator makes no changes. If
    you explicitly set the spec.application.route.enabled field in your Custom Resource
    (CR) to false, no changes are made. If you define spec.application.route.host
    in the Backstage CR, the base URLs are set to https://<spec.application.route.host>.
    If you specify the spec.application.route.subdomain in the Backstage CR, the base
    URLs are set to https://<spec.application.route.subdomain>.<cluster_ingress_domain>.
    If no custom host or subdomain is provided, the Operator sets the base URLs to
    https://backstage <cr_name> <namespace>.<cluster_ingress_domain>, which is the
    default domain for the created Route resource. The Operator updates the following
    base URLs in the default app-config ConfigMap: app.baseUrl backend.baseUrl backend.cors.origin
    [NOTE] ---- You can perform these actions on a best-effort basis and only on OpenShift.
    During an error or on non-OpenShift clusters, you can still override these defaults
    by providing a custom app-config ConfigMap. ---- ## Mounts for default Secrets
    and Persistent Volume Claims (PVCs) You can use annotations to configure mount
    paths and specify containers for Secrets and Persistent Volume Claims (PVCs) that
    are attached to the Operator default resources in your Red Hat Developer Hub deployment.
    This method is specific for default objects, for instance, the Backstage Deployment
    that the Operator manages. ### Configuring mount paths for default Secrets and
    Persistent Volume Claims (PVCs) By default, the mount path is /opt/app-root/src.
    To specify a different path, add the rhdh.redhat.com/mount-path annotation to
    your resource. 1. To specify a PVC mount path, add the rhdh.redhat.com/mount-path
    annotation to your configuration file as shown in the following example: Example
    specifying the PVC mount path ```yaml apiVersion: v1 kind: PersistentVolumeClaim
    metadata: name: <my_claim> # Specifies the PVC to mount annotations: # Specifies
    which mount path the PVC mounts to (in this case, /mount/path/from/annotation
    directory) rhdh.redhat.com/mount-path: /mount/path/from/annotation ``` 2. To specify
    a Secret mount path, add the rhdh.redhat.com/mount-path annotation to your configuration
    file as shown in the following example: Example specifying where the Secret mounts
    ```yaml apiVersion: v1 kind: Secret metadata: name: <my_secret> # Specifies the
    Secret name annotations: rhdh.redhat.com/mount-path: /mount/path/from/annotation
    ``` ### Mounting Secrets and PVCs to specific containers By default, Secrets and
    PVCs mount only to the Red Hat Developer Hub backstage-backend container. You
    can add the rhdh.redhat.com/containers'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:30:36.211887'
    uuid: 712261ea-8cde-4a9d-baca-26013d936f00
  response: To use the Red Hat Developer Hub Helm chart with a custom configuration,
    you must have developer permissions to an OpenShift Container Platform project
    where your custom configuration files and secrets are uploaded. First, go to the
    Helm tab and find the Helm release you want to use. Click its overflow menu and
    select Upgrade. Use the YAML view to edit the configuration, setting the values
    for the `upstream.backstage.extraAppConfig.configMapRef` and `upstream.backstage.extraAppConfig.filename`
    parameters. After setting these, click Upgrade.
  user_input: how do i use a helm chart for a custom configuraton in Red Hat Developer
    Hub?
- context:
  - 'Configuring an external PostgreSQL instance using the Operator You can configure
    an external PostgreSQL instance using the Red Hat Developer Hub Operator. By default,
    the Operator creates and manages a local instance of PostgreSQL in the same namespace
    where you have deployed the RHDH instance. However, you can change this default
    setting to configure an external PostgreSQL database server, for example, Amazon
    Web Services (AWS) Relational Database Service (RDS) or Azure database. You meet
    the Sizing requirements for external PostgreSQL deployments. You are using a supported
    version of PostgreSQL. For more information, see the Product life cycle page.
    You have the following details: db host: Denotes your PostgreSQL instance Domain
    Name System (DNS) or IP address db port: Denotes your PostgreSQL instance port
    number, such as 5432 username: Denotes the user name to connect to your PostgreSQL
    instance password: Denotes the password to connect to your PostgreSQL instance
    You have installed the Red Hat Developer Hub Operator. Optional: You have a CA
    certificate, Transport Layer Security (TLS) private key, and TLS certificate so
    that you can secure your database connection by using the TLS protocol. For more
    information, refer to your PostgreSQL vendor documentation. [NOTE] ---- By default,
    Developer Hub uses a database for each plugin and automatically creates it if
    none is found. You might need the Create Database privilege in addition to PSQL
    Database privileges for configuring an external PostgreSQL instance. ---- 1. Optional:
    Create a certificate secret to configure your PostgreSQL instance with a TLS connection:
    ```yaml cat <<EOF | oc n my rhdh project create f apiVersion: v1 kind: Secret
    metadata: name: my rhdh database certificates secrets 1 type: Opaque stringData:
    postgres ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres
    key.key: | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: |
    ---- BEGIN CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name
    of the certificate secret. Provide the CA certificate key. Optional: Provide the
    TLS private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```yaml cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based on the required Secure Sockets Layer (SSL) mode. Optional:
    Provide the value only if you need a TLS connection for your PostgreSQL instance.
    3. Create your Backstage custom resource (CR): ```terminal cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name:
    <backstage-instance-name> spec: database: enableLocalDb: false 1 application:
    extraFiles: mountPath: <path> # e g /opt/app-root/src secrets: - name: my-rhdh-database-certificates-secrets
    2 key: postgres-crt.pem, postgres-ca.pem, postgres-key.key # key name as in my-rhdh-database-certificates-secrets
    Secret extraEnvs: secrets: - name: my-rhdh-database-secrets 3 # ... ``` Set the
    value of the enableLocalDb parameter to false to disable creating local PostgreSQL
    instances. Provide the name of the certificate secret if you have configured a
    TLS connection. Provide the name of the credential secret that you created. [NOTE]
    ---- The environment variables listed in the Backstage CR work with the Operator
    default configuration. If you have changed the Operator default configuration,
    you must reconfigure the Backstage CR accordingly. ---- 4. Apply the Backstage
    CR to the namespace where you have deployed the Developer Hub instance. ## Configuring
    an external PostgreSQL instance using the Helm Chart You can configure an external
    PostgreSQL instance by using the Helm Chart. By default, the Helm Chart creates
    and manages a local instance of PostgreSQL in the same namespace where you have
    deployed the RHDH instance. However, you can change this default setting to configure
    an external PostgreSQL database server, for example, Amazon Web Services (AWS)
    Relational Database Service (RDS) or Azure database. You meet the Sizing requirements
    for external PostgreSQL deployments. You are using a supported version of PostgreSQL.
    For more information, see the Product life cycle page. You have the following
    details: db host: Denotes your PostgreSQL instance Domain Name System (DNS) or
    IP address db port: Denotes your PostgreSQL instance port number, such as 5432
    username: Denotes the user name to connect to your PostgreSQL instance password:
    Denotes the password to connect to your PostgreSQL instance You have installed
    the RHDH application by using the Helm Chart. Optional: You have a CA certificate,
    Transport Layer Security (TLS) private key, and TLS certificate so that you can
    secure your database connection by using the TLS protocol. For more information,
    refer to your PostgreSQL vendor documentation. [NOTE] ---- By default, Developer
    Hub uses a database for each plugin and automatically creates it if none is found.
    You might need the Create Database privilege in addition to PSQL Database privileges
    for configuring an external PostgreSQL instance. ---- 1. Optional: Create a certificate
    secret to configure your PostgreSQL instance with a TLS connection: ```terminal
    cat <<EOF | oc n <your namespace> create f apiVersion: v1 kind: Secret metadata:
    name: my rhdh database certificates secrets 1 type: Opaque stringData: postgres
    ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres key.key:
    | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: | ---- BEGIN
    CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name of the
    certificate secret. Provide the CA certificate key. Optional: Provide the TLS
    private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```terminal cat <<EOF | oc -n
    <your-namespace> create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:30:46.347761'
    uuid: f7d2db76-b0b6-4b93-976a-d62a4799f982
  response: To secure your database connection using the Transport Layer Security
    (TLS) protocol, you optionally need a CA certificate, a TLS private key, and a
    TLS certificate. The first optional step is to create a certificate secret for
    the TLS connection. This secret should be named and contain the CA certificate
    key, and optionally the TLS private key and TLS certificate key. The second step
    is to create a credential secret to connect with the PostgreSQL instance, which
    for a TLS connection, can optionally include a value for `PGSSLMODE` and `NODE_EXTRA_CA_CERTS`.
    Finally, when creating your Backstage custom resource (CR), you must provide the
    name of the certificate secret under `spec.application.secrets` and the name of
    the credential secret under `spec.application.extraEnvs.secrets`.
  user_input: I'm trying to figure out the proccess for our external PostgreSQL setup
    with Red Hat Developer Hub, what are the specific requirments and steps involved
    if we want to secure the database connection using Transprt Layer Securty (TLS)
    when we are using the Operator method?
- context:
  - 'Configuring an external PostgreSQL instance using the Operator You can configure
    an external PostgreSQL instance using the Red Hat Developer Hub Operator. By default,
    the Operator creates and manages a local instance of PostgreSQL in the same namespace
    where you have deployed the RHDH instance. However, you can change this default
    setting to configure an external PostgreSQL database server, for example, Amazon
    Web Services (AWS) Relational Database Service (RDS) or Azure database. You meet
    the Sizing requirements for external PostgreSQL deployments. You are using a supported
    version of PostgreSQL. For more information, see the Product life cycle page.
    You have the following details: db host: Denotes your PostgreSQL instance Domain
    Name System (DNS) or IP address db port: Denotes your PostgreSQL instance port
    number, such as 5432 username: Denotes the user name to connect to your PostgreSQL
    instance password: Denotes the password to connect to your PostgreSQL instance
    You have installed the Red Hat Developer Hub Operator. Optional: You have a CA
    certificate, Transport Layer Security (TLS) private key, and TLS certificate so
    that you can secure your database connection by using the TLS protocol. For more
    information, refer to your PostgreSQL vendor documentation. [NOTE] ---- By default,
    Developer Hub uses a database for each plugin and automatically creates it if
    none is found. You might need the Create Database privilege in addition to PSQL
    Database privileges for configuring an external PostgreSQL instance. ---- 1. Optional:
    Create a certificate secret to configure your PostgreSQL instance with a TLS connection:
    ```yaml cat <<EOF | oc n my rhdh project create f apiVersion: v1 kind: Secret
    metadata: name: my rhdh database certificates secrets 1 type: Opaque stringData:
    postgres ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres
    key.key: | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: |
    ---- BEGIN CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name
    of the certificate secret. Provide the CA certificate key. Optional: Provide the
    TLS private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```yaml cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based on the required Secure Sockets Layer (SSL) mode. Optional:
    Provide the value only if you need a TLS connection for your PostgreSQL instance.
    3. Create your Backstage custom resource (CR): ```terminal cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name:
    <backstage-instance-name> spec: database: enableLocalDb: false 1 application:
    extraFiles: mountPath: <path> # e g /opt/app-root/src secrets: - name: my-rhdh-database-certificates-secrets
    2 key: postgres-crt.pem, postgres-ca.pem, postgres-key.key # key name as in my-rhdh-database-certificates-secrets
    Secret extraEnvs: secrets: - name: my-rhdh-database-secrets 3 # ... ``` Set the
    value of the enableLocalDb parameter to false to disable creating local PostgreSQL
    instances. Provide the name of the certificate secret if you have configured a
    TLS connection. Provide the name of the credential secret that you created. [NOTE]
    ---- The environment variables listed in the Backstage CR work with the Operator
    default configuration. If you have changed the Operator default configuration,
    you must reconfigure the Backstage CR accordingly. ---- 4. Apply the Backstage
    CR to the namespace where you have deployed the Developer Hub instance. ## Configuring
    an external PostgreSQL instance using the Helm Chart You can configure an external
    PostgreSQL instance by using the Helm Chart. By default, the Helm Chart creates
    and manages a local instance of PostgreSQL in the same namespace where you have
    deployed the RHDH instance. However, you can change this default setting to configure
    an external PostgreSQL database server, for example, Amazon Web Services (AWS)
    Relational Database Service (RDS) or Azure database. You meet the Sizing requirements
    for external PostgreSQL deployments. You are using a supported version of PostgreSQL.
    For more information, see the Product life cycle page. You have the following
    details: db host: Denotes your PostgreSQL instance Domain Name System (DNS) or
    IP address db port: Denotes your PostgreSQL instance port number, such as 5432
    username: Denotes the user name to connect to your PostgreSQL instance password:
    Denotes the password to connect to your PostgreSQL instance You have installed
    the RHDH application by using the Helm Chart. Optional: You have a CA certificate,
    Transport Layer Security (TLS) private key, and TLS certificate so that you can
    secure your database connection by using the TLS protocol. For more information,
    refer to your PostgreSQL vendor documentation. [NOTE] ---- By default, Developer
    Hub uses a database for each plugin and automatically creates it if none is found.
    You might need the Create Database privilege in addition to PSQL Database privileges
    for configuring an external PostgreSQL instance. ---- 1. Optional: Create a certificate
    secret to configure your PostgreSQL instance with a TLS connection: ```terminal
    cat <<EOF | oc n <your namespace> create f apiVersion: v1 kind: Secret metadata:
    name: my rhdh database certificates secrets 1 type: Opaque stringData: postgres
    ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres key.key:
    | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: | ---- BEGIN
    CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name of the
    certificate secret. Provide the CA certificate key. Optional: Provide the TLS
    private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```terminal cat <<EOF | oc -n
    <your-namespace> create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:31:00.275186'
    uuid: ccd4dbbc-e713-4f21-ad74-4ca78ab59857
  response: To create your Backstage custom resource (CR), you use a `cat <<EOF |
    oc -n my-rhdh-project create -f -` command with the apiVersion `rhdh.redhat.com/v1alpha3`
    and kind `Backstage`. Within the `spec`, you must set the `enableLocalDb` parameter
    to `false` to disable the creation of local PostgreSQL instances. You also need
    to provide the name of the credential secret you created under `extraEnvs.secrets`.
    If you have configured a TLS connection, you must also provide the name of the
    certificate secret under `application.secrets`. Finally, you apply the Backstage
    CR to the namespace where you have deployed the Developer Hub instance.
  user_input: how do i create the backstge cr?
- context:
  - 'Configuring an external PostgreSQL instance using the Operator You can configure
    an external PostgreSQL instance using the Red Hat Developer Hub Operator. By default,
    the Operator creates and manages a local instance of PostgreSQL in the same namespace
    where you have deployed the RHDH instance. However, you can change this default
    setting to configure an external PostgreSQL database server, for example, Amazon
    Web Services (AWS) Relational Database Service (RDS) or Azure database. You meet
    the Sizing requirements for external PostgreSQL deployments. You are using a supported
    version of PostgreSQL. For more information, see the Product life cycle page.
    You have the following details: db host: Denotes your PostgreSQL instance Domain
    Name System (DNS) or IP address db port: Denotes your PostgreSQL instance port
    number, such as 5432 username: Denotes the user name to connect to your PostgreSQL
    instance password: Denotes the password to connect to your PostgreSQL instance
    You have installed the Red Hat Developer Hub Operator. Optional: You have a CA
    certificate, Transport Layer Security (TLS) private key, and TLS certificate so
    that you can secure your database connection by using the TLS protocol. For more
    information, refer to your PostgreSQL vendor documentation. [NOTE] ---- By default,
    Developer Hub uses a database for each plugin and automatically creates it if
    none is found. You might need the Create Database privilege in addition to PSQL
    Database privileges for configuring an external PostgreSQL instance. ---- 1. Optional:
    Create a certificate secret to configure your PostgreSQL instance with a TLS connection:
    ```yaml cat <<EOF | oc n my rhdh project create f apiVersion: v1 kind: Secret
    metadata: name: my rhdh database certificates secrets 1 type: Opaque stringData:
    postgres ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres
    key.key: | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: |
    ---- BEGIN CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name
    of the certificate secret. Provide the CA certificate key. Optional: Provide the
    TLS private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```yaml cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based on the required Secure Sockets Layer (SSL) mode. Optional:
    Provide the value only if you need a TLS connection for your PostgreSQL instance.
    3. Create your Backstage custom resource (CR): ```terminal cat <<EOF | oc -n my-rhdh-project
    create -f - apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name:
    <backstage-instance-name> spec: database: enableLocalDb: false 1 application:
    extraFiles: mountPath: <path> # e g /opt/app-root/src secrets: - name: my-rhdh-database-certificates-secrets
    2 key: postgres-crt.pem, postgres-ca.pem, postgres-key.key # key name as in my-rhdh-database-certificates-secrets
    Secret extraEnvs: secrets: - name: my-rhdh-database-secrets 3 # ... ``` Set the
    value of the enableLocalDb parameter to false to disable creating local PostgreSQL
    instances. Provide the name of the certificate secret if you have configured a
    TLS connection. Provide the name of the credential secret that you created. [NOTE]
    ---- The environment variables listed in the Backstage CR work with the Operator
    default configuration. If you have changed the Operator default configuration,
    you must reconfigure the Backstage CR accordingly. ---- 4. Apply the Backstage
    CR to the namespace where you have deployed the Developer Hub instance. ## Configuring
    an external PostgreSQL instance using the Helm Chart You can configure an external
    PostgreSQL instance by using the Helm Chart. By default, the Helm Chart creates
    and manages a local instance of PostgreSQL in the same namespace where you have
    deployed the RHDH instance. However, you can change this default setting to configure
    an external PostgreSQL database server, for example, Amazon Web Services (AWS)
    Relational Database Service (RDS) or Azure database. You meet the Sizing requirements
    for external PostgreSQL deployments. You are using a supported version of PostgreSQL.
    For more information, see the Product life cycle page. You have the following
    details: db host: Denotes your PostgreSQL instance Domain Name System (DNS) or
    IP address db port: Denotes your PostgreSQL instance port number, such as 5432
    username: Denotes the user name to connect to your PostgreSQL instance password:
    Denotes the password to connect to your PostgreSQL instance You have installed
    the RHDH application by using the Helm Chart. Optional: You have a CA certificate,
    Transport Layer Security (TLS) private key, and TLS certificate so that you can
    secure your database connection by using the TLS protocol. For more information,
    refer to your PostgreSQL vendor documentation. [NOTE] ---- By default, Developer
    Hub uses a database for each plugin and automatically creates it if none is found.
    You might need the Create Database privilege in addition to PSQL Database privileges
    for configuring an external PostgreSQL instance. ---- 1. Optional: Create a certificate
    secret to configure your PostgreSQL instance with a TLS connection: ```terminal
    cat <<EOF | oc n <your namespace> create f apiVersion: v1 kind: Secret metadata:
    name: my rhdh database certificates secrets 1 type: Opaque stringData: postgres
    ca.pem: | ---- BEGIN CERTIFICATE---- <ca certificate key> 2 postgres key.key:
    | ---- BEGIN CERTIFICATE---- <tls private key> 3 postgres crt.pem: | ---- BEGIN
    CERTIFICATE---- <tls certificate key> 4 # ... EOF ``` Provide the name of the
    certificate secret. Provide the CA certificate key. Optional: Provide the TLS
    private key. Optional: Provide the TLS certificate key. 2. Create a credential
    secret to connect with the PostgreSQL instance: ```terminal cat <<EOF | oc -n
    <your-namespace> create -f - apiVersion: v1 kind: Secret metadata: name: my-rhdh-database-secrets
    1 type: Opaque stringData: 2 POSTGRES_PASSWORD: <password> POSTGRES_PORT: "<db-port>"
    POSTGRES_USER: <username> POSTGRES_HOST: <db-host> PGSSLMODE: <ssl-mode> # for
    TLS connection 3 NODE_EXTRA_CA_CERTS: <abs-path-to-pem-file> # for TLS connection,
    e.g. /opt/app-root/src/postgres-crt.pem 4 EOF ``` Provide the name of the credential
    secret. Provide credential data to connect with your PostgreSQL instance. Optional:
    Provide the value based'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:31:29.563219'
    uuid: 157f09e0-2420-4beb-b969-2e96a192b8ea
  response: 'To configure an external PostgreSQL instance using the Helm Chart, you
    must meet the Sizing requirements for external PostgreSQL deployments and be using
    a supported version of PostgreSQL. You need to have the RHDH application installed
    by using the Helm Chart. You must also have the following details for your instance:
    the db host (DNS or IP address), db port (such as 5432), the username, and the
    password. Optionally, for a secure TLS connection, you can have a CA certificate,
    a Transport Layer Security (TLS) private key, and a TLS certificate.'
  user_input: What are the prerequisits and details I need to have ready to configur
    an extenal PostgreSQL instance using a Heln Chart?
- context:
  - 'on the required Secure Sockets Layer (SSL) mode. Optional: Provide the value
    only if you need a TLS connection for your PostgreSQL instance. 3. Configure your
    PostgreSQL instance in the Helm configuration file named values.yaml: ```yaml
    # ... upstream: postgresql: enabled: false # disable PostgreSQL instance creation
    1 auth: existingSecret: my-rhdh-database-secrets # inject credentials secret to
    Backstage 2 backstage: appConfig: backend: database: connection: # configure Backstage
    DB connection parameters host: ${POSTGRES_HOST} port: ${POSTGRES_PORT} user: ${POSTGRES_USER}
    password: ${POSTGRES_PASSWORD} ssl: rejectUnauthorized: true, ca: $file: /opt/app-root/src/postgres-ca.pem
    key: $file: /opt/app-root/src/postgres-key.key cert: $file: /opt/app-root/src/postgres-crt.pem
    extraEnvVarsSecrets: - my-rhdh-database-secrets # inject credentials secret to
    Backstage 3 extraEnvVars: - name: BACKEND_SECRET valueFrom: secretKeyRef: key:
    backend-secret name: ''{{ include "janus-idp.backend-secret-name" $ }}'' extraVolumeMounts:
    - mountPath: /opt/app-root/src/dynamic-plugins-root name: dynamic-plugins-root
    - mountPath: /opt/app-root/src/postgres-crt.pem name: postgres-crt # inject TLS
    certificate to Backstage cont. 4 subPath: postgres-crt.pem - mountPath: /opt/app-root/src/postgres-ca.pem
    name: postgres-ca # inject CA certificate to Backstage cont. 5 subPath: postgres-ca.pem
    - mountPath: /opt/app-root/src/postgres-key.key name: postgres-key # inject TLS
    private key to Backstage cont. 6 subPath: postgres-key.key extraVolumes: - ephemeral:
    volumeClaimTemplate: spec: accessModes: - ReadWriteOnce resources: requests: storage:
    1Gi name: dynamic-plugins-root - configMap: defaultMode: 420 name: dynamic-plugins
    optional: true name: dynamic-plugins - name: dynamic-plugins-npmrc secret: defaultMode:
    420 optional: true secretName: ''{{ printf "%s-dynamic-plugins-npmrc" .Release.Name
    }}'' - name: postgres-crt secret: secretName: my-rhdh-database-certificates-secrets
    7 # ... ``` Set the value of the upstream.postgresql.enabled parameter to false
    to disable creating local PostgreSQL instances. Provide the name of the credential
    secret. Provide the name of the credential secret. Optional: Provide the name
    of the TLS certificate only for a TLS connection. Optional: Provide the name of
    the CA certificate only for a TLS connection. Optional: Provide the name of the
    TLS private key only if your TLS connection requires a private key. Provide the
    name of the certificate secret if you have configured a TLS connection. 4. Apply
    the configuration changes in your Helm configuration file named values.yaml: ```terminal
    helm upgrade n <your namespace> <your deploy name> openshift helm charts/redhat
    developer hub f values.yaml - version 1.8.0 ``` ## Migrating local databases to
    an external database server using the Operator By default, Red Hat Developer Hub
    hosts the data for each plugin in a PostgreSQL database. When you fetch the list
    of databases, you might see multiple databases based on the number of plugins
    configured in Developer Hub. You can migrate the data from an RHDH instance hosted
    on a local PostgreSQL server to an external PostgreSQL service, such as AWS RDS,
    Azure database, or Crunchy database. To migrate the data from each RHDH instance,
    you can use PostgreSQL utilities, such as pg_dump with psql or pgAdmin. [NOTE]
    ---- The following procedure uses a database copy script to do a quick migration.
    ---- You have installed the pg_dump and psql utilities on your local machine.
    For data export, you have the PGSQL user privileges to make a full dump of local
    databases. For data import, you have the PGSQL admin privileges to create an external
    database and populate it with database dumps. 1. Configure port forwarding for
    the local PostgreSQL database pod by running the following command on a terminal:
    ```terminal oc port forward n <your namespace> <pgsql pod name> <forward to port>:<forward
    from port> ``` Where: * The <pgsql-pod-name> variable denotes the name of a PostgreSQL
    pod with the format backstage-psql-<deployment-name>-<_index>. * The <forward-to-port>
    variable denotes the port of your choice to forward PostgreSQL data to. * The
    <forward-from-port> variable denotes the local PostgreSQL instance port, such
    as 5432. Example: Configuring port forwarding ```terminal oc port forward n developer
    hub backstage psql developer hub 0 15432:5432 ``` 2. Make a copy of the following
    db_copy.sh script and edit the details based on your configuration: ```bash #!/bin/bash
    to_host=<db service host> 1 to_port=5432 2 to_user=postgres 3 from_host=127.0.0.1
    4 from_port=15432 5 from_user=postgres 6 allDB=("backstage_plugin_app" "backstage_plugin_auth"
    "backstage_plugin_catalog" "backstage_plugin_permission" "backstage_plugin_scaffolder"
    "backstage_plugin_search") 7 for db in ${!allDB[@]}; do db=${allDB[$db]} echo
    Copying database: $db PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user
    -c "create database $db;" pg_dump -h $from_host -p $from_port -U $from_user -d
    $db | PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user -d $db done
    ``` The destination host name, for example, <db-instance-name>.rds.amazonaws.com.
    The destination port, such as 5432. The destination server username, for example,
    postgres. The source host name, such as 127.0.0.1. The source port number, such
    as the <forward-to-port> variable. The source server username, for example, postgres.
    The name of databases to import in double quotes separated by spaces, for example,
    ("backstage_plugin_app" "backstage_plugin_auth" "backstage_plugin_catalog" "backstage_plugin_permission"
    "backstage_plugin_scaffolder" "backstage_plugin_search"). 3. Create a destination
    database for copying the data: ```terminal /bin/bash TO_PSW=<destination db password>
    /path/to/db_copy.sh 1 ``` The <destination-db-password> variable denotes the password
    to connect to the destination database. [NOTE] ---- You can stop port forwarding
    when the copying of the data is complete. For more information about handling
    large databases and using the compression tools, see the Handling Large Databases
    section on the PostgreSQL website. ---- 4. Reconfigure your Backstage custom resource
    (CR). For more information, see Configuring an external PostgreSQL instance using
    the Operator. 5. Check that the following code is present at the end of your Backstage
    CR after reconfiguration: ```yaml # ... spec: database: enableLocalDb: false application:
    # ... extraFiles: secrets: - name: my-rhdh-database-certificates-secrets key:
    postgres-crt.pem # key name as in my-rhdh-database-certificates-secrets Secret
    extraEnvs: secrets: - name: my-rhdh-database-secrets # ... ``` [NOTE] ---- Reconfiguring
    the Backstage CR deletes the corresponding StatefulSet and Pod objects, but does
    not delete the PersistenceVolumeClaim object. Use the following command to delete
    the local PersistenceVolumeClaim object: ```terminal oc n developer hub delete
    pvc <local psql pvc name> ``` where, the <local-psql-pvc-name> variable is in
    the data-<psql-pod-name> format. ---- 6. Apply the configuration changes. 1. Verify
    that your RHDH instance is running with the migrated data and does not contain
    the local PostgreSQL database by running the following command: ```terminal oc
    get pods n <your namespace> ``` 2. Check the output for the following details:
    * The backstage-developer-hub-xxx pod is in running state. * The backstage-psql-developer-hub-0
    pod is not available. You can also verify these details using the Topology view
    in the OpenShift'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:31:37.958054'
    uuid: 2a3aaf61-97ba-45f9-8638-08fd0a58269c
  response: 'To configure the Secure Sockets Layer (SSL) for a PostgreSQL database
    connection in the Helm configuration file, you can set the following parameters
    under `backstage.appConfig.backend.database.connection`: `rejectUnauthorized`,
    `ca`, `key`, and `cert`. Providing these values is optional and only necessary
    if a TLS connection is required for your PostgreSQL instance. The `ca` parameter
    points to the CA certificate file, `key` to the TLS private key file, and `cert`
    to the TLS certificate file.'
  user_input: backstage postgresql SSL connection parameters
- context:
  - 'on the required Secure Sockets Layer (SSL) mode. Optional: Provide the value
    only if you need a TLS connection for your PostgreSQL instance. 3. Configure your
    PostgreSQL instance in the Helm configuration file named values.yaml: ```yaml
    # ... upstream: postgresql: enabled: false # disable PostgreSQL instance creation
    1 auth: existingSecret: my-rhdh-database-secrets # inject credentials secret to
    Backstage 2 backstage: appConfig: backend: database: connection: # configure Backstage
    DB connection parameters host: ${POSTGRES_HOST} port: ${POSTGRES_PORT} user: ${POSTGRES_USER}
    password: ${POSTGRES_PASSWORD} ssl: rejectUnauthorized: true, ca: $file: /opt/app-root/src/postgres-ca.pem
    key: $file: /opt/app-root/src/postgres-key.key cert: $file: /opt/app-root/src/postgres-crt.pem
    extraEnvVarsSecrets: - my-rhdh-database-secrets # inject credentials secret to
    Backstage 3 extraEnvVars: - name: BACKEND_SECRET valueFrom: secretKeyRef: key:
    backend-secret name: ''{{ include "janus-idp.backend-secret-name" $ }}'' extraVolumeMounts:
    - mountPath: /opt/app-root/src/dynamic-plugins-root name: dynamic-plugins-root
    - mountPath: /opt/app-root/src/postgres-crt.pem name: postgres-crt # inject TLS
    certificate to Backstage cont. 4 subPath: postgres-crt.pem - mountPath: /opt/app-root/src/postgres-ca.pem
    name: postgres-ca # inject CA certificate to Backstage cont. 5 subPath: postgres-ca.pem
    - mountPath: /opt/app-root/src/postgres-key.key name: postgres-key # inject TLS
    private key to Backstage cont. 6 subPath: postgres-key.key extraVolumes: - ephemeral:
    volumeClaimTemplate: spec: accessModes: - ReadWriteOnce resources: requests: storage:
    1Gi name: dynamic-plugins-root - configMap: defaultMode: 420 name: dynamic-plugins
    optional: true name: dynamic-plugins - name: dynamic-plugins-npmrc secret: defaultMode:
    420 optional: true secretName: ''{{ printf "%s-dynamic-plugins-npmrc" .Release.Name
    }}'' - name: postgres-crt secret: secretName: my-rhdh-database-certificates-secrets
    7 # ... ``` Set the value of the upstream.postgresql.enabled parameter to false
    to disable creating local PostgreSQL instances. Provide the name of the credential
    secret. Provide the name of the credential secret. Optional: Provide the name
    of the TLS certificate only for a TLS connection. Optional: Provide the name of
    the CA certificate only for a TLS connection. Optional: Provide the name of the
    TLS private key only if your TLS connection requires a private key. Provide the
    name of the certificate secret if you have configured a TLS connection. 4. Apply
    the configuration changes in your Helm configuration file named values.yaml: ```terminal
    helm upgrade n <your namespace> <your deploy name> openshift helm charts/redhat
    developer hub f values.yaml - version 1.8.0 ``` ## Migrating local databases to
    an external database server using the Operator By default, Red Hat Developer Hub
    hosts the data for each plugin in a PostgreSQL database. When you fetch the list
    of databases, you might see multiple databases based on the number of plugins
    configured in Developer Hub. You can migrate the data from an RHDH instance hosted
    on a local PostgreSQL server to an external PostgreSQL service, such as AWS RDS,
    Azure database, or Crunchy database. To migrate the data from each RHDH instance,
    you can use PostgreSQL utilities, such as pg_dump with psql or pgAdmin. [NOTE]
    ---- The following procedure uses a database copy script to do a quick migration.
    ---- You have installed the pg_dump and psql utilities on your local machine.
    For data export, you have the PGSQL user privileges to make a full dump of local
    databases. For data import, you have the PGSQL admin privileges to create an external
    database and populate it with database dumps. 1. Configure port forwarding for
    the local PostgreSQL database pod by running the following command on a terminal:
    ```terminal oc port forward n <your namespace> <pgsql pod name> <forward to port>:<forward
    from port> ``` Where: * The <pgsql-pod-name> variable denotes the name of a PostgreSQL
    pod with the format backstage-psql-<deployment-name>-<_index>. * The <forward-to-port>
    variable denotes the port of your choice to forward PostgreSQL data to. * The
    <forward-from-port> variable denotes the local PostgreSQL instance port, such
    as 5432. Example: Configuring port forwarding ```terminal oc port forward n developer
    hub backstage psql developer hub 0 15432:5432 ``` 2. Make a copy of the following
    db_copy.sh script and edit the details based on your configuration: ```bash #!/bin/bash
    to_host=<db service host> 1 to_port=5432 2 to_user=postgres 3 from_host=127.0.0.1
    4 from_port=15432 5 from_user=postgres 6 allDB=("backstage_plugin_app" "backstage_plugin_auth"
    "backstage_plugin_catalog" "backstage_plugin_permission" "backstage_plugin_scaffolder"
    "backstage_plugin_search") 7 for db in ${!allDB[@]}; do db=${allDB[$db]} echo
    Copying database: $db PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user
    -c "create database $db;" pg_dump -h $from_host -p $from_port -U $from_user -d
    $db | PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user -d $db done
    ``` The destination host name, for example, <db-instance-name>.rds.amazonaws.com.
    The destination port, such as 5432. The destination server username, for example,
    postgres. The source host name, such as 127.0.0.1. The source port number, such
    as the <forward-to-port> variable. The source server username, for example, postgres.
    The name of databases to import in double quotes separated by spaces, for example,
    ("backstage_plugin_app" "backstage_plugin_auth" "backstage_plugin_catalog" "backstage_plugin_permission"
    "backstage_plugin_scaffolder" "backstage_plugin_search"). 3. Create a destination
    database for copying the data: ```terminal /bin/bash TO_PSW=<destination db password>
    /path/to/db_copy.sh 1 ``` The <destination-db-password> variable denotes the password
    to connect to the destination database. [NOTE] ---- You can stop port forwarding
    when the copying of the data is complete. For more information about handling
    large databases and using the compression tools, see the Handling Large Databases
    section on the PostgreSQL website. ---- 4. Reconfigure your Backstage custom resource
    (CR). For more information, see Configuring an external PostgreSQL instance using
    the Operator. 5. Check that the following code is present at the end of your Backstage
    CR after reconfiguration: ```yaml # ... spec: database: enableLocalDb: false application:
    # ... extraFiles: secrets: - name: my-rhdh-database-certificates-secrets key:
    postgres-crt.pem # key name as in my-rhdh-database-certificates-secrets Secret
    extraEnvs: secrets: - name: my-rhdh-database-secrets # ... ``` [NOTE] ---- Reconfiguring
    the Backstage CR deletes the corresponding StatefulSet and Pod objects, but does
    not delete the PersistenceVolumeClaim object. Use the following command to delete
    the local PersistenceVolumeClaim object: ```terminal oc n developer hub delete
    pvc <local psql pvc name> ``` where, the <local-psql-pvc-name> variable is in
    the data-<psql-pod-name> format. ---- 6. Apply the configuration changes. 1. Verify
    that your RHDH instance is running with the migrated data and does not contain
    the local PostgreSQL database by running the following command: ```terminal oc
    get pods n <your namespace> ``` 2. Check the output for the following details:
    * The backstage-developer-hub-xxx pod is in running state. * The backstage-psql-developer-hub-0
    pod is not available. You can also verify these details using the Topology view
    in the OpenShift'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:31:48.209863'
    uuid: 82600c35-9312-4d36-a75c-5aee51b124dd
  response: 'To apply the configuration changes in your Helm configuration file named
    values.yaml, you must run the following command: "helm upgrade n <your namespace>
    <your deploy name> openshift helm charts/redhat developer hub f values.yaml -
    version 1.8.0".'
  user_input: how i apply the configuration changes in my helm configuration file
    named values.yaml?
- context:
  - 'on the required Secure Sockets Layer (SSL) mode. Optional: Provide the value
    only if you need a TLS connection for your PostgreSQL instance. 3. Configure your
    PostgreSQL instance in the Helm configuration file named values.yaml: ```yaml
    # ... upstream: postgresql: enabled: false # disable PostgreSQL instance creation
    1 auth: existingSecret: my-rhdh-database-secrets # inject credentials secret to
    Backstage 2 backstage: appConfig: backend: database: connection: # configure Backstage
    DB connection parameters host: ${POSTGRES_HOST} port: ${POSTGRES_PORT} user: ${POSTGRES_USER}
    password: ${POSTGRES_PASSWORD} ssl: rejectUnauthorized: true, ca: $file: /opt/app-root/src/postgres-ca.pem
    key: $file: /opt/app-root/src/postgres-key.key cert: $file: /opt/app-root/src/postgres-crt.pem
    extraEnvVarsSecrets: - my-rhdh-database-secrets # inject credentials secret to
    Backstage 3 extraEnvVars: - name: BACKEND_SECRET valueFrom: secretKeyRef: key:
    backend-secret name: ''{{ include "janus-idp.backend-secret-name" $ }}'' extraVolumeMounts:
    - mountPath: /opt/app-root/src/dynamic-plugins-root name: dynamic-plugins-root
    - mountPath: /opt/app-root/src/postgres-crt.pem name: postgres-crt # inject TLS
    certificate to Backstage cont. 4 subPath: postgres-crt.pem - mountPath: /opt/app-root/src/postgres-ca.pem
    name: postgres-ca # inject CA certificate to Backstage cont. 5 subPath: postgres-ca.pem
    - mountPath: /opt/app-root/src/postgres-key.key name: postgres-key # inject TLS
    private key to Backstage cont. 6 subPath: postgres-key.key extraVolumes: - ephemeral:
    volumeClaimTemplate: spec: accessModes: - ReadWriteOnce resources: requests: storage:
    1Gi name: dynamic-plugins-root - configMap: defaultMode: 420 name: dynamic-plugins
    optional: true name: dynamic-plugins - name: dynamic-plugins-npmrc secret: defaultMode:
    420 optional: true secretName: ''{{ printf "%s-dynamic-plugins-npmrc" .Release.Name
    }}'' - name: postgres-crt secret: secretName: my-rhdh-database-certificates-secrets
    7 # ... ``` Set the value of the upstream.postgresql.enabled parameter to false
    to disable creating local PostgreSQL instances. Provide the name of the credential
    secret. Provide the name of the credential secret. Optional: Provide the name
    of the TLS certificate only for a TLS connection. Optional: Provide the name of
    the CA certificate only for a TLS connection. Optional: Provide the name of the
    TLS private key only if your TLS connection requires a private key. Provide the
    name of the certificate secret if you have configured a TLS connection. 4. Apply
    the configuration changes in your Helm configuration file named values.yaml: ```terminal
    helm upgrade n <your namespace> <your deploy name> openshift helm charts/redhat
    developer hub f values.yaml - version 1.8.0 ``` ## Migrating local databases to
    an external database server using the Operator By default, Red Hat Developer Hub
    hosts the data for each plugin in a PostgreSQL database. When you fetch the list
    of databases, you might see multiple databases based on the number of plugins
    configured in Developer Hub. You can migrate the data from an RHDH instance hosted
    on a local PostgreSQL server to an external PostgreSQL service, such as AWS RDS,
    Azure database, or Crunchy database. To migrate the data from each RHDH instance,
    you can use PostgreSQL utilities, such as pg_dump with psql or pgAdmin. [NOTE]
    ---- The following procedure uses a database copy script to do a quick migration.
    ---- You have installed the pg_dump and psql utilities on your local machine.
    For data export, you have the PGSQL user privileges to make a full dump of local
    databases. For data import, you have the PGSQL admin privileges to create an external
    database and populate it with database dumps. 1. Configure port forwarding for
    the local PostgreSQL database pod by running the following command on a terminal:
    ```terminal oc port forward n <your namespace> <pgsql pod name> <forward to port>:<forward
    from port> ``` Where: * The <pgsql-pod-name> variable denotes the name of a PostgreSQL
    pod with the format backstage-psql-<deployment-name>-<_index>. * The <forward-to-port>
    variable denotes the port of your choice to forward PostgreSQL data to. * The
    <forward-from-port> variable denotes the local PostgreSQL instance port, such
    as 5432. Example: Configuring port forwarding ```terminal oc port forward n developer
    hub backstage psql developer hub 0 15432:5432 ``` 2. Make a copy of the following
    db_copy.sh script and edit the details based on your configuration: ```bash #!/bin/bash
    to_host=<db service host> 1 to_port=5432 2 to_user=postgres 3 from_host=127.0.0.1
    4 from_port=15432 5 from_user=postgres 6 allDB=("backstage_plugin_app" "backstage_plugin_auth"
    "backstage_plugin_catalog" "backstage_plugin_permission" "backstage_plugin_scaffolder"
    "backstage_plugin_search") 7 for db in ${!allDB[@]}; do db=${allDB[$db]} echo
    Copying database: $db PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user
    -c "create database $db;" pg_dump -h $from_host -p $from_port -U $from_user -d
    $db | PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user -d $db done
    ``` The destination host name, for example, <db-instance-name>.rds.amazonaws.com.
    The destination port, such as 5432. The destination server username, for example,
    postgres. The source host name, such as 127.0.0.1. The source port number, such
    as the <forward-to-port> variable. The source server username, for example, postgres.
    The name of databases to import in double quotes separated by spaces, for example,
    ("backstage_plugin_app" "backstage_plugin_auth" "backstage_plugin_catalog" "backstage_plugin_permission"
    "backstage_plugin_scaffolder" "backstage_plugin_search"). 3. Create a destination
    database for copying the data: ```terminal /bin/bash TO_PSW=<destination db password>
    /path/to/db_copy.sh 1 ``` The <destination-db-password> variable denotes the password
    to connect to the destination database. [NOTE] ---- You can stop port forwarding
    when the copying of the data is complete. For more information about handling
    large databases and using the compression tools, see the Handling Large Databases
    section on the PostgreSQL website. ---- 4. Reconfigure your Backstage custom resource
    (CR). For more information, see Configuring an external PostgreSQL instance using
    the Operator. 5. Check that the following code is present at the end of your Backstage
    CR after reconfiguration: ```yaml # ... spec: database: enableLocalDb: false application:
    # ... extraFiles: secrets: - name: my-rhdh-database-certificates-secrets key:
    postgres-crt.pem # key name as in my-rhdh-database-certificates-secrets Secret
    extraEnvs: secrets: - name: my-rhdh-database-secrets # ... ``` [NOTE] ---- Reconfiguring
    the Backstage CR deletes the corresponding StatefulSet and Pod objects, but does
    not delete the PersistenceVolumeClaim object. Use the following command to delete
    the local PersistenceVolumeClaim object: ```terminal oc n developer hub delete
    pvc <local psql pvc name> ``` where, the <local-psql-pvc-name> variable is in
    the data-<psql-pod-name> format. ---- 6. Apply the configuration changes. 1. Verify
    that your RHDH instance is running with the migrated data and does not contain
    the local PostgreSQL database by running the following command: ```terminal oc
    get pods n <your namespace> ``` 2. Check the output for the following details:
    * The backstage-developer-hub-xxx pod is in running state. * The backstage-psql-developer-hub-0
    pod is not available. You can also verify these details using the Topology view
    in the OpenShift'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:31:55.978768'
    uuid: 837f59fb-a2a3-43e7-a3dd-919341893e30
  response: 'To configure the Secure Sockets Layer (SSL) mode for a PostgreSQL instance,
    which is an optional step for a TLS connection, you must modify the `values.yaml`
    Helm configuration file. Under the `backstage.appConfig.backend.database.connection`
    section, you can configure the `ssl` parameters. An example configuration includes
    setting `rejectUnauthorized: true`, and providing file paths for the CA certificate,
    key, and certificate: `ca: $file: /opt/app-root/src/postgres-ca.pem`, `key: $file:
    /opt/app-root/src/postgres-key.key`, and `cert: $file: /opt/app-root/src/postgres-crt.pem`.
    These files are made available to the container by defining `extraVolumeMounts`
    and `extraVolumes` that reference a secret containing the certificates, such as
    `my-rhdh-database-certificates-secrets`.'
  user_input: how to configure SSL for backstage postgresql helm
- context:
  - 'path (for example, /<custom_pvc_mount_path>). spec.application.extraEnvs.configMaps.containers::
    Injects the specified ConfigMap key as an environment variable into all containers
    ("*"). spec.application.extraEnvs.secrets.name:: Injects all keys from the Secret
    as environment variables into the default container. spec.application.envs.containers::
    Targets only the listed container for the static environment variable injection.
    [NOTE] ---- The following explicit options are supported: * No or an empty field:
    Mounts only to the backstage-backend container. * * (asterisk) as the first and
    only array element: Mounts to all containers. * Explicit container names, for
    example, install-dynamic-plugins: Mounts only to the listed containers. ---- The
    files are mounted with the following correct paths and container targets: ## annotation
    to your configuration file to specify the containers to mount to. 1. To mount
    Secrets to all containers, set the rhdh.redhat.com/containers annotation to *
    in your configuration file: Example mounting to all containers ```yaml apiVersion:
    v1 kind: Secret metadata: name: <my_secret> annotations: rhdh.redhat.com/containers:
    ``` [IMPORTANT] ---- Set rhdh.redhat.com/containers to * to mount it to all containers
    in the deployment. ---- 2. To mount to specific containers, separate the names
    with commas: Example separating the list of containers ```yaml apiVersion: v1
    kind: PersistentVolumeClaim metadata: name: <my_claim> annotations: rhdh.redhat.com/containers:
    "init dynamic plugins,backstage backend" ``` [NOTE] ---- This configuration mounts
    the <my_claim> PVC to the init-dynamic-plugins and backstage-backend containers.
    ---- # Configuring external PostgreSQL databases As an administrator, you can
    configure and use external PostgreSQL databases in Red Hat Developer Hub. You
    can use a PostgreSQL certificate file to configure an external PostgreSQL instance
    using the Operator or Helm Chart. [NOTE] ---- Developer Hub supports the configuration
    of external PostgreSQL databases. You can perform maintenance activities, such
    as backing up your data or configuring high availability (HA) for the external
    PostgreSQL databases. By default, the Red Hat Developer Hub operator or Helm Chart
    creates a local PostgreSQL database. However, this configuration is not suitable
    for the production environments. For production deployments, disable the creation
    of local database and configure Developer Hub to connect to an external PostgreSQL
    instance instead. ---- ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:32:05.403144'
    uuid: ccf52462-e51e-48e1-9e1e-c073f66d38f0
  response: The rhdh.redhat.com/containers annotation is used in your configuration
    file to specify the containers to which a resource should be mounted. To mount
    a resource, such as a Secret, to all containers, you must set the annotation to
    an asterisk (*). To mount a resource to specific containers, you list the container
    names separated by commas. For example, setting the annotation on a PersistentVolumeClaim
    to "init dynamic plugins,backstage backend" will mount that PVC to only the init-dynamic-plugins
    and backstage-backend containers.
  user_input: How can I utilize the rhdh.redhat.com/containers annotation to control
    whether a resource is mounted to all containers or only to specific ones within
    the deployment?
- context:
  - 'path (for example, /<custom_pvc_mount_path>). spec.application.extraEnvs.configMaps.containers::
    Injects the specified ConfigMap key as an environment variable into all containers
    ("*"). spec.application.extraEnvs.secrets.name:: Injects all keys from the Secret
    as environment variables into the default container. spec.application.envs.containers::
    Targets only the listed container for the static environment variable injection.
    [NOTE] ---- The following explicit options are supported: * No or an empty field:
    Mounts only to the backstage-backend container. * * (asterisk) as the first and
    only array element: Mounts to all containers. * Explicit container names, for
    example, install-dynamic-plugins: Mounts only to the listed containers. ---- The
    files are mounted with the following correct paths and container targets: ## annotation
    to your configuration file to specify the containers to mount to. 1. To mount
    Secrets to all containers, set the rhdh.redhat.com/containers annotation to *
    in your configuration file: Example mounting to all containers ```yaml apiVersion:
    v1 kind: Secret metadata: name: <my_secret> annotations: rhdh.redhat.com/containers:
    ``` [IMPORTANT] ---- Set rhdh.redhat.com/containers to * to mount it to all containers
    in the deployment. ---- 2. To mount to specific containers, separate the names
    with commas: Example separating the list of containers ```yaml apiVersion: v1
    kind: PersistentVolumeClaim metadata: name: <my_claim> annotations: rhdh.redhat.com/containers:
    "init dynamic plugins,backstage backend" ``` [NOTE] ---- This configuration mounts
    the <my_claim> PVC to the init-dynamic-plugins and backstage-backend containers.
    ---- # Configuring external PostgreSQL databases As an administrator, you can
    configure and use external PostgreSQL databases in Red Hat Developer Hub. You
    can use a PostgreSQL certificate file to configure an external PostgreSQL instance
    using the Operator or Helm Chart. [NOTE] ---- Developer Hub supports the configuration
    of external PostgreSQL databases. You can perform maintenance activities, such
    as backing up your data or configuring high availability (HA) for the external
    PostgreSQL databases. By default, the Red Hat Developer Hub operator or Helm Chart
    creates a local PostgreSQL database. However, this configuration is not suitable
    for the production environments. For production deployments, disable the creation
    of local database and configure Developer Hub to connect to an external PostgreSQL
    instance instead. ---- ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:32:15.861407'
    uuid: 13e56924-f5d6-4838-883b-bc1b4223a580
  response: To mount a PersistentVolumeClaim to specific containers, you add an annotation
    to your configuration file where you separate the container names with commas.
    For example, to mount a PVC named `<my_claim>` to the `init-dynamic-plugins` and
    `backstage-backend` containers, you would set the `rhdh.redhat.com/containers`
    annotation in the metadata to `"init dynamic plugins,backstage backend"`.
  user_input: how to mount a PersistentVolumeClaim to specific containers
- context:
  - 'path (for example, /<custom_pvc_mount_path>). spec.application.extraEnvs.configMaps.containers::
    Injects the specified ConfigMap key as an environment variable into all containers
    ("*"). spec.application.extraEnvs.secrets.name:: Injects all keys from the Secret
    as environment variables into the default container. spec.application.envs.containers::
    Targets only the listed container for the static environment variable injection.
    [NOTE] ---- The following explicit options are supported: * No or an empty field:
    Mounts only to the backstage-backend container. * * (asterisk) as the first and
    only array element: Mounts to all containers. * Explicit container names, for
    example, install-dynamic-plugins: Mounts only to the listed containers. ---- The
    files are mounted with the following correct paths and container targets: ## annotation
    to your configuration file to specify the containers to mount to. 1. To mount
    Secrets to all containers, set the rhdh.redhat.com/containers annotation to *
    in your configuration file: Example mounting to all containers ```yaml apiVersion:
    v1 kind: Secret metadata: name: <my_secret> annotations: rhdh.redhat.com/containers:
    ``` [IMPORTANT] ---- Set rhdh.redhat.com/containers to * to mount it to all containers
    in the deployment. ---- 2. To mount to specific containers, separate the names
    with commas: Example separating the list of containers ```yaml apiVersion: v1
    kind: PersistentVolumeClaim metadata: name: <my_claim> annotations: rhdh.redhat.com/containers:
    "init dynamic plugins,backstage backend" ``` [NOTE] ---- This configuration mounts
    the <my_claim> PVC to the init-dynamic-plugins and backstage-backend containers.
    ---- # Configuring external PostgreSQL databases As an administrator, you can
    configure and use external PostgreSQL databases in Red Hat Developer Hub. You
    can use a PostgreSQL certificate file to configure an external PostgreSQL instance
    using the Operator or Helm Chart. [NOTE] ---- Developer Hub supports the configuration
    of external PostgreSQL databases. You can perform maintenance activities, such
    as backing up your data or configuring high availability (HA) for the external
    PostgreSQL databases. By default, the Red Hat Developer Hub operator or Helm Chart
    creates a local PostgreSQL database. However, this configuration is not suitable
    for the production environments. For production deployments, disable the creation
    of local database and configure Developer Hub to connect to an external PostgreSQL
    instance instead. ---- ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:32:24.802314'
    uuid: d22f54d7-81dd-4d3a-889b-f5629b2a68f2
  response: 'To mount a resource only to the backstage-backend container, the configuration
    should have no field or an empty field for the `rhdh.redhat.com/containers` annotation.
    This is the default behavior. You can also mount to specific containers, including
    `backstage-backend`, by explicitly listing the container names separated by commas
    in the annotation, as shown in the example: `rhdh.redhat.com/containers: \"init
    dynamic plugins,backstage backend\"`.'
  user_input: how do i mount a pvc to just the backstaege-backend containr?
- context:
  - 'Container Platform web console. !:previouscontext: # Configuring Red Hat Developer
    Hub deployment when using the Operator The Red Hat Developer Hub Operator exposes
    a rhdh.redhat.com/v1alpha3 API Version of its custom resource (CR). This CR exposes
    a generic spec.deployment.patch field, which gives you full control over the Developer
    Hub Deployment resource. This field can be a fragment of the standard apps.Deployment
    Kubernetes object. 1. Create a Backstage CR with the following fields: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: ``` labels:: Add labels to the Developer
    Hub pod. Example adding the label my=true ```yaml apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    metadata: labels: my: true ``` volumes:: Add an additional volume named my-volume
    and mount it under /my/path in the Developer Hub application container. ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: spec: containers: name: backstage
    backend volumeMounts: mountPath: /my/path name: my volume volumes: ephemeral:
    volumeClaimTemplate: spec: storageClassName: "special" name: my volume ``` Replace
    the default dynamic-plugins-root volume with a persistent volume claim (PVC) named
    dynamic-plugins-root. Note the $patch: replace directive, otherwise a new volume
    will be added. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` cpu request:: Set the CPU request for the Developer Hub application container
    to 250m. Example CPU request ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: backstage backend resources: requests: cpu: 250m ``` my-sidecar
    container:: Add a new my-sidecar sidecar container into the Developer Hub Pod.
    Example side car container ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: my sidecar image: quay.io/my org/my sidecar:latest ```
    Strategic Merge Patch # Configuring high availability in Red Hat Developer Hub
    High availability (HA) is a system design approach that ensures a service remains
    continuously accessible, even during failures of individual components, by eliminating
    single points of failure. It introduces redundancy and failover mechanisms to
    minimize downtime and maintain operational continuity. Red Hat Developer Hub supports
    HA deployments on the following platforms: Red Hat OpenShift Container Platform
    Azure Kubernetes Service Elastic Kubernetes Service Google Kubernetes Engine The
    HA deployments enable more resilient and reliable service availability across
    supported environments. In a single instance deployment, if a failure occurs,
    whether due to software crashes, hardware issues, or other unexpected disruptions,
    it would make the entire service unavailable, interrupting development workflows
    and access to key resources. With HA enabled, you can scale the number of backend
    replicas to introduce redundancy. This setup ensures that if one pod or component
    fails, others continue to serve requests without disruption. The built-in load
    balancer manages ingress traffic and distributes the load across the available
    pods. Meanwhile, the RHDH backend manages concurrent requests and resolves resource-level
    conflicts effectively. As an administrator, you can configure high availability
    by adjusting replica values in your configuration file: If you installed using
    the Operator, configure the replica values in your Backstage custom resource.
    If you used the Helm chart, set the replica values in the Helm configuration.
    ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:32:34.790418'
    uuid: 669ae477-57eb-405b-b55d-3633104d1332
  response: Red Hat Developer Hub supports High Availability (HA) deployments on Google
    Kubernetes Engine, in addition to Red Hat OpenShift Container Platform, Azure
    Kubernetes Service, and Elastic Kubernetes Service. The HA deployments enable
    more resilient and reliable service availability across these supported environments.
  user_input: Does Red Hat Developer Hub support high availability on Google Kubernetes
    Engine?
- context:
  - 'Container Platform web console. !:previouscontext: # Configuring Red Hat Developer
    Hub deployment when using the Operator The Red Hat Developer Hub Operator exposes
    a rhdh.redhat.com/v1alpha3 API Version of its custom resource (CR). This CR exposes
    a generic spec.deployment.patch field, which gives you full control over the Developer
    Hub Deployment resource. This field can be a fragment of the standard apps.Deployment
    Kubernetes object. 1. Create a Backstage CR with the following fields: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: ``` labels:: Add labels to the Developer
    Hub pod. Example adding the label my=true ```yaml apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    metadata: labels: my: true ``` volumes:: Add an additional volume named my-volume
    and mount it under /my/path in the Developer Hub application container. ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: spec: containers: name: backstage
    backend volumeMounts: mountPath: /my/path name: my volume volumes: ephemeral:
    volumeClaimTemplate: spec: storageClassName: "special" name: my volume ``` Replace
    the default dynamic-plugins-root volume with a persistent volume claim (PVC) named
    dynamic-plugins-root. Note the $patch: replace directive, otherwise a new volume
    will be added. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` cpu request:: Set the CPU request for the Developer Hub application container
    to 250m. Example CPU request ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: backstage backend resources: requests: cpu: 250m ``` my-sidecar
    container:: Add a new my-sidecar sidecar container into the Developer Hub Pod.
    Example side car container ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: my sidecar image: quay.io/my org/my sidecar:latest ```
    Strategic Merge Patch # Configuring high availability in Red Hat Developer Hub
    High availability (HA) is a system design approach that ensures a service remains
    continuously accessible, even during failures of individual components, by eliminating
    single points of failure. It introduces redundancy and failover mechanisms to
    minimize downtime and maintain operational continuity. Red Hat Developer Hub supports
    HA deployments on the following platforms: Red Hat OpenShift Container Platform
    Azure Kubernetes Service Elastic Kubernetes Service Google Kubernetes Engine The
    HA deployments enable more resilient and reliable service availability across
    supported environments. In a single instance deployment, if a failure occurs,
    whether due to software crashes, hardware issues, or other unexpected disruptions,
    it would make the entire service unavailable, interrupting development workflows
    and access to key resources. With HA enabled, you can scale the number of backend
    replicas to introduce redundancy. This setup ensures that if one pod or component
    fails, others continue to serve requests without disruption. The built-in load
    balancer manages ingress traffic and distributes the load across the available
    pods. Meanwhile, the RHDH backend manages concurrent requests and resolves resource-level
    conflicts effectively. As an administrator, you can configure high availability
    by adjusting replica values in your configuration file: If you installed using
    the Operator, configure the replica values in your Backstage custom resource.
    If you used the Helm chart, set the replica values in the Helm configuration.
    ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:32:44.005358'
    uuid: e955a976-165e-4d16-9e43-03406c648bf0
  response: 'The Red Hat Developer Hub Operator exposes a custom resource (CR) with
    a generic `spec.deployment.patch` field that gives you full control over the Developer
    Hub Deployment resource. By creating a `Backstage` CR, you can use this field
    to perform several actions, including: adding labels to the Developer Hub pod,
    adding an additional volume and mounting it in the application container, replacing
    the default `dynamic-plugins-root` volume with a persistent volume claim (PVC)
    using the `$patch: replace` directive, setting the CPU request for the application
    container, and adding a new sidecar container into the Developer Hub Pod.'
  user_input: how can i use the Backstage CR to patch the deployment, what kind of
    things is it possible to change on the developer hub pod?
- context:
  - 'Container Platform web console. !:previouscontext: # Configuring Red Hat Developer
    Hub deployment when using the Operator The Red Hat Developer Hub Operator exposes
    a rhdh.redhat.com/v1alpha3 API Version of its custom resource (CR). This CR exposes
    a generic spec.deployment.patch field, which gives you full control over the Developer
    Hub Deployment resource. This field can be a fragment of the standard apps.Deployment
    Kubernetes object. 1. Create a Backstage CR with the following fields: ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: ``` labels:: Add labels to the Developer
    Hub pod. Example adding the label my=true ```yaml apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    metadata: labels: my: true ``` volumes:: Add an additional volume named my-volume
    and mount it under /my/path in the Developer Hub application container. ```yaml
    apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata: name: developer
    hub spec: deployment: patch: spec: template: spec: containers: name: backstage
    backend volumeMounts: mountPath: /my/path name: my volume volumes: ephemeral:
    volumeClaimTemplate: spec: storageClassName: "special" name: my volume ``` Replace
    the default dynamic-plugins-root volume with a persistent volume claim (PVC) named
    dynamic-plugins-root. Note the $patch: replace directive, otherwise a new volume
    will be added. ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` cpu request:: Set the CPU request for the Developer Hub application container
    to 250m. Example CPU request ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: backstage backend resources: requests: cpu: 250m ``` my-sidecar
    container:: Add a new my-sidecar sidecar container into the Developer Hub Pod.
    Example side car container ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind:
    Backstage metadata: name: developer hub spec: deployment: patch: spec: template:
    spec: containers: name: my sidecar image: quay.io/my org/my sidecar:latest ```
    Strategic Merge Patch # Configuring high availability in Red Hat Developer Hub
    High availability (HA) is a system design approach that ensures a service remains
    continuously accessible, even during failures of individual components, by eliminating
    single points of failure. It introduces redundancy and failover mechanisms to
    minimize downtime and maintain operational continuity. Red Hat Developer Hub supports
    HA deployments on the following platforms: Red Hat OpenShift Container Platform
    Azure Kubernetes Service Elastic Kubernetes Service Google Kubernetes Engine The
    HA deployments enable more resilient and reliable service availability across
    supported environments. In a single instance deployment, if a failure occurs,
    whether due to software crashes, hardware issues, or other unexpected disruptions,
    it would make the entire service unavailable, interrupting development workflows
    and access to key resources. With HA enabled, you can scale the number of backend
    replicas to introduce redundancy. This setup ensures that if one pod or component
    fails, others continue to serve requests without disruption. The built-in load
    balancer manages ingress traffic and distributes the load across the available
    pods. Meanwhile, the RHDH backend manages concurrent requests and resolves resource-level
    conflicts effectively. As an administrator, you can configure high availability
    by adjusting replica values in your configuration file: If you installed using
    the Operator, configure the replica values in your Backstage custom resource.
    If you used the Helm chart, set the replica values in the Helm configuration.
    ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:32:52.464553'
    uuid: b2ee181f-a03f-4db9-83a8-abd1bd65fdf9
  response: If you installed Red Hat Developer Hub using the Helm chart, you can configure
    high availability by setting the replica values in the Helm configuration.
  user_input: How do I configure high availability in Red Hat Developer Hub using
    a Helm chart?
- context:
  - 'Configuring high availability in a Red Hat Developer Hub Operator deployment
    RHDH instances that are deployed with the Operator use configurations in the Backstage
    custom resource (CR). In the Backstage CR, the default value for the replicas
    field is 1. If you want to configure your RHDH instance for high availability,
    you must set replicas to a value greater than 1. In your Backstage custom resource
    (CR), set replicas to a value greater than 1. For example, to configure two replicas
    (one backup instance): ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <your_yaml_file> spec: deployment: patch: spec: replicas: 2 ```
    ## Configuring high availability in a Red Hat Developer Hub Helm chart deployment
    When you are deploying Developer Hub using the Helm chart, you must set replicas
    to a value greater than 1 in your Helm chart. The default value for replicas is
    1. In your Helm chart configuration file, set replicas to a value greater than
    1. For example, to configure two replicas (one backup instance): ```yaml upstream:
    backstage: replicas: 2 ``` !:previouscontext: # Running Red Hat Developer Hub
    behind a corporate proxy In a network restricted environment, configure Red Hat
    Developer Hub to use your proxy to access remote network resources. You can run
    the Developer Hub application behind a corporate proxy by setting any of the following
    environment variables before starting the application: HTTP_PROXY:: Denotes the
    proxy to use for HTTP requests. HTTPS_PROXY:: Denotes the proxy to use for HTTPS
    requests. NO_PROXY:: Set the environment variable to bypass the proxy for certain
    domains. The variable value is a comma-separated list of hostnames or IP addresses
    that can be accessed without the proxy, even if one is specified. ## The NO_PROXY
    exclusion rules NO_PROXY is a comma or space-separated list of hostnames or IP
    addresses, with optional port numbers. If the input URL matches any of the entries
    listed in NO_PROXY, a direct request fetches that URL, for example, bypassing
    the proxy settings. [NOTE] ---- The default value for NO_PROXY in RHDH is localhost,127.0.0.1.
    If you want to override it, include at least localhost or localhost:7007 in the
    list. Otherwise, the RHDH backend might fail. ---- Matching follows the rules
    below: NO_PROXY= will bypass the proxy for all requests. Space and commas might
    separate the entries in the NO_PROXY list. For example, NO_PROXY="localhost,example.com",
    or NO_PROXY="localhost example.com", or NO_PROXY="localhost, example.com" would
    have the same effect. If NO_PROXY contains no entries, configuring the HTTP(S)_PROXY
    settings makes the backend send all requests through the proxy. The backend does
    not perform a DNS lookup to determine if a request should bypass the proxy or
    not. For example, if DNS resolves example.com to 1.2.3.4, setting NO_PROXY=1.2.3.4
    has no effect on requests sent to example.com. Only requests sent to the IP address
    1.2.3.4 bypass the proxy. If you add a port after the hostname or IP address,
    the request must match both the host/IP and port to bypass the proxy. For example,
    NO_PROXY=example.com:1234 would bypass the proxy for requests to http(s)://example.com:1234,
    but not for requests on other ports, like http(s)://example.com. If you do not
    specify a port after the hostname or IP address, all requests to that host/IP
    address will bypass the proxy regardless of the port. For example, NO_PROXY=localhost
    would bypass the proxy for requests sent to URLs like http(s)://localhost:7077
    and http(s)://localhost:8888. IP Address blocks in CIDR notation will not work.
    So setting NO_PROXY=10.11.0.0/16 will not have any effect, even if the backend
    sends a request to an IP address in that block. Supports only IPv4 addresses.
    IPv6 addresses like ::1 will not work. Generally, the proxy is only bypassed if
    the hostname is an exact match for an entry in the NO_PROXY list. The only exceptions
    are entries that start with a dot (.) or with a wildcard ( ). In such a case,
    bypass the proxy if the hostname ends with the entry. [NOTE] ---- List the domain
    and the wildcard domain if you want to exclude a given domain and all its subdomains.
    For example, you would set NO_PROXY=example.com,.example.com to bypass the proxy
    for requests sent to http(s)://example.com and http(s)://subdomain.example.com.
    ---- ## Configuring proxy information in Operator deployment For Operator-based
    deployment, the approach you use for proxy configuration is based on your role:
    As a cluster administrator with access to the Operator namespace, you can configure
    the proxy variables in the Operator''s default ConfigMap file. This configuration
    applies the proxy settings to all the users of the Operator. As a developer, you
    can configure the proxy variables in a custom resource (CR) file. This configuration
    applies the proxy settings to the RHDH application created from that CR. You have
    installed the Red Hat Developer Hub application. 1. Perform one of the following
    steps based on your role: * As an administrator, set the proxy information in
    the Operator''s default ConfigMap file: 1. Search for a ConfigMap file named backstage-default-config
    in the default namespace rhdh-operator and open it. 2. Find the deployment.yaml
    key. 3. Set the value of the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY environment
    variables in the Deployment spec as shown in the following example: Example: Setting
    proxy variables in a ConfigMap file ```yaml # Other fields omitted deployment.yaml:
    | apiVersion: apps/v1 kind: Deployment spec: template: spec: # Other fields omitted
    initContainers: name: install dynamic plugins # command omitted env: name: NPM_CONFIG_USERCONFIG
    value: /opt/app root/src/.npmrc.dynamic plugins name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    # Other fields omitted containers: name: backstage backend # Other fields omitted
    env: name: APP_CONFIG_backend_listen_port value: "7007" name: HTTP_PROXY value:
    ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' ``` As a developer, set the proxy
    information in your Backstage CR file as shown in the following example: Example:
    Setting proxy variables in a CR file ```yaml spec: # Other fields omitted application:
    extraEnvs: envs: name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY
    value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. ## Configuring proxy information in Helm
    deployment For Helm-based deployment, either a developer or a cluster administrator
    with permissions to create'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:33:01.028678'
    uuid: 587f9449-ab40-4718-b5f7-1ffad8c6ccd1
  response: For an Operator-based deployment, a cluster administrator with access
    to the Operator namespace can configure proxy variables for all users by using
    the Operator's default ConfigMap file. The process is to first search for a ConfigMap
    file named "backstage-default-config" in the default namespace "rhdh-operator"
    and open it. Then, you must find the "deployment.yaml" key and set the value of
    the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY environment variables within the Deployment
    spec.
  user_input: As a platform engineer, how do I configure the proxy settings for all
    users of a Red Hat Developer Hub Operator deployment using the default ConfigMap
    file?
- context:
  - 'Configuring high availability in a Red Hat Developer Hub Operator deployment
    RHDH instances that are deployed with the Operator use configurations in the Backstage
    custom resource (CR). In the Backstage CR, the default value for the replicas
    field is 1. If you want to configure your RHDH instance for high availability,
    you must set replicas to a value greater than 1. In your Backstage custom resource
    (CR), set replicas to a value greater than 1. For example, to configure two replicas
    (one backup instance): ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <your_yaml_file> spec: deployment: patch: spec: replicas: 2 ```
    ## Configuring high availability in a Red Hat Developer Hub Helm chart deployment
    When you are deploying Developer Hub using the Helm chart, you must set replicas
    to a value greater than 1 in your Helm chart. The default value for replicas is
    1. In your Helm chart configuration file, set replicas to a value greater than
    1. For example, to configure two replicas (one backup instance): ```yaml upstream:
    backstage: replicas: 2 ``` !:previouscontext: # Running Red Hat Developer Hub
    behind a corporate proxy In a network restricted environment, configure Red Hat
    Developer Hub to use your proxy to access remote network resources. You can run
    the Developer Hub application behind a corporate proxy by setting any of the following
    environment variables before starting the application: HTTP_PROXY:: Denotes the
    proxy to use for HTTP requests. HTTPS_PROXY:: Denotes the proxy to use for HTTPS
    requests. NO_PROXY:: Set the environment variable to bypass the proxy for certain
    domains. The variable value is a comma-separated list of hostnames or IP addresses
    that can be accessed without the proxy, even if one is specified. ## The NO_PROXY
    exclusion rules NO_PROXY is a comma or space-separated list of hostnames or IP
    addresses, with optional port numbers. If the input URL matches any of the entries
    listed in NO_PROXY, a direct request fetches that URL, for example, bypassing
    the proxy settings. [NOTE] ---- The default value for NO_PROXY in RHDH is localhost,127.0.0.1.
    If you want to override it, include at least localhost or localhost:7007 in the
    list. Otherwise, the RHDH backend might fail. ---- Matching follows the rules
    below: NO_PROXY= will bypass the proxy for all requests. Space and commas might
    separate the entries in the NO_PROXY list. For example, NO_PROXY="localhost,example.com",
    or NO_PROXY="localhost example.com", or NO_PROXY="localhost, example.com" would
    have the same effect. If NO_PROXY contains no entries, configuring the HTTP(S)_PROXY
    settings makes the backend send all requests through the proxy. The backend does
    not perform a DNS lookup to determine if a request should bypass the proxy or
    not. For example, if DNS resolves example.com to 1.2.3.4, setting NO_PROXY=1.2.3.4
    has no effect on requests sent to example.com. Only requests sent to the IP address
    1.2.3.4 bypass the proxy. If you add a port after the hostname or IP address,
    the request must match both the host/IP and port to bypass the proxy. For example,
    NO_PROXY=example.com:1234 would bypass the proxy for requests to http(s)://example.com:1234,
    but not for requests on other ports, like http(s)://example.com. If you do not
    specify a port after the hostname or IP address, all requests to that host/IP
    address will bypass the proxy regardless of the port. For example, NO_PROXY=localhost
    would bypass the proxy for requests sent to URLs like http(s)://localhost:7077
    and http(s)://localhost:8888. IP Address blocks in CIDR notation will not work.
    So setting NO_PROXY=10.11.0.0/16 will not have any effect, even if the backend
    sends a request to an IP address in that block. Supports only IPv4 addresses.
    IPv6 addresses like ::1 will not work. Generally, the proxy is only bypassed if
    the hostname is an exact match for an entry in the NO_PROXY list. The only exceptions
    are entries that start with a dot (.) or with a wildcard ( ). In such a case,
    bypass the proxy if the hostname ends with the entry. [NOTE] ---- List the domain
    and the wildcard domain if you want to exclude a given domain and all its subdomains.
    For example, you would set NO_PROXY=example.com,.example.com to bypass the proxy
    for requests sent to http(s)://example.com and http(s)://subdomain.example.com.
    ---- ## Configuring proxy information in Operator deployment For Operator-based
    deployment, the approach you use for proxy configuration is based on your role:
    As a cluster administrator with access to the Operator namespace, you can configure
    the proxy variables in the Operator''s default ConfigMap file. This configuration
    applies the proxy settings to all the users of the Operator. As a developer, you
    can configure the proxy variables in a custom resource (CR) file. This configuration
    applies the proxy settings to the RHDH application created from that CR. You have
    installed the Red Hat Developer Hub application. 1. Perform one of the following
    steps based on your role: * As an administrator, set the proxy information in
    the Operator''s default ConfigMap file: 1. Search for a ConfigMap file named backstage-default-config
    in the default namespace rhdh-operator and open it. 2. Find the deployment.yaml
    key. 3. Set the value of the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY environment
    variables in the Deployment spec as shown in the following example: Example: Setting
    proxy variables in a ConfigMap file ```yaml # Other fields omitted deployment.yaml:
    | apiVersion: apps/v1 kind: Deployment spec: template: spec: # Other fields omitted
    initContainers: name: install dynamic plugins # command omitted env: name: NPM_CONFIG_USERCONFIG
    value: /opt/app root/src/.npmrc.dynamic plugins name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    # Other fields omitted containers: name: backstage backend # Other fields omitted
    env: name: APP_CONFIG_backend_listen_port value: "7007" name: HTTP_PROXY value:
    ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' ``` As a developer, set the proxy
    information in your Backstage CR file as shown in the following example: Example:
    Setting proxy variables in a CR file ```yaml spec: # Other fields omitted application:
    extraEnvs: envs: name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY
    value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. ## Configuring proxy information in Helm
    deployment For Helm-based deployment, either a developer or a cluster administrator
    with permissions to create'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:33:10.745717'
    uuid: 8649e3e0-c014-4789-930e-ce2868f2c9f2
  response: 'For Red Hat Developer Hub (RHDH) instances that are deployed with the
    Operator, you use configurations in the Backstage custom resource (CR). To configure
    your RHDH instance for high availability, you must set the "replicas" field to
    a value greater than 1, as the default value is 1. For example, to configure two
    replicas, you would set "replicas: 2" in your Backstage CR under "spec.deployment.patch.spec".'
  user_input: How do I configure high availability for a Red Hat Developer Hub instance
    using the Backstage custom resource?
- context:
  - 'Configuring high availability in a Red Hat Developer Hub Operator deployment
    RHDH instances that are deployed with the Operator use configurations in the Backstage
    custom resource (CR). In the Backstage CR, the default value for the replicas
    field is 1. If you want to configure your RHDH instance for high availability,
    you must set replicas to a value greater than 1. In your Backstage custom resource
    (CR), set replicas to a value greater than 1. For example, to configure two replicas
    (one backup instance): ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage
    metadata: name: <your_yaml_file> spec: deployment: patch: spec: replicas: 2 ```
    ## Configuring high availability in a Red Hat Developer Hub Helm chart deployment
    When you are deploying Developer Hub using the Helm chart, you must set replicas
    to a value greater than 1 in your Helm chart. The default value for replicas is
    1. In your Helm chart configuration file, set replicas to a value greater than
    1. For example, to configure two replicas (one backup instance): ```yaml upstream:
    backstage: replicas: 2 ``` !:previouscontext: # Running Red Hat Developer Hub
    behind a corporate proxy In a network restricted environment, configure Red Hat
    Developer Hub to use your proxy to access remote network resources. You can run
    the Developer Hub application behind a corporate proxy by setting any of the following
    environment variables before starting the application: HTTP_PROXY:: Denotes the
    proxy to use for HTTP requests. HTTPS_PROXY:: Denotes the proxy to use for HTTPS
    requests. NO_PROXY:: Set the environment variable to bypass the proxy for certain
    domains. The variable value is a comma-separated list of hostnames or IP addresses
    that can be accessed without the proxy, even if one is specified. ## The NO_PROXY
    exclusion rules NO_PROXY is a comma or space-separated list of hostnames or IP
    addresses, with optional port numbers. If the input URL matches any of the entries
    listed in NO_PROXY, a direct request fetches that URL, for example, bypassing
    the proxy settings. [NOTE] ---- The default value for NO_PROXY in RHDH is localhost,127.0.0.1.
    If you want to override it, include at least localhost or localhost:7007 in the
    list. Otherwise, the RHDH backend might fail. ---- Matching follows the rules
    below: NO_PROXY= will bypass the proxy for all requests. Space and commas might
    separate the entries in the NO_PROXY list. For example, NO_PROXY="localhost,example.com",
    or NO_PROXY="localhost example.com", or NO_PROXY="localhost, example.com" would
    have the same effect. If NO_PROXY contains no entries, configuring the HTTP(S)_PROXY
    settings makes the backend send all requests through the proxy. The backend does
    not perform a DNS lookup to determine if a request should bypass the proxy or
    not. For example, if DNS resolves example.com to 1.2.3.4, setting NO_PROXY=1.2.3.4
    has no effect on requests sent to example.com. Only requests sent to the IP address
    1.2.3.4 bypass the proxy. If you add a port after the hostname or IP address,
    the request must match both the host/IP and port to bypass the proxy. For example,
    NO_PROXY=example.com:1234 would bypass the proxy for requests to http(s)://example.com:1234,
    but not for requests on other ports, like http(s)://example.com. If you do not
    specify a port after the hostname or IP address, all requests to that host/IP
    address will bypass the proxy regardless of the port. For example, NO_PROXY=localhost
    would bypass the proxy for requests sent to URLs like http(s)://localhost:7077
    and http(s)://localhost:8888. IP Address blocks in CIDR notation will not work.
    So setting NO_PROXY=10.11.0.0/16 will not have any effect, even if the backend
    sends a request to an IP address in that block. Supports only IPv4 addresses.
    IPv6 addresses like ::1 will not work. Generally, the proxy is only bypassed if
    the hostname is an exact match for an entry in the NO_PROXY list. The only exceptions
    are entries that start with a dot (.) or with a wildcard ( ). In such a case,
    bypass the proxy if the hostname ends with the entry. [NOTE] ---- List the domain
    and the wildcard domain if you want to exclude a given domain and all its subdomains.
    For example, you would set NO_PROXY=example.com,.example.com to bypass the proxy
    for requests sent to http(s)://example.com and http(s)://subdomain.example.com.
    ---- ## Configuring proxy information in Operator deployment For Operator-based
    deployment, the approach you use for proxy configuration is based on your role:
    As a cluster administrator with access to the Operator namespace, you can configure
    the proxy variables in the Operator''s default ConfigMap file. This configuration
    applies the proxy settings to all the users of the Operator. As a developer, you
    can configure the proxy variables in a custom resource (CR) file. This configuration
    applies the proxy settings to the RHDH application created from that CR. You have
    installed the Red Hat Developer Hub application. 1. Perform one of the following
    steps based on your role: * As an administrator, set the proxy information in
    the Operator''s default ConfigMap file: 1. Search for a ConfigMap file named backstage-default-config
    in the default namespace rhdh-operator and open it. 2. Find the deployment.yaml
    key. 3. Set the value of the HTTP_PROXY, HTTPS_PROXY, and NO_PROXY environment
    variables in the Deployment spec as shown in the following example: Example: Setting
    proxy variables in a ConfigMap file ```yaml # Other fields omitted deployment.yaml:
    | apiVersion: apps/v1 kind: Deployment spec: template: spec: # Other fields omitted
    initContainers: name: install dynamic plugins # command omitted env: name: NPM_CONFIG_USERCONFIG
    value: /opt/app root/src/.npmrc.dynamic plugins name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    # Other fields omitted containers: name: backstage backend # Other fields omitted
    env: name: APP_CONFIG_backend_listen_port value: "7007" name: HTTP_PROXY value:
    ''http://10.10.10.105:3128'' name: HTTPS_PROXY value: ''http://10.10.10.106:3128''
    name: NO_PROXY value: ''localhost,example.org'' ``` As a developer, set the proxy
    information in your Backstage CR file as shown in the following example: Example:
    Setting proxy variables in a CR file ```yaml spec: # Other fields omitted application:
    extraEnvs: envs: name: HTTP_PROXY value: ''http://10.10.10.105:3128'' name: HTTPS_PROXY
    value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. ## Configuring proxy information in Helm
    deployment For Helm-based deployment, either a developer or a cluster administrator
    with permissions to create'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:33:21.076306'
    uuid: 88772518-85b7-43f9-83fe-5353733d151c
  response: 'According to the rules, IP Address blocks in CIDR notation will not work;
    for example, setting NO_PROXY=10.11.0.0/16 will not have any effect. The NO_PROXY
    variable is a comma or space-separated list of hostnames or IP addresses, with
    optional port numbers, that can be accessed without the proxy. The matching rules
    are as follows: the backend does not perform a DNS lookup, so a request to a hostname
    will not be bypassed even if its resolved IP is in the NO_PROXY list. Generally,
    the proxy is bypassed only if the hostname is an exact match, with exceptions
    for entries starting with a dot (.) or a wildcard (*), in which case the proxy
    is bypassed if the hostname ends with the entry. If a port is specified after
    a hostname or IP, the request must match both to bypass the proxy. If no port
    is specified, all requests to that host or IP will bypass the proxy regardless
    of the port. The variable only supports IPv4 addresses, as IPv6 addresses will
    not work.'
  user_input: How the NO_PROXY exclusion rules is working? We try to use IP address
    blocks but it dont work.
- context:
  - 'resources in the cluster can configure the proxy variables in a values.yaml Helm
    configuration file. You have installed the Red Hat Developer Hub application.
    1. Set the proxy information in your Helm configuration file: ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''<http_proxy_url>'' name: HTTPS_PROXY
    value: ''<https_proxy_url>'' name: NO_PROXY value: ''<no_proxy_settings>'' ```
    Where, <http_proxy_url>:: Denotes a variable that you must replace with the HTTP
    proxy URL. <https_proxy_url>:: Denotes a variable that you must replace with the
    HTTPS proxy URL. <no_proxy_settings>:: Denotes a variable that you must replace
    with comma-separated URLs, which you want to exclude from proxying, for example,
    foo.com,baz.com. Example: Setting proxy variables using Helm Chart ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. !:previouscontext: # Configuring an RHDH
    instance with a TLS connection in Kubernetes You can configure a RHDH instance
    with a Transport Layer Security (TLS) connection in a Kubernetes cluster, such
    as an Azure Red Hat OpenShift (ARO) cluster, any cluster from a supported cloud
    provider, or your own cluster with proper configuration. Transport Layer Security
    (TLS) ensures a secure connection for the RHDH instance with other entities, such
    as third-party applications, or external databases. However, you must use a public
    Certificate Authority (CA)-signed certificate to configure your Kubernetes cluster.
    You have set up an Azure Red Hat OpenShift (ARO) cluster with a public CA signed
    certificate. For more information about obtaining CA certificates, refer to your
    vendor documentation. You have created a namespace and setup a service account
    with proper read permissions on resources. Example: Kubernetes manifest for role
    based access control ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: apiGroups: '' '' resources: pods configmaps
    services deployments replicasets horizontalpodautoscalers ingresses statefulsets
    limitranges resourcequotas daemonsets verbs: get list watch #... ``` You have
    obtained the secret and the service CA certificate associated with your service
    account. You have created some resources and added annotations to them so they
    can be discovered by the Kubernetes plugin. You can apply these Kubernetes annotations:
    backstage.io/kubernetes id to label components backstage.io/kubernetes namespace
    to label namespaces 1. Enable the Kubernetes plugins in the dynamic-plugins-rhdh.yaml
    file: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins rhdh
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic disabled:
    false 1 package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false 2 # ... ``` Set the value to false to enable the backstage-plugin-kubernetes-backend-dynamic
    plugin. Set the value to false to enable the backstage-plugin-kubernetes plugin.
    [NOTE] ---- The backstage-plugin-kubernetes plugin is currently in Technology
    Preview. As an alternative, you can use the ./dynamic-plugins/dist/backstage-plugin-topology-dynamic
    plugin, which is Generally Available (GA). ---- 2. Set the Kubernetes cluster
    details and configure the catalog sync options in the app-config.yaml configuration
    file. ```yaml kind: ConfigMap apiVersion: v1 metadata: name: my-rhdh-app-config
    data: "app-config.yaml": | # ... catalog: rules: - allow: [Component, System,
    API, Resource, Location] providers: kubernetes: openshift: cluster: openshift
    processor: namespaceOverride: default defaultOwner: guests schedule: frequency:
    seconds: 30 timeout: seconds: 5 kubernetes: serviceLocatorMethod: type: ''multiTenant''
    clusterLocatorMethods: - type: ''config'' clusters: - url: <target-cluster-api-server-url>
    1 name: openshift authProvider: ''serviceAccount'' skipTLSVerify: false 2 skipMetricsLookup:
    true dashboardUrl: <target-cluster-console-url> 3 dashboardApp: openshift serviceAccountToken:
    ${K8S_SERVICE_ACCOUNT_TOKEN} 4 caData: ${K8S_CONFIG_CA_DATA} 5 # ... ``` The base
    URL to the Kubernetes control plane. You can run the kubectl cluster-info command
    to get the base URL. Set the value of this parameter to false to enable the verification
    of the TLS certificate. Optional: The link to the Kubernetes dashboard managing
    the ARO cluster. Optional: Pass the service account token using a K8S_SERVICE_ACCOUNT_TOKEN
    environment variable that you define in your <my_product_secrets> secret. Pass
    the CA data using a K8S_CONFIG_CA_DATA environment variable that you define in
    your <my_product_secrets> secret. 3. Save the configuration changes. 1. Run the
    RHDH application to import your catalog: ```terminal kubectl n rhdh operator get
    pods w ``` 2. Verify that the pod log shows no errors for your configuration.
    3. Go to Catalog and check the component page in the Developer Hub instance to
    verify the cluster connection and the presence of your created resources. [NOTE]
    ---- If you encounter connection errors, such as certificate issues or permissions,
    check the message box in the component page or view the logs of the pod. ----
    # Using the dynamic plugins cache ## Using the dynamic plugins cache The dynamic
    plugins cache in Red Hat Developer Hub (RHDH) enhances the installation process
    and reduces platform boot time by storing previously installed plugins. If the
    configuration remains unchanged, this feature prevents the need to re-download
    plugins on subsequent boots. When you enable dynamic plugins cache: The system
    calculates a checksum of each plugin''s YAML configuration (excluding pluginConfig).
    The checksum is stored in a file named dynamic plugin config.hash within the plugin''s
    directory. During boot, if a plugin''s package reference matches the previous
    installation and the checksum is unchanged, the download is skipped. Plugins that
    are disabled since the previous boot are automatically removed. [NOTE] ---- To
    enable the dynamic plugins cache in RHDH, the plugins directory dynamic-plugins-root
    must be a persistent volume. ---- ## Creating a PVC for the dynamic plugin cache
    by using the Operator For operator-based installations, you must manually create
    the persistent volume claim (PVC) by replacing the default dynamic-plugins-root
    volume with a PVC named dynamic-plugins-root. You have installed Red Hat Developer
    Hub on OpenShift Container Platform using the Red Hat Developer Hub Operator.
    You have installed the OpenShift CLI (oc). 1. Create the persistent volume definition
    and save it to a file, such as pvc.yaml. For example: ```yaml kind: PersistentVolumeClaim
    apiVersion: v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce
    resources: requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce
    as the access mode which prevents multiple replicas from sharing the PVC across
    different nodes. To run multiple replicas on different nodes, depending on your
    storage driver, you must use an access mode such as ReadWriteMany. ---- 2. To
    apply this PVC to your cluster, run the following command: ```terminal oc apply
    f pvc.yaml'
  metadata:
    classification:
      category: catalog
      datetime: '2025-12-10T16:33:35.745995'
    uuid: 592fcfb8-0efc-44ed-80ce-92488f46ea3e
  response: To set the Kubernetes cluster details and configure the catalog sync options,
    you must edit the app-config.yaml configuration file. In this file, under `catalog.providers.kubernetes.openshift`,
    you configure the cluster with parameters including the `url` for the target cluster
    API server, a `name` such as 'openshift', and an `authProvider` of 'serviceAccount'.
    To enable verification of the TLS certificate, the `skipTLSVerify` value should
    be set to `false`. You can also optionally provide the `dashboardUrl`. The `serviceAccountToken`
    and `caData` are passed using the `K8S_SERVICE_ACCOUNT_TOKEN` and `K8S_CONFIG_CA_DATA`
    environment variables, which you define in your secrets.
  user_input: How do I configure the catalog sync for Red Hat Develper Hub to connect
    to my OpenShft cluster?
- context:
  - 'resources in the cluster can configure the proxy variables in a values.yaml Helm
    configuration file. You have installed the Red Hat Developer Hub application.
    1. Set the proxy information in your Helm configuration file: ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''<http_proxy_url>'' name: HTTPS_PROXY
    value: ''<https_proxy_url>'' name: NO_PROXY value: ''<no_proxy_settings>'' ```
    Where, <http_proxy_url>:: Denotes a variable that you must replace with the HTTP
    proxy URL. <https_proxy_url>:: Denotes a variable that you must replace with the
    HTTPS proxy URL. <no_proxy_settings>:: Denotes a variable that you must replace
    with comma-separated URLs, which you want to exclude from proxying, for example,
    foo.com,baz.com. Example: Setting proxy variables using Helm Chart ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. !:previouscontext: # Configuring an RHDH
    instance with a TLS connection in Kubernetes You can configure a RHDH instance
    with a Transport Layer Security (TLS) connection in a Kubernetes cluster, such
    as an Azure Red Hat OpenShift (ARO) cluster, any cluster from a supported cloud
    provider, or your own cluster with proper configuration. Transport Layer Security
    (TLS) ensures a secure connection for the RHDH instance with other entities, such
    as third-party applications, or external databases. However, you must use a public
    Certificate Authority (CA)-signed certificate to configure your Kubernetes cluster.
    You have set up an Azure Red Hat OpenShift (ARO) cluster with a public CA signed
    certificate. For more information about obtaining CA certificates, refer to your
    vendor documentation. You have created a namespace and setup a service account
    with proper read permissions on resources. Example: Kubernetes manifest for role
    based access control ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: apiGroups: '' '' resources: pods configmaps
    services deployments replicasets horizontalpodautoscalers ingresses statefulsets
    limitranges resourcequotas daemonsets verbs: get list watch #... ``` You have
    obtained the secret and the service CA certificate associated with your service
    account. You have created some resources and added annotations to them so they
    can be discovered by the Kubernetes plugin. You can apply these Kubernetes annotations:
    backstage.io/kubernetes id to label components backstage.io/kubernetes namespace
    to label namespaces 1. Enable the Kubernetes plugins in the dynamic-plugins-rhdh.yaml
    file: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins rhdh
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic disabled:
    false 1 package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false 2 # ... ``` Set the value to false to enable the backstage-plugin-kubernetes-backend-dynamic
    plugin. Set the value to false to enable the backstage-plugin-kubernetes plugin.
    [NOTE] ---- The backstage-plugin-kubernetes plugin is currently in Technology
    Preview. As an alternative, you can use the ./dynamic-plugins/dist/backstage-plugin-topology-dynamic
    plugin, which is Generally Available (GA). ---- 2. Set the Kubernetes cluster
    details and configure the catalog sync options in the app-config.yaml configuration
    file. ```yaml kind: ConfigMap apiVersion: v1 metadata: name: my-rhdh-app-config
    data: "app-config.yaml": | # ... catalog: rules: - allow: [Component, System,
    API, Resource, Location] providers: kubernetes: openshift: cluster: openshift
    processor: namespaceOverride: default defaultOwner: guests schedule: frequency:
    seconds: 30 timeout: seconds: 5 kubernetes: serviceLocatorMethod: type: ''multiTenant''
    clusterLocatorMethods: - type: ''config'' clusters: - url: <target-cluster-api-server-url>
    1 name: openshift authProvider: ''serviceAccount'' skipTLSVerify: false 2 skipMetricsLookup:
    true dashboardUrl: <target-cluster-console-url> 3 dashboardApp: openshift serviceAccountToken:
    ${K8S_SERVICE_ACCOUNT_TOKEN} 4 caData: ${K8S_CONFIG_CA_DATA} 5 # ... ``` The base
    URL to the Kubernetes control plane. You can run the kubectl cluster-info command
    to get the base URL. Set the value of this parameter to false to enable the verification
    of the TLS certificate. Optional: The link to the Kubernetes dashboard managing
    the ARO cluster. Optional: Pass the service account token using a K8S_SERVICE_ACCOUNT_TOKEN
    environment variable that you define in your <my_product_secrets> secret. Pass
    the CA data using a K8S_CONFIG_CA_DATA environment variable that you define in
    your <my_product_secrets> secret. 3. Save the configuration changes. 1. Run the
    RHDH application to import your catalog: ```terminal kubectl n rhdh operator get
    pods w ``` 2. Verify that the pod log shows no errors for your configuration.
    3. Go to Catalog and check the component page in the Developer Hub instance to
    verify the cluster connection and the presence of your created resources. [NOTE]
    ---- If you encounter connection errors, such as certificate issues or permissions,
    check the message box in the component page or view the logs of the pod. ----
    # Using the dynamic plugins cache ## Using the dynamic plugins cache The dynamic
    plugins cache in Red Hat Developer Hub (RHDH) enhances the installation process
    and reduces platform boot time by storing previously installed plugins. If the
    configuration remains unchanged, this feature prevents the need to re-download
    plugins on subsequent boots. When you enable dynamic plugins cache: The system
    calculates a checksum of each plugin''s YAML configuration (excluding pluginConfig).
    The checksum is stored in a file named dynamic plugin config.hash within the plugin''s
    directory. During boot, if a plugin''s package reference matches the previous
    installation and the checksum is unchanged, the download is skipped. Plugins that
    are disabled since the previous boot are automatically removed. [NOTE] ---- To
    enable the dynamic plugins cache in RHDH, the plugins directory dynamic-plugins-root
    must be a persistent volume. ---- ## Creating a PVC for the dynamic plugin cache
    by using the Operator For operator-based installations, you must manually create
    the persistent volume claim (PVC) by replacing the default dynamic-plugins-root
    volume with a PVC named dynamic-plugins-root. You have installed Red Hat Developer
    Hub on OpenShift Container Platform using the Red Hat Developer Hub Operator.
    You have installed the OpenShift CLI (oc). 1. Create the persistent volume definition
    and save it to a file, such as pvc.yaml. For example: ```yaml kind: PersistentVolumeClaim
    apiVersion: v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce
    resources: requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce
    as the access mode which prevents multiple replicas from sharing the PVC across
    different nodes. To run multiple replicas on different nodes, depending on your
    storage driver, you must use an access mode such as ReadWriteMany. ---- 2. To
    apply this PVC to your cluster, run the following command: ```terminal oc apply
    f pvc.yaml'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:33:43.430197'
    uuid: 166acc94-29a6-41af-8110-563ffabbcdf1
  response: To enable discovery by the Kubernetes plugin, you can apply the `backstage.io/kubernetes
    id` annotation to label components and the `backstage.io/kubernetes namespace`
    annotation to label namespaces.
  user_input: What Backstage annotations can I apply to my Kubernetes resources so
    they can be discovered?
- context:
  - 'resources in the cluster can configure the proxy variables in a values.yaml Helm
    configuration file. You have installed the Red Hat Developer Hub application.
    1. Set the proxy information in your Helm configuration file: ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''<http_proxy_url>'' name: HTTPS_PROXY
    value: ''<https_proxy_url>'' name: NO_PROXY value: ''<no_proxy_settings>'' ```
    Where, <http_proxy_url>:: Denotes a variable that you must replace with the HTTP
    proxy URL. <https_proxy_url>:: Denotes a variable that you must replace with the
    HTTPS proxy URL. <no_proxy_settings>:: Denotes a variable that you must replace
    with comma-separated URLs, which you want to exclude from proxying, for example,
    foo.com,baz.com. Example: Setting proxy variables using Helm Chart ```yaml upstream:
    backstage: extraEnvVars: name: HTTP_PROXY value: ''http://10.10.10.105:3128''
    name: HTTPS_PROXY value: ''http://10.10.10.106:3128'' name: NO_PROXY value: ''localhost,example.org''
    ``` 2. Save the configuration changes. !:previouscontext: # Configuring an RHDH
    instance with a TLS connection in Kubernetes You can configure a RHDH instance
    with a Transport Layer Security (TLS) connection in a Kubernetes cluster, such
    as an Azure Red Hat OpenShift (ARO) cluster, any cluster from a supported cloud
    provider, or your own cluster with proper configuration. Transport Layer Security
    (TLS) ensures a secure connection for the RHDH instance with other entities, such
    as third-party applications, or external databases. However, you must use a public
    Certificate Authority (CA)-signed certificate to configure your Kubernetes cluster.
    You have set up an Azure Red Hat OpenShift (ARO) cluster with a public CA signed
    certificate. For more information about obtaining CA certificates, refer to your
    vendor documentation. You have created a namespace and setup a service account
    with proper read permissions on resources. Example: Kubernetes manifest for role
    based access control ```yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole
    metadata: name: backstage read only rules: apiGroups: '' '' resources: pods configmaps
    services deployments replicasets horizontalpodautoscalers ingresses statefulsets
    limitranges resourcequotas daemonsets verbs: get list watch #... ``` You have
    obtained the secret and the service CA certificate associated with your service
    account. You have created some resources and added annotations to them so they
    can be discovered by the Kubernetes plugin. You can apply these Kubernetes annotations:
    backstage.io/kubernetes id to label components backstage.io/kubernetes namespace
    to label namespaces 1. Enable the Kubernetes plugins in the dynamic-plugins-rhdh.yaml
    file: ```yaml kind: ConfigMap apiVersion: v1 metadata: name: dynamic plugins rhdh
    data: dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins:
    package: ./dynamic plugins/dist/backstage plugin kubernetes backend dynamic disabled:
    false 1 package: ./dynamic plugins/dist/backstage plugin kubernetes disabled:
    false 2 # ... ``` Set the value to false to enable the backstage-plugin-kubernetes-backend-dynamic
    plugin. Set the value to false to enable the backstage-plugin-kubernetes plugin.
    [NOTE] ---- The backstage-plugin-kubernetes plugin is currently in Technology
    Preview. As an alternative, you can use the ./dynamic-plugins/dist/backstage-plugin-topology-dynamic
    plugin, which is Generally Available (GA). ---- 2. Set the Kubernetes cluster
    details and configure the catalog sync options in the app-config.yaml configuration
    file. ```yaml kind: ConfigMap apiVersion: v1 metadata: name: my-rhdh-app-config
    data: "app-config.yaml": | # ... catalog: rules: - allow: [Component, System,
    API, Resource, Location] providers: kubernetes: openshift: cluster: openshift
    processor: namespaceOverride: default defaultOwner: guests schedule: frequency:
    seconds: 30 timeout: seconds: 5 kubernetes: serviceLocatorMethod: type: ''multiTenant''
    clusterLocatorMethods: - type: ''config'' clusters: - url: <target-cluster-api-server-url>
    1 name: openshift authProvider: ''serviceAccount'' skipTLSVerify: false 2 skipMetricsLookup:
    true dashboardUrl: <target-cluster-console-url> 3 dashboardApp: openshift serviceAccountToken:
    ${K8S_SERVICE_ACCOUNT_TOKEN} 4 caData: ${K8S_CONFIG_CA_DATA} 5 # ... ``` The base
    URL to the Kubernetes control plane. You can run the kubectl cluster-info command
    to get the base URL. Set the value of this parameter to false to enable the verification
    of the TLS certificate. Optional: The link to the Kubernetes dashboard managing
    the ARO cluster. Optional: Pass the service account token using a K8S_SERVICE_ACCOUNT_TOKEN
    environment variable that you define in your <my_product_secrets> secret. Pass
    the CA data using a K8S_CONFIG_CA_DATA environment variable that you define in
    your <my_product_secrets> secret. 3. Save the configuration changes. 1. Run the
    RHDH application to import your catalog: ```terminal kubectl n rhdh operator get
    pods w ``` 2. Verify that the pod log shows no errors for your configuration.
    3. Go to Catalog and check the component page in the Developer Hub instance to
    verify the cluster connection and the presence of your created resources. [NOTE]
    ---- If you encounter connection errors, such as certificate issues or permissions,
    check the message box in the component page or view the logs of the pod. ----
    # Using the dynamic plugins cache ## Using the dynamic plugins cache The dynamic
    plugins cache in Red Hat Developer Hub (RHDH) enhances the installation process
    and reduces platform boot time by storing previously installed plugins. If the
    configuration remains unchanged, this feature prevents the need to re-download
    plugins on subsequent boots. When you enable dynamic plugins cache: The system
    calculates a checksum of each plugin''s YAML configuration (excluding pluginConfig).
    The checksum is stored in a file named dynamic plugin config.hash within the plugin''s
    directory. During boot, if a plugin''s package reference matches the previous
    installation and the checksum is unchanged, the download is skipped. Plugins that
    are disabled since the previous boot are automatically removed. [NOTE] ---- To
    enable the dynamic plugins cache in RHDH, the plugins directory dynamic-plugins-root
    must be a persistent volume. ---- ## Creating a PVC for the dynamic plugin cache
    by using the Operator For operator-based installations, you must manually create
    the persistent volume claim (PVC) by replacing the default dynamic-plugins-root
    volume with a PVC named dynamic-plugins-root. You have installed Red Hat Developer
    Hub on OpenShift Container Platform using the Red Hat Developer Hub Operator.
    You have installed the OpenShift CLI (oc). 1. Create the persistent volume definition
    and save it to a file, such as pvc.yaml. For example: ```yaml kind: PersistentVolumeClaim
    apiVersion: v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce
    resources: requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce
    as the access mode which prevents multiple replicas from sharing the PVC across
    different nodes. To run multiple replicas on different nodes, depending on your
    storage driver, you must use an access mode such as ReadWriteMany. ---- 2. To
    apply this PVC to your cluster, run the following command: ```terminal oc apply
    f pvc.yaml'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:34:11.526899'
    uuid: b83a6a23-dfca-4a77-bd0d-9f390992eaa6
  response: "To configure the connection to your OpenShift cluster, you must set the\
    \ Kubernetes cluster details and catalog sync options in the app-config.yaml configuration\
    \ file. The configuration should specify a 'multiTenant' service locator method\
    \ and a 'config' type for the cluster locator method. The specific cluster details\
    \ are as follows:\n\n```yaml\ncatalog:\n  rules:\n    - allow: [Component, System,\
    \ API, Resource, Location]\n  providers:\n    kubernetes:\n      openshift:\n\
    \        cluster: openshift\n        processor:\n          namespaceOverride:\
    \ default\n          defaultOwner: guests\n        schedule:\n          frequency:\
    \ {seconds: 30}\n          timeout: {seconds: 5}\n    kubernetes:\n      serviceLocatorMethod:\n\
    \        type: 'multiTenant'\n      clusterLocatorMethods:\n        - type: 'config'\n\
    \          clusters:\n            - url: <target-cluster-api-server-url>\n   \
    \           name: openshift\n              authProvider: 'serviceAccount'\n  \
    \            skipTLSVerify: false\n              skipMetricsLookup: true\n   \
    \           dashboardUrl: <target-cluster-console-url>\n              dashboardApp:\
    \ openshift\n              serviceAccountToken: ${K8S_SERVICE_ACCOUNT_TOKEN}\n\
    \              caData: ${K8S_CONFIG_CA_DATA}\n```\n\nKey parameters include:\n\
    - **url**: The base URL to the Kubernetes control plane, which can be obtained\
    \ by running the `kubectl cluster-info` command.\n- **skipTLSVerify**: This must\
    \ be set to `false` to enable the verification of the TLS certificate.\n- **dashboardUrl**:\
    \ An optional link to the Kubernetes dashboard for the ARO cluster.\n- **serviceAccountToken**:\
    \ This is an optional parameter to pass the service account token using a `K8S_SERVICE_ACCOUNT_TOKEN`\
    \ environment variable defined in your secrets.\n- **caData**: This parameter\
    \ passes the CA data using a `K8S_CONFIG_CA_DATA` environment variable, also defined\
    \ in your secrets."
  user_input: Given that my team is responsible for integrating Red Hat Developer
    Hub with our existing Azure Red Hat OpenShift cluster, what are the precise configuration
    details and catalog sync options that must be set in the app-config.yaml file
    to establish a secure, multi-tenant connection, including the cluster URL, authentication
    provider, and the specific environment variables required for the service account
    token and CA data?
- context:
  - '``` 3. Replace the default dynamic-plugins-root volume with a PVC named dynamic-plugins-root.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` [NOTE] ---- To avoid adding a new volume, you must use the $patch: replace
    directive. ---- ## Creating a PVC for the dynamic plugin cache using the Helm
    Chart For Helm chart installations, if you require the dynamic plugin cache to
    persist across pod restarts, you must create a persistent volume claim (PVC) and
    configure the Helm chart to use it. You have installed Red Hat Developer Hub using
    the Helm chart. You have installed the OpenShift CLI (oc). 1. Create the persistent
    volume definition. For example: ```yaml kind: PersistentVolumeClaim apiVersion:
    v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce resources:
    requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce as the
    access mode which prevents multiple replicas from sharing the PVC across different
    nodes. To run multiple replicas on different nodes, depending on your storage
    driver, you must use an access mode such as ReadWriteMany. ---- 2. To apply this
    PVC to your cluster, run the following command: ```terminal oc apply f pvc.yaml
    ``` 3. Configure the Helm chart to use the PVC. For example: ```yaml upstream:
    backstage: extraVolumes: name: dynamic plugins root persistentVolumeClaim: claimName:
    dynamic plugins root name: dynamic plugins configMap: defaultMode: 420 name: ''{{
    printf "%s dynamic plugins" .Release.Name }}'' optional: true name: dynamic plugins
    npmrc secret: defaultMode: 420 optional: true secretName: ''{{ printf "%s dynamic
    plugins npmrc" .Release.Name }}'' name: dynamic plugins registry auth secret:
    defaultMode: 416 optional: true secretName: ''{{ printf "%s dynamic plugins registry
    auth" .Release.Name }}'' name: npmcacache emptyDir: {} name: temp emptyDir: {}
    ``` [NOTE] ---- When you configure the Helm chart to use the PVC, you must also
    include the extraVolumes section defined in the default Helm chart values. ----
    ## Configuring the dynamic plugins cache To configure the dynamic plugins cache,
    set the following optional dynamic plugin cache parameters in your dynamic plugins.yaml
    file: pullPolicy: IfNotPresent (default):: Download the artifact if it is not
    already present in the dynamic plugins root folder, without checking image digests.
    pullPolicy: Always:: Compare the image digest in the remote registry and downloads
    the artifact if it has changed, even if Developer Hub has already downloaded the
    plugin before. When applied to the Node Package Manager (NPM) downloading method,
    download the remote artifact without a digest check. Example dynamic-plugins.yaml
    file configuration to download the remote artifact without a digest check: ```yaml
    plugins: disabled: false pullPolicy: Always package: ''oci://quay.io/example org/example
    plugin:v1.0.0!internal backstage plugin example'' ``` forceDownload: false (default)::
    Older option to download the artifact if it is not already present in the dynamic-plugins-root
    folder, without checking image digests. forceDownload: true:: Older option to
    force a reinstall of the plugin, bypassing the cache. [NOTE] ---- The pullPolicy
    option takes precedence over the forceDownload option. The forceDownload option
    might become deprecated in a future Developer Hub release. ---- # Enabling the
    Red Hat Developer Hub plugin assets cache By default, Red Hat Developer Hub does
    not cache plugin assets. You can use a Redis cache store to improve Developer
    Hub performance and reliability. Configured plugins in Developer Hub receive dedicated
    cache connections, which are powered by the Keyv Redis client. You have installed
    Red Hat Developer Hub. You have an active Redis server. For more information on
    setting up an external Redis server, see the official Redis documentation. 1.
    Enable the Developer Hub cache by defining Redis as the cache store type and entering
    your Redis server connection URL in your app-config.yaml file. app-config.yaml
    file fragment ```yaml backend: cache: store: redis connection: redis://user:pass@cache.example.com:6379
    ``` 2. Enable the cache for Techdocs by adding the techdocs.cache.ttl setting
    in your app-config.yaml file. This setting specifies how long, in milliseconds,
    a statically built asset should stay in the cache. app-config.yaml file fragment
    ```yaml techdocs: cache: ttl: 3600000 ``` [TIP] ---- Optionally, enable the cache
    for unsupported plugins that support this feature. See their respective documentation
    for details. ----'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:34:19.452142'
    uuid: 70672465-f075-44d6-99ec-86b35e6dcaa5
  response: When the `pullPolicy` is set to `Always` and applied to the Node Package
    Manager (NPM) downloading method, it downloads the remote artifact without a digest
    check.
  user_input: So im trying to figure out this dynamic plugins cache config, and i
    see this pullPolicy setting, but what does it do, like if i set pullPolicy to
    Always, how does that specifically affect the Node Package Manager downloading
    method for plugins, what is the behavior i should expect to see?
- context:
  - '``` 3. Replace the default dynamic-plugins-root volume with a PVC named dynamic-plugins-root.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` [NOTE] ---- To avoid adding a new volume, you must use the $patch: replace
    directive. ---- ## Creating a PVC for the dynamic plugin cache using the Helm
    Chart For Helm chart installations, if you require the dynamic plugin cache to
    persist across pod restarts, you must create a persistent volume claim (PVC) and
    configure the Helm chart to use it. You have installed Red Hat Developer Hub using
    the Helm chart. You have installed the OpenShift CLI (oc). 1. Create the persistent
    volume definition. For example: ```yaml kind: PersistentVolumeClaim apiVersion:
    v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce resources:
    requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce as the
    access mode which prevents multiple replicas from sharing the PVC across different
    nodes. To run multiple replicas on different nodes, depending on your storage
    driver, you must use an access mode such as ReadWriteMany. ---- 2. To apply this
    PVC to your cluster, run the following command: ```terminal oc apply f pvc.yaml
    ``` 3. Configure the Helm chart to use the PVC. For example: ```yaml upstream:
    backstage: extraVolumes: name: dynamic plugins root persistentVolumeClaim: claimName:
    dynamic plugins root name: dynamic plugins configMap: defaultMode: 420 name: ''{{
    printf "%s dynamic plugins" .Release.Name }}'' optional: true name: dynamic plugins
    npmrc secret: defaultMode: 420 optional: true secretName: ''{{ printf "%s dynamic
    plugins npmrc" .Release.Name }}'' name: dynamic plugins registry auth secret:
    defaultMode: 416 optional: true secretName: ''{{ printf "%s dynamic plugins registry
    auth" .Release.Name }}'' name: npmcacache emptyDir: {} name: temp emptyDir: {}
    ``` [NOTE] ---- When you configure the Helm chart to use the PVC, you must also
    include the extraVolumes section defined in the default Helm chart values. ----
    ## Configuring the dynamic plugins cache To configure the dynamic plugins cache,
    set the following optional dynamic plugin cache parameters in your dynamic plugins.yaml
    file: pullPolicy: IfNotPresent (default):: Download the artifact if it is not
    already present in the dynamic plugins root folder, without checking image digests.
    pullPolicy: Always:: Compare the image digest in the remote registry and downloads
    the artifact if it has changed, even if Developer Hub has already downloaded the
    plugin before. When applied to the Node Package Manager (NPM) downloading method,
    download the remote artifact without a digest check. Example dynamic-plugins.yaml
    file configuration to download the remote artifact without a digest check: ```yaml
    plugins: disabled: false pullPolicy: Always package: ''oci://quay.io/example org/example
    plugin:v1.0.0!internal backstage plugin example'' ``` forceDownload: false (default)::
    Older option to download the artifact if it is not already present in the dynamic-plugins-root
    folder, without checking image digests. forceDownload: true:: Older option to
    force a reinstall of the plugin, bypassing the cache. [NOTE] ---- The pullPolicy
    option takes precedence over the forceDownload option. The forceDownload option
    might become deprecated in a future Developer Hub release. ---- # Enabling the
    Red Hat Developer Hub plugin assets cache By default, Red Hat Developer Hub does
    not cache plugin assets. You can use a Redis cache store to improve Developer
    Hub performance and reliability. Configured plugins in Developer Hub receive dedicated
    cache connections, which are powered by the Keyv Redis client. You have installed
    Red Hat Developer Hub. You have an active Redis server. For more information on
    setting up an external Redis server, see the official Redis documentation. 1.
    Enable the Developer Hub cache by defining Redis as the cache store type and entering
    your Redis server connection URL in your app-config.yaml file. app-config.yaml
    file fragment ```yaml backend: cache: store: redis connection: redis://user:pass@cache.example.com:6379
    ``` 2. Enable the cache for Techdocs by adding the techdocs.cache.ttl setting
    in your app-config.yaml file. This setting specifies how long, in milliseconds,
    a statically built asset should stay in the cache. app-config.yaml file fragment
    ```yaml techdocs: cache: ttl: 3600000 ``` [TIP] ---- Optionally, enable the cache
    for unsupported plugins that support this feature. See their respective documentation
    for details. ----'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:34:33.427152'
    uuid: bafb9557-f65c-4b7e-b8ff-6ae077bc9e46
  response: When the `pullPolicy` is set to `Always` and applied to the Node Package
    Manager (NPM) downloading method, it downloads the remote artifact without a digest
    check.
  user_input: how dose pullPolicy Always affect the Node Package Manager?
- context:
  - '``` 3. Replace the default dynamic-plugins-root volume with a PVC named dynamic-plugins-root.
    For example: ```yaml apiVersion: rhdh.redhat.com/v1alpha3 kind: Backstage metadata:
    name: developer hub spec: deployment: patch: spec: template: spec: volumes: $patch:
    replace name: dynamic plugins root persistentVolumeClaim: claimName: dynamic plugins
    root ``` [NOTE] ---- To avoid adding a new volume, you must use the $patch: replace
    directive. ---- ## Creating a PVC for the dynamic plugin cache using the Helm
    Chart For Helm chart installations, if you require the dynamic plugin cache to
    persist across pod restarts, you must create a persistent volume claim (PVC) and
    configure the Helm chart to use it. You have installed Red Hat Developer Hub using
    the Helm chart. You have installed the OpenShift CLI (oc). 1. Create the persistent
    volume definition. For example: ```yaml kind: PersistentVolumeClaim apiVersion:
    v1 metadata: name: dynamic plugins root spec: accessModes: ReadWriteOnce resources:
    requests: storage: 5Gi ``` [NOTE] ---- This example uses ReadWriteOnce as the
    access mode which prevents multiple replicas from sharing the PVC across different
    nodes. To run multiple replicas on different nodes, depending on your storage
    driver, you must use an access mode such as ReadWriteMany. ---- 2. To apply this
    PVC to your cluster, run the following command: ```terminal oc apply f pvc.yaml
    ``` 3. Configure the Helm chart to use the PVC. For example: ```yaml upstream:
    backstage: extraVolumes: name: dynamic plugins root persistentVolumeClaim: claimName:
    dynamic plugins root name: dynamic plugins configMap: defaultMode: 420 name: ''{{
    printf "%s dynamic plugins" .Release.Name }}'' optional: true name: dynamic plugins
    npmrc secret: defaultMode: 420 optional: true secretName: ''{{ printf "%s dynamic
    plugins npmrc" .Release.Name }}'' name: dynamic plugins registry auth secret:
    defaultMode: 416 optional: true secretName: ''{{ printf "%s dynamic plugins registry
    auth" .Release.Name }}'' name: npmcacache emptyDir: {} name: temp emptyDir: {}
    ``` [NOTE] ---- When you configure the Helm chart to use the PVC, you must also
    include the extraVolumes section defined in the default Helm chart values. ----
    ## Configuring the dynamic plugins cache To configure the dynamic plugins cache,
    set the following optional dynamic plugin cache parameters in your dynamic plugins.yaml
    file: pullPolicy: IfNotPresent (default):: Download the artifact if it is not
    already present in the dynamic plugins root folder, without checking image digests.
    pullPolicy: Always:: Compare the image digest in the remote registry and downloads
    the artifact if it has changed, even if Developer Hub has already downloaded the
    plugin before. When applied to the Node Package Manager (NPM) downloading method,
    download the remote artifact without a digest check. Example dynamic-plugins.yaml
    file configuration to download the remote artifact without a digest check: ```yaml
    plugins: disabled: false pullPolicy: Always package: ''oci://quay.io/example org/example
    plugin:v1.0.0!internal backstage plugin example'' ``` forceDownload: false (default)::
    Older option to download the artifact if it is not already present in the dynamic-plugins-root
    folder, without checking image digests. forceDownload: true:: Older option to
    force a reinstall of the plugin, bypassing the cache. [NOTE] ---- The pullPolicy
    option takes precedence over the forceDownload option. The forceDownload option
    might become deprecated in a future Developer Hub release. ---- # Enabling the
    Red Hat Developer Hub plugin assets cache By default, Red Hat Developer Hub does
    not cache plugin assets. You can use a Redis cache store to improve Developer
    Hub performance and reliability. Configured plugins in Developer Hub receive dedicated
    cache connections, which are powered by the Keyv Redis client. You have installed
    Red Hat Developer Hub. You have an active Redis server. For more information on
    setting up an external Redis server, see the official Redis documentation. 1.
    Enable the Developer Hub cache by defining Redis as the cache store type and entering
    your Redis server connection URL in your app-config.yaml file. app-config.yaml
    file fragment ```yaml backend: cache: store: redis connection: redis://user:pass@cache.example.com:6379
    ``` 2. Enable the cache for Techdocs by adding the techdocs.cache.ttl setting
    in your app-config.yaml file. This setting specifies how long, in milliseconds,
    a statically built asset should stay in the cache. app-config.yaml file fragment
    ```yaml techdocs: cache: ttl: 3600000 ``` [TIP] ---- Optionally, enable the cache
    for unsupported plugins that support this feature. See their respective documentation
    for details. ----'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:34:46.583525'
    uuid: f7094485-5324-414f-b1a6-d5970dd7eaec
  response: 'To create the persistent volume definition, you can use this example:
    "kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: dynamic plugins
    root\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage:
    5Gi". This example uses `ReadWriteOnce` as the access mode, which prevents multiple
    replicas from sharing the PVC across different nodes. To run multiple replicas
    on different nodes, you must use an access mode such as `ReadWriteMany`, depending
    on your storage driver. To apply this PVC to your cluster, you run the command:
    `oc apply f pvc.yaml`.'
  user_input: how i can create the pvc for dynamic plugin cache, what is the yaml
    for it?
- context:
  - "# Operator flavors for Red Hat Developer Hub # Red Hat Developer Hub Operator\
    \ Flavors ## Flavor framework architecture The flavor framework for the Red Hat\
    \ Developer Hub (RHDH) Operator is an extension of the existing Configuration\
    \ Profiles mechanism. A flavor is a specialized profile that goes beyond simple\
    \ configuration to encompass a complete, opinionated RHDH installation. The architecture\
    \ is designed to be flexible and modular, allowing for the creation of turnkey\
    \ solutions. The core of the framework is its reliance on Kustomize, a tool used\
    \ by the operator to manage and apply Kubernetes manifests. Flavors act as Kustomize\
    \ overlays, which means they can modify and extend a base RHDH deployment with\
    \ specific configurations, resources, and dependencies. A complete flavor is defined\
    \ by a standardized set of directories and files: Flavor Manifest:: A kustomization.yaml\
    \ file that acts as the central definition for the flavor, orchestrating how all\
    \ the other components are applied. Configuration Directory (config/):: Contains\
    \ RHDH application and plugin configuration files. Resources Directory (resources/)::\
    \ Holds additional Kubernetes resources that need to be deployed, such as custom\
    \ resource definitions (CRDs), catalog entities, and templates. Hooks Directory\
    \ (hooks/):: Stores manifests for pre-installation and post-installation tasks,\
    \ which are executed as Kubernetes jobs. ## Flavor framework implementation The\
    \ implementation of the flavor framework is handled by the RHDH Operator itself,\
    \ which is extended to recognize and process the spec.flavor field in the Backstage\
    \ custom resource (CR). The implementation details include: Flavor selection::\
    \ The Backstage CR is extended to include a spec.flavor field, allowing users\
    \ to select a predefined or custom flavor. Operator integration:: When a Backstage\
    \ CR is applied, the operator checks for the specified flavor. It then uses Kustomize\
    \ to process the flavor's manifest and apply its configurations, resources, and\
    \ hooks to the cluster. Dependency management:: The Operator is responsible for\
    \ automatically checking for and deploying any required infrastructure dependencies\
    \ (for example, other operators or CRDs) that a flavor's plugins might need. It\
    \ validates these requirements before applying the flavor's configuration. Hooks\
    \ execution:: The Operator handles the lifecycle of pre-installation and post-installation\
    \ hooks. It monitors the status of the Kubernetes jobs created by these hooks\
    \ and adjusts the deployment process accordingly. Distribution:: Flavors can be\
    \ shipped with the Operator or distributed externally as container images. When\
    \ a user specifies an external flavor image, the Operator pulls the image, extracts\
    \ the files of the flavor, and applies them in the same way as a built-in flavor.\
    \ This container-based approach provides a consistent and secure way to manage\
    \ custom flavors. ## Creating a custom flavor A custom flavor is a new operator\
    \ profile with a specific directory structure. You can create a new flavor by\
    \ following these steps: 1. Create a dedicated directory for your flavor, following\
    \ a standardized structure. This structure helps the operator identify and process\
    \ all the components of your flavor: ```terminal flavors/ \u2514\u2500\u2500 my-custom-flavor/\
    \ \u251C\u2500\u2500 kustomize.yaml \u251C\u2500\u2500 config/ \u2502 \u251C\u2500\
    \u2500 app-config.yaml \u2502 \u2514\u2500\u2500 plugins/ \u2502 \u2514\u2500\u2500\
    \ my-plugin.yaml \u251C\u2500\u2500 resources/ \u2502 \u251C\u2500\u2500 dependencies.yaml\
    \ \u2502 \u2514\u2500\u2500 catalog/ \u2502 \u2514\u2500\u2500 entities.yaml \u2514\
    \u2500\u2500 hooks/ \u251C\u2500\u2500 pre-install/ \u2502 \u2514\u2500\u2500\
    \ job.yaml \u2514\u2500\u2500 post-install/ \u2514\u2500\u2500 job.yaml ``` where\
    \ kustomize.yaml:: This is your flavor's manifest file that acts as the central\
    \ definition, orchestrating the application of all other files in the directory.\
    \ config/:: Contains the core app-config.yaml for Red Hat Developer Hub, along\
    \ with any plugin-specific configuration files. resources/:: Holds additional\
    \ Kubernetes resources your flavor needs. This can include CRDs for dependencies\
    \ or initial catalog entities to populate RHDH. hooks/:: Contains manifests for\
    \ Kubernetes jobs that run before (pre-install) or after (post-install) the RHDH\
    \ instance is deployed. 2. (Optional) If your flavor uses dynamic plugins that\
    \ require specific Kubernetes resources, define these resources as YAML manifests\
    \ in your config/profile/{PROFILE}/plugin-deps directory. 3. (Optional) For dependencies\
    \ that require operators or other infrastructure, specify them in the plugin-infra\
    \ directory. 4. (Optional) Write Kubernetes job manifests for any pre-installation\
    \ or post-installation tasks. The Operator will execute these jobs and monitor\
    \ their status. ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:34:57.590376'
    uuid: ab9e3a6f-42ac-4752-bcd0-1a740f7c1cfc
  response: The Red Hat Developer Hub (RHDH) Operator's flavor framework is an extension
    of its Configuration Profiles mechanism that relies on Kustomize to manage and
    apply Kubernetes manifests. The Operator is extended to recognize and process
    a "spec.flavor" field in the Backstage custom resource (CR). When a flavor is
    specified, the Operator uses Kustomize to apply the flavor's configurations, resources,
    and hooks. A flavor's directory structure can include a "resources" directory
    for additional Kubernetes resources like custom resource definitions (CRDs) and
    a "hooks" directory containing manifests for pre- and post-installation tasks,
    which are executed as Kubernetes jobs. The Operator handles the lifecycle of these
    jobs, monitoring their status and adjusting the deployment process accordingly.
  user_input: From a platform engineering perspective, how does the Red Hat Developer
    Hub Operator utilize Kubernetes resources to manage the implementation and lifecycle
    of its flavor framework?
- context:
  - "# Operator flavors for Red Hat Developer Hub # Red Hat Developer Hub Operator\
    \ Flavors ## Flavor framework architecture The flavor framework for the Red Hat\
    \ Developer Hub (RHDH) Operator is an extension of the existing Configuration\
    \ Profiles mechanism. A flavor is a specialized profile that goes beyond simple\
    \ configuration to encompass a complete, opinionated RHDH installation. The architecture\
    \ is designed to be flexible and modular, allowing for the creation of turnkey\
    \ solutions. The core of the framework is its reliance on Kustomize, a tool used\
    \ by the operator to manage and apply Kubernetes manifests. Flavors act as Kustomize\
    \ overlays, which means they can modify and extend a base RHDH deployment with\
    \ specific configurations, resources, and dependencies. A complete flavor is defined\
    \ by a standardized set of directories and files: Flavor Manifest:: A kustomization.yaml\
    \ file that acts as the central definition for the flavor, orchestrating how all\
    \ the other components are applied. Configuration Directory (config/):: Contains\
    \ RHDH application and plugin configuration files. Resources Directory (resources/)::\
    \ Holds additional Kubernetes resources that need to be deployed, such as custom\
    \ resource definitions (CRDs), catalog entities, and templates. Hooks Directory\
    \ (hooks/):: Stores manifests for pre-installation and post-installation tasks,\
    \ which are executed as Kubernetes jobs. ## Flavor framework implementation The\
    \ implementation of the flavor framework is handled by the RHDH Operator itself,\
    \ which is extended to recognize and process the spec.flavor field in the Backstage\
    \ custom resource (CR). The implementation details include: Flavor selection::\
    \ The Backstage CR is extended to include a spec.flavor field, allowing users\
    \ to select a predefined or custom flavor. Operator integration:: When a Backstage\
    \ CR is applied, the operator checks for the specified flavor. It then uses Kustomize\
    \ to process the flavor's manifest and apply its configurations, resources, and\
    \ hooks to the cluster. Dependency management:: The Operator is responsible for\
    \ automatically checking for and deploying any required infrastructure dependencies\
    \ (for example, other operators or CRDs) that a flavor's plugins might need. It\
    \ validates these requirements before applying the flavor's configuration. Hooks\
    \ execution:: The Operator handles the lifecycle of pre-installation and post-installation\
    \ hooks. It monitors the status of the Kubernetes jobs created by these hooks\
    \ and adjusts the deployment process accordingly. Distribution:: Flavors can be\
    \ shipped with the Operator or distributed externally as container images. When\
    \ a user specifies an external flavor image, the Operator pulls the image, extracts\
    \ the files of the flavor, and applies them in the same way as a built-in flavor.\
    \ This container-based approach provides a consistent and secure way to manage\
    \ custom flavors. ## Creating a custom flavor A custom flavor is a new operator\
    \ profile with a specific directory structure. You can create a new flavor by\
    \ following these steps: 1. Create a dedicated directory for your flavor, following\
    \ a standardized structure. This structure helps the operator identify and process\
    \ all the components of your flavor: ```terminal flavors/ \u2514\u2500\u2500 my-custom-flavor/\
    \ \u251C\u2500\u2500 kustomize.yaml \u251C\u2500\u2500 config/ \u2502 \u251C\u2500\
    \u2500 app-config.yaml \u2502 \u2514\u2500\u2500 plugins/ \u2502 \u2514\u2500\u2500\
    \ my-plugin.yaml \u251C\u2500\u2500 resources/ \u2502 \u251C\u2500\u2500 dependencies.yaml\
    \ \u2502 \u2514\u2500\u2500 catalog/ \u2502 \u2514\u2500\u2500 entities.yaml \u2514\
    \u2500\u2500 hooks/ \u251C\u2500\u2500 pre-install/ \u2502 \u2514\u2500\u2500\
    \ job.yaml \u2514\u2500\u2500 post-install/ \u2514\u2500\u2500 job.yaml ``` where\
    \ kustomize.yaml:: This is your flavor's manifest file that acts as the central\
    \ definition, orchestrating the application of all other files in the directory.\
    \ config/:: Contains the core app-config.yaml for Red Hat Developer Hub, along\
    \ with any plugin-specific configuration files. resources/:: Holds additional\
    \ Kubernetes resources your flavor needs. This can include CRDs for dependencies\
    \ or initial catalog entities to populate RHDH. hooks/:: Contains manifests for\
    \ Kubernetes jobs that run before (pre-install) or after (post-install) the RHDH\
    \ instance is deployed. 2. (Optional) If your flavor uses dynamic plugins that\
    \ require specific Kubernetes resources, define these resources as YAML manifests\
    \ in your config/profile/{PROFILE}/plugin-deps directory. 3. (Optional) For dependencies\
    \ that require operators or other infrastructure, specify them in the plugin-infra\
    \ directory. 4. (Optional) Write Kubernetes job manifests for any pre-installation\
    \ or post-installation tasks. The Operator will execute these jobs and monitor\
    \ their status. ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:35:08.904238'
    uuid: 6a14a83f-d565-445e-930c-d0236d4f20ca
  response: The RHDH Operator handles the flavor framework by being extended to recognize
    and process the spec.flavor field in the Backstage custom resource (CR). When
    a Backstage CR is applied, the operator checks for the specified flavor and uses
    Kustomize to process the flavor's manifest, applying its configurations, resources,
    and hooks to the cluster. The Operator is also responsible for automatically checking
    for and deploying required infrastructure dependencies for a flavor's plugins.
    Additionally, it manages the lifecycle of pre-installation and post-installation
    hooks by monitoring the Kubernetes jobs they create. For external flavors distributed
    as container images, the Operator pulls the image, extracts the flavor's files,
    and applies them.
  user_input: how rhdh operator use a flavor?
- context:
  - "# Operator flavors for Red Hat Developer Hub # Red Hat Developer Hub Operator\
    \ Flavors ## Flavor framework architecture The flavor framework for the Red Hat\
    \ Developer Hub (RHDH) Operator is an extension of the existing Configuration\
    \ Profiles mechanism. A flavor is a specialized profile that goes beyond simple\
    \ configuration to encompass a complete, opinionated RHDH installation. The architecture\
    \ is designed to be flexible and modular, allowing for the creation of turnkey\
    \ solutions. The core of the framework is its reliance on Kustomize, a tool used\
    \ by the operator to manage and apply Kubernetes manifests. Flavors act as Kustomize\
    \ overlays, which means they can modify and extend a base RHDH deployment with\
    \ specific configurations, resources, and dependencies. A complete flavor is defined\
    \ by a standardized set of directories and files: Flavor Manifest:: A kustomization.yaml\
    \ file that acts as the central definition for the flavor, orchestrating how all\
    \ the other components are applied. Configuration Directory (config/):: Contains\
    \ RHDH application and plugin configuration files. Resources Directory (resources/)::\
    \ Holds additional Kubernetes resources that need to be deployed, such as custom\
    \ resource definitions (CRDs), catalog entities, and templates. Hooks Directory\
    \ (hooks/):: Stores manifests for pre-installation and post-installation tasks,\
    \ which are executed as Kubernetes jobs. ## Flavor framework implementation The\
    \ implementation of the flavor framework is handled by the RHDH Operator itself,\
    \ which is extended to recognize and process the spec.flavor field in the Backstage\
    \ custom resource (CR). The implementation details include: Flavor selection::\
    \ The Backstage CR is extended to include a spec.flavor field, allowing users\
    \ to select a predefined or custom flavor. Operator integration:: When a Backstage\
    \ CR is applied, the operator checks for the specified flavor. It then uses Kustomize\
    \ to process the flavor's manifest and apply its configurations, resources, and\
    \ hooks to the cluster. Dependency management:: The Operator is responsible for\
    \ automatically checking for and deploying any required infrastructure dependencies\
    \ (for example, other operators or CRDs) that a flavor's plugins might need. It\
    \ validates these requirements before applying the flavor's configuration. Hooks\
    \ execution:: The Operator handles the lifecycle of pre-installation and post-installation\
    \ hooks. It monitors the status of the Kubernetes jobs created by these hooks\
    \ and adjusts the deployment process accordingly. Distribution:: Flavors can be\
    \ shipped with the Operator or distributed externally as container images. When\
    \ a user specifies an external flavor image, the Operator pulls the image, extracts\
    \ the files of the flavor, and applies them in the same way as a built-in flavor.\
    \ This container-based approach provides a consistent and secure way to manage\
    \ custom flavors. ## Creating a custom flavor A custom flavor is a new operator\
    \ profile with a specific directory structure. You can create a new flavor by\
    \ following these steps: 1. Create a dedicated directory for your flavor, following\
    \ a standardized structure. This structure helps the operator identify and process\
    \ all the components of your flavor: ```terminal flavors/ \u2514\u2500\u2500 my-custom-flavor/\
    \ \u251C\u2500\u2500 kustomize.yaml \u251C\u2500\u2500 config/ \u2502 \u251C\u2500\
    \u2500 app-config.yaml \u2502 \u2514\u2500\u2500 plugins/ \u2502 \u2514\u2500\u2500\
    \ my-plugin.yaml \u251C\u2500\u2500 resources/ \u2502 \u251C\u2500\u2500 dependencies.yaml\
    \ \u2502 \u2514\u2500\u2500 catalog/ \u2502 \u2514\u2500\u2500 entities.yaml \u2514\
    \u2500\u2500 hooks/ \u251C\u2500\u2500 pre-install/ \u2502 \u2514\u2500\u2500\
    \ job.yaml \u2514\u2500\u2500 post-install/ \u2514\u2500\u2500 job.yaml ``` where\
    \ kustomize.yaml:: This is your flavor's manifest file that acts as the central\
    \ definition, orchestrating the application of all other files in the directory.\
    \ config/:: Contains the core app-config.yaml for Red Hat Developer Hub, along\
    \ with any plugin-specific configuration files. resources/:: Holds additional\
    \ Kubernetes resources your flavor needs. This can include CRDs for dependencies\
    \ or initial catalog entities to populate RHDH. hooks/:: Contains manifests for\
    \ Kubernetes jobs that run before (pre-install) or after (post-install) the RHDH\
    \ instance is deployed. 2. (Optional) If your flavor uses dynamic plugins that\
    \ require specific Kubernetes resources, define these resources as YAML manifests\
    \ in your config/profile/{PROFILE}/plugin-deps directory. 3. (Optional) For dependencies\
    \ that require operators or other infrastructure, specify them in the plugin-infra\
    \ directory. 4. (Optional) Write Kubernetes job manifests for any pre-installation\
    \ or post-installation tasks. The Operator will execute these jobs and monitor\
    \ their status. ##"
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:35:19.937911'
    uuid: db134f42-90e1-41c6-bf0d-308611c7ff85
  response: The flavor framework for the Red Hat Developer Hub (RHDH) Operator has
    a core reliance on Kustomize, which the operator uses to manage and apply Kubernetes
    manifests. Flavors are designed to act as Kustomize overlays, enabling them to
    modify and extend a base RHDH deployment with specific configurations, resources,
    and dependencies. When a Backstage custom resource (CR) is applied with a specified
    flavor, the operator uses Kustomize to process the flavor's manifest (a kustomization.yaml
    file) and apply its configurations, resources, and hooks to the cluster.
  user_input: How does the Red Hat Developer Hub Operator's flavor framework utilize
    Kustomize to manage and apply configurations for a deployment?
- context:
  - "Distributing a custom flavor Custom flavors can be distributed as container images,\
    \ offering a secure and versioned approach. 1. Create a container image that contains\
    \ your flavor's directory structure at a specific location, typically /flavor/.\
    \ The image should be lightweight and contain only the necessary manifests and\
    \ files. ```terminal /flavor/ \u251C\u2500\u2500 flavor.yaml # Flavor manifest\
    \ \u251C\u2500\u2500 config/ \u251C\u2500\u2500 resources/ \u2514\u2500\u2500\
    \ hooks/ ``` 2. When the image is built, push it to a container registry which\
    \ makes the flavor accessible to others, for example: ```terminal podman push\
    \ quay.io/myorg/my custom flavor:1.0.0 ``` 3. Users can deploy your custom flavor\
    \ by referencing the container image directly in their Backstage custom resource.\
    \ The operator pulls the image, extracts the contents, and applies the configuration\
    \ automatically. For example: ```yaml apiVersion: backstage.redhat.com/v1alpha1\
    \ kind: Backstage metadata: name: custom hub spec: flavor: name: my custom flavor\
    \ image: quay.io/myorg/my custom flavor:1.0.0 ``` ## Flavor manifest schema The\
    \ flavor manifest is a kustomization.yaml file that serves as the central definition\
    \ for a flavor. This file is used by the RHDH Operator to orchestrate the deployment\
    \ of all other components. The manifest schema leverages standard Kustomize fields\
    \ and is typically structured as follows: ```yaml apiVersion: kustomize.config.k8s.io/v1beta1\
    \ kind: Kustomization resources: config/ resources/ hooks/ ``` apiVersion and\
    \ kind:: These are standard Kustomize fields that define the schema version and\
    \ type. resources:: This field is a list that points to the directories containing\
    \ the flavor's configuration files, Kubernetes resources, and hooks. The Operator\
    \ uses this list to process and apply all the components within the flavor. ###\
    \ Configuration options A flavor&#8217;s configuration is managed through the\
    \ directories and files referenced in its manifest. The primary configuration\
    \ options are: RHDH application configuration:: The config/app-config.yaml file\
    \ contains the core configuration for the RHDH instance. This can include settings\
    \ for the backend, authentication providers, and other core functionalities. Dynamic\
    \ plugins configuration:: Files located in the config/plugins/ directory define\
    \ the settings for specific dynamic plugins. This includes enabling or disabling\
    \ plugins and configuring their unique properties. Kubernetes resources:: The\
    \ resources/ directory contains standard Kubernetes manifests. This can include:\
    \ * Dependency manifests that define Custom Resource Definitions (CRDs) for external\
    \ services. * Catalog entities which are YAML files for initial catalog entries,\
    \ such as templates, components, and APIs. Hooks:: The hooks/ directory contains\
    \ manifests for Kubernetes jobs. These jobs can be used to perform pre-installation\
    \ or post-installation tasks, such as creating secrets or running data migrations.\
    \ Platform-Specific Overrides:: Flavors can include platform-specific patches.\
    \ Files with a .k8s or .ocp extension for example, app-config.yaml.ocp provide\
    \ overrides for vanilla Kubernetes and OpenShift environments, respectively. The\
    \ operator automatically applies the correct patch based on the cluster's platform."
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:35:29.050877'
    uuid: d3018e72-7ab6-4409-ba1e-edcf71257403
  response: 'Users can deploy a custom flavor by referencing the container image directly
    in their Backstage custom resource. The operator then pulls the image, extracts
    its contents, and applies the configuration automatically. This is configured
    in the custom resource under the `spec.flavor` field, by providing the image location,
    for example: `image: quay.io/myorg/my custom flavor:1.0.0`.'
  user_input: How can users deploy a custom Backstage flavor that has been distributed
    as a container image?
- context:
  - "Distributing a custom flavor Custom flavors can be distributed as container images,\
    \ offering a secure and versioned approach. 1. Create a container image that contains\
    \ your flavor's directory structure at a specific location, typically /flavor/.\
    \ The image should be lightweight and contain only the necessary manifests and\
    \ files. ```terminal /flavor/ \u251C\u2500\u2500 flavor.yaml # Flavor manifest\
    \ \u251C\u2500\u2500 config/ \u251C\u2500\u2500 resources/ \u2514\u2500\u2500\
    \ hooks/ ``` 2. When the image is built, push it to a container registry which\
    \ makes the flavor accessible to others, for example: ```terminal podman push\
    \ quay.io/myorg/my custom flavor:1.0.0 ``` 3. Users can deploy your custom flavor\
    \ by referencing the container image directly in their Backstage custom resource.\
    \ The operator pulls the image, extracts the contents, and applies the configuration\
    \ automatically. For example: ```yaml apiVersion: backstage.redhat.com/v1alpha1\
    \ kind: Backstage metadata: name: custom hub spec: flavor: name: my custom flavor\
    \ image: quay.io/myorg/my custom flavor:1.0.0 ``` ## Flavor manifest schema The\
    \ flavor manifest is a kustomization.yaml file that serves as the central definition\
    \ for a flavor. This file is used by the RHDH Operator to orchestrate the deployment\
    \ of all other components. The manifest schema leverages standard Kustomize fields\
    \ and is typically structured as follows: ```yaml apiVersion: kustomize.config.k8s.io/v1beta1\
    \ kind: Kustomization resources: config/ resources/ hooks/ ``` apiVersion and\
    \ kind:: These are standard Kustomize fields that define the schema version and\
    \ type. resources:: This field is a list that points to the directories containing\
    \ the flavor's configuration files, Kubernetes resources, and hooks. The Operator\
    \ uses this list to process and apply all the components within the flavor. ###\
    \ Configuration options A flavor&#8217;s configuration is managed through the\
    \ directories and files referenced in its manifest. The primary configuration\
    \ options are: RHDH application configuration:: The config/app-config.yaml file\
    \ contains the core configuration for the RHDH instance. This can include settings\
    \ for the backend, authentication providers, and other core functionalities. Dynamic\
    \ plugins configuration:: Files located in the config/plugins/ directory define\
    \ the settings for specific dynamic plugins. This includes enabling or disabling\
    \ plugins and configuring their unique properties. Kubernetes resources:: The\
    \ resources/ directory contains standard Kubernetes manifests. This can include:\
    \ * Dependency manifests that define Custom Resource Definitions (CRDs) for external\
    \ services. * Catalog entities which are YAML files for initial catalog entries,\
    \ such as templates, components, and APIs. Hooks:: The hooks/ directory contains\
    \ manifests for Kubernetes jobs. These jobs can be used to perform pre-installation\
    \ or post-installation tasks, such as creating secrets or running data migrations.\
    \ Platform-Specific Overrides:: Flavors can include platform-specific patches.\
    \ Files with a .k8s or .ocp extension for example, app-config.yaml.ocp provide\
    \ overrides for vanilla Kubernetes and OpenShift environments, respectively. The\
    \ operator automatically applies the correct patch based on the cluster's platform."
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:35:38.092489'
    uuid: 2361cc4b-e25f-44cf-9043-6749f219de5a
  response: The flavor manifest is a kustomization.yaml file that acts as the central
    definition for a flavor. The manifest schema utilizes standard Kustomize fields.
    The `apiVersion` and `kind` fields define the schema version and type. The `resources`
    field is a list that points to directories containing the flavor's configuration
    files, Kubernetes resources, and hooks, which the RHDH Operator uses to process
    and apply all the components within the flavor.
  user_input: how is kustomise used in the flavor manifest?
- context:
  - "Distributing a custom flavor Custom flavors can be distributed as container images,\
    \ offering a secure and versioned approach. 1. Create a container image that contains\
    \ your flavor's directory structure at a specific location, typically /flavor/.\
    \ The image should be lightweight and contain only the necessary manifests and\
    \ files. ```terminal /flavor/ \u251C\u2500\u2500 flavor.yaml # Flavor manifest\
    \ \u251C\u2500\u2500 config/ \u251C\u2500\u2500 resources/ \u2514\u2500\u2500\
    \ hooks/ ``` 2. When the image is built, push it to a container registry which\
    \ makes the flavor accessible to others, for example: ```terminal podman push\
    \ quay.io/myorg/my custom flavor:1.0.0 ``` 3. Users can deploy your custom flavor\
    \ by referencing the container image directly in their Backstage custom resource.\
    \ The operator pulls the image, extracts the contents, and applies the configuration\
    \ automatically. For example: ```yaml apiVersion: backstage.redhat.com/v1alpha1\
    \ kind: Backstage metadata: name: custom hub spec: flavor: name: my custom flavor\
    \ image: quay.io/myorg/my custom flavor:1.0.0 ``` ## Flavor manifest schema The\
    \ flavor manifest is a kustomization.yaml file that serves as the central definition\
    \ for a flavor. This file is used by the RHDH Operator to orchestrate the deployment\
    \ of all other components. The manifest schema leverages standard Kustomize fields\
    \ and is typically structured as follows: ```yaml apiVersion: kustomize.config.k8s.io/v1beta1\
    \ kind: Kustomization resources: config/ resources/ hooks/ ``` apiVersion and\
    \ kind:: These are standard Kustomize fields that define the schema version and\
    \ type. resources:: This field is a list that points to the directories containing\
    \ the flavor's configuration files, Kubernetes resources, and hooks. The Operator\
    \ uses this list to process and apply all the components within the flavor. ###\
    \ Configuration options A flavor&#8217;s configuration is managed through the\
    \ directories and files referenced in its manifest. The primary configuration\
    \ options are: RHDH application configuration:: The config/app-config.yaml file\
    \ contains the core configuration for the RHDH instance. This can include settings\
    \ for the backend, authentication providers, and other core functionalities. Dynamic\
    \ plugins configuration:: Files located in the config/plugins/ directory define\
    \ the settings for specific dynamic plugins. This includes enabling or disabling\
    \ plugins and configuring their unique properties. Kubernetes resources:: The\
    \ resources/ directory contains standard Kubernetes manifests. This can include:\
    \ * Dependency manifests that define Custom Resource Definitions (CRDs) for external\
    \ services. * Catalog entities which are YAML files for initial catalog entries,\
    \ such as templates, components, and APIs. Hooks:: The hooks/ directory contains\
    \ manifests for Kubernetes jobs. These jobs can be used to perform pre-installation\
    \ or post-installation tasks, such as creating secrets or running data migrations.\
    \ Platform-Specific Overrides:: Flavors can include platform-specific patches.\
    \ Files with a .k8s or .ocp extension for example, app-config.yaml.ocp provide\
    \ overrides for vanilla Kubernetes and OpenShift environments, respectively. The\
    \ operator automatically applies the correct patch based on the cluster's platform."
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:35:45.049327'
    uuid: ede6d435-3667-468c-851f-63d39a86d47c
  response: Flavors can include platform-specific patches. Files with a .ocp extension,
    such as app-config.yaml.ocp, provide overrides for OpenShift environments. The
    operator is responsible for automatically applying the correct patch based on
    the cluster's platform.
  user_input: How do the flavors handle platform-specific stuff for OpenShift, like
    what file do i need to make for them overrides?
- context:
  - '# Orchestrator in Red Hat Developer Hub # About Orchestrator in Red Hat Developer
    Hub You can streamline and automate your work by using the Orchestrator in Red
    Hat Developer Hub. It enables you to: Design, run, and monitor workflows to simplify
    multi step processes across applications and services. Standardize onboarding,
    migration, and integration workflows to reduce manual effort and improve consistency.
    Extend RHDH with enterprise grade Orchestration features to support collaboration
    and scalability. [NOTE] ---- Orchestrator currently supports only Red Hat OpenShift
    Container Platform (OpenShift Container Platform); it is not available on Microsoft
    Azure Kubernetes Service (AKS), Amazon Elastic Kubernetes Service (EKS), or Google
    Kubernetes Engine (GKE). ---- To start using Orchestrator in RHDH, you must: Install
    the required infrastructure components, such as Red Hat OpenShift Serverless Operator,
    Knative Serving, Knative Eventing, and OpenShift Serverless Logic Operator Configure
    your Backstage custom resource (CR) or Helm values file for Orchestrator ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:35:55.936228'
    uuid: 6aa18fbc-e894-40a9-a1f3-1f129ef9ac8a
  response: Orchestrator is not available on Amazon Elastic Kubernetes Service (EKS).
    It currently supports only Red Hat OpenShift Container Platform.
  user_input: Does the Orchestrator in Red Hat Develper Hub have suport for our Amazon
    Elastic Kubernetes Service clusters?
- context:
  - '# Orchestrator in Red Hat Developer Hub # About Orchestrator in Red Hat Developer
    Hub You can streamline and automate your work by using the Orchestrator in Red
    Hat Developer Hub. It enables you to: Design, run, and monitor workflows to simplify
    multi step processes across applications and services. Standardize onboarding,
    migration, and integration workflows to reduce manual effort and improve consistency.
    Extend RHDH with enterprise grade Orchestration features to support collaboration
    and scalability. [NOTE] ---- Orchestrator currently supports only Red Hat OpenShift
    Container Platform (OpenShift Container Platform); it is not available on Microsoft
    Azure Kubernetes Service (AKS), Amazon Elastic Kubernetes Service (EKS), or Google
    Kubernetes Engine (GKE). ---- To start using Orchestrator in RHDH, you must: Install
    the required infrastructure components, such as Red Hat OpenShift Serverless Operator,
    Knative Serving, Knative Eventing, and OpenShift Serverless Logic Operator Configure
    your Backstage custom resource (CR) or Helm values file for Orchestrator ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:36:04.864281'
    uuid: 36c4377f-5ead-4644-94cf-7ba43a7e5c7a
  response: To start using the Orchestrator in Red Hat Developer Hub, you must install
    the required infrastructure components, and Knative Eventing is listed as one
    of these components, alongside Red Hat OpenShift Serverless Operator, Knative
    Serving, and OpenShift Serverless Logic Operator.
  user_input: I'm trying to get the Orchestrator in Red Hat Developer Hub setup, and
    the docs mention we need to install several infrastructre components. Can someone
    explain why Knative Eventing is listed as a required component we must install
    to start using the Orchestrator?
- context:
  - '# Orchestrator in Red Hat Developer Hub # About Orchestrator in Red Hat Developer
    Hub You can streamline and automate your work by using the Orchestrator in Red
    Hat Developer Hub. It enables you to: Design, run, and monitor workflows to simplify
    multi step processes across applications and services. Standardize onboarding,
    migration, and integration workflows to reduce manual effort and improve consistency.
    Extend RHDH with enterprise grade Orchestration features to support collaboration
    and scalability. [NOTE] ---- Orchestrator currently supports only Red Hat OpenShift
    Container Platform (OpenShift Container Platform); it is not available on Microsoft
    Azure Kubernetes Service (AKS), Amazon Elastic Kubernetes Service (EKS), or Google
    Kubernetes Engine (GKE). ---- To start using Orchestrator in RHDH, you must: Install
    the required infrastructure components, such as Red Hat OpenShift Serverless Operator,
    Knative Serving, Knative Eventing, and OpenShift Serverless Logic Operator Configure
    your Backstage custom resource (CR) or Helm values file for Orchestrator ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:36:15.572341'
    uuid: c2f4c5d8-8a32-489e-a060-47108b90e983
  response: The Orchestrator in Red Hat Developer Hub enables you to design, run,
    and monitor workflows to simplify multi-step processes across applications and
    services. It also allows you to standardize onboarding, migration, and integration
    workflows to reduce manual effort and improve consistency, and extend RHDH with
    enterprise-grade Orchestration features to support collaboration and scalability.
  user_input: Red Hat Developer Hub Orchestrator features
- context:
  - 'Understand Orchestrator architecture The Orchestrator architecture is composed
    of several components, each contributing to the running and management of workflows.
    Red Hat Developer Hub (RHDH):: Serves as the primary interface. It contains the
    following subcomponents: Orchestrator frontend plugins:: Provide the interface
    for users to run and monitor workflows within RHDH. Orchestrator backend plugins::
    Get workflow data into Developer Hub. Notifications plugins:: Inform users about
    workflow events. Sonataflow:: The Sonataflow orchestrator and its subcomponents
    handle the workflows. The Red Hat Developer Hub Orchestrator and the Red Hat Developer
    Hub Helm chart manage the following subcomponents lifecycle: OpenShift Serverless
    Logic Operator:: Manages the Sonataflow custom resource (CR), where each CR represents
    a deployed workflow. Sonataflow Runtime/Workflow Application:: Functions as a
    deployed workflow. Operates as an HTTP server, handling requests for running workflow
    instances. It is managed as a Kubernetes (K8s) deployment by the Openshift Serverless
    Logic Operator. Data Index Service:: Serves as a repository for workflow definitions,
    instances, and associated jobs. It exposes a GraphQL API used by the Orchestrator
    backend plugin to retrieve workflow definitions and instances. Job Service:: Orchestrates
    scheduled tasks for workflows. OpenShift Serverless:: Provides serverless capabilities
    essential for workflow communication. It employs Knative eventing to interface
    with the Data Index service and uses Knative functions to introduce more complex
    logic to workflows. PostgreSQL Server:: Provides a database solution essential
    for data persistence within the Orchestrator ecosystem. The system uses PostgreSQL
    Server for storing both Sonataflow information and Developer Hub data. OpenShift
    AMQ Streams (Strimzi/Kafka):: Provides enhanced reliability of the eventing system.
    Eventing can work without Kafka by using direct HTTP calls, however, this approach
    is not reliable. Optional: The current deployment iteration does not natively
    integrate or include the AMQ Streams Operator. However, you can add the Operator
    post-install for enhanced reliability if you require it. ## Compatibility guide
    for Orchestrator The following table lists the RHDH Orchestrator plugin versions
    and their compatible corresponding infrastructure versions. [NOTE] ---- Orchestrator
    plugin supports the same OpenShift Container Platform versions as RHDH. See the
    Life Cycle page. ---- ## Orchestrator plugin dependencies for Operator installation
    When you enable the Orchestrator plugin in your Backstage custom resource (CR),
    the Operator automatically provisions the following required dependencies: A SonataflowPlatform
    CR NetworkPolicies that allow traffic between infrastructure resources (Knative,
    Serverless Logic Operator), monitoring traffic, and intra namespace traffic The
    Orchestrator plugin requires these components to run. For example, to communicate
    with the SonataFlow platform, the Orchestrator plugin uses the sonataflow-platform-data-index-service,
    which is created by the SonataFlowPlatform CR. [IMPORTANT] ---- The SonataFlowPlatform
    CR contains Data Index service that requires PostgreSQL database as shown in the
    following example: ```yaml persistence: postgresql: secretRef: name: backstage-psql-secret-{{backstage-name}}
    userKey: POSTGRES_USER passwordKey: POSTGRES_PASSWORD serviceRef: name: backstage-psql-{{backstage-name}}
    # # Namespace where the Backstage CR is created namespace: {{backstage-ns}} #
    Namespace where the Backstage (CR) is created databaseName: backstage_plugin_orchestrator
    ``` ---- By default, the Orchestrator plugin dependencies use the following: The
    PostgreSQL database named backstage_plugin_orchestrator created by Backstage A
    Secret created by Backstage Operator for the PostgreSQL with POSTGRES_USER and
    POSTGRES_PASSWORD keys as the database credentials in the Backstage CR namespace.
    A Service created by Backstage Operator for the PostgreSQL database with the name
    backstage psql {{backstage name}} in the Backstage CR namespace. [NOTE] ---- To
    enable the Backstage Operator to work with the SonataFlow platform, its ServiceAccount
    must have the appropriate permissions. The Operator automatically creates the
    required Role and RoleBinding resource in profile/rhdh/plugin-rbac directory.
    ---- Dynamic plugins dependency management ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:36:26.998784'
    uuid: 3fee6346-7d54-4b54-8836-a1d6a4522000
  response: Within the Orchestrator architecture, OpenShift AMQ Streams (Strimzi/Kafka)
    provides enhanced reliability for the eventing system. While the eventing system
    can function without Kafka by using direct HTTP calls, that approach is not reliable.
    The AMQ Streams Operator is an optional component that is not natively integrated
    in the current deployment, but it can be added post-install to achieve this enhanced
    reliability.
  user_input: According to the Orchestrator architecture documentation, what is the
    specific function of OpenShift AMQ Streams (Kafka) and how does it impact the
    system's reliability?
- context:
  - 'Understand Orchestrator architecture The Orchestrator architecture is composed
    of several components, each contributing to the running and management of workflows.
    Red Hat Developer Hub (RHDH):: Serves as the primary interface. It contains the
    following subcomponents: Orchestrator frontend plugins:: Provide the interface
    for users to run and monitor workflows within RHDH. Orchestrator backend plugins::
    Get workflow data into Developer Hub. Notifications plugins:: Inform users about
    workflow events. Sonataflow:: The Sonataflow orchestrator and its subcomponents
    handle the workflows. The Red Hat Developer Hub Orchestrator and the Red Hat Developer
    Hub Helm chart manage the following subcomponents lifecycle: OpenShift Serverless
    Logic Operator:: Manages the Sonataflow custom resource (CR), where each CR represents
    a deployed workflow. Sonataflow Runtime/Workflow Application:: Functions as a
    deployed workflow. Operates as an HTTP server, handling requests for running workflow
    instances. It is managed as a Kubernetes (K8s) deployment by the Openshift Serverless
    Logic Operator. Data Index Service:: Serves as a repository for workflow definitions,
    instances, and associated jobs. It exposes a GraphQL API used by the Orchestrator
    backend plugin to retrieve workflow definitions and instances. Job Service:: Orchestrates
    scheduled tasks for workflows. OpenShift Serverless:: Provides serverless capabilities
    essential for workflow communication. It employs Knative eventing to interface
    with the Data Index service and uses Knative functions to introduce more complex
    logic to workflows. PostgreSQL Server:: Provides a database solution essential
    for data persistence within the Orchestrator ecosystem. The system uses PostgreSQL
    Server for storing both Sonataflow information and Developer Hub data. OpenShift
    AMQ Streams (Strimzi/Kafka):: Provides enhanced reliability of the eventing system.
    Eventing can work without Kafka by using direct HTTP calls, however, this approach
    is not reliable. Optional: The current deployment iteration does not natively
    integrate or include the AMQ Streams Operator. However, you can add the Operator
    post-install for enhanced reliability if you require it. ## Compatibility guide
    for Orchestrator The following table lists the RHDH Orchestrator plugin versions
    and their compatible corresponding infrastructure versions. [NOTE] ---- Orchestrator
    plugin supports the same OpenShift Container Platform versions as RHDH. See the
    Life Cycle page. ---- ## Orchestrator plugin dependencies for Operator installation
    When you enable the Orchestrator plugin in your Backstage custom resource (CR),
    the Operator automatically provisions the following required dependencies: A SonataflowPlatform
    CR NetworkPolicies that allow traffic between infrastructure resources (Knative,
    Serverless Logic Operator), monitoring traffic, and intra namespace traffic The
    Orchestrator plugin requires these components to run. For example, to communicate
    with the SonataFlow platform, the Orchestrator plugin uses the sonataflow-platform-data-index-service,
    which is created by the SonataFlowPlatform CR. [IMPORTANT] ---- The SonataFlowPlatform
    CR contains Data Index service that requires PostgreSQL database as shown in the
    following example: ```yaml persistence: postgresql: secretRef: name: backstage-psql-secret-{{backstage-name}}
    userKey: POSTGRES_USER passwordKey: POSTGRES_PASSWORD serviceRef: name: backstage-psql-{{backstage-name}}
    # # Namespace where the Backstage CR is created namespace: {{backstage-ns}} #
    Namespace where the Backstage (CR) is created databaseName: backstage_plugin_orchestrator
    ``` ---- By default, the Orchestrator plugin dependencies use the following: The
    PostgreSQL database named backstage_plugin_orchestrator created by Backstage A
    Secret created by Backstage Operator for the PostgreSQL with POSTGRES_USER and
    POSTGRES_PASSWORD keys as the database credentials in the Backstage CR namespace.
    A Service created by Backstage Operator for the PostgreSQL database with the name
    backstage psql {{backstage name}} in the Backstage CR namespace. [NOTE] ---- To
    enable the Backstage Operator to work with the SonataFlow platform, its ServiceAccount
    must have the appropriate permissions. The Operator automatically creates the
    required Role and RoleBinding resource in profile/rhdh/plugin-rbac directory.
    ---- Dynamic plugins dependency management ##'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:36:38.968746'
    uuid: 9b7c1d2c-f65f-4d2f-9add-64e09c567802
  response: OpenShift Serverless provides serverless capabilities that are essential
    for workflow communication. It employs Knative eventing to interface with the
    Data Index service and also uses Knative functions to introduce more complex logic
    to workflows.
  user_input: My team is asking about the orchestrator setup and i dont get it, what
    is the point of OpenShift Serverless and how it is using knative for the eventing
    to talk to data index service, is it really essential for the workflow communication?
- context:
  - 'Understand Orchestrator architecture The Orchestrator architecture is composed
    of several components, each contributing to the running and management of workflows.
    Red Hat Developer Hub (RHDH):: Serves as the primary interface. It contains the
    following subcomponents: Orchestrator frontend plugins:: Provide the interface
    for users to run and monitor workflows within RHDH. Orchestrator backend plugins::
    Get workflow data into Developer Hub. Notifications plugins:: Inform users about
    workflow events. Sonataflow:: The Sonataflow orchestrator and its subcomponents
    handle the workflows. The Red Hat Developer Hub Orchestrator and the Red Hat Developer
    Hub Helm chart manage the following subcomponents lifecycle: OpenShift Serverless
    Logic Operator:: Manages the Sonataflow custom resource (CR), where each CR represents
    a deployed workflow. Sonataflow Runtime/Workflow Application:: Functions as a
    deployed workflow. Operates as an HTTP server, handling requests for running workflow
    instances. It is managed as a Kubernetes (K8s) deployment by the Openshift Serverless
    Logic Operator. Data Index Service:: Serves as a repository for workflow definitions,
    instances, and associated jobs. It exposes a GraphQL API used by the Orchestrator
    backend plugin to retrieve workflow definitions and instances. Job Service:: Orchestrates
    scheduled tasks for workflows. OpenShift Serverless:: Provides serverless capabilities
    essential for workflow communication. It employs Knative eventing to interface
    with the Data Index service and uses Knative functions to introduce more complex
    logic to workflows. PostgreSQL Server:: Provides a database solution essential
    for data persistence within the Orchestrator ecosystem. The system uses PostgreSQL
    Server for storing both Sonataflow information and Developer Hub data. OpenShift
    AMQ Streams (Strimzi/Kafka):: Provides enhanced reliability of the eventing system.
    Eventing can work without Kafka by using direct HTTP calls, however, this approach
    is not reliable. Optional: The current deployment iteration does not natively
    integrate or include the AMQ Streams Operator. However, you can add the Operator
    post-install for enhanced reliability if you require it. ## Compatibility guide
    for Orchestrator The following table lists the RHDH Orchestrator plugin versions
    and their compatible corresponding infrastructure versions. [NOTE] ---- Orchestrator
    plugin supports the same OpenShift Container Platform versions as RHDH. See the
    Life Cycle page. ---- ## Orchestrator plugin dependencies for Operator installation
    When you enable the Orchestrator plugin in your Backstage custom resource (CR),
    the Operator automatically provisions the following required dependencies: A SonataflowPlatform
    CR NetworkPolicies that allow traffic between infrastructure resources (Knative,
    Serverless Logic Operator), monitoring traffic, and intra namespace traffic The
    Orchestrator plugin requires these components to run. For example, to communicate
    with the SonataFlow platform, the Orchestrator plugin uses the sonataflow-platform-data-index-service,
    which is created by the SonataFlowPlatform CR. [IMPORTANT] ---- The SonataFlowPlatform
    CR contains Data Index service that requires PostgreSQL database as shown in the
    following example: ```yaml persistence: postgresql: secretRef: name: backstage-psql-secret-{{backstage-name}}
    userKey: POSTGRES_USER passwordKey: POSTGRES_PASSWORD serviceRef: name: backstage-psql-{{backstage-name}}
    # # Namespace where the Backstage CR is created namespace: {{backstage-ns}} #
    Namespace where the Backstage (CR) is created databaseName: backstage_plugin_orchestrator
    ``` ---- By default, the Orchestrator plugin dependencies use the following: The
    PostgreSQL database named backstage_plugin_orchestrator created by Backstage A
    Secret created by Backstage Operator for the PostgreSQL with POSTGRES_USER and
    POSTGRES_PASSWORD keys as the database credentials in the Backstage CR namespace.
    A Service created by Backstage Operator for the PostgreSQL database with the name
    backstage psql {{backstage name}} in the Backstage CR namespace. [NOTE] ---- To
    enable the Backstage Operator to work with the SonataFlow platform, its ServiceAccount
    must have the appropriate permissions. The Operator automatically creates the
    required Role and RoleBinding resource in profile/rhdh/plugin-rbac directory.
    ---- Dynamic plugins dependency management ##'
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:36:50.399062'
    uuid: e63b822d-5434-4a7b-8187-bd810ab14e54
  response: As part of the OpenShift Serverless component, Knative provides essential
    serverless capabilities for workflow communication. Specifically, it employs Knative
    eventing to interface with the Data Index service and uses Knative functions to
    introduce more complex logic to workflows.
  user_input: Within the Orchestrator architecture, what specific functions does Knative
    perform as part of the OpenShift Serverless component to support workflows?
- context:
  - 'Enabling Orchestrator plugins components To use the Orchestrator, enable the
    Orchestrator plugins for Red Hat Developer Hub, that are disabled by default:
    Orchestrator frontend plugins:: backstage-plugin-orchestrator:: Provides the interface
    for users to run and monitor workflows within RHDH. You can run and track the
    execution status of processes. backstage-plugin-orchestrator-form-widgets:: Provides
    custom widgets for the workflow execution form, allowing you to customize input
    fields and streamline the process of launching workflows. backstage-plugin-orchestrator-form::
    Provides the workflow execution form where you can define and submit the necessary
    input data required to start a new workflow instance. backstage-plugin-orchestrator-form-api::
    Defines the API for extending the workflow execution form. Orchestrator backend
    plugins:: backstage-plugin-orchestrator-backend:: Gets workflow data into Developer
    Hub making sure RHDH ingests critical workflow metadata and runtime status fulfilling
    your need for visibility. backstage-plugin-orchestrator-common:: Contains the
    backend OpenAPI specification along with autogenerated API documentation and client
    libraries. scaffolder-backend-module-orchestrator:: Provides callable actions
    from scaffolder templates, such as orchestrator:workflow:run or orchestrator:workflow:get_params.
    Notification plugins:: backstage-plugin-notifications:: Provides notification
    frontend components that allow you to display immediate, visible alerts about
    key workflow state changes, allowing real-time status tracking. backstage-plugin-signals::
    Provides notification frontend components user experience enhancements so you
    can process the real-time lifecycle events. backstage-plugin-notifications-backend-dynamic::
    Provides notification backend components allowing you to manage and store the
    stream of workflow events, making sure that critical notifications are ready to
    be served to the front-end user interface. backstage-plugin-signals-backend-dynamic::
    Provides the backend components for notification user experience enhancements
    allowing you to establish the necessary communication channels for the event-driven
    orchestration that is core to Serverless Workflows. You have installed the following
    operators: Openshift Serverless Openshift Serverless Logic (OSL) (Optional) For
    managing the Orchestrator project, you have an instance of Argo CD or Red Hat
    OpenShift GitOps in the cluster. It is disabled by default. (Optional) To use
    Tekton tasks and the build pipeline, you have an instance of Tekton or Red Hat
    OpenShift Pipelines in the cluster. These features are disabled by default. Locate
    your Developer Hub configuration and enable the Orchestrator plugins and the supporting
    notification plugins. ```yaml plugins: package: "@redhat/backstage plugin orchestrator@1.8.0"
    disabled: false package: "@redhat/backstage plugin orchestrator backend dynamic@1.8.0"
    disabled: false package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    common@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator form
    api@1.8.0" disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" disabled: false ``` ### Installing components using the Orchestrator
    Infrastructure for Red Hat Developer Hub Helm chart You can use Orchestrator Infrastructure
    for Red Hat Developer Hub to install components for the Orchestrator plugins.
    1. Run the helm install command for the orchestrator-infra chart. This command
    initiates the installation of the Red Hat Serverless Operator and Red Hat Serverless
    Logic Operator components. ```terminal helm install <release_name> redhat developer/redhat
    developer hub orchestrator infra ``` [NOTE] ---- You must complete this one-off
    requirement before enabling the Orchestrator plugin. ---- 2. Manually approve
    the install plans for the Operators. You must run the oc patch installplan commands
    provided in the output to approve their installation. [IMPORTANT] ---- By default,
    Orchestrator Infrastructure for Red Hat Developer Hub Helm chart does not auto-approve
    the required Serverless Operators. You must manually approve the install plans.
    ---- ### Installing Orchestrator components manually on OpenShift Container Platform
    Use manual installation when you want full control of the setup process and component
    versions. Manual installation method focuses on setting up the underlying infrastructure.
    1. Install the OpenShift Serverless components manually by following the instructions
    in the Red Hat OpenShift Serverless documentation. 2. (Optional) If required,
    deploy a custom PostgreSQL database. [IMPORTANT] ---- Prevent workflow context
    from being lost when the Pod restarts by configuring workflow persistence. You
    can configure persistence at the namespace level by using the SonataFlowPlatform
    or SonataFlow custom resources (CR). For more information, check the Managing
    workflow persistence documentation. ---- ### Installing components using the RHDH
    helper script You can use the RHDH helper script plugin-infra.sh to quickly install
    the OpenShift Serverless infrastructure and Openshift Serverless Logic infrastructure
    required by the Orchestrator plugin. [WARNING] --- Do not use plugin infra.sh
    in production. ---- 1. Download the plugin-infra.sh script as shown in the following
    example: ```terminal curl -sSLO https://raw.githubusercontent.com/redhat-developer/rhdh-operator/refs/heads/release-${PRODUCT_VERSION}/config/profile/rhdh/plugin-infra/plugin-infra.sh
    # Specify the Red Hat Developer Hub version in the URL or use main ``` 2. Run
    the script: ```terminal $ ./plugin infra.sh ``` ##'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:36:59.070628'
    uuid: e29af860-ee62-4b44-8608-b017cd20424e
  response: To use the Orchestrator Infrastructure for Red Hat Developer Hub Helm
    chart, you must first run the `helm install <release_name> redhat developer/redhat
    developer hub orchestrator infra` command, which starts the installation of the
    Red Hat Serverless Operator and Red Hat Serverless Logic Operator components.
    Following this, you must manually approve the install plans for these operators.
    The Helm chart does not auto-approve them, so you are required to run the `oc
    patch installplan` commands that are provided in the output to approve their installation.
  user_input: What are the specific steps for using the Orchestrator Infrastructure
    for Red Hat Developer Hub Helm chart to install the required components, and are
    there any manual actions needed after the initial command?
- context:
  - 'Enabling Orchestrator plugins components To use the Orchestrator, enable the
    Orchestrator plugins for Red Hat Developer Hub, that are disabled by default:
    Orchestrator frontend plugins:: backstage-plugin-orchestrator:: Provides the interface
    for users to run and monitor workflows within RHDH. You can run and track the
    execution status of processes. backstage-plugin-orchestrator-form-widgets:: Provides
    custom widgets for the workflow execution form, allowing you to customize input
    fields and streamline the process of launching workflows. backstage-plugin-orchestrator-form::
    Provides the workflow execution form where you can define and submit the necessary
    input data required to start a new workflow instance. backstage-plugin-orchestrator-form-api::
    Defines the API for extending the workflow execution form. Orchestrator backend
    plugins:: backstage-plugin-orchestrator-backend:: Gets workflow data into Developer
    Hub making sure RHDH ingests critical workflow metadata and runtime status fulfilling
    your need for visibility. backstage-plugin-orchestrator-common:: Contains the
    backend OpenAPI specification along with autogenerated API documentation and client
    libraries. scaffolder-backend-module-orchestrator:: Provides callable actions
    from scaffolder templates, such as orchestrator:workflow:run or orchestrator:workflow:get_params.
    Notification plugins:: backstage-plugin-notifications:: Provides notification
    frontend components that allow you to display immediate, visible alerts about
    key workflow state changes, allowing real-time status tracking. backstage-plugin-signals::
    Provides notification frontend components user experience enhancements so you
    can process the real-time lifecycle events. backstage-plugin-notifications-backend-dynamic::
    Provides notification backend components allowing you to manage and store the
    stream of workflow events, making sure that critical notifications are ready to
    be served to the front-end user interface. backstage-plugin-signals-backend-dynamic::
    Provides the backend components for notification user experience enhancements
    allowing you to establish the necessary communication channels for the event-driven
    orchestration that is core to Serverless Workflows. You have installed the following
    operators: Openshift Serverless Openshift Serverless Logic (OSL) (Optional) For
    managing the Orchestrator project, you have an instance of Argo CD or Red Hat
    OpenShift GitOps in the cluster. It is disabled by default. (Optional) To use
    Tekton tasks and the build pipeline, you have an instance of Tekton or Red Hat
    OpenShift Pipelines in the cluster. These features are disabled by default. Locate
    your Developer Hub configuration and enable the Orchestrator plugins and the supporting
    notification plugins. ```yaml plugins: package: "@redhat/backstage plugin orchestrator@1.8.0"
    disabled: false package: "@redhat/backstage plugin orchestrator backend dynamic@1.8.0"
    disabled: false package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    common@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator form
    api@1.8.0" disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" disabled: false ``` ### Installing components using the Orchestrator
    Infrastructure for Red Hat Developer Hub Helm chart You can use Orchestrator Infrastructure
    for Red Hat Developer Hub to install components for the Orchestrator plugins.
    1. Run the helm install command for the orchestrator-infra chart. This command
    initiates the installation of the Red Hat Serverless Operator and Red Hat Serverless
    Logic Operator components. ```terminal helm install <release_name> redhat developer/redhat
    developer hub orchestrator infra ``` [NOTE] ---- You must complete this one-off
    requirement before enabling the Orchestrator plugin. ---- 2. Manually approve
    the install plans for the Operators. You must run the oc patch installplan commands
    provided in the output to approve their installation. [IMPORTANT] ---- By default,
    Orchestrator Infrastructure for Red Hat Developer Hub Helm chart does not auto-approve
    the required Serverless Operators. You must manually approve the install plans.
    ---- ### Installing Orchestrator components manually on OpenShift Container Platform
    Use manual installation when you want full control of the setup process and component
    versions. Manual installation method focuses on setting up the underlying infrastructure.
    1. Install the OpenShift Serverless components manually by following the instructions
    in the Red Hat OpenShift Serverless documentation. 2. (Optional) If required,
    deploy a custom PostgreSQL database. [IMPORTANT] ---- Prevent workflow context
    from being lost when the Pod restarts by configuring workflow persistence. You
    can configure persistence at the namespace level by using the SonataFlowPlatform
    or SonataFlow custom resources (CR). For more information, check the Managing
    workflow persistence documentation. ---- ### Installing components using the RHDH
    helper script You can use the RHDH helper script plugin-infra.sh to quickly install
    the OpenShift Serverless infrastructure and Openshift Serverless Logic infrastructure
    required by the Orchestrator plugin. [WARNING] --- Do not use plugin infra.sh
    in production. ---- 1. Download the plugin-infra.sh script as shown in the following
    example: ```terminal curl -sSLO https://raw.githubusercontent.com/redhat-developer/rhdh-operator/refs/heads/release-${PRODUCT_VERSION}/config/profile/rhdh/plugin-infra/plugin-infra.sh
    # Specify the Red Hat Developer Hub version in the URL or use main ``` 2. Run
    the script: ```terminal $ ./plugin infra.sh ``` ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:37:07.793654'
    uuid: ab2bf8cf-cfda-4706-9598-97f17ae5b948
  response: "To use the Orchestrator, you must enable several plugins that are disabled\
    \ by default. These are categorized as Orchestrator frontend plugins, Orchestrator\
    \ backend plugins, and Notification plugins. \n\n**Orchestrator frontend plugins**:\n\
    * **backstage-plugin-orchestrator**: Provides the user interface to run and monitor\
    \ workflows within RHDH.\n* **backstage-plugin-orchestrator-form-widgets**: Offers\
    \ custom widgets to customize input fields for the workflow execution form.\n\
    * **backstage-plugin-orchestrator-form**: Provides the form where users define\
    \ and submit the input data needed to start a workflow.\n* **backstage-plugin-orchestrator-form-api**:\
    \ Defines the API for extending the workflow execution form.\n\n**Orchestrator\
    \ backend plugins**:\n* **backstage-plugin-orchestrator-backend**: Ingests workflow\
    \ metadata and runtime status into Developer Hub for visibility.\n* **backstage-plugin-orchestrator-common**:\
    \ Contains the backend OpenAPI specification, API documentation, and client libraries.\n\
    * **scaffolder-backend-module-orchestrator**: Provides callable actions from scaffolder\
    \ templates, like `orchestrator:workflow:run`.\n\n**Notification plugins**:\n\
    * **backstage-plugin-notifications**: Provides frontend components to display\
    \ visible alerts about workflow state changes.\n* **backstage-plugin-signals**:\
    \ Provides frontend components for user experience enhancements to process real-time\
    \ lifecycle events.\n* **backstage-plugin-notifications-backend-dynamic**: Provides\
    \ backend components to manage and store workflow events for the user interface.\n\
    * **backstage-plugin-signals-backend-dynamic**: Provides backend components that\
    \ establish communication channels for event-driven orchestration."
  user_input: What are the different Orchestrator plugins and components for Red Hat
    Developer Hub?
- context:
  - 'Enabling Orchestrator plugins components To use the Orchestrator, enable the
    Orchestrator plugins for Red Hat Developer Hub, that are disabled by default:
    Orchestrator frontend plugins:: backstage-plugin-orchestrator:: Provides the interface
    for users to run and monitor workflows within RHDH. You can run and track the
    execution status of processes. backstage-plugin-orchestrator-form-widgets:: Provides
    custom widgets for the workflow execution form, allowing you to customize input
    fields and streamline the process of launching workflows. backstage-plugin-orchestrator-form::
    Provides the workflow execution form where you can define and submit the necessary
    input data required to start a new workflow instance. backstage-plugin-orchestrator-form-api::
    Defines the API for extending the workflow execution form. Orchestrator backend
    plugins:: backstage-plugin-orchestrator-backend:: Gets workflow data into Developer
    Hub making sure RHDH ingests critical workflow metadata and runtime status fulfilling
    your need for visibility. backstage-plugin-orchestrator-common:: Contains the
    backend OpenAPI specification along with autogenerated API documentation and client
    libraries. scaffolder-backend-module-orchestrator:: Provides callable actions
    from scaffolder templates, such as orchestrator:workflow:run or orchestrator:workflow:get_params.
    Notification plugins:: backstage-plugin-notifications:: Provides notification
    frontend components that allow you to display immediate, visible alerts about
    key workflow state changes, allowing real-time status tracking. backstage-plugin-signals::
    Provides notification frontend components user experience enhancements so you
    can process the real-time lifecycle events. backstage-plugin-notifications-backend-dynamic::
    Provides notification backend components allowing you to manage and store the
    stream of workflow events, making sure that critical notifications are ready to
    be served to the front-end user interface. backstage-plugin-signals-backend-dynamic::
    Provides the backend components for notification user experience enhancements
    allowing you to establish the necessary communication channels for the event-driven
    orchestration that is core to Serverless Workflows. You have installed the following
    operators: Openshift Serverless Openshift Serverless Logic (OSL) (Optional) For
    managing the Orchestrator project, you have an instance of Argo CD or Red Hat
    OpenShift GitOps in the cluster. It is disabled by default. (Optional) To use
    Tekton tasks and the build pipeline, you have an instance of Tekton or Red Hat
    OpenShift Pipelines in the cluster. These features are disabled by default. Locate
    your Developer Hub configuration and enable the Orchestrator plugins and the supporting
    notification plugins. ```yaml plugins: package: "@redhat/backstage plugin orchestrator@1.8.0"
    disabled: false package: "@redhat/backstage plugin orchestrator backend dynamic@1.8.0"
    disabled: false package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    common@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator
    form@1.8.0" disabled: false package: "@redhat/backstage plugin orchestrator form
    api@1.8.0" disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" disabled: false ``` ### Installing components using the Orchestrator
    Infrastructure for Red Hat Developer Hub Helm chart You can use Orchestrator Infrastructure
    for Red Hat Developer Hub to install components for the Orchestrator plugins.
    1. Run the helm install command for the orchestrator-infra chart. This command
    initiates the installation of the Red Hat Serverless Operator and Red Hat Serverless
    Logic Operator components. ```terminal helm install <release_name> redhat developer/redhat
    developer hub orchestrator infra ``` [NOTE] ---- You must complete this one-off
    requirement before enabling the Orchestrator plugin. ---- 2. Manually approve
    the install plans for the Operators. You must run the oc patch installplan commands
    provided in the output to approve their installation. [IMPORTANT] ---- By default,
    Orchestrator Infrastructure for Red Hat Developer Hub Helm chart does not auto-approve
    the required Serverless Operators. You must manually approve the install plans.
    ---- ### Installing Orchestrator components manually on OpenShift Container Platform
    Use manual installation when you want full control of the setup process and component
    versions. Manual installation method focuses on setting up the underlying infrastructure.
    1. Install the OpenShift Serverless components manually by following the instructions
    in the Red Hat OpenShift Serverless documentation. 2. (Optional) If required,
    deploy a custom PostgreSQL database. [IMPORTANT] ---- Prevent workflow context
    from being lost when the Pod restarts by configuring workflow persistence. You
    can configure persistence at the namespace level by using the SonataFlowPlatform
    or SonataFlow custom resources (CR). For more information, check the Managing
    workflow persistence documentation. ---- ### Installing components using the RHDH
    helper script You can use the RHDH helper script plugin-infra.sh to quickly install
    the OpenShift Serverless infrastructure and Openshift Serverless Logic infrastructure
    required by the Orchestrator plugin. [WARNING] --- Do not use plugin infra.sh
    in production. ---- 1. Download the plugin-infra.sh script as shown in the following
    example: ```terminal curl -sSLO https://raw.githubusercontent.com/redhat-developer/rhdh-operator/refs/heads/release-${PRODUCT_VERSION}/config/profile/rhdh/plugin-infra/plugin-infra.sh
    # Specify the Red Hat Developer Hub version in the URL or use main ``` 2. Run
    the script: ```terminal $ ./plugin infra.sh ``` ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:37:19.563962'
    uuid: 9576ad55-48de-4e31-b78b-b22a64ec1296
  response: To prevent workflow context from being lost when a Pod restarts, you must
    configure workflow persistence. You can configure persistence at the namespace
    level by using the SonataFlowPlatform or SonataFlow custom resources (CR).
  user_input: I'm looking at the manual instalation process for the Orchestrator components
    and I'm concerned about workflow persistance. How can we make sure the workflow
    context isn't lost if a Pod restats, and what exactly are the SonataFlowPlatform
    or SonataFlow custom resouces used for in this situation?
- context:
  - "Best practices when creating serverless workflows Create effective serverless\
    \ workflows using thoughtful approaches to design, handle data, and manage error\
    \ by following these best practices based on the Serverless Workflow Domain Specific\
    \ Language (DSL) principles. These principles help you to build robust workflows.\
    \ Workflow design principles:: The Serverless Workflow DSL prioritizes clarity\
    \ and ease of use when writing workflows. Priority of constituencies:: When developing\
    \ workflows or APIs, ensure the needs of the author (workflow writer) come first.\
    \ The constituencies are prioritized in the following order: Authors &gt; Operators\
    \ &gt; Implementors &gt; Specifications writers. Linguistic fluency and clarity::\
    \ * Use imperative verbs such as Call, Emit, For, Fork, Raise, Run, Set, Switch,\
    \ and Wait. These simple, universally understood terms make your workflow simple\
    \ to read and understand. Structure and extensibility:: * Use implicit default\
    \ behaviors to reduce redundancy. * Declare components inline if they are not\
    \ reusable to keep the definition self-contained. * Use external references to\
    \ import and reuse shared components, which promotes a modular design. * Prioritize\
    \ flexibility over strict enumerations to ensure extensibility and adaptability\
    \ across different runtime environments. Data flow and runtime management:: Controlling\
    \ data flow is critical for efficient workflows. Tasks are the fundamental computing\
    \ units of a workflow. The Domain Specific Language (DSL) defines several default\
    \ task types that runtimes must do. These include Do, Listen, Raise, Run, Try,\
    \ and Wait. Security and error handling:: Secrets:: Use Secrets with caution.\
    \ Avoid passing them directly in call inputs as this might expose sensitive information.\
    \ Fault tolerance and error handling:: Serverless Workflow is designed with resilience\
    \ in mind to recover from failures. Orchestrator UI integration best practices::\
    \ For your workflow results to be effectively displayed in the Orchestrator UI\
    \ and to facilitate chaining of workflows, you must structure the output data\
    \ according to the WorkflowResult schema. Additionally, include any error information\
    \ as part of the workflow output so the UI and subsequent workflows can handle\
    \ them accordingly. Workflow output schema:: Results placement:: The primary output\
    \ intended for subsequent processing must be placed under the data.result property.\
    \ Schema reference:: Your output schema file (schemas/workflow-output-schema.json)\
    \ must reference the WorkflowResult schema. Outputs definition:: Include an outputs\
    \ section in your workflow definition. This section contains human-readable key/value\
    \ pairs that the UI will display. Structure of workflow: ```yaml id: my-workflow\
    \ version: \"0.8\" specVersion: \"0.8\" name: My Workflow start: ImmediatelyEnd\
    \ dataInputSchema: schemas/basic__main-schema.json extensions: - extensionid:\
    \ workflow-output-schema outputSchema: schemas/workflow-output-schema.json functions:\
    \ - name: print type: custom operation: sysout - name: successResult type: expression\
    \ operation: '{ \"result\": { \"message\": \"Project \" + .projectName + \" active\"\
    , \"outputs\":[] } }' start: \"successResult\" states: - name: successResult type:\
    \ operation actions: - name: setOutput functionRef: refName: successResult end:\
    \ true ``` # Build and deploy serverless workflows To deploy a workflow and make\
    \ it available in the Orchestrator plugin, follow these main steps: Building workflow\
    \ images Generating workflow manifests Deploying workflows to a cluster This process\
    \ moves the workflow from your local machine to deployment on a cluster. ## Benefits\
    \ of workflow images While the OpenShift Serverless Logic Operator supports the\
    \ building of workflows dynamically, this approach is primarily for experimentation.\
    \ For production deployments, building images is the preferred method due to the\
    \ following reasons: Production readiness: Prebuilt images can be scanned, secured,\
    \ and tested before going live. GitOps compatibility: The Orchestrator relies\
    \ on a central OpenShift Serverless Logic Operator instance to track workflows\
    \ and their state. To use this tracking service, you must deploy workflows with\
    \ the gitops profile, which expects a prebuilt image. Testing and quality: Building\
    \ an image gives you more control over the testing process. ### Project structure\
    \ overview The project utilizes Quarkus project layout (Maven project structure).\
    \ This structure is illustrated by the following 01_basic workflow example: ```yaml\
    \ 01_basic \u251C\u2500\u2500 pom.xml \u251C\u2500\u2500 README.md \u2514\u2500\
    \u2500 src \u2514\u2500\u2500 main \u251C\u2500\u2500 docker \u2502 \u251C\u2500\
    \u2500 Dockerfile.jvm \u2502 \u251C\u2500\u2500 Dockerfile.legacy-jar \u2502 \u251C\
    \u2500\u2500 Dockerfile.native \u2502 \u2514\u2500\u2500 Dockerfile.native-micro\
    \ \u2514\u2500\u2500 resources \u251C\u2500\u2500 application.properties \u251C\
    \u2500\u2500 basic.svg \u251C\u2500\u2500 basic.sw.yaml \u251C\u2500\u2500 schemas\
    \ \u2502 \u251C\u2500\u2500 basic__main-schema.json \u2502 \u2514\u2500\u2500\
    \ workflow-output-schema.json \u2514\u2500\u2500 secret.properties ``` The main\
    \ workflow resources are located under the src/main/resources/ directory. The\
    \ kn-workflow CLI generated this project structure. You can try generating the\
    \ structure yourself by following the Getting Started guide. For more information\
    \ on the Quarkus project, see Creating your first application. ### Creating and\
    \ running your serverless workflow project locally The kn-workflow CLI is an essential\
    \ tool that generates workflow manifests and project structures. To ensure successful\
    \ development and immediate testing, begin developing a new serverless workflow\
    \ locally by completing the following steps: 1. Use the kn-workflow CLI to create\
    \ a new workflow project, which adheres to the Quarkus structure as shown in the\
    \ following example: ```bash kn-workflow quarkus create --name <specify project\
    \ name, for example ,00_new_project> ``` 2. Edit the workflow, add schema and\
    \ specific files, and run it locally from project folder as shown in the following\
    \ example: ```bash kn workflow quarkus run ``` 3. Run the workflow locally using\
    \ the kn-workflow run which pulls the following image: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf devmode rhel8:1.36.0 ``` 4. For building the workflow\
    \ image, the kn-workflow CLI pulls the following images: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf builder rhel8:1.36.0 8 registry.access.redhat.com/ubi9/openjdk\
    \ 17:1.21 2 ``` About OpenShift Serverless Logic OpenShift Serverless Logic Tutorial\
    \ Running Red Hat Developer Hub behind a corporate proxy Using the Red Hat hosted\
    \ Quarkus repository ## Building workflow images locally You can use the build\
    \ script (build.sh) to build workflow images. You can run it either locally or\
    \ inside a container. This section highlights how build workflow images locally.\
    \ 1. Clone the project as shown in the following example: ```yaml git clone git@github.com:rhdhorchestrator/orchestrator\
    \ demo.git cd orchestrator demo ``` 2. Check the help menu of the script: ```yaml\
    \ ./scripts/build.sh - help ``` 3. Run the build.sh script, providing the required\
    \ flags, for instance, the image path (-i), workflow source directory (-w), and\
    \ manifests output directory (-m). [IMPORTANT] ---- You must specify the full\
    \ target image path with a tag as shown in the following example: ```yaml ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` ---- ### The build-sh script functionality and important"
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:37:29.528824'
    uuid: aaec0764-92eb-45be-930b-54fdb2e5e004
  response: The Serverless Workflow Domain Specific Language (DSL) outlines several
    best practices and principles to build robust workflows. The DSL prioritizes clarity
    and ease of use, with the primary constituency being the author (workflow writer),
    followed by operators, implementors, and specifications writers. For linguistic
    fluency, it is recommended to use simple, universally understood imperative verbs
    such as Call, Emit, For, Fork, Raise, Run, Set, Switch, and Wait. Regarding structure
    and extensibility, best practices include using implicit default behaviors to
    reduce redundancy, declaring non-reusable components inline to keep the definition
    self-contained, and using external references to import and reuse shared components
    for a modular design. Finally, it is advised to prioritize flexibility over strict
    enumerations to ensure extensibility and adaptability across different runtime
    environments.
  user_input: As a Platform Engineer responsible for our development environment,
    could you please provide a comprehensive overview of the fundamental design principles
    and best practices recommended by the Serverless Workflow DSL for creating robust,
    clear, and extensible serverless workflows for our teams?
- context:
  - "Best practices when creating serverless workflows Create effective serverless\
    \ workflows using thoughtful approaches to design, handle data, and manage error\
    \ by following these best practices based on the Serverless Workflow Domain Specific\
    \ Language (DSL) principles. These principles help you to build robust workflows.\
    \ Workflow design principles:: The Serverless Workflow DSL prioritizes clarity\
    \ and ease of use when writing workflows. Priority of constituencies:: When developing\
    \ workflows or APIs, ensure the needs of the author (workflow writer) come first.\
    \ The constituencies are prioritized in the following order: Authors &gt; Operators\
    \ &gt; Implementors &gt; Specifications writers. Linguistic fluency and clarity::\
    \ * Use imperative verbs such as Call, Emit, For, Fork, Raise, Run, Set, Switch,\
    \ and Wait. These simple, universally understood terms make your workflow simple\
    \ to read and understand. Structure and extensibility:: * Use implicit default\
    \ behaviors to reduce redundancy. * Declare components inline if they are not\
    \ reusable to keep the definition self-contained. * Use external references to\
    \ import and reuse shared components, which promotes a modular design. * Prioritize\
    \ flexibility over strict enumerations to ensure extensibility and adaptability\
    \ across different runtime environments. Data flow and runtime management:: Controlling\
    \ data flow is critical for efficient workflows. Tasks are the fundamental computing\
    \ units of a workflow. The Domain Specific Language (DSL) defines several default\
    \ task types that runtimes must do. These include Do, Listen, Raise, Run, Try,\
    \ and Wait. Security and error handling:: Secrets:: Use Secrets with caution.\
    \ Avoid passing them directly in call inputs as this might expose sensitive information.\
    \ Fault tolerance and error handling:: Serverless Workflow is designed with resilience\
    \ in mind to recover from failures. Orchestrator UI integration best practices::\
    \ For your workflow results to be effectively displayed in the Orchestrator UI\
    \ and to facilitate chaining of workflows, you must structure the output data\
    \ according to the WorkflowResult schema. Additionally, include any error information\
    \ as part of the workflow output so the UI and subsequent workflows can handle\
    \ them accordingly. Workflow output schema:: Results placement:: The primary output\
    \ intended for subsequent processing must be placed under the data.result property.\
    \ Schema reference:: Your output schema file (schemas/workflow-output-schema.json)\
    \ must reference the WorkflowResult schema. Outputs definition:: Include an outputs\
    \ section in your workflow definition. This section contains human-readable key/value\
    \ pairs that the UI will display. Structure of workflow: ```yaml id: my-workflow\
    \ version: \"0.8\" specVersion: \"0.8\" name: My Workflow start: ImmediatelyEnd\
    \ dataInputSchema: schemas/basic__main-schema.json extensions: - extensionid:\
    \ workflow-output-schema outputSchema: schemas/workflow-output-schema.json functions:\
    \ - name: print type: custom operation: sysout - name: successResult type: expression\
    \ operation: '{ \"result\": { \"message\": \"Project \" + .projectName + \" active\"\
    , \"outputs\":[] } }' start: \"successResult\" states: - name: successResult type:\
    \ operation actions: - name: setOutput functionRef: refName: successResult end:\
    \ true ``` # Build and deploy serverless workflows To deploy a workflow and make\
    \ it available in the Orchestrator plugin, follow these main steps: Building workflow\
    \ images Generating workflow manifests Deploying workflows to a cluster This process\
    \ moves the workflow from your local machine to deployment on a cluster. ## Benefits\
    \ of workflow images While the OpenShift Serverless Logic Operator supports the\
    \ building of workflows dynamically, this approach is primarily for experimentation.\
    \ For production deployments, building images is the preferred method due to the\
    \ following reasons: Production readiness: Prebuilt images can be scanned, secured,\
    \ and tested before going live. GitOps compatibility: The Orchestrator relies\
    \ on a central OpenShift Serverless Logic Operator instance to track workflows\
    \ and their state. To use this tracking service, you must deploy workflows with\
    \ the gitops profile, which expects a prebuilt image. Testing and quality: Building\
    \ an image gives you more control over the testing process. ### Project structure\
    \ overview The project utilizes Quarkus project layout (Maven project structure).\
    \ This structure is illustrated by the following 01_basic workflow example: ```yaml\
    \ 01_basic \u251C\u2500\u2500 pom.xml \u251C\u2500\u2500 README.md \u2514\u2500\
    \u2500 src \u2514\u2500\u2500 main \u251C\u2500\u2500 docker \u2502 \u251C\u2500\
    \u2500 Dockerfile.jvm \u2502 \u251C\u2500\u2500 Dockerfile.legacy-jar \u2502 \u251C\
    \u2500\u2500 Dockerfile.native \u2502 \u2514\u2500\u2500 Dockerfile.native-micro\
    \ \u2514\u2500\u2500 resources \u251C\u2500\u2500 application.properties \u251C\
    \u2500\u2500 basic.svg \u251C\u2500\u2500 basic.sw.yaml \u251C\u2500\u2500 schemas\
    \ \u2502 \u251C\u2500\u2500 basic__main-schema.json \u2502 \u2514\u2500\u2500\
    \ workflow-output-schema.json \u2514\u2500\u2500 secret.properties ``` The main\
    \ workflow resources are located under the src/main/resources/ directory. The\
    \ kn-workflow CLI generated this project structure. You can try generating the\
    \ structure yourself by following the Getting Started guide. For more information\
    \ on the Quarkus project, see Creating your first application. ### Creating and\
    \ running your serverless workflow project locally The kn-workflow CLI is an essential\
    \ tool that generates workflow manifests and project structures. To ensure successful\
    \ development and immediate testing, begin developing a new serverless workflow\
    \ locally by completing the following steps: 1. Use the kn-workflow CLI to create\
    \ a new workflow project, which adheres to the Quarkus structure as shown in the\
    \ following example: ```bash kn-workflow quarkus create --name <specify project\
    \ name, for example ,00_new_project> ``` 2. Edit the workflow, add schema and\
    \ specific files, and run it locally from project folder as shown in the following\
    \ example: ```bash kn workflow quarkus run ``` 3. Run the workflow locally using\
    \ the kn-workflow run which pulls the following image: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf devmode rhel8:1.36.0 ``` 4. For building the workflow\
    \ image, the kn-workflow CLI pulls the following images: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf builder rhel8:1.36.0 8 registry.access.redhat.com/ubi9/openjdk\
    \ 17:1.21 2 ``` About OpenShift Serverless Logic OpenShift Serverless Logic Tutorial\
    \ Running Red Hat Developer Hub behind a corporate proxy Using the Red Hat hosted\
    \ Quarkus repository ## Building workflow images locally You can use the build\
    \ script (build.sh) to build workflow images. You can run it either locally or\
    \ inside a container. This section highlights how build workflow images locally.\
    \ 1. Clone the project as shown in the following example: ```yaml git clone git@github.com:rhdhorchestrator/orchestrator\
    \ demo.git cd orchestrator demo ``` 2. Check the help menu of the script: ```yaml\
    \ ./scripts/build.sh - help ``` 3. Run the build.sh script, providing the required\
    \ flags, for instance, the image path (-i), workflow source directory (-w), and\
    \ manifests output directory (-m). [IMPORTANT] ---- You must specify the full\
    \ target image path with a tag as shown in the following example: ```yaml ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` ---- ### The build-sh script functionality and important"
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:37:38.699082'
    uuid: 53a78227-6eaf-48eb-a2f9-8261ee37a327
  response: For GitOps compatibility, the Orchestrator depends on a central OpenShift
    Serverless Logic Operator instance for tracking workflows and their state. To
    use this tracking service, you are required to deploy workflows using the gitops
    profile, which necessitates a prebuilt image.
  user_input: serverless workflow GitOps compatibility requirements
- context:
  - "Best practices when creating serverless workflows Create effective serverless\
    \ workflows using thoughtful approaches to design, handle data, and manage error\
    \ by following these best practices based on the Serverless Workflow Domain Specific\
    \ Language (DSL) principles. These principles help you to build robust workflows.\
    \ Workflow design principles:: The Serverless Workflow DSL prioritizes clarity\
    \ and ease of use when writing workflows. Priority of constituencies:: When developing\
    \ workflows or APIs, ensure the needs of the author (workflow writer) come first.\
    \ The constituencies are prioritized in the following order: Authors &gt; Operators\
    \ &gt; Implementors &gt; Specifications writers. Linguistic fluency and clarity::\
    \ * Use imperative verbs such as Call, Emit, For, Fork, Raise, Run, Set, Switch,\
    \ and Wait. These simple, universally understood terms make your workflow simple\
    \ to read and understand. Structure and extensibility:: * Use implicit default\
    \ behaviors to reduce redundancy. * Declare components inline if they are not\
    \ reusable to keep the definition self-contained. * Use external references to\
    \ import and reuse shared components, which promotes a modular design. * Prioritize\
    \ flexibility over strict enumerations to ensure extensibility and adaptability\
    \ across different runtime environments. Data flow and runtime management:: Controlling\
    \ data flow is critical for efficient workflows. Tasks are the fundamental computing\
    \ units of a workflow. The Domain Specific Language (DSL) defines several default\
    \ task types that runtimes must do. These include Do, Listen, Raise, Run, Try,\
    \ and Wait. Security and error handling:: Secrets:: Use Secrets with caution.\
    \ Avoid passing them directly in call inputs as this might expose sensitive information.\
    \ Fault tolerance and error handling:: Serverless Workflow is designed with resilience\
    \ in mind to recover from failures. Orchestrator UI integration best practices::\
    \ For your workflow results to be effectively displayed in the Orchestrator UI\
    \ and to facilitate chaining of workflows, you must structure the output data\
    \ according to the WorkflowResult schema. Additionally, include any error information\
    \ as part of the workflow output so the UI and subsequent workflows can handle\
    \ them accordingly. Workflow output schema:: Results placement:: The primary output\
    \ intended for subsequent processing must be placed under the data.result property.\
    \ Schema reference:: Your output schema file (schemas/workflow-output-schema.json)\
    \ must reference the WorkflowResult schema. Outputs definition:: Include an outputs\
    \ section in your workflow definition. This section contains human-readable key/value\
    \ pairs that the UI will display. Structure of workflow: ```yaml id: my-workflow\
    \ version: \"0.8\" specVersion: \"0.8\" name: My Workflow start: ImmediatelyEnd\
    \ dataInputSchema: schemas/basic__main-schema.json extensions: - extensionid:\
    \ workflow-output-schema outputSchema: schemas/workflow-output-schema.json functions:\
    \ - name: print type: custom operation: sysout - name: successResult type: expression\
    \ operation: '{ \"result\": { \"message\": \"Project \" + .projectName + \" active\"\
    , \"outputs\":[] } }' start: \"successResult\" states: - name: successResult type:\
    \ operation actions: - name: setOutput functionRef: refName: successResult end:\
    \ true ``` # Build and deploy serverless workflows To deploy a workflow and make\
    \ it available in the Orchestrator plugin, follow these main steps: Building workflow\
    \ images Generating workflow manifests Deploying workflows to a cluster This process\
    \ moves the workflow from your local machine to deployment on a cluster. ## Benefits\
    \ of workflow images While the OpenShift Serverless Logic Operator supports the\
    \ building of workflows dynamically, this approach is primarily for experimentation.\
    \ For production deployments, building images is the preferred method due to the\
    \ following reasons: Production readiness: Prebuilt images can be scanned, secured,\
    \ and tested before going live. GitOps compatibility: The Orchestrator relies\
    \ on a central OpenShift Serverless Logic Operator instance to track workflows\
    \ and their state. To use this tracking service, you must deploy workflows with\
    \ the gitops profile, which expects a prebuilt image. Testing and quality: Building\
    \ an image gives you more control over the testing process. ### Project structure\
    \ overview The project utilizes Quarkus project layout (Maven project structure).\
    \ This structure is illustrated by the following 01_basic workflow example: ```yaml\
    \ 01_basic \u251C\u2500\u2500 pom.xml \u251C\u2500\u2500 README.md \u2514\u2500\
    \u2500 src \u2514\u2500\u2500 main \u251C\u2500\u2500 docker \u2502 \u251C\u2500\
    \u2500 Dockerfile.jvm \u2502 \u251C\u2500\u2500 Dockerfile.legacy-jar \u2502 \u251C\
    \u2500\u2500 Dockerfile.native \u2502 \u2514\u2500\u2500 Dockerfile.native-micro\
    \ \u2514\u2500\u2500 resources \u251C\u2500\u2500 application.properties \u251C\
    \u2500\u2500 basic.svg \u251C\u2500\u2500 basic.sw.yaml \u251C\u2500\u2500 schemas\
    \ \u2502 \u251C\u2500\u2500 basic__main-schema.json \u2502 \u2514\u2500\u2500\
    \ workflow-output-schema.json \u2514\u2500\u2500 secret.properties ``` The main\
    \ workflow resources are located under the src/main/resources/ directory. The\
    \ kn-workflow CLI generated this project structure. You can try generating the\
    \ structure yourself by following the Getting Started guide. For more information\
    \ on the Quarkus project, see Creating your first application. ### Creating and\
    \ running your serverless workflow project locally The kn-workflow CLI is an essential\
    \ tool that generates workflow manifests and project structures. To ensure successful\
    \ development and immediate testing, begin developing a new serverless workflow\
    \ locally by completing the following steps: 1. Use the kn-workflow CLI to create\
    \ a new workflow project, which adheres to the Quarkus structure as shown in the\
    \ following example: ```bash kn-workflow quarkus create --name <specify project\
    \ name, for example ,00_new_project> ``` 2. Edit the workflow, add schema and\
    \ specific files, and run it locally from project folder as shown in the following\
    \ example: ```bash kn workflow quarkus run ``` 3. Run the workflow locally using\
    \ the kn-workflow run which pulls the following image: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf devmode rhel8:1.36.0 ``` 4. For building the workflow\
    \ image, the kn-workflow CLI pulls the following images: ```yaml registry.redhat.io/openshift\
    \ serverless 1/logic swf builder rhel8:1.36.0 8 registry.access.redhat.com/ubi9/openjdk\
    \ 17:1.21 2 ``` About OpenShift Serverless Logic OpenShift Serverless Logic Tutorial\
    \ Running Red Hat Developer Hub behind a corporate proxy Using the Red Hat hosted\
    \ Quarkus repository ## Building workflow images locally You can use the build\
    \ script (build.sh) to build workflow images. You can run it either locally or\
    \ inside a container. This section highlights how build workflow images locally.\
    \ 1. Clone the project as shown in the following example: ```yaml git clone git@github.com:rhdhorchestrator/orchestrator\
    \ demo.git cd orchestrator demo ``` 2. Check the help menu of the script: ```yaml\
    \ ./scripts/build.sh - help ``` 3. Run the build.sh script, providing the required\
    \ flags, for instance, the image path (-i), workflow source directory (-w), and\
    \ manifests output directory (-m). [IMPORTANT] ---- You must specify the full\
    \ target image path with a tag as shown in the following example: ```yaml ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` ---- ### The build-sh script functionality and important"
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:37:47.841466'
    uuid: 74d10a19-ac11-4671-a4b2-da8964117eb7
  response: For production deployments, building images is the preferred method due
    to reasons like GitOps compatibility. The Orchestrator relies on a central OpenShift
    Serverless Logic Operator instance to track workflows and their state. To use
    this tracking service, you must deploy workflows with the gitops profile, which
    expects a prebuilt image.
  user_input: What are the specific requirements for deploying serverless workflows
    to be compatible with a GitOps profile and why is this the preferred method for
    production?
- context:
  - "flags The build-sh script does the following tasks in order: Generates workflow\
    \ manifests using the kn workflow CLI. Builds the workflow image using podman\
    \ or docker. Optional: The script pushes the images to an image registry and deploys\
    \ the workflow using kubectl. You can review the script configuration options\
    \ and see available flags and their functions by accessing the help menu: ```bash\
    \ ./scripts/build.sh [flags] ``` The following flags are essential for running\
    \ the script: [TIP] ---- The script also supports builder and runtime image overrides,\
    \ namespace targeting, and persistence flags. ---- ### Environment variables supported\
    \ by the build script The build-sh script supports the following environment variables\
    \ to customize the workflow build process without modifying the script itself:\
    \ QUARKUS_EXTENSIONS:: The QUARKUS_EXTENSIONS variable specifies additional Quarkus\
    \ extensions required by the workflow. This variable takes the format of a comma-separated\
    \ list of fully qualified extension IDs as shown in the following example: ```yaml\
    \ export QUARKUS_EXTENSIONS=\"io.quarkus:quarkus smallrye reactive messaging kafka\"\
    \ ``` Add Kafka messaging support or other integrations at build time. MAVEN_ARGS_APPEND::\
    \ The MAVEN_ARGS_APPEND variable appends additional arguments to the Maven build\
    \ command. This variable takes the format of a string of Maven CLI arguments as\
    \ shown in the following example: ```yaml export MAVEN_ARGS_APPEND=\" DmaxYamlCodePoints=35000000\"\
    \ ``` Control build behavior. For example, set maxYamlCodePoints parameter that\
    \ controls the maximum input size for YAML input files to 35000000 characters\
    \ (~33MB in UTF-8). ### Required tools To run the build-sh script locally and\
    \ manage the workflow lifecycle, you must install the following command-line tools:\
    \ ### Building the 01_basic workflow To run the script from the root directory\
    \ of the repository, you must use the -w flag to point to the workflow directory.\
    \ Additionally, specify the output directory with the -m flag. You have specified\
    \ the target image using a tag. 1. Run the following command: ```bash ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` This build command produces the following two artifacts: * A workflow image\
    \ and Kubernetes manifests: quay.io/orchestrator/demo-basic:test and tagged as\
    \ latest. * Kubernetes manifests under: 01_basic/manifests/ 2. Optional: You can\
    \ add the --push flag to automatically push the image after building. Otherwise,\
    \ pushing manually is mandatory before deploying. ## Generated workflow manifests\
    \ The following example is an illustration of what is generated under the 01_basic/manifests:\
    \ ```yaml 01_basic/manifests \u251C\u2500\u2500 00 secret_basic secrets.yaml \u251C\
    \u2500\u2500 01 configmap_basic props.yaml \u251C\u2500\u2500 02 configmap_01\
    \ basic resources schemas.yaml \u2514\u2500\u2500 03 sonataflow_basic.yaml ```\
    \ 00-secret_basic-secrets.yaml:: Contains secrets from 01_basic/src/main/resources/secret.properties.\
    \ Values are not required at this stage as you can set them later after applying\
    \ CRs or when using GitOps. In OpenShift Serverless Logic v1.36, after updating\
    \ a secret, you must manually restart the workflow Pod for changes to apply. 01-configmap_basic-props.yaml::\
    \ Holds application properties from application.properties. Any change to this\
    \ ConfigMap triggers an automatic Pod restart. 02-configmap_01-basic-resources-schemas.yaml::\
    \ Contains JSON schemas from src/main/resources/schemas. [NOTE] ---- You do not\
    \ need to deploy certain configuration resources when using the GitOps profile.\
    \ ---- 03-sonataflow_basic.yaml:: The SonataFlow custom resource (CR) that defines\
    \ the workflow. ```yaml podTemplate: container: image: quay.io/orchestrator/demo\
    \ basic resources: {} envFrom: secretRef: name: basic secrets ``` ```yaml persistence:\
    \ postgresql: secretRef: name: sonataflow psql postgresql userKey: <your_postgres_username>\
    \ passwordKey: <your_postgres_password> serviceRef: name: sonataflow psql postgresql\
    \ port: 5432 databaseName: sonataflow databaseSchema: basic ``` where: postgresql:secretRef:name::\
    \ Enter the Secret name for your deployment. postgresql:secretRef:userKey:: Enter\
    \ the key for your deployment. postgresql:secretRef:passwordKey:: Enter the password\
    \ for your deployment. postgresql:serviceRef:name:: Enter the Service name for\
    \ your deployment. If you must connect to an external database, replace serviceRef\
    \ with jdbcUrl. See Managing workflow persistence. By default, the script generates\
    \ all the manifests without a namespace. You can specify a namespace to the script\
    \ by using the --namespace flag if you know the target namespace in advance. Otherwise,\
    \ you must provide the namespace when applying the manifests to the cluster. See\
    \ Configuring workflow services. ##"
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:37:59.886572'
    uuid: 5528741b-52d4-47d0-9ada-c6da7f343e94
  response: To add Kafka messaging support at build time, you must use the `QUARKUS_EXTENSIONS`
    environment variable. This variable specifies additional Quarkus extensions required
    by the workflow and takes a comma-separated list of fully qualified extension
    IDs. For example, you would use `export QUARKUS_EXTENSIONS=\"io.quarkus:quarkus
    smallrye reactive messaging kafka\"`.
  user_input: According to the build script documentation, what is the specific procedure
    for incorporating Kafka messaging support into a workflow during the build process?
- context:
  - "flags The build-sh script does the following tasks in order: Generates workflow\
    \ manifests using the kn workflow CLI. Builds the workflow image using podman\
    \ or docker. Optional: The script pushes the images to an image registry and deploys\
    \ the workflow using kubectl. You can review the script configuration options\
    \ and see available flags and their functions by accessing the help menu: ```bash\
    \ ./scripts/build.sh [flags] ``` The following flags are essential for running\
    \ the script: [TIP] ---- The script also supports builder and runtime image overrides,\
    \ namespace targeting, and persistence flags. ---- ### Environment variables supported\
    \ by the build script The build-sh script supports the following environment variables\
    \ to customize the workflow build process without modifying the script itself:\
    \ QUARKUS_EXTENSIONS:: The QUARKUS_EXTENSIONS variable specifies additional Quarkus\
    \ extensions required by the workflow. This variable takes the format of a comma-separated\
    \ list of fully qualified extension IDs as shown in the following example: ```yaml\
    \ export QUARKUS_EXTENSIONS=\"io.quarkus:quarkus smallrye reactive messaging kafka\"\
    \ ``` Add Kafka messaging support or other integrations at build time. MAVEN_ARGS_APPEND::\
    \ The MAVEN_ARGS_APPEND variable appends additional arguments to the Maven build\
    \ command. This variable takes the format of a string of Maven CLI arguments as\
    \ shown in the following example: ```yaml export MAVEN_ARGS_APPEND=\" DmaxYamlCodePoints=35000000\"\
    \ ``` Control build behavior. For example, set maxYamlCodePoints parameter that\
    \ controls the maximum input size for YAML input files to 35000000 characters\
    \ (~33MB in UTF-8). ### Required tools To run the build-sh script locally and\
    \ manage the workflow lifecycle, you must install the following command-line tools:\
    \ ### Building the 01_basic workflow To run the script from the root directory\
    \ of the repository, you must use the -w flag to point to the workflow directory.\
    \ Additionally, specify the output directory with the -m flag. You have specified\
    \ the target image using a tag. 1. Run the following command: ```bash ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` This build command produces the following two artifacts: * A workflow image\
    \ and Kubernetes manifests: quay.io/orchestrator/demo-basic:test and tagged as\
    \ latest. * Kubernetes manifests under: 01_basic/manifests/ 2. Optional: You can\
    \ add the --push flag to automatically push the image after building. Otherwise,\
    \ pushing manually is mandatory before deploying. ## Generated workflow manifests\
    \ The following example is an illustration of what is generated under the 01_basic/manifests:\
    \ ```yaml 01_basic/manifests \u251C\u2500\u2500 00 secret_basic secrets.yaml \u251C\
    \u2500\u2500 01 configmap_basic props.yaml \u251C\u2500\u2500 02 configmap_01\
    \ basic resources schemas.yaml \u2514\u2500\u2500 03 sonataflow_basic.yaml ```\
    \ 00-secret_basic-secrets.yaml:: Contains secrets from 01_basic/src/main/resources/secret.properties.\
    \ Values are not required at this stage as you can set them later after applying\
    \ CRs or when using GitOps. In OpenShift Serverless Logic v1.36, after updating\
    \ a secret, you must manually restart the workflow Pod for changes to apply. 01-configmap_basic-props.yaml::\
    \ Holds application properties from application.properties. Any change to this\
    \ ConfigMap triggers an automatic Pod restart. 02-configmap_01-basic-resources-schemas.yaml::\
    \ Contains JSON schemas from src/main/resources/schemas. [NOTE] ---- You do not\
    \ need to deploy certain configuration resources when using the GitOps profile.\
    \ ---- 03-sonataflow_basic.yaml:: The SonataFlow custom resource (CR) that defines\
    \ the workflow. ```yaml podTemplate: container: image: quay.io/orchestrator/demo\
    \ basic resources: {} envFrom: secretRef: name: basic secrets ``` ```yaml persistence:\
    \ postgresql: secretRef: name: sonataflow psql postgresql userKey: <your_postgres_username>\
    \ passwordKey: <your_postgres_password> serviceRef: name: sonataflow psql postgresql\
    \ port: 5432 databaseName: sonataflow databaseSchema: basic ``` where: postgresql:secretRef:name::\
    \ Enter the Secret name for your deployment. postgresql:secretRef:userKey:: Enter\
    \ the key for your deployment. postgresql:secretRef:passwordKey:: Enter the password\
    \ for your deployment. postgresql:serviceRef:name:: Enter the Service name for\
    \ your deployment. If you must connect to an external database, replace serviceRef\
    \ with jdbcUrl. See Managing workflow persistence. By default, the script generates\
    \ all the manifests without a namespace. You can specify a namespace to the script\
    \ by using the --namespace flag if you know the target namespace in advance. Otherwise,\
    \ you must provide the namespace when applying the manifests to the cluster. See\
    \ Configuring workflow services. ##"
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:38:09.620965'
    uuid: 64f1c7a4-0ec6-4522-a51e-4608cd0ad3e5
  response: You do not need to deploy certain configuration resources when using the
    GitOps profile. Additionally, for secrets contained in `00-secret_basic-secrets.yaml`,
    the values are not required at the initial stage as you can set them later when
    using GitOps.
  user_input: Wich configeration resources can I skip deployin if I'm using a GitOps
    profile for my workflow?
- context:
  - "flags The build-sh script does the following tasks in order: Generates workflow\
    \ manifests using the kn workflow CLI. Builds the workflow image using podman\
    \ or docker. Optional: The script pushes the images to an image registry and deploys\
    \ the workflow using kubectl. You can review the script configuration options\
    \ and see available flags and their functions by accessing the help menu: ```bash\
    \ ./scripts/build.sh [flags] ``` The following flags are essential for running\
    \ the script: [TIP] ---- The script also supports builder and runtime image overrides,\
    \ namespace targeting, and persistence flags. ---- ### Environment variables supported\
    \ by the build script The build-sh script supports the following environment variables\
    \ to customize the workflow build process without modifying the script itself:\
    \ QUARKUS_EXTENSIONS:: The QUARKUS_EXTENSIONS variable specifies additional Quarkus\
    \ extensions required by the workflow. This variable takes the format of a comma-separated\
    \ list of fully qualified extension IDs as shown in the following example: ```yaml\
    \ export QUARKUS_EXTENSIONS=\"io.quarkus:quarkus smallrye reactive messaging kafka\"\
    \ ``` Add Kafka messaging support or other integrations at build time. MAVEN_ARGS_APPEND::\
    \ The MAVEN_ARGS_APPEND variable appends additional arguments to the Maven build\
    \ command. This variable takes the format of a string of Maven CLI arguments as\
    \ shown in the following example: ```yaml export MAVEN_ARGS_APPEND=\" DmaxYamlCodePoints=35000000\"\
    \ ``` Control build behavior. For example, set maxYamlCodePoints parameter that\
    \ controls the maximum input size for YAML input files to 35000000 characters\
    \ (~33MB in UTF-8). ### Required tools To run the build-sh script locally and\
    \ manage the workflow lifecycle, you must install the following command-line tools:\
    \ ### Building the 01_basic workflow To run the script from the root directory\
    \ of the repository, you must use the -w flag to point to the workflow directory.\
    \ Additionally, specify the output directory with the -m flag. You have specified\
    \ the target image using a tag. 1. Run the following command: ```bash ./scripts/build.sh\
    \ - image=quay.io/orchestrator/demo basic:test w 01_basic/ m 01_basic/manifests\
    \ ``` This build command produces the following two artifacts: * A workflow image\
    \ and Kubernetes manifests: quay.io/orchestrator/demo-basic:test and tagged as\
    \ latest. * Kubernetes manifests under: 01_basic/manifests/ 2. Optional: You can\
    \ add the --push flag to automatically push the image after building. Otherwise,\
    \ pushing manually is mandatory before deploying. ## Generated workflow manifests\
    \ The following example is an illustration of what is generated under the 01_basic/manifests:\
    \ ```yaml 01_basic/manifests \u251C\u2500\u2500 00 secret_basic secrets.yaml \u251C\
    \u2500\u2500 01 configmap_basic props.yaml \u251C\u2500\u2500 02 configmap_01\
    \ basic resources schemas.yaml \u2514\u2500\u2500 03 sonataflow_basic.yaml ```\
    \ 00-secret_basic-secrets.yaml:: Contains secrets from 01_basic/src/main/resources/secret.properties.\
    \ Values are not required at this stage as you can set them later after applying\
    \ CRs or when using GitOps. In OpenShift Serverless Logic v1.36, after updating\
    \ a secret, you must manually restart the workflow Pod for changes to apply. 01-configmap_basic-props.yaml::\
    \ Holds application properties from application.properties. Any change to this\
    \ ConfigMap triggers an automatic Pod restart. 02-configmap_01-basic-resources-schemas.yaml::\
    \ Contains JSON schemas from src/main/resources/schemas. [NOTE] ---- You do not\
    \ need to deploy certain configuration resources when using the GitOps profile.\
    \ ---- 03-sonataflow_basic.yaml:: The SonataFlow custom resource (CR) that defines\
    \ the workflow. ```yaml podTemplate: container: image: quay.io/orchestrator/demo\
    \ basic resources: {} envFrom: secretRef: name: basic secrets ``` ```yaml persistence:\
    \ postgresql: secretRef: name: sonataflow psql postgresql userKey: <your_postgres_username>\
    \ passwordKey: <your_postgres_password> serviceRef: name: sonataflow psql postgresql\
    \ port: 5432 databaseName: sonataflow databaseSchema: basic ``` where: postgresql:secretRef:name::\
    \ Enter the Secret name for your deployment. postgresql:secretRef:userKey:: Enter\
    \ the key for your deployment. postgresql:secretRef:passwordKey:: Enter the password\
    \ for your deployment. postgresql:serviceRef:name:: Enter the Service name for\
    \ your deployment. If you must connect to an external database, replace serviceRef\
    \ with jdbcUrl. See Managing workflow persistence. By default, the script generates\
    \ all the manifests without a namespace. You can specify a namespace to the script\
    \ by using the --namespace flag if you know the target namespace in advance. Otherwise,\
    \ you must provide the namespace when applying the manifests to the cluster. See\
    \ Configuring workflow services. ##"
  metadata:
    classification:
      category: ci_cd
      datetime: '2025-12-10T16:38:17.116240'
    uuid: a47c3831-c53f-4ac7-90dd-54a93a8d9554
  response: The build-sh script builds the workflow image using podman or docker.
  user_input: what podman do in build script?
- context:
  - 'Deploying workflows on a cluster You can deploy the workflow on a cluster, since
    the image is pushed to the image registry and the deployment manifests are available.
    You have an OpenShift Container Platform cluster with the following versions of
    components installed: Red Hat Developer Hub (RHDH) v1.7 Orchestrator plugins v1.7.1
    OpenShift Serverless v1.36 OpenShift Serverless Logic v1.36 For instructions on
    how to install these components, see the Orchestrator plugin components on OpenShift
    Container Platform. * You must apply the workflow manifests in a namespace that
    contains a SonataflowPlatform custom resource (CR), which manages the supporting
    services. 1. Use the kubectl create command specifying the target namespace to
    apply the Kubernetes manifests as shown in the following example: ```bash kubectl
    create n <your_namespace> f ./01_basic/manifests/. ``` 2. After deployment, monitor
    the status of the workflow pods as shown in the following example: ```yaml kubectl
    get pods n <your_namespace> l app=basic ``` The pod may initially appear in an
    Error state because of missing or incomplete configuration in the Secret or ConfigMap.
    3. Inspect the Pod logs as shown in the following example: ```yaml oc logs n <your_namespace>
    basic f7c6ff455 vwl56 ``` The following code is an example of the output: ```yaml
    SRCFG00040: The config property quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token
    is defined as the empty String ("") which the following Converter considered to
    be null: io.smallrye.config.Converters$BuiltInConverter java.lang.RuntimeException:
    Failed to start quarkus ... Caused by: io.quarkus.runtime.configuration.ConfigurationException:
    Failed to read configuration properties ``` The error indicates a missing property:
    quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token. 4. In such
    a case where the logs show the ConfigurationException: Failed to read configuration
    properties error or indicate a missing value, retrieve the ConfigMap as shown
    in the following example: ```yaml oc get n <your_namespace> configmaps basic props
    o yaml ``` The following code is an example of the sample output: ```yaml apiVersion:
    v1 data: application.properties: | # Backstage notifications service quarkus.rest
    client.notifications.url=${BACKSTAGE_NOTIFICATIONS_URL} quarkus.openapi generator.notifications.auth.BearerToken.bearer
    token=${NOTIFICATIONS_BEARER_TOKEN} ... ``` Resolve the placeholders using values
    provided using a Secret. 5. You must edit the corresponding Secret and provide
    appropriate base64-encoded values to resolve the placeholders in application.properties
    as shown in the following example: ```yaml kubectl edit secrets n <your_namespace>
    basic secrets ``` 6. Restart the workflow Pod for Secret changes to take effect
    in OpenShift Serverless Logic v1.36. 1. Verify the deployment status by checking
    the Pods again as shown in the following example: ```yaml oc get pods n <your_namespace>
    l app=basic ``` The expected status for a successfully deployed workflow Pod is
    as shown in the following example: ```yaml NAME READY STATUS RESTARTS AGE basic-f7c6ff455-grkxd
    1/1 Running 0 47s ``` 2. Once the Pod is in the Running state, the workflow now
    appears in the Orchestrator plugin inside the Red Hat Developer Hub. Inspect the
    provided build script to extract the actual steps and implement them in your preferred
    CI/CD tool, for example, GitHub Actions, GitLab CI, Jenkins, and Tekton. # Installing
    Red Hat Developer Hub with Orchestrator To install Red Hat Developer Hub, use
    one of the following methods: The Red Hat Developer Hub Operator The Red Hat Developer
    Hub Helm chart ##'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:38:28.378885'
    uuid: 0020eb16-64e8-47ba-98f8-a5d8ad06dc65
  response: 'When the pod is in an Error state and the logs show a "ConfigurationException:
    Failed to read configuration properties" error, this indicates a missing property.
    You should first retrieve the ConfigMap using the command "oc get n <your_namespace>
    configmaps basic props o yaml". This will show you the application.properties
    file, which contains placeholders that need to be resolved using values from a
    Secret. To fix this, you must edit the corresponding Secret and provide the appropriate
    base64-encoded values using the command "kubectl edit secrets n <your_namespace>
    basic secrets". After editing the Secret, you must restart the workflow Pod for
    the changes to take effect. You can then verify the deployment status by checking
    the Pods again with "oc get pods n <your_namespace> l app=basic". Once the Pod
    is in the Running state, the workflow will appear in the Orchestrator plugin inside
    the Red Hat Developer Hub.'
  user_input: Hey so i followed the steps to deploy my workflow for the Orchestrator
    plugins on my openshift cluster but the pod is in error state and i dont see nothing
    in the Red Hat Developer Hub, what do i do when the logs say ConfigurationException
    and how do i fix it so it shows up?
- context:
  - 'Deploying workflows on a cluster You can deploy the workflow on a cluster, since
    the image is pushed to the image registry and the deployment manifests are available.
    You have an OpenShift Container Platform cluster with the following versions of
    components installed: Red Hat Developer Hub (RHDH) v1.7 Orchestrator plugins v1.7.1
    OpenShift Serverless v1.36 OpenShift Serverless Logic v1.36 For instructions on
    how to install these components, see the Orchestrator plugin components on OpenShift
    Container Platform. * You must apply the workflow manifests in a namespace that
    contains a SonataflowPlatform custom resource (CR), which manages the supporting
    services. 1. Use the kubectl create command specifying the target namespace to
    apply the Kubernetes manifests as shown in the following example: ```bash kubectl
    create n <your_namespace> f ./01_basic/manifests/. ``` 2. After deployment, monitor
    the status of the workflow pods as shown in the following example: ```yaml kubectl
    get pods n <your_namespace> l app=basic ``` The pod may initially appear in an
    Error state because of missing or incomplete configuration in the Secret or ConfigMap.
    3. Inspect the Pod logs as shown in the following example: ```yaml oc logs n <your_namespace>
    basic f7c6ff455 vwl56 ``` The following code is an example of the output: ```yaml
    SRCFG00040: The config property quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token
    is defined as the empty String ("") which the following Converter considered to
    be null: io.smallrye.config.Converters$BuiltInConverter java.lang.RuntimeException:
    Failed to start quarkus ... Caused by: io.quarkus.runtime.configuration.ConfigurationException:
    Failed to read configuration properties ``` The error indicates a missing property:
    quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token. 4. In such
    a case where the logs show the ConfigurationException: Failed to read configuration
    properties error or indicate a missing value, retrieve the ConfigMap as shown
    in the following example: ```yaml oc get n <your_namespace> configmaps basic props
    o yaml ``` The following code is an example of the sample output: ```yaml apiVersion:
    v1 data: application.properties: | # Backstage notifications service quarkus.rest
    client.notifications.url=${BACKSTAGE_NOTIFICATIONS_URL} quarkus.openapi generator.notifications.auth.BearerToken.bearer
    token=${NOTIFICATIONS_BEARER_TOKEN} ... ``` Resolve the placeholders using values
    provided using a Secret. 5. You must edit the corresponding Secret and provide
    appropriate base64-encoded values to resolve the placeholders in application.properties
    as shown in the following example: ```yaml kubectl edit secrets n <your_namespace>
    basic secrets ``` 6. Restart the workflow Pod for Secret changes to take effect
    in OpenShift Serverless Logic v1.36. 1. Verify the deployment status by checking
    the Pods again as shown in the following example: ```yaml oc get pods n <your_namespace>
    l app=basic ``` The expected status for a successfully deployed workflow Pod is
    as shown in the following example: ```yaml NAME READY STATUS RESTARTS AGE basic-f7c6ff455-grkxd
    1/1 Running 0 47s ``` 2. Once the Pod is in the Running state, the workflow now
    appears in the Orchestrator plugin inside the Red Hat Developer Hub. Inspect the
    provided build script to extract the actual steps and implement them in your preferred
    CI/CD tool, for example, GitHub Actions, GitLab CI, Jenkins, and Tekton. # Installing
    Red Hat Developer Hub with Orchestrator To install Red Hat Developer Hub, use
    one of the following methods: The Red Hat Developer Hub Operator The Red Hat Developer
    Hub Helm chart ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:38:38.168889'
    uuid: 49d84b62-6ddf-4433-8478-50cc641d03ad
  response: When deploying workflows on a cluster, you must apply the workflow manifests
    in a namespace that contains a SonataflowPlatform custom resource (CR), which
    is responsible for managing the supporting services.
  user_input: What is the requirment for a namespac when deploying workflow manifests
    regarding the sonataflowplatfrom CR?
- context:
  - 'Deploying workflows on a cluster You can deploy the workflow on a cluster, since
    the image is pushed to the image registry and the deployment manifests are available.
    You have an OpenShift Container Platform cluster with the following versions of
    components installed: Red Hat Developer Hub (RHDH) v1.7 Orchestrator plugins v1.7.1
    OpenShift Serverless v1.36 OpenShift Serverless Logic v1.36 For instructions on
    how to install these components, see the Orchestrator plugin components on OpenShift
    Container Platform. * You must apply the workflow manifests in a namespace that
    contains a SonataflowPlatform custom resource (CR), which manages the supporting
    services. 1. Use the kubectl create command specifying the target namespace to
    apply the Kubernetes manifests as shown in the following example: ```bash kubectl
    create n <your_namespace> f ./01_basic/manifests/. ``` 2. After deployment, monitor
    the status of the workflow pods as shown in the following example: ```yaml kubectl
    get pods n <your_namespace> l app=basic ``` The pod may initially appear in an
    Error state because of missing or incomplete configuration in the Secret or ConfigMap.
    3. Inspect the Pod logs as shown in the following example: ```yaml oc logs n <your_namespace>
    basic f7c6ff455 vwl56 ``` The following code is an example of the output: ```yaml
    SRCFG00040: The config property quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token
    is defined as the empty String ("") which the following Converter considered to
    be null: io.smallrye.config.Converters$BuiltInConverter java.lang.RuntimeException:
    Failed to start quarkus ... Caused by: io.quarkus.runtime.configuration.ConfigurationException:
    Failed to read configuration properties ``` The error indicates a missing property:
    quarkus.openapi-generator.notifications.auth.BearerToken.bearer-token. 4. In such
    a case where the logs show the ConfigurationException: Failed to read configuration
    properties error or indicate a missing value, retrieve the ConfigMap as shown
    in the following example: ```yaml oc get n <your_namespace> configmaps basic props
    o yaml ``` The following code is an example of the sample output: ```yaml apiVersion:
    v1 data: application.properties: | # Backstage notifications service quarkus.rest
    client.notifications.url=${BACKSTAGE_NOTIFICATIONS_URL} quarkus.openapi generator.notifications.auth.BearerToken.bearer
    token=${NOTIFICATIONS_BEARER_TOKEN} ... ``` Resolve the placeholders using values
    provided using a Secret. 5. You must edit the corresponding Secret and provide
    appropriate base64-encoded values to resolve the placeholders in application.properties
    as shown in the following example: ```yaml kubectl edit secrets n <your_namespace>
    basic secrets ``` 6. Restart the workflow Pod for Secret changes to take effect
    in OpenShift Serverless Logic v1.36. 1. Verify the deployment status by checking
    the Pods again as shown in the following example: ```yaml oc get pods n <your_namespace>
    l app=basic ``` The expected status for a successfully deployed workflow Pod is
    as shown in the following example: ```yaml NAME READY STATUS RESTARTS AGE basic-f7c6ff455-grkxd
    1/1 Running 0 47s ``` 2. Once the Pod is in the Running state, the workflow now
    appears in the Orchestrator plugin inside the Red Hat Developer Hub. Inspect the
    provided build script to extract the actual steps and implement them in your preferred
    CI/CD tool, for example, GitHub Actions, GitLab CI, Jenkins, and Tekton. # Installing
    Red Hat Developer Hub with Orchestrator To install Red Hat Developer Hub, use
    one of the following methods: The Red Hat Developer Hub Operator The Red Hat Developer
    Hub Helm chart ##'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:38:49.817947'
    uuid: 57cb86f5-3ca9-49ca-901e-d3bd57afce52
  response: You must restart the workflow Pod for Secret changes to take effect in
    OpenShift Serverless Logic v1.36.
  user_input: Why I must restart pod for OpenShift Serverless Logic after secret change?
- context:
  - 'Enabling the Orchestrator plugin using Operator You can enable the Orchestrator
    plugin in RHDH by configuring dynamic plugins in your Backstage custom resource
    (CR). You have installed RHDH on OpenShift Container Platform. You have access
    to edit or create ConfigMaps in the namespace where the Backstage CR is deployed.
    1. To enable the Orchestrator plugin with default settings, set disabled: false
    for the package. For example, package: "@redhat/backstage-plugin-orchestrator@<plugin_version>
    is set to disabled: false: ```yaml package: "@redhat/backstage plugin orchestrator@<plugin_version>"
    disabled: false ``` Example: Complete configuration of the Orchestrator plugin
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: orchestrator plugin data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.7.1" disabled: false pluginConfig: dynamicPlugins:
    frontend: red hat developer hub.backstage plugin orchestrator: appIcons: importName:
    OrchestratorIcon name: orchestratorIcon dynamicRoutes: importName: OrchestratorPage
    menuItem: icon: orchestratorIcon text: Orchestrator path: /orchestrator entityTabs:
    path: /workflows title: Workflows mountPoint: entity.page.workflows mountPoints:
    mountPoint: entity.page.workflows/cards importName: OrchestratorCatalogTab config:
    layout: gridColumn: ''1 / 1'' if: anyOf: IsOrchestratorCatalogTabAvailable package:
    "@redhat/backstage plugin orchestrator backend dynamic@1.7.1" disabled: false
    pluginConfig: orchestrator: dataIndexService: url: http://sonataflow platform
    data index service dependencies: ref: sonataflow package: "@redhat/backstage plugin
    scaffolder backend module orchestrator dynamic@1.7.1" disabled: false pluginConfig:
    orchestrator: dataIndexService: url: http://sonataflow platform data index service
    package: "@redhat/backstage plugin orchestrator form widgets@1.7.1" disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin orchestrator form widgets: { } -- apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: orchestrator spec: application: appConfig: configMaps:
    name: app config rhdh dynamicPluginsConfigMapName: orchestrator plugin ``` 2.
    Create a secret containing the BACKEND_SECRET value as shown in the following
    example: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh
    data: app-config.yaml: |- auth: environment: development providers: guest: # using
    the guest user to query the ''/api/dynamic-plugins-info/loaded-plugins'' endpoint.
    dangerouslyAllowOutsideDevelopment: true backend: auth: externalAccess: - type:
    static options: token: ${BACKEND_SECRET} subject: orchestrator --- apiVersion:
    v1 kind: Secret metadata: name: backend-auth-secret stringData: # generated with
    the command below (from https://backstage.io/docs/auth/service-to-service-auth/#setup):
    # node -p ''require("crypto").randomBytes(24).toString("base64")'' # notsecret
    BACKEND_SECRET: "R2FxRVNrcmwzYzhhN3l0V1VRcnQ3L1pLT09WaVhDNUEK" ``` 3. Configure
    your Backstage CR to update the secret name in the extraEnvs field as shown in
    the following example: ```yaml apiVersion: rhdh.redhat.com/v1alpha4 kind: Backstage
    metadata: name: orchestrator spec: application: appConfig: configMaps: - name:
    app-config-rhdh dynamicPluginsConfigMapName: orchestrator-plugin extraEnvs: secrets:
    # secret that contains the BACKEND_SECRET key - name: backend-auth-secret ```
    In the RHDH console, confirm that the Orchestrator frontend and backend features
    are available. ## Upgrading the Orchestrator plugin from 1.7 to 1.8 You can upgrade
    an existing 1.7 Operator-backed instance with Orchestrator enabled by upgrading
    the Red Hat Developer Hub Operator to 1.8. After upgrading the Operator to 1.8,
    manually update the dynamic-plugins ConfigMap to set the Orchestrator plugin versions
    to 1.8.2. You have have a running instance of Red Hat Developer Hub with Orchestrator
    1.7 backed by the Operator. You have upgraded the Red Hat Developer Hub Operator
    to 1.8. 1. Update your dynamic-plugins ConfigMap to set the version of the Orchestrator
    plugin to 1.8.2. The following YAML configuration is an example of a dynamic-plugins
    ConfigMap enabling the Orchestrator plugins in RHDH for Operator-backed instances:
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic plugins rhdh data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.8.2" disabled: false package: "@redhat/backstage
    plugin orchestrator backend dynamic@1.8.2" disabled: false dependencies: ref:
    sonataflow package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.2" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.2" disabled: false ``` 1. Navigate to your Red Hat Developer
    Hub instance. [NOTE] ---- The upgrade takes a few minutes to complete. The Red
    Hat Developer Hub version does not update in the UI until all running Backstage
    pods are successfully recreated. ---- 2. From the profile dropdown in the top
    menu, click the Settings icon and then locate the RHDH metadata card. 3. Confirm
    that the value displayed for RHDH version is 1.8. 4. Alternatively, run the following
    command in your terminal to wait for all pods in the current project to be in
    the running state: ```terminal oc get pods w ``` The upgrade is successful when
    all Backstage-related pods show a stable Running status. ## Installing Red Hat
    Developer Hub (RHDH) on OpenShift Container Platform with the Orchestrator using
    the Helm CLI You can install Red Hat Developer Hub (RHDH) on OpenShift Container
    Platform with the Orchestrator by using the Helm CLI. The installation automatically
    enables the required dynamic plugins and integrates workflow infrastructure. You
    are logged in as an administrator and have access to the Red Hat Developer Hub
    Helm chart repository. You can install the necessary infrastructures resources,
    such as SonataFlow, alongside RHDH in the same namespace. This is a one-off requirement
    and must be completed before enabling the Orchestrator plugin. 1. As an administrator,
    install relevant cluster-wide resources. ```yaml helm repo add openshift helm
    charts https://charts.openshift.io/ helm install <release_name> openshift helm
    charts/redhat developer hub orchestrator infra ``` [IMPORTANT] ---- You must be
    an administrator to install the redhat-developer-hub-orchestrator-infra Helm chart
    because it deploys additional cluster-scoped OpenShift Serverless and OpenShift
    Serverless Logic Operators. As an administrator, you must manually approve the
    install plans for OpenShift Serverless and Serverless Logic Operators. ---- 2.
    Install the Backstage chart with the orchestrator enabled as shown in the following
    example: ```terminal $ helm install <release_name> openshift-helm-charts/redhat-developer-hub
    --version 1.8.0 \ --set orchestrator.enabled=true ``` 3. (Optional) Enable Notifications
    and Signals plugins by adding them to the global.dynamic.plugins list in your
    values.yaml file as shown in the following example: ```yaml global: dynamic: plugins:
    disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" ``` 4. (Optional) You can disable the Serverless Logic and Serverless
    Operators individually or together by setting their values to false, as shown
    in the following example: ```terminal helm install <release_name> openshift helm
    charts/redhat developer hub \ version 1.8.0 \ set orchestrator.enabled=true \
    set orchestrator.serverlessOperator=false \ set orchestrator.serverlessLogicOperator=false
    ``` 5. (Optional) If you are using an external database, add the following configuration
    under orchestrator.sonataflowPlatform in your values.yaml file: ```yaml orchestrator:
    sonataflowPlatform: externalDBsecretRef: "<cred-secret>" externalDBName: "<database_name>"
    # The name of the user-configured existing database (Not'
  metadata:
    classification:
      category: kubernetes
      datetime: '2025-12-10T16:39:01.931163'
    uuid: 908195a2-ab8b-40e6-b3fd-b5c0d33c79b1
  response: "You configure your Backstage CR to update the secret name in the extraEnvs\
    \ field. An example is shown in the following YAML: ```yaml\napiVersion: rhdh.redhat.com/v1alpha4\n\
    kind: Backstage\nmetadata:\n  name: orchestrator\nspec:\n  application:\n    appConfig:\n\
    \      configMaps:\n        - name: app-config-rhdh\n      dynamicPluginsConfigMapName:\
    \ orchestrator-plugin\n    extraEnvs:\n      secrets:\n        # secret that contains\
    \ the BACKEND_SECRET key\n        - name: backend-auth-secret\n```"
  user_input: How do I configure my Backstge CR to use a secert?
- context:
  - 'Enabling the Orchestrator plugin using Operator You can enable the Orchestrator
    plugin in RHDH by configuring dynamic plugins in your Backstage custom resource
    (CR). You have installed RHDH on OpenShift Container Platform. You have access
    to edit or create ConfigMaps in the namespace where the Backstage CR is deployed.
    1. To enable the Orchestrator plugin with default settings, set disabled: false
    for the package. For example, package: "@redhat/backstage-plugin-orchestrator@<plugin_version>
    is set to disabled: false: ```yaml package: "@redhat/backstage plugin orchestrator@<plugin_version>"
    disabled: false ``` Example: Complete configuration of the Orchestrator plugin
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: orchestrator plugin data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.7.1" disabled: false pluginConfig: dynamicPlugins:
    frontend: red hat developer hub.backstage plugin orchestrator: appIcons: importName:
    OrchestratorIcon name: orchestratorIcon dynamicRoutes: importName: OrchestratorPage
    menuItem: icon: orchestratorIcon text: Orchestrator path: /orchestrator entityTabs:
    path: /workflows title: Workflows mountPoint: entity.page.workflows mountPoints:
    mountPoint: entity.page.workflows/cards importName: OrchestratorCatalogTab config:
    layout: gridColumn: ''1 / 1'' if: anyOf: IsOrchestratorCatalogTabAvailable package:
    "@redhat/backstage plugin orchestrator backend dynamic@1.7.1" disabled: false
    pluginConfig: orchestrator: dataIndexService: url: http://sonataflow platform
    data index service dependencies: ref: sonataflow package: "@redhat/backstage plugin
    scaffolder backend module orchestrator dynamic@1.7.1" disabled: false pluginConfig:
    orchestrator: dataIndexService: url: http://sonataflow platform data index service
    package: "@redhat/backstage plugin orchestrator form widgets@1.7.1" disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin orchestrator form widgets: { } -- apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: orchestrator spec: application: appConfig: configMaps:
    name: app config rhdh dynamicPluginsConfigMapName: orchestrator plugin ``` 2.
    Create a secret containing the BACKEND_SECRET value as shown in the following
    example: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh
    data: app-config.yaml: |- auth: environment: development providers: guest: # using
    the guest user to query the ''/api/dynamic-plugins-info/loaded-plugins'' endpoint.
    dangerouslyAllowOutsideDevelopment: true backend: auth: externalAccess: - type:
    static options: token: ${BACKEND_SECRET} subject: orchestrator --- apiVersion:
    v1 kind: Secret metadata: name: backend-auth-secret stringData: # generated with
    the command below (from https://backstage.io/docs/auth/service-to-service-auth/#setup):
    # node -p ''require("crypto").randomBytes(24).toString("base64")'' # notsecret
    BACKEND_SECRET: "R2FxRVNrcmwzYzhhN3l0V1VRcnQ3L1pLT09WaVhDNUEK" ``` 3. Configure
    your Backstage CR to update the secret name in the extraEnvs field as shown in
    the following example: ```yaml apiVersion: rhdh.redhat.com/v1alpha4 kind: Backstage
    metadata: name: orchestrator spec: application: appConfig: configMaps: - name:
    app-config-rhdh dynamicPluginsConfigMapName: orchestrator-plugin extraEnvs: secrets:
    # secret that contains the BACKEND_SECRET key - name: backend-auth-secret ```
    In the RHDH console, confirm that the Orchestrator frontend and backend features
    are available. ## Upgrading the Orchestrator plugin from 1.7 to 1.8 You can upgrade
    an existing 1.7 Operator-backed instance with Orchestrator enabled by upgrading
    the Red Hat Developer Hub Operator to 1.8. After upgrading the Operator to 1.8,
    manually update the dynamic-plugins ConfigMap to set the Orchestrator plugin versions
    to 1.8.2. You have have a running instance of Red Hat Developer Hub with Orchestrator
    1.7 backed by the Operator. You have upgraded the Red Hat Developer Hub Operator
    to 1.8. 1. Update your dynamic-plugins ConfigMap to set the version of the Orchestrator
    plugin to 1.8.2. The following YAML configuration is an example of a dynamic-plugins
    ConfigMap enabling the Orchestrator plugins in RHDH for Operator-backed instances:
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic plugins rhdh data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.8.2" disabled: false package: "@redhat/backstage
    plugin orchestrator backend dynamic@1.8.2" disabled: false dependencies: ref:
    sonataflow package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.2" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.2" disabled: false ``` 1. Navigate to your Red Hat Developer
    Hub instance. [NOTE] ---- The upgrade takes a few minutes to complete. The Red
    Hat Developer Hub version does not update in the UI until all running Backstage
    pods are successfully recreated. ---- 2. From the profile dropdown in the top
    menu, click the Settings icon and then locate the RHDH metadata card. 3. Confirm
    that the value displayed for RHDH version is 1.8. 4. Alternatively, run the following
    command in your terminal to wait for all pods in the current project to be in
    the running state: ```terminal oc get pods w ``` The upgrade is successful when
    all Backstage-related pods show a stable Running status. ## Installing Red Hat
    Developer Hub (RHDH) on OpenShift Container Platform with the Orchestrator using
    the Helm CLI You can install Red Hat Developer Hub (RHDH) on OpenShift Container
    Platform with the Orchestrator by using the Helm CLI. The installation automatically
    enables the required dynamic plugins and integrates workflow infrastructure. You
    are logged in as an administrator and have access to the Red Hat Developer Hub
    Helm chart repository. You can install the necessary infrastructures resources,
    such as SonataFlow, alongside RHDH in the same namespace. This is a one-off requirement
    and must be completed before enabling the Orchestrator plugin. 1. As an administrator,
    install relevant cluster-wide resources. ```yaml helm repo add openshift helm
    charts https://charts.openshift.io/ helm install <release_name> openshift helm
    charts/redhat developer hub orchestrator infra ``` [IMPORTANT] ---- You must be
    an administrator to install the redhat-developer-hub-orchestrator-infra Helm chart
    because it deploys additional cluster-scoped OpenShift Serverless and OpenShift
    Serverless Logic Operators. As an administrator, you must manually approve the
    install plans for OpenShift Serverless and Serverless Logic Operators. ---- 2.
    Install the Backstage chart with the orchestrator enabled as shown in the following
    example: ```terminal $ helm install <release_name> openshift-helm-charts/redhat-developer-hub
    --version 1.8.0 \ --set orchestrator.enabled=true ``` 3. (Optional) Enable Notifications
    and Signals plugins by adding them to the global.dynamic.plugins list in your
    values.yaml file as shown in the following example: ```yaml global: dynamic: plugins:
    disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" ``` 4. (Optional) You can disable the Serverless Logic and Serverless
    Operators individually or together by setting their values to false, as shown
    in the following example: ```terminal helm install <release_name> openshift helm
    charts/redhat developer hub \ version 1.8.0 \ set orchestrator.enabled=true \
    set orchestrator.serverlessOperator=false \ set orchestrator.serverlessLogicOperator=false
    ``` 5. (Optional) If you are using an external database, add the following configuration
    under orchestrator.sonataflowPlatform in your values.yaml file: ```yaml orchestrator:
    sonataflowPlatform: externalDBsecretRef: "<cred-secret>" externalDBName: "<database_name>"
    # The name of the user-configured existing database (Not'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:39:13.470623'
    uuid: 7108d109-eeb9-4ec5-8505-4063bf5f26d2
  response: You must be an administrator to install the redhat-developer-hub-orchestrator-infra
    Helm chart because it deploys additional cluster-scoped OpenShift Serverless and
    OpenShift Serverless Logic Operators. As an administrator, you must manually approve
    the install plans for OpenShift Serverless and Serverless Logic Operators.
  user_input: why i need admin for OpenShift Serverless install
- context:
  - 'Enabling the Orchestrator plugin using Operator You can enable the Orchestrator
    plugin in RHDH by configuring dynamic plugins in your Backstage custom resource
    (CR). You have installed RHDH on OpenShift Container Platform. You have access
    to edit or create ConfigMaps in the namespace where the Backstage CR is deployed.
    1. To enable the Orchestrator plugin with default settings, set disabled: false
    for the package. For example, package: "@redhat/backstage-plugin-orchestrator@<plugin_version>
    is set to disabled: false: ```yaml package: "@redhat/backstage plugin orchestrator@<plugin_version>"
    disabled: false ``` Example: Complete configuration of the Orchestrator plugin
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: orchestrator plugin data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.7.1" disabled: false pluginConfig: dynamicPlugins:
    frontend: red hat developer hub.backstage plugin orchestrator: appIcons: importName:
    OrchestratorIcon name: orchestratorIcon dynamicRoutes: importName: OrchestratorPage
    menuItem: icon: orchestratorIcon text: Orchestrator path: /orchestrator entityTabs:
    path: /workflows title: Workflows mountPoint: entity.page.workflows mountPoints:
    mountPoint: entity.page.workflows/cards importName: OrchestratorCatalogTab config:
    layout: gridColumn: ''1 / 1'' if: anyOf: IsOrchestratorCatalogTabAvailable package:
    "@redhat/backstage plugin orchestrator backend dynamic@1.7.1" disabled: false
    pluginConfig: orchestrator: dataIndexService: url: http://sonataflow platform
    data index service dependencies: ref: sonataflow package: "@redhat/backstage plugin
    scaffolder backend module orchestrator dynamic@1.7.1" disabled: false pluginConfig:
    orchestrator: dataIndexService: url: http://sonataflow platform data index service
    package: "@redhat/backstage plugin orchestrator form widgets@1.7.1" disabled:
    false pluginConfig: dynamicPlugins: frontend: red hat developer hub.backstage
    plugin orchestrator form widgets: { } -- apiVersion: rhdh.redhat.com/v1alpha3
    kind: Backstage metadata: name: orchestrator spec: application: appConfig: configMaps:
    name: app config rhdh dynamicPluginsConfigMapName: orchestrator plugin ``` 2.
    Create a secret containing the BACKEND_SECRET value as shown in the following
    example: ```yaml apiVersion: v1 kind: ConfigMap metadata: name: app-config-rhdh
    data: app-config.yaml: |- auth: environment: development providers: guest: # using
    the guest user to query the ''/api/dynamic-plugins-info/loaded-plugins'' endpoint.
    dangerouslyAllowOutsideDevelopment: true backend: auth: externalAccess: - type:
    static options: token: ${BACKEND_SECRET} subject: orchestrator --- apiVersion:
    v1 kind: Secret metadata: name: backend-auth-secret stringData: # generated with
    the command below (from https://backstage.io/docs/auth/service-to-service-auth/#setup):
    # node -p ''require("crypto").randomBytes(24).toString("base64")'' # notsecret
    BACKEND_SECRET: "R2FxRVNrcmwzYzhhN3l0V1VRcnQ3L1pLT09WaVhDNUEK" ``` 3. Configure
    your Backstage CR to update the secret name in the extraEnvs field as shown in
    the following example: ```yaml apiVersion: rhdh.redhat.com/v1alpha4 kind: Backstage
    metadata: name: orchestrator spec: application: appConfig: configMaps: - name:
    app-config-rhdh dynamicPluginsConfigMapName: orchestrator-plugin extraEnvs: secrets:
    # secret that contains the BACKEND_SECRET key - name: backend-auth-secret ```
    In the RHDH console, confirm that the Orchestrator frontend and backend features
    are available. ## Upgrading the Orchestrator plugin from 1.7 to 1.8 You can upgrade
    an existing 1.7 Operator-backed instance with Orchestrator enabled by upgrading
    the Red Hat Developer Hub Operator to 1.8. After upgrading the Operator to 1.8,
    manually update the dynamic-plugins ConfigMap to set the Orchestrator plugin versions
    to 1.8.2. You have have a running instance of Red Hat Developer Hub with Orchestrator
    1.7 backed by the Operator. You have upgraded the Red Hat Developer Hub Operator
    to 1.8. 1. Update your dynamic-plugins ConfigMap to set the version of the Orchestrator
    plugin to 1.8.2. The following YAML configuration is an example of a dynamic-plugins
    ConfigMap enabling the Orchestrator plugins in RHDH for Operator-backed instances:
    ```yaml apiVersion: v1 kind: ConfigMap metadata: name: dynamic plugins rhdh data:
    dynamic plugins.yaml: | includes: dynamic plugins.default.yaml plugins: package:
    "@redhat/backstage plugin orchestrator@1.8.2" disabled: false package: "@redhat/backstage
    plugin orchestrator backend dynamic@1.8.2" disabled: false dependencies: ref:
    sonataflow package: "@redhat/backstage plugin scaffolder backend module orchestrator
    dynamic@1.8.2" disabled: false package: "@redhat/backstage plugin orchestrator
    form widgets@1.8.2" disabled: false ``` 1. Navigate to your Red Hat Developer
    Hub instance. [NOTE] ---- The upgrade takes a few minutes to complete. The Red
    Hat Developer Hub version does not update in the UI until all running Backstage
    pods are successfully recreated. ---- 2. From the profile dropdown in the top
    menu, click the Settings icon and then locate the RHDH metadata card. 3. Confirm
    that the value displayed for RHDH version is 1.8. 4. Alternatively, run the following
    command in your terminal to wait for all pods in the current project to be in
    the running state: ```terminal oc get pods w ``` The upgrade is successful when
    all Backstage-related pods show a stable Running status. ## Installing Red Hat
    Developer Hub (RHDH) on OpenShift Container Platform with the Orchestrator using
    the Helm CLI You can install Red Hat Developer Hub (RHDH) on OpenShift Container
    Platform with the Orchestrator by using the Helm CLI. The installation automatically
    enables the required dynamic plugins and integrates workflow infrastructure. You
    are logged in as an administrator and have access to the Red Hat Developer Hub
    Helm chart repository. You can install the necessary infrastructures resources,
    such as SonataFlow, alongside RHDH in the same namespace. This is a one-off requirement
    and must be completed before enabling the Orchestrator plugin. 1. As an administrator,
    install relevant cluster-wide resources. ```yaml helm repo add openshift helm
    charts https://charts.openshift.io/ helm install <release_name> openshift helm
    charts/redhat developer hub orchestrator infra ``` [IMPORTANT] ---- You must be
    an administrator to install the redhat-developer-hub-orchestrator-infra Helm chart
    because it deploys additional cluster-scoped OpenShift Serverless and OpenShift
    Serverless Logic Operators. As an administrator, you must manually approve the
    install plans for OpenShift Serverless and Serverless Logic Operators. ---- 2.
    Install the Backstage chart with the orchestrator enabled as shown in the following
    example: ```terminal $ helm install <release_name> openshift-helm-charts/redhat-developer-hub
    --version 1.8.0 \ --set orchestrator.enabled=true ``` 3. (Optional) Enable Notifications
    and Signals plugins by adding them to the global.dynamic.plugins list in your
    values.yaml file as shown in the following example: ```yaml global: dynamic: plugins:
    disabled: false package: "./dynamic plugins/dist/backstage plugin notifications"
    disabled: false package: "./dynamic plugins/dist/backstage plugin signals" disabled:
    false package: "./dynamic plugins/dist/backstage plugin notifications backend
    dynamic" disabled: false package: "./dynamic plugins/dist/backstage plugin signals
    backend dynamic" ``` 4. (Optional) You can disable the Serverless Logic and Serverless
    Operators individually or together by setting their values to false, as shown
    in the following example: ```terminal helm install <release_name> openshift helm
    charts/redhat developer hub \ version 1.8.0 \ set orchestrator.enabled=true \
    set orchestrator.serverlessOperator=false \ set orchestrator.serverlessLogicOperator=false
    ``` 5. (Optional) If you are using an external database, add the following configuration
    under orchestrator.sonataflowPlatform in your values.yaml file: ```yaml orchestrator:
    sonataflowPlatform: externalDBsecretRef: "<cred-secret>" externalDBName: "<database_name>"
    # The name of the user-configured existing database (Not'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:39:24.036063'
    uuid: 81389ced-c2f5-4f4b-b539-a5b10380a54a
  response: 'To install Red Hat Developer Hub (RHDH) on OpenShift Container Platform
    with the Orchestrator using the Helm CLI, you must be logged in as an administrator
    with access to the Red Hat Developer Hub Helm chart repository. First, as an administrator,
    you must install the relevant cluster-wide resources by running `helm install
    <release_name> openshift helm charts/redhat developer hub orchestrator infra`.
    This step requires an administrator because it deploys cluster-scoped OpenShift
    Serverless and Serverless Logic Operators, and their install plans must be manually
    approved. After that, install the Backstage chart with the orchestrator enabled
    using the command: `helm install <release_name> openshift-helm-charts/redhat-developer-hub
    --version 1.8.0 --set orchestrator.enabled=true`. There are also optional steps,
    such as enabling Notifications and Signals plugins, disabling the Serverless operators,
    or configuring an external database.'
  user_input: As a Platform Engineer, what is the procedure for installing RHDH on
    OpenShift Container Platform with the Orchestrator plugin by using the Helm CLI?
- context:
  - 'the database that the orchestrator and sonataflow resources use). externalDBHost:
    "<database_host>" externalDBPort: "<database_port>" ``` [NOTE] ---- This step
    only configures the Orchestrators use of an external database. To configure Red
    Hat Developer Hub to use an external PostgreSQL instance, follow the steps in
    Configuring a PostgreSQL instance using Helm. ---- 1. Verify that the Orchestrator
    plugin is visible in the Red Hat Developer Hub UI. 2. Create and run sample workflows
    to confirm the orchestration is functioning correctly. ## Install Red Hat Developer
    Hub (RHDH) using Helm from the OpenShift Container Platform web console You can
    install Red Hat Developer Hub (RHDH) with the Orchestrator by using the (OpenShift
    Container Platform) web console. This method is useful if you prefer a graphical
    interface or want to deploy cluster-wide resources without using the Helm CLI.
    You are logged in to the OpenShift Container Platform web console as an administrator.
    You have access to the Red Hat Developer Hub Helm chart repository. Your cluster
    has internet access or the Helm charts are mirrored in a disconnected environment.
    1. In the OpenShift Container Platform web console, go to the Helm Charts and
    verify that the Red Hat Developer Hub Helm chart repository is available. 2. Search
    for the Orchestrator infrastructure for Red Hat Developer Hub and select Install.
    [IMPORTANT] ---- You must be an administrator to install the Orchestrator Infrastructure
    for Red Hat Developer Hub Helm chart because it deploys cluster-scoped resources.
    As an administrator, you must manually approve the install plans for OpenShift
    Serverless and Serverless Logic Operators. ---- As a regular user, search for
    the Red Hat Developer Hub chart and install it by setting the value of orchestrator.enabled
    to true. Otherwise, the Orchestrator will not be deployed. 3. Wait until they
    are successfully deployed. 4. Monitor the deployment status by navigating to Pods
    or releases. After deployment completes: The orchestrator related pods are running
    in the selected namespace. Cluster wide resources are present. You can start connecting
    the orchestrator to your Red Hat Developer Hub UI. ## Resource limits for installing
    Red Hat Developer Hub with the Orchestrator plugin when using Helm When installing
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin using Helm, the chart
    defines default CPU and memory limits for the SonataFlowPlatform component. These
    limits are enforced by the cluster so that pods do not exceed their allocated
    resources. 1. Default resource limits 1. You can override these values in any
    of the following ways: * With values.yaml * With --set flags 2. Override defaults
    with values.yaml as shown in the following example: ```yaml orchestrator: enabled:
    true sonataflowPlatform: resources: limits: cpu: "500m" memory: "1Gi" ``` 3. Override
    with --set as shown in the following example: ```terminal helm upgrade - install
    <release_name> openshift helm charts/redhat developer hub \ set orchestrator.enabled=true
    \ set orchestrator.sonataflowPlatform.resources.requests.cpu=500m \ set orchestrator.sonataflowPlatform.resources.requests.memory=128Mi
    \ set orchestrator.sonataflowPlatform.resources.limits.cpu=1 \ set orchestrator.sonataflowPlatform.resources.limits.memory=2Gi
    ``` [NOTE] ---- The --set setting is applicable only when orchestrator.enabled
    is true. By default, it is set to false. ---- # Installing Orchestrator plugin
    in an air-gapped environment with the Helm chart You can configure Red Hat Developer
    Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially disconnected
    environment by using the Helm chart. ## Installing Red Hat Developer Hub with
    Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Helm chart You can install Red Hat Developer Hub (RHDH) with the Orchestrator
    plugin in a fully air-gapped OpenShift Container Platform environment using the
    Helm chart. You can mirror images to an intermediary disk, and then mirror from
    the disk to your target local registry and apply the generated cluster resources.
    You have set up your disconnected environment using a local registry. You have
    permissions to push NPM packages to an NPM server available in your restricted
    network. You have installed the oc mirror tool, with a version corresponding to
    the version of your OpenShift Container Platform cluster. 1. Create an ImageSetConfiguration.yaml
    file for oc-mirror. You must use an ImageSetConfiguration file to include all
    mirrored images required by the Serverless Logic Operator, as shown in the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman
    commands to find the missing images and add them to the additionalimages list
    if the versions change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command pulls the charts listed in the ImageSetConfiguration file
    and makes them available as tgz archives under the /path/to/mirror-archive directory.
    ---- 3. Apply the cluster-wide resources generated during the push step to redirect
    all image pulls to your local registry, as shown in the following example: ```terminal
    cd <workspace folder>/working dir/cluster resources/ oc apply f . ``` 4. Transfer
    the generated mirror archive file, for example, /path/to/mirror-archive/mirror_000001.tar,
    to a bastion host within your disconnected environment. 5. From the bastion host
    in your disconnected environment, which has access to the mirror registry, mirror
    the images from the archive file to your target registry. For example: ```terminal
    oc mirror - v2 - from <mirror archive file> docker://<target registry'
  metadata:
    classification:
      category: configuration
      datetime: '2025-12-10T16:39:34.476251'
    uuid: eea7d8a2-b7be-427f-982f-808b8c085634
  response: To configure Red Hat Developer Hub to use an external PostgreSQL instance,
    you must follow the steps in Configuring a PostgreSQL instance using Helm.
  user_input: How can I configure Red Hat Developer Hub to utilize an external PostgreSQL
    instance?
- context:
  - 'the database that the orchestrator and sonataflow resources use). externalDBHost:
    "<database_host>" externalDBPort: "<database_port>" ``` [NOTE] ---- This step
    only configures the Orchestrators use of an external database. To configure Red
    Hat Developer Hub to use an external PostgreSQL instance, follow the steps in
    Configuring a PostgreSQL instance using Helm. ---- 1. Verify that the Orchestrator
    plugin is visible in the Red Hat Developer Hub UI. 2. Create and run sample workflows
    to confirm the orchestration is functioning correctly. ## Install Red Hat Developer
    Hub (RHDH) using Helm from the OpenShift Container Platform web console You can
    install Red Hat Developer Hub (RHDH) with the Orchestrator by using the (OpenShift
    Container Platform) web console. This method is useful if you prefer a graphical
    interface or want to deploy cluster-wide resources without using the Helm CLI.
    You are logged in to the OpenShift Container Platform web console as an administrator.
    You have access to the Red Hat Developer Hub Helm chart repository. Your cluster
    has internet access or the Helm charts are mirrored in a disconnected environment.
    1. In the OpenShift Container Platform web console, go to the Helm Charts and
    verify that the Red Hat Developer Hub Helm chart repository is available. 2. Search
    for the Orchestrator infrastructure for Red Hat Developer Hub and select Install.
    [IMPORTANT] ---- You must be an administrator to install the Orchestrator Infrastructure
    for Red Hat Developer Hub Helm chart because it deploys cluster-scoped resources.
    As an administrator, you must manually approve the install plans for OpenShift
    Serverless and Serverless Logic Operators. ---- As a regular user, search for
    the Red Hat Developer Hub chart and install it by setting the value of orchestrator.enabled
    to true. Otherwise, the Orchestrator will not be deployed. 3. Wait until they
    are successfully deployed. 4. Monitor the deployment status by navigating to Pods
    or releases. After deployment completes: The orchestrator related pods are running
    in the selected namespace. Cluster wide resources are present. You can start connecting
    the orchestrator to your Red Hat Developer Hub UI. ## Resource limits for installing
    Red Hat Developer Hub with the Orchestrator plugin when using Helm When installing
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin using Helm, the chart
    defines default CPU and memory limits for the SonataFlowPlatform component. These
    limits are enforced by the cluster so that pods do not exceed their allocated
    resources. 1. Default resource limits 1. You can override these values in any
    of the following ways: * With values.yaml * With --set flags 2. Override defaults
    with values.yaml as shown in the following example: ```yaml orchestrator: enabled:
    true sonataflowPlatform: resources: limits: cpu: "500m" memory: "1Gi" ``` 3. Override
    with --set as shown in the following example: ```terminal helm upgrade - install
    <release_name> openshift helm charts/redhat developer hub \ set orchestrator.enabled=true
    \ set orchestrator.sonataflowPlatform.resources.requests.cpu=500m \ set orchestrator.sonataflowPlatform.resources.requests.memory=128Mi
    \ set orchestrator.sonataflowPlatform.resources.limits.cpu=1 \ set orchestrator.sonataflowPlatform.resources.limits.memory=2Gi
    ``` [NOTE] ---- The --set setting is applicable only when orchestrator.enabled
    is true. By default, it is set to false. ---- # Installing Orchestrator plugin
    in an air-gapped environment with the Helm chart You can configure Red Hat Developer
    Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially disconnected
    environment by using the Helm chart. ## Installing Red Hat Developer Hub with
    Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Helm chart You can install Red Hat Developer Hub (RHDH) with the Orchestrator
    plugin in a fully air-gapped OpenShift Container Platform environment using the
    Helm chart. You can mirror images to an intermediary disk, and then mirror from
    the disk to your target local registry and apply the generated cluster resources.
    You have set up your disconnected environment using a local registry. You have
    permissions to push NPM packages to an NPM server available in your restricted
    network. You have installed the oc mirror tool, with a version corresponding to
    the version of your OpenShift Container Platform cluster. 1. Create an ImageSetConfiguration.yaml
    file for oc-mirror. You must use an ImageSetConfiguration file to include all
    mirrored images required by the Serverless Logic Operator, as shown in the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman
    commands to find the missing images and add them to the additionalimages list
    if the versions change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command pulls the charts listed in the ImageSetConfiguration file
    and makes them available as tgz archives under the /path/to/mirror-archive directory.
    ---- 3. Apply the cluster-wide resources generated during the push step to redirect
    all image pulls to your local registry, as shown in the following example: ```terminal
    cd <workspace folder>/working dir/cluster resources/ oc apply f . ``` 4. Transfer
    the generated mirror archive file, for example, /path/to/mirror-archive/mirror_000001.tar,
    to a bastion host within your disconnected environment. 5. From the bastion host
    in your disconnected environment, which has access to the mirror registry, mirror
    the images from the archive file to your target registry. For example: ```terminal
    oc mirror - v2 - from <mirror archive file> docker://<target registry'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:39:43.172592'
    uuid: 3d48d240-9725-4698-baf2-86506525af19
  response: To install Red Hat Developer Hub (RHDH) with the Orchestrator using the
    OpenShift Container Platform web console, you must be logged in as an administrator,
    have access to the Red Hat Developer Hub Helm chart repository, and your cluster
    must have internet access or have the Helm charts mirrored in a disconnected environment.
    If you are an administrator, you must install the Orchestrator Infrastructure
    for Red Hat Developer Hub Helm chart and manually approve the install plans for
    OpenShift Serverless and Serverless Logic Operators. If you are a regular user,
    you must install the Red Hat Developer Hub chart and set the value of orchestrator.enabled
    to true.
  user_input: how i install Red Hat Developer Hub with orchestrator from the openshift
    console what i need?
- context:
  - 'the database that the orchestrator and sonataflow resources use). externalDBHost:
    "<database_host>" externalDBPort: "<database_port>" ``` [NOTE] ---- This step
    only configures the Orchestrators use of an external database. To configure Red
    Hat Developer Hub to use an external PostgreSQL instance, follow the steps in
    Configuring a PostgreSQL instance using Helm. ---- 1. Verify that the Orchestrator
    plugin is visible in the Red Hat Developer Hub UI. 2. Create and run sample workflows
    to confirm the orchestration is functioning correctly. ## Install Red Hat Developer
    Hub (RHDH) using Helm from the OpenShift Container Platform web console You can
    install Red Hat Developer Hub (RHDH) with the Orchestrator by using the (OpenShift
    Container Platform) web console. This method is useful if you prefer a graphical
    interface or want to deploy cluster-wide resources without using the Helm CLI.
    You are logged in to the OpenShift Container Platform web console as an administrator.
    You have access to the Red Hat Developer Hub Helm chart repository. Your cluster
    has internet access or the Helm charts are mirrored in a disconnected environment.
    1. In the OpenShift Container Platform web console, go to the Helm Charts and
    verify that the Red Hat Developer Hub Helm chart repository is available. 2. Search
    for the Orchestrator infrastructure for Red Hat Developer Hub and select Install.
    [IMPORTANT] ---- You must be an administrator to install the Orchestrator Infrastructure
    for Red Hat Developer Hub Helm chart because it deploys cluster-scoped resources.
    As an administrator, you must manually approve the install plans for OpenShift
    Serverless and Serverless Logic Operators. ---- As a regular user, search for
    the Red Hat Developer Hub chart and install it by setting the value of orchestrator.enabled
    to true. Otherwise, the Orchestrator will not be deployed. 3. Wait until they
    are successfully deployed. 4. Monitor the deployment status by navigating to Pods
    or releases. After deployment completes: The orchestrator related pods are running
    in the selected namespace. Cluster wide resources are present. You can start connecting
    the orchestrator to your Red Hat Developer Hub UI. ## Resource limits for installing
    Red Hat Developer Hub with the Orchestrator plugin when using Helm When installing
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin using Helm, the chart
    defines default CPU and memory limits for the SonataFlowPlatform component. These
    limits are enforced by the cluster so that pods do not exceed their allocated
    resources. 1. Default resource limits 1. You can override these values in any
    of the following ways: * With values.yaml * With --set flags 2. Override defaults
    with values.yaml as shown in the following example: ```yaml orchestrator: enabled:
    true sonataflowPlatform: resources: limits: cpu: "500m" memory: "1Gi" ``` 3. Override
    with --set as shown in the following example: ```terminal helm upgrade - install
    <release_name> openshift helm charts/redhat developer hub \ set orchestrator.enabled=true
    \ set orchestrator.sonataflowPlatform.resources.requests.cpu=500m \ set orchestrator.sonataflowPlatform.resources.requests.memory=128Mi
    \ set orchestrator.sonataflowPlatform.resources.limits.cpu=1 \ set orchestrator.sonataflowPlatform.resources.limits.memory=2Gi
    ``` [NOTE] ---- The --set setting is applicable only when orchestrator.enabled
    is true. By default, it is set to false. ---- # Installing Orchestrator plugin
    in an air-gapped environment with the Helm chart You can configure Red Hat Developer
    Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially disconnected
    environment by using the Helm chart. ## Installing Red Hat Developer Hub with
    Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Helm chart You can install Red Hat Developer Hub (RHDH) with the Orchestrator
    plugin in a fully air-gapped OpenShift Container Platform environment using the
    Helm chart. You can mirror images to an intermediary disk, and then mirror from
    the disk to your target local registry and apply the generated cluster resources.
    You have set up your disconnected environment using a local registry. You have
    permissions to push NPM packages to an NPM server available in your restricted
    network. You have installed the oc mirror tool, with a version corresponding to
    the version of your OpenShift Container Platform cluster. 1. Create an ImageSetConfiguration.yaml
    file for oc-mirror. You must use an ImageSetConfiguration file to include all
    mirrored images required by the Serverless Logic Operator, as shown in the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman
    commands to find the missing images and add them to the additionalimages list
    if the versions change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command pulls the charts listed in the ImageSetConfiguration file
    and makes them available as tgz archives under the /path/to/mirror-archive directory.
    ---- 3. Apply the cluster-wide resources generated during the push step to redirect
    all image pulls to your local registry, as shown in the following example: ```terminal
    cd <workspace folder>/working dir/cluster resources/ oc apply f . ``` 4. Transfer
    the generated mirror archive file, for example, /path/to/mirror-archive/mirror_000001.tar,
    to a bastion host within your disconnected environment. 5. From the bastion host
    in your disconnected environment, which has access to the mirror registry, mirror
    the images from the archive file to your target registry. For example: ```terminal
    oc mirror - v2 - from <mirror archive file> docker://<target registry'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:39:52.961060'
    uuid: cf34d655-c238-449b-ab0f-4021d94c567d
  response: 'As an alternative for finding missing images to add to the additionalimages
    list if versions change, you can use a series of podman commands. The sequence
    is as follows: `IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36`,
    `mkdir local-manifests-osl`, `podman create --name temp-container "$IMG" -c "cat
    /manifests/logic-operator-rhel8.clusterserviceversion.yaml"`, `podman cp temp-container:/manifests
    ./local-manifests-osl`, `podman rm temp-container`, and finally `yq -r ''.data."controllers_cfg.yaml"
    | from_yaml | .. | select(tag == "!!str") | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml`.'
  user_input: Regarding the installation of the Orchestrator plugin within a fully
    disconnected OpenShift environment, what is the specific sequence of podman commands
    that can be utilized as an alternative method to identify missing images for the
    additionalimages list, particularly when image versions have been altered?
- context:
  - 'url:port> - workspace file://<workspace folder> - authfile /path/to/authfile
    ``` where: <mirror-archive-file>:: Enter the name of the transferred tar file.
    <target-registry-url:port>:: Enter your local registry, for example, registry.localhost:5000.
    6. Download the Node Package Manager (NPM) packages for orchestrator 1.8.0 using
    any of the following methods: * Download them as tgz files from the following
    registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 9. Apply the RHDH 1.8 Helm chart. Include the
    version 1.8.0 and enable the Orchestrator plugin, as shown in the following example:
    ```yaml orchestrator.enabled=true ``` 10. The RHDH 1.8 Helm chart defaults to
    pulling Orchestrator plugins from the official Red Hat NPM registry using full
    URL references. You must override this behavior to point to your local registry.
    To configure the Orchestrator plugins to use a custom registry, complete the following
    steps: * Open your values.yaml file. * Explicitly list the Orchestrator plugin
    packages under the orchestrator.plugins section. You must replace the simplified
    package references with the full URLs that point to your custom NPM registry,
    as shown in the following example: ```yaml orchestrator: plugins: disabled: false
    package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    backend dynamic/ /backstage plugin orchestrator backend dynamic {product bundle
    version}.tgz integrity: sha512 xxxxxx disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator/ /backstage plugin orchestrator {product bundle version}.tgz
    integrity: sha512 xxxxxy disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator form widgets/ /backstage plugin orchestrator form widgets
    {product bundle version}.tgz integrity: sha512 xxxxxz disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin scaffolder backend
    module orchestrator dynamic/ /backstage plugin scaffolder backend module orchestrator
    dynamic {product bundle version}.tgz integrity: sha512 xxxx1 ``` where: <custom_NPM_registry_URL>::
    Enter the address of your custom registry and make sure the integrity checksum,
    such as sha512-xxxxxx, matches the files in your registry. Restart the RHDH Pod
    and wait for the components to deploy properly. After deployment is complete,
    go to the RHDH UI and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Helm chart You can install
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin in a partial OpenShift
    Container Platform environment using the Helm chart. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the oc-mirror command to mirror resources directly to your accessible
    local registry and apply the generated cluster resources. You have set up your
    disconnected environment using a local registry. You have permissions to push
    NPM packages to an NPM server available in your restricted network. You have installed
    the oc mirror tool, with a version corresponding to the version of your OpenShift
    Container Platform cluster. 1. Create an ImageSetConfiguration file for oc-mirror.
    You must include the images and operators required by the Serverless Logic Operator
    in the ImageSetConfiguration file, as oc-mirror does not automatically mirror
    all images. Use the following example: ```yaml apiVersion: mirror.openshift.io/v2alpha1
    kind: ImageSetConfiguration mirror: additionalimages: name: registry.redhat.io/openshift
    serverless 1/logic jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` 2. Mirror the images in the ImageSetConfiguration.yaml
    file by running the oc-mirror command to pull images and charts, and push the
    images directly to the target registry. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 ``` [NOTE] ---- The oc-mirror command pulls the charts
    listed in the ImageSetConfiguration file and makes them available as tgz archives
    under the <workspace folder> directory. ---- 3. Apply the generated cluster resources
    to the disconnected cluster. For example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 4. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    5. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 6. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 7. Apply the RHDH 1.8 Helm'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:40:02.607029'
    uuid: 573aa07b-780c-4e6b-9e39-fb38f7ac22eb
  response: You must have the oc mirror tool installed, with a version corresponding
    to the version of your OpenShift Container Platform cluster.
  user_input: what version oc mirror tool i need for OpenShift Container Platform?
- context:
  - 'url:port> - workspace file://<workspace folder> - authfile /path/to/authfile
    ``` where: <mirror-archive-file>:: Enter the name of the transferred tar file.
    <target-registry-url:port>:: Enter your local registry, for example, registry.localhost:5000.
    6. Download the Node Package Manager (NPM) packages for orchestrator 1.8.0 using
    any of the following methods: * Download them as tgz files from the following
    registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 9. Apply the RHDH 1.8 Helm chart. Include the
    version 1.8.0 and enable the Orchestrator plugin, as shown in the following example:
    ```yaml orchestrator.enabled=true ``` 10. The RHDH 1.8 Helm chart defaults to
    pulling Orchestrator plugins from the official Red Hat NPM registry using full
    URL references. You must override this behavior to point to your local registry.
    To configure the Orchestrator plugins to use a custom registry, complete the following
    steps: * Open your values.yaml file. * Explicitly list the Orchestrator plugin
    packages under the orchestrator.plugins section. You must replace the simplified
    package references with the full URLs that point to your custom NPM registry,
    as shown in the following example: ```yaml orchestrator: plugins: disabled: false
    package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    backend dynamic/ /backstage plugin orchestrator backend dynamic {product bundle
    version}.tgz integrity: sha512 xxxxxx disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator/ /backstage plugin orchestrator {product bundle version}.tgz
    integrity: sha512 xxxxxy disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator form widgets/ /backstage plugin orchestrator form widgets
    {product bundle version}.tgz integrity: sha512 xxxxxz disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin scaffolder backend
    module orchestrator dynamic/ /backstage plugin scaffolder backend module orchestrator
    dynamic {product bundle version}.tgz integrity: sha512 xxxx1 ``` where: <custom_NPM_registry_URL>::
    Enter the address of your custom registry and make sure the integrity checksum,
    such as sha512-xxxxxx, matches the files in your registry. Restart the RHDH Pod
    and wait for the components to deploy properly. After deployment is complete,
    go to the RHDH UI and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Helm chart You can install
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin in a partial OpenShift
    Container Platform environment using the Helm chart. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the oc-mirror command to mirror resources directly to your accessible
    local registry and apply the generated cluster resources. You have set up your
    disconnected environment using a local registry. You have permissions to push
    NPM packages to an NPM server available in your restricted network. You have installed
    the oc mirror tool, with a version corresponding to the version of your OpenShift
    Container Platform cluster. 1. Create an ImageSetConfiguration file for oc-mirror.
    You must include the images and operators required by the Serverless Logic Operator
    in the ImageSetConfiguration file, as oc-mirror does not automatically mirror
    all images. Use the following example: ```yaml apiVersion: mirror.openshift.io/v2alpha1
    kind: ImageSetConfiguration mirror: additionalimages: name: registry.redhat.io/openshift
    serverless 1/logic jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` 2. Mirror the images in the ImageSetConfiguration.yaml
    file by running the oc-mirror command to pull images and charts, and push the
    images directly to the target registry. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 ``` [NOTE] ---- The oc-mirror command pulls the charts
    listed in the ImageSetConfiguration file and makes them available as tgz archives
    under the <workspace folder> directory. ---- 3. Apply the generated cluster resources
    to the disconnected cluster. For example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 4. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    5. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 6. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 7. Apply the RHDH 1.8 Helm'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:40:15.680617'
    uuid: 5296766e-ab16-472d-bfb8-21e92827b86c
  response: To configure the Orchestrator plugins to use a custom registry, you must
    override the default behavior of the RHDH 1.8 Helm chart, which pulls from the
    official Red Hat NPM registry. This is accomplished by opening your values.yaml
    file and explicitly listing the Orchestrator plugin packages under the orchestrator.plugins
    section. Within this section, you must replace the simplified package references
    with the full URLs that point to your custom NPM registry, and ensure the integrity
    checksum matches the files in your registry.
  user_input: How is the Orchestrator plugin configured to use a custom NPM registry?
- context:
  - 'url:port> - workspace file://<workspace folder> - authfile /path/to/authfile
    ``` where: <mirror-archive-file>:: Enter the name of the transferred tar file.
    <target-registry-url:port>:: Enter your local registry, for example, registry.localhost:5000.
    6. Download the Node Package Manager (NPM) packages for orchestrator 1.8.0 using
    any of the following methods: * Download them as tgz files from the following
    registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 9. Apply the RHDH 1.8 Helm chart. Include the
    version 1.8.0 and enable the Orchestrator plugin, as shown in the following example:
    ```yaml orchestrator.enabled=true ``` 10. The RHDH 1.8 Helm chart defaults to
    pulling Orchestrator plugins from the official Red Hat NPM registry using full
    URL references. You must override this behavior to point to your local registry.
    To configure the Orchestrator plugins to use a custom registry, complete the following
    steps: * Open your values.yaml file. * Explicitly list the Orchestrator plugin
    packages under the orchestrator.plugins section. You must replace the simplified
    package references with the full URLs that point to your custom NPM registry,
    as shown in the following example: ```yaml orchestrator: plugins: disabled: false
    package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    backend dynamic/ /backstage plugin orchestrator backend dynamic {product bundle
    version}.tgz integrity: sha512 xxxxxx disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator/ /backstage plugin orchestrator {product bundle version}.tgz
    integrity: sha512 xxxxxy disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator form widgets/ /backstage plugin orchestrator form widgets
    {product bundle version}.tgz integrity: sha512 xxxxxz disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin scaffolder backend
    module orchestrator dynamic/ /backstage plugin scaffolder backend module orchestrator
    dynamic {product bundle version}.tgz integrity: sha512 xxxx1 ``` where: <custom_NPM_registry_URL>::
    Enter the address of your custom registry and make sure the integrity checksum,
    such as sha512-xxxxxx, matches the files in your registry. Restart the RHDH Pod
    and wait for the components to deploy properly. After deployment is complete,
    go to the RHDH UI and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Helm chart You can install
    Red Hat Developer Hub (RHDH) with the Orchestrator plugin in a partial OpenShift
    Container Platform environment using the Helm chart. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the oc-mirror command to mirror resources directly to your accessible
    local registry and apply the generated cluster resources. You have set up your
    disconnected environment using a local registry. You have permissions to push
    NPM packages to an NPM server available in your restricted network. You have installed
    the oc mirror tool, with a version corresponding to the version of your OpenShift
    Container Platform cluster. 1. Create an ImageSetConfiguration file for oc-mirror.
    You must include the images and operators required by the Serverless Logic Operator
    in the ImageSetConfiguration file, as oc-mirror does not automatically mirror
    all images. Use the following example: ```yaml apiVersion: mirror.openshift.io/v2alpha1
    kind: ImageSetConfiguration mirror: additionalimages: name: registry.redhat.io/openshift
    serverless 1/logic jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 helm: repositories: name: openshift
    charts url: https://charts.openshift.io charts: name: redhat developer hub version:
    "1.8.0" name: redhat developer hub orchestrator infra version: "1.8.0" operators:
    catalog: registry.redhat.io/redhat/redhat operator index:4.19 # For example: registry.redhat.io/redhat/redhat
    operator index:v4.19 packages: name: logic operator rhel8 channels: name: alpha
    minVersion: 1.36.0 maxVersion: 1.36.0 name: serverless operator channels: name:
    stable minVersion: 1.36.0 maxVersion: 1.36.1 ``` 2. Mirror the images in the ImageSetConfiguration.yaml
    file by running the oc-mirror command to pull images and charts, and push the
    images directly to the target registry. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 ``` [NOTE] ---- The oc-mirror command pulls the charts
    listed in the ImageSetConfiguration file and makes them available as tgz archives
    under the <workspace folder> directory. ---- 3. Apply the generated cluster resources
    to the disconnected cluster. For example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 4. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    5. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 6. Apply the redhat-developer-hub-orchestrator-infra
    Helm chart and approve the install plans. See Air-gapped installation with Helm
    chart instructions for details. 7. Apply the RHDH 1.8 Helm'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:40:25.216108'
    uuid: 5678752c-a929-424c-981c-0f18aed9d472
  response: 'You can download the Node Package Manager (NPM) packages for orchestrator
    1.8.0 using one of two methods. You can download them as tgz files from the following
    URLs: https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz,
    https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz,
    https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz,
    and https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz.
    Alternatively, you can use the `npm pack` command with the Red Hat NPM registry,
    as shown in these examples: `npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com`, `npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com`,
    `npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com`, and `npm pack "@redhat/backstage
    plugin orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com`.'
  user_input: How can I download the Orchestrator 1.8.0 NPM packages from the Red
    Hat registry for a disconnected installation?
- context:
  - 'chart. Include the version 1.8.0 and enable the Orchestrator plugin, as shown
    in the following example: ```yaml orchestrator.enabled=true ``` 8. The RHDH 1.8
    Helm chart defaults to pulling Orchestrator plugins from the official Red Hat
    NPM registry using full URL references. You must override this behavior to point
    to your local registry. To configure the Orchestrator plugins to use a custom
    registry, complete the following steps: * Open your values.yaml file. * Explicitly
    list the Orchestrator plugin packages under the orchestrator.plugins section.
    You must replace the simplified package references with the full URLs that point
    to your custom NPM registry, as shown in the following example: ```yaml orchestrator:
    plugins: disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator backend dynamic/ /backstage plugin orchestrator backend dynamic
    {product bundle version}.tgz integrity: sha512 xxxxxx disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator/ /backstage
    plugin orchestrator {product bundle version}.tgz integrity: sha512 xxxxxy disabled:
    false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    form widgets/ /backstage plugin orchestrator form widgets {product bundle version}.tgz
    integrity: sha512 xxxxxz disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin scaffolder backend module orchestrator dynamic/ /backstage plugin scaffolder
    backend module orchestrator dynamic {product bundle version}.tgz integrity: sha512
    xxxx1 ``` where: <custom_NPM_registry_URL>:: Enter the address of your custom
    registry and make sure the integrity checksum, such as sha512-xxxxxx, matches
    the files in your registry. Restart the RHDH pod and wait for the components to
    deploy properly. After deployment is complete, go to the RHDH UI and confirm that
    the Orchestrator UI is accessible and functioning correctly. [NOTE] ---- The successful
    accessibility of the Orchestrator UI confirms that the underlying components are
    running and the cluster recognizes the plugin. ---- # Installing Orchestrator
    plugin in an air-gapped environment with the Operator You can configure Red Hat
    Developer Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially
    disconnected environment by using the Operator. ## Installing Red Hat Developer
    Hub with Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Operator You can install Red Hat Developer Hub with Orchestrator plugin
    in a fully air-gapped environment using the Operator. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the helper script to install Red Hat Developer Hub by mirroring the
    Operator-related images to disk and transferring them to your disconnected environment
    without any connection to the internet. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a fully disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman commands to find
    the missing images and add them to the additionalimages list if the versions change:
    ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command generates a local workspace containing the mirror archive
    files and the required cluster manifests. ---- 3. Transfer the directory specified
    by /path/to/mirror-archive to a bastion host within your disconnected environment.
    4. From the bastion host which has access to the mirror registry, mirror the images
    from the disk directory to your target registry. For example: ```yaml oc mirror
    - v2 - from <mirror archive file> docker://<target registry url:port> - workspace
    file://<workspace folder> - authfile /path/to/authfile ``` where: <mirror-archive-file>::
    Enter the name of the transferred tar file. <target-registry-url:port>:: Enter
    your local registry, for example, registry.localhost:5000. 5. Apply the cluster-wide
    resources generated during the push step to redirect all image pulls to your local
    registry, as shown in the following example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 6. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 9. Create
    a Backstage custom resource (CR). 10. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:40:32.974420'
    uuid: f9bacfb6-342f-4ea3-b100-d7f13dc07c54
  response: You can install Red Hat Developer Hub with the Orchestrator plugin in
    a fully air-gapped environment using the Operator. A helper script can be used
    to install Red Hat Developer Hub by mirroring the Operator-related images to disk
    and then transferring them to your disconnected environment without any internet
    connection. This method of disconnected installation prevents unauthorized access,
    data transfer, or communication with external sources.
  user_input: What is the procedure for installing the Red Hat Developer Hub with
    the Orchestrator plugin in a fully disconnected environment using the Operator?
- context:
  - 'chart. Include the version 1.8.0 and enable the Orchestrator plugin, as shown
    in the following example: ```yaml orchestrator.enabled=true ``` 8. The RHDH 1.8
    Helm chart defaults to pulling Orchestrator plugins from the official Red Hat
    NPM registry using full URL references. You must override this behavior to point
    to your local registry. To configure the Orchestrator plugins to use a custom
    registry, complete the following steps: * Open your values.yaml file. * Explicitly
    list the Orchestrator plugin packages under the orchestrator.plugins section.
    You must replace the simplified package references with the full URLs that point
    to your custom NPM registry, as shown in the following example: ```yaml orchestrator:
    plugins: disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator backend dynamic/ /backstage plugin orchestrator backend dynamic
    {product bundle version}.tgz integrity: sha512 xxxxxx disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator/ /backstage
    plugin orchestrator {product bundle version}.tgz integrity: sha512 xxxxxy disabled:
    false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    form widgets/ /backstage plugin orchestrator form widgets {product bundle version}.tgz
    integrity: sha512 xxxxxz disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin scaffolder backend module orchestrator dynamic/ /backstage plugin scaffolder
    backend module orchestrator dynamic {product bundle version}.tgz integrity: sha512
    xxxx1 ``` where: <custom_NPM_registry_URL>:: Enter the address of your custom
    registry and make sure the integrity checksum, such as sha512-xxxxxx, matches
    the files in your registry. Restart the RHDH pod and wait for the components to
    deploy properly. After deployment is complete, go to the RHDH UI and confirm that
    the Orchestrator UI is accessible and functioning correctly. [NOTE] ---- The successful
    accessibility of the Orchestrator UI confirms that the underlying components are
    running and the cluster recognizes the plugin. ---- # Installing Orchestrator
    plugin in an air-gapped environment with the Operator You can configure Red Hat
    Developer Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially
    disconnected environment by using the Operator. ## Installing Red Hat Developer
    Hub with Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Operator You can install Red Hat Developer Hub with Orchestrator plugin
    in a fully air-gapped environment using the Operator. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the helper script to install Red Hat Developer Hub by mirroring the
    Operator-related images to disk and transferring them to your disconnected environment
    without any connection to the internet. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a fully disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman commands to find
    the missing images and add them to the additionalimages list if the versions change:
    ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command generates a local workspace containing the mirror archive
    files and the required cluster manifests. ---- 3. Transfer the directory specified
    by /path/to/mirror-archive to a bastion host within your disconnected environment.
    4. From the bastion host which has access to the mirror registry, mirror the images
    from the disk directory to your target registry. For example: ```yaml oc mirror
    - v2 - from <mirror archive file> docker://<target registry url:port> - workspace
    file://<workspace folder> - authfile /path/to/authfile ``` where: <mirror-archive-file>::
    Enter the name of the transferred tar file. <target-registry-url:port>:: Enter
    your local registry, for example, registry.localhost:5000. 5. Apply the cluster-wide
    resources generated during the push step to redirect all image pulls to your local
    registry, as shown in the following example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 6. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 9. Create
    a Backstage custom resource (CR). 10. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:40:41.804928'
    uuid: 660fcdcf-99ac-41b8-a2f9-db8e6bead5b8
  response: 'To install Red Hat Developer Hub with the Orchestrator plugin in a fully
    disconnected environment using the Operator, you must first meet the prerequisites
    of having mirrored the RHDH Operator images to a local registry, set up the disconnected
    environment with a local registry, possess permissions to push NPM packages to
    an NPM server on the restricted network, and have the oc mirror tool installed.
    The process is as follows: 1. Create an ImageSetConfiguration file for oc-mirror,
    including the necessary images and operators for the Serverless Logic Operator.
    2. Mirror the images from the configuration file by running the `oc mirror` command.
    3. Transfer the generated mirror archive directory to a bastion host within the
    disconnected environment. 4. From the bastion host, mirror the images from the
    disk directory to your target registry. 5. Apply the generated cluster-wide resources
    to redirect all image pulls to your local registry. 6. Download the NPM packages
    for orchestrator 1.8.0, either as tgz files from the Red Hat registry or by using
    the `npm pack` command. 7. Push the downloaded NPM packages to your NPM server.
    8. Install the OpenShift Serverless Operator and OpenShift Serverless Logic Operators
    through OperatorHub. 9. Create a Backstage custom resource (CR). 10. Configure
    the Backstage CR for the Orchestrator.'
  user_input: What are the detailed steps for installing the Red Hat Developer Hub
    with the Orchestrator plugin in a fully disconnected, air-gapped OpenShift Container
    Platform environment using the Operator?
- context:
  - 'chart. Include the version 1.8.0 and enable the Orchestrator plugin, as shown
    in the following example: ```yaml orchestrator.enabled=true ``` 8. The RHDH 1.8
    Helm chart defaults to pulling Orchestrator plugins from the official Red Hat
    NPM registry using full URL references. You must override this behavior to point
    to your local registry. To configure the Orchestrator plugins to use a custom
    registry, complete the following steps: * Open your values.yaml file. * Explicitly
    list the Orchestrator plugin packages under the orchestrator.plugins section.
    You must replace the simplified package references with the full URLs that point
    to your custom NPM registry, as shown in the following example: ```yaml orchestrator:
    plugins: disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin orchestrator backend dynamic/ /backstage plugin orchestrator backend dynamic
    {product bundle version}.tgz integrity: sha512 xxxxxx disabled: false package:
    <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator/ /backstage
    plugin orchestrator {product bundle version}.tgz integrity: sha512 xxxxxy disabled:
    false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage plugin orchestrator
    form widgets/ /backstage plugin orchestrator form widgets {product bundle version}.tgz
    integrity: sha512 xxxxxz disabled: false package: <custom_NPM_registry_URL>[:<port>]/@redhat/backstage
    plugin scaffolder backend module orchestrator dynamic/ /backstage plugin scaffolder
    backend module orchestrator dynamic {product bundle version}.tgz integrity: sha512
    xxxx1 ``` where: <custom_NPM_registry_URL>:: Enter the address of your custom
    registry and make sure the integrity checksum, such as sha512-xxxxxx, matches
    the files in your registry. Restart the RHDH pod and wait for the components to
    deploy properly. After deployment is complete, go to the RHDH UI and confirm that
    the Orchestrator UI is accessible and functioning correctly. [NOTE] ---- The successful
    accessibility of the Orchestrator UI confirms that the underlying components are
    running and the cluster recognizes the plugin. ---- # Installing Orchestrator
    plugin in an air-gapped environment with the Operator You can configure Red Hat
    Developer Hub (RHDH) with the Orchestrator plugin in a fully disconnected or partially
    disconnected environment by using the Operator. ## Installing Red Hat Developer
    Hub with Orchestrator in a fully disconnected OpenShift Container Platform environment
    using the Operator You can install Red Hat Developer Hub with Orchestrator plugin
    in a fully air-gapped environment using the Operator. A disconnected installation
    prevents unauthorized access, data transfer, or communication with external sources.
    You can use the helper script to install Red Hat Developer Hub by mirroring the
    Operator-related images to disk and transferring them to your disconnected environment
    without any connection to the internet. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a fully disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use podman commands to find
    the missing images and add them to the additionalimages list if the versions change:
    ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=ImageSetConfiguration.yaml
    file:///path/to/mirror archive - authfile /path/to/authfile - v2 ``` [NOTE] ----
    The oc-mirror command generates a local workspace containing the mirror archive
    files and the required cluster manifests. ---- 3. Transfer the directory specified
    by /path/to/mirror-archive to a bastion host within your disconnected environment.
    4. From the bastion host which has access to the mirror registry, mirror the images
    from the disk directory to your target registry. For example: ```yaml oc mirror
    - v2 - from <mirror archive file> docker://<target registry url:port> - workspace
    file://<workspace folder> - authfile /path/to/authfile ``` where: <mirror-archive-file>::
    Enter the name of the transferred tar file. <target-registry-url:port>:: Enter
    your local registry, for example, registry.localhost:5000. 5. Apply the cluster-wide
    resources generated during the push step to redirect all image pulls to your local
    registry, as shown in the following example: ```terminal cd <workspace folder>/working
    dir/cluster resources/ oc apply f . ``` 6. Download the Node Package Manager (NPM)
    packages for orchestrator 1.8.0 using any of the following methods: * Download
    them as tgz files from the following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    7. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 8. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 9. Create
    a Backstage custom resource (CR). 10. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:40:55.380609'
    uuid: b43d6fa1-b6ed-41c5-96a5-9da22a64dc83
  response: To configure the Orchestrator plugins to use a custom registry, you must
    open your values.yaml file and explicitly list the Orchestrator plugin packages
    under the orchestrator.plugins section. You need to replace the simplified package
    references with the full URLs that point to your custom NPM registry, ensuring
    the integrity checksum matches the files. To get the packages, you can download
    the Node Package Manager (NPM) packages for orchestrator 1.8.0 as tgz files from
    the Red Hat registry or use the `npm pack` command. After downloading, you must
    push the NPM packages to your NPM server using the `npm publish` command for each
    .tgz file.
  user_input: How do I configure the Orchestrator plugin to use our custom NPM regstry
    and what are the steps to get the pakages there?
- context:
  - 'configure the Backstage instance accordingly. See Configuring a custom NPM registry
    for instructions on how to point RHDH towards the custom NPM registry. Restart
    the RHDH pod and wait for the components to deploy properly. Once stable, go to
    the RHDH UI, and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Operator You can install Red
    Hat Developer Hub with Orchestrator plugin in a partial air-gapped environment
    using the Operator. A disconnected installation prevents unauthorized access,
    data transfer, or communication with external sources. You can use the oc-mirror
    command to mirror resources directly to your accessible local mirror registry
    and apply the generated cluster resources. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a partially disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use the podman commands to
    find the missing images and add them to the additionalimages list if the versions
    change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36.0-8
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 cd <workspace folder>/working dir/cluster resources/ oc
    apply f . ``` 3. Download the Node Package Manager (NPM) packages for orchestrator
    1.8.0 using any of the following methods: * Download them as tgz files from the
    following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    4. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 5. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 6. Create
    a Backstage custom resource (CR). 7. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and configure the Backstage instance accordingly. See
    Configuring a custom NPM registry for instructions on how to point RHDH towards
    the custom NPM registry. Restart the RHDH pod and wait for the components to deploy
    properly. Once stable, go to the RHDH UI, and confirm that the Orchestrator UI
    is accessible and functioning correctly. [NOTE] ---- The successful accessibility
    of the Orchestrator UI confirms that the underlying components are running and
    the cluster recognizes the plugin. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:41:05.242723'
    uuid: 8169ce55-d1ac-4e87-babc-0371fef18258
  response: After downloading the Node Package Manager (NPM) packages, you must push
    them to your NPM server. Next, install the OpenShift Serverless Operator and OpenShift
    Serverless Logic Operators using OperatorHub. You then need to create a Backstage
    custom resource (CR) and configure it for the Orchestrator. This involves creating
    all the resources, configuring the Backstage instance, and pointing RHDH towards
    the custom NPM registry. To complete the process, restart the RHDH pod, wait for
    the components to deploy, and once stable, go to the RHDH UI to confirm that the
    Orchestrator UI is accessible and functioning correctly.
  user_input: I've got all the NPM packages for the orchestrator plugin downloaded,
    but I'm a bit confused on the next steps, can you tell me what I need to do to
    properly configure the Backstge custom resourse and get it running in our disconected
    OpenShift envirnment?
- context:
  - 'configure the Backstage instance accordingly. See Configuring a custom NPM registry
    for instructions on how to point RHDH towards the custom NPM registry. Restart
    the RHDH pod and wait for the components to deploy properly. Once stable, go to
    the RHDH UI, and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Operator You can install Red
    Hat Developer Hub with Orchestrator plugin in a partial air-gapped environment
    using the Operator. A disconnected installation prevents unauthorized access,
    data transfer, or communication with external sources. You can use the oc-mirror
    command to mirror resources directly to your accessible local mirror registry
    and apply the generated cluster resources. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a partially disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use the podman commands to
    find the missing images and add them to the additionalimages list if the versions
    change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36.0-8
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 cd <workspace folder>/working dir/cluster resources/ oc
    apply f . ``` 3. Download the Node Package Manager (NPM) packages for orchestrator
    1.8.0 using any of the following methods: * Download them as tgz files from the
    following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    4. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 5. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 6. Create
    a Backstage custom resource (CR). 7. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and configure the Backstage instance accordingly. See
    Configuring a custom NPM registry for instructions on how to point RHDH towards
    the custom NPM registry. Restart the RHDH pod and wait for the components to deploy
    properly. Once stable, go to the RHDH UI, and confirm that the Orchestrator UI
    is accessible and functioning correctly. [NOTE] ---- The successful accessibility
    of the Orchestrator UI confirms that the underlying components are running and
    the cluster recognizes the plugin. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:41:13.901035'
    uuid: 4777fd7a-4409-4f40-8e1b-26c7f3a3f27d
  response: "To install Red Hat Developer Hub with the Orchestrator plugin in a partially\
    \ disconnected OpenShift Container Platform environment, you must first meet several\
    \ prerequisites: you have mirrored the RHDH Operator images to a local registry,\
    \ set up a disconnected environment with a local registry, have permissions to\
    \ push NPM packages to an NPM server on your network, and have installed the oc\
    \ mirror tool corresponding to your cluster's version. The installation process\
    \ is as follows: \n1. Create an ImageSetConfiguration file for oc-mirror, ensuring\
    \ you include the images and operators required by the Serverless Logic Operator.\
    \ \n2. Mirror the images specified in the ImageSetConfiguration.yaml file by running\
    \ the `oc-mirror` command, and then apply the generated cluster resources. \n\
    3. Download the Node Package Manager (NPM) packages for orchestrator 1.8.0, either\
    \ as tgz files from the provided URLs or by using `npm pack` commands. \n4. Push\
    \ the downloaded NPM packages to your NPM server using the `npm publish` command.\
    \ \n5. Install the OpenShift Serverless Operator and OpenShift Serverless Logic\
    \ Operators through the OperatorHub. \n6. Create a Backstage custom resource (CR).\
    \ \n7. Configure the Backstage CR for the Orchestrator, create all necessary resources,\
    \ and configure the Backstage instance, including pointing it to your custom NPM\
    \ registry. Finally, restart the RHDH pod and verify that the Orchestrator UI\
    \ is accessible and functioning correctly."
  user_input: What are the detailed steps for installing Red Hat Developer Hub with
    the Orchestrator plugin in a partially disconnected OpenShift Container Platform
    environment using the Operator?
- context:
  - 'configure the Backstage instance accordingly. See Configuring a custom NPM registry
    for instructions on how to point RHDH towards the custom NPM registry. Restart
    the RHDH pod and wait for the components to deploy properly. Once stable, go to
    the RHDH UI, and confirm that the Orchestrator UI is accessible and functioning
    correctly. [NOTE] ---- The successful accessibility of the Orchestrator UI confirms
    that the underlying components are running and the cluster recognizes the plugin.
    ---- ## Installing Red Hat Developer Hub with Orchestrator in a partially disconnected
    OpenShift Container Platform environment using the Operator You can install Red
    Hat Developer Hub with Orchestrator plugin in a partial air-gapped environment
    using the Operator. A disconnected installation prevents unauthorized access,
    data transfer, or communication with external sources. You can use the oc-mirror
    command to mirror resources directly to your accessible local mirror registry
    and apply the generated cluster resources. You have mirrored the Red Hat Developer
    Hub Operator images to the local registry using the RHDH mirroring script. For
    more information, see Installing Red Hat Developer Hub in a partially disconnected
    environment with the Operator. You have set up your disconnected environment using
    a local registry. You have permissions to push NPM packages to an NPM server available
    in your restricted network. You have installed the oc mirror tool, with a version
    corresponding to the version of your OpenShift Container Platform cluster. 1.
    Create an ImageSetConfiguration file for oc-mirror. You must include the images
    and operators required by the Serverless Logic Operator in the ImageSetConfiguration
    file, as oc-mirror does not automatically mirror all images. Use the following
    example: ```yaml apiVersion: mirror.openshift.io/v2alpha1 kind: ImageSetConfiguration
    mirror: additionalimages: name: registry.redhat.io/openshift serverless 1/logic
    jobs service postgresql rhel8:1.36.0 name: registry.redhat.io/openshift serverless
    1/logic jobs service ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index postgresql rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic data index ephemeral rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic db migrator tool rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf builder rhel8:1.36.0 name: registry.redhat.io/openshift
    serverless 1/logic swf devmode rhel8:1.36.0 operators: catalog: registry.redhat.io/redhat/redhat
    operator index:4.19 # For example: registry.redhat.io/redhat/redhat operator index:v4.19
    packages: name: logic operator rhel8 channels: name: alpha minVersion: 1.36.0
    maxVersion: 1.36.0 name: serverless operator channels: name: stable minVersion:
    1.36.0 maxVersion: 1.36.1 ``` Alternatively, you can use the podman commands to
    find the missing images and add them to the additionalimages list if the versions
    change: ```terminal IMG=registry.redhat.io/openshift-serverless-1/logic-operator-bundle:1.36.0-8
    mkdir local-manifests-osl podman create --name temp-container "$IMG" -c "cat /manifests/logic-operator-rhel8.clusterserviceversion.yaml"
    podman cp temp-container:/manifests ./local-manifests-osl podman rm temp-container
    yq -r ''.data."controllers_cfg.yaml" | from_yaml | .. | select(tag == "!!str")
    | select(test("^.\\/.:.*$"))'' ./local-manifests-osl/manifests/logic-operator-rhel8-controllers-config_v1_configmap.yaml
    ``` 2. Mirror the images in the ImageSetConfiguration.yaml file by running the
    oc-mirror command. For example: ```terminal oc mirror - config=imagesetconfiguration.yaml
    docker://<registry URL:port> - workspace file://<workspace folder> - authfile
    /path/to/authfile - v2 cd <workspace folder>/working dir/cluster resources/ oc
    apply f . ``` 3. Download the Node Package Manager (NPM) packages for orchestrator
    1.8.0 using any of the following methods: * Download them as tgz files from the
    following registry: * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator/-/backstage-plugin-orchestrator-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-backend-dynamic/-/backstage-plugin-orchestrator-backend-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic/-/backstage-plugin-scaffolder-backend-module-orchestrator-dynamic-1.8.0.tgz
    * https://npm.registry.redhat.com/@redhat/backstage-plugin-orchestrator-form-widgets/-/backstage-plugin-orchestrator-form-widgets-1.8.0.tgz
    * Alternatively, use the NPM packages from Red Hat NPM registry as shown in the
    following example: ``` npm pack "@redhat/backstage plugin orchestrator@1.8.0"
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator backend dynamic@1.8.0" - registry=https://npm.registry.redhat.com
    npm pack "@redhat/backstage plugin scaffolder backend module orchestrator dynamic@1.8.0
    - registry=https://npm.registry.redhat.com npm pack "@redhat/backstage plugin
    orchestrator form widgets@1.8.0" - registry=https://npm.registry.redhat.com ```
    4. Push the NPM packages you have downloaded to your NPM server, as shown in the
    following example: ``` npm publish backstage plugin orchestrator 1.8.0.tgz npm
    publish backstage plugin orchestrator backend dynamic 1.8.0.tgz npm publish backstage
    plugin orchestrator form widgets 1.8.0.tgz npm publish backstage plugin scaffolder
    backend module orchestrator dynamic 1.8.0.tgz ``` 5. Install the OpenShift Serverless
    Operator and OpenShift Serverless Logic Operators using OperatorHub. 6. Create
    a Backstage custom resource (CR). 7. Configure the Backstage CR for the Orchestrator
    as described in the Orchestrator plugin dependencies for Operator installation.
    Create all the resources and configure the Backstage instance accordingly. See
    Configuring a custom NPM registry for instructions on how to point RHDH towards
    the custom NPM registry. Restart the RHDH pod and wait for the components to deploy
    properly. Once stable, go to the RHDH UI, and confirm that the Orchestrator UI
    is accessible and functioning correctly. [NOTE] ---- The successful accessibility
    of the Orchestrator UI confirms that the underlying components are running and
    the cluster recognizes the plugin. ----'
  metadata:
    classification:
      category: installation
      datetime: '2025-12-10T16:41:24.097565'
    uuid: 776d4819-a0ea-4990-82b3-1b2ab8f00e54
  response: You can install Red Hat Developer Hub with the Orchestrator plugin in
    a partial air-gapped OpenShift Container Platform environment using the Operator,
    which prevents unauthorized access and communication with external sources. The
    process involves using the oc-mirror command to mirror resources to your local
    mirror registry and applying the generated cluster resources. You will need to
    create an ImageSetConfiguration file, mirror the images, download and push the
    necessary Node Package Manager (NPM) packages to your server, install the OpenShift
    Serverless and Serverless Logic Operators, and then create and configure a Backstage
    custom resource (CR).
  user_input: how do i instal RHDH on a disconected OpenShift Container Platfrom?
- context:
  - '# Introduction to plugins # Plugins in Red Hat Developer Hub The Red Hat Developer
    Hub (RHDH) application offers a unified platform with various plugins. Using the
    plugin ecosystem within the RHDH application, you can access any kind of development
    infrastructure or software development tool. Plugins are modular extensions for
    RHDH that extend functionality, streamline development workflows, and improve
    the developer experience. You can add and configure plugins in RHDH to access
    various software development tools. Each plugin is designed as a self-contained
    application and can incorporate any type of content. The plugins utilize a shared
    set of platform APIs and reusable UI components. Plugins can also retrieve data
    from external sources through APIs or by relying on external modules to perform
    the tasks. RHDH provides both static and dynamic plugins that enhance its functionality.
    Static plugins are integrated into the core of the RHDH application, while dynamic
    plugins can be sideloaded into your Developer Hub instance without the need to
    recompile your code or rebuild the container. To install or update a static plugin
    you must update your RHDH application source code and rebuild the application
    and container image. To install or update a dynamic plugin, you must restart your
    RHDH application source code after installing the plugin. You can also import
    your own custom-built or custom plugins or create new features using dynamic plugins.
    Dynamic plugins boost modularity and scalability by enabling more flexible and
    efficient functionality loading, significantly enhancing the developer experience
    and customization of your RHDH instance. ## Dynamic plugins in Red Hat Developer
    Hub You can use RHDH dynamic plugins in environments where flexibility, scalability,
    and customization are key. Using dynamic plugins in RHDH provides: Modularity
    and extensibility:: You can add or modify features without altering the core RHDH
    application. This modular approach makes it easier to extend functionality as
    needs evolve. Customization:: You can tailor RHDH to fit specific workflows and
    use cases, enhancing the overall user experience. Reduced maintenance and update
    overhead:: You can deploy the updates or new features independently of the main
    RHDH codebase, reducing the risks and efforts associated with maintaining and
    updating the platform. Faster iteration:: You can create and test new features
    more rapidly as plugins, encouraging experimentation and enabling you to quickly
    iterate based on feedback. Improved collaboration:: You can share plugins across
    teams or even externally. This sharing can foster collaboration and reduce duplication
    of effort, as well as help establish best practices across an organization. Scalability::
    As organizations grow, their needs become complex. Dynamic plugins enable RHDH
    to scale alongside such complex needs, accommodating an increasing number of users
    and services. Ecosystem growth:: Fostering the development of plugins can create
    a dynamic ecosystem around RHDH. This community can contribute to plugins that
    cater to different needs, thereby enhancing the platform. Security and compliance::
    You can develop plugins with specific security and compliance requirements in
    mind, ensuring that RHDH installations meet the necessary standards without compromising
    the core application. Overall, the use of dynamic plugins in RHDH promotes a flexible,
    adaptable, and sustainable approach to managing and scaling development infrastructure.
    ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:41:32.226065'
    uuid: dc3c5ea0-cbbf-4901-b311-b34f6cd2c7cb
  response: In Red Hat Developer Hub (RHDH), plugins are modular extensions that extend
    functionality, streamline development workflows, and improve the developer experience,
    allowing you to access any kind of development infrastructure or software development
    tool. Each plugin is designed as a self-contained application that utilizes a
    shared set of platform APIs and reusable UI components. RHDH provides both static
    and dynamic plugins. Static plugins are integrated into the core of the RHDH application,
    and to install or update one, you must update your RHDH application source code
    and rebuild the application and container image. Dynamic plugins can be sideloaded
    into your Developer Hub instance without needing to recompile your code or rebuild
    the container; you only need to restart your RHDH application after installing
    the plugin to install or update it.
  user_input: how do plugins work in Red Hat Developer Hub for add new tools and what
    is the different kinds?
- context:
  - '# Introduction to plugins # Plugins in Red Hat Developer Hub The Red Hat Developer
    Hub (RHDH) application offers a unified platform with various plugins. Using the
    plugin ecosystem within the RHDH application, you can access any kind of development
    infrastructure or software development tool. Plugins are modular extensions for
    RHDH that extend functionality, streamline development workflows, and improve
    the developer experience. You can add and configure plugins in RHDH to access
    various software development tools. Each plugin is designed as a self-contained
    application and can incorporate any type of content. The plugins utilize a shared
    set of platform APIs and reusable UI components. Plugins can also retrieve data
    from external sources through APIs or by relying on external modules to perform
    the tasks. RHDH provides both static and dynamic plugins that enhance its functionality.
    Static plugins are integrated into the core of the RHDH application, while dynamic
    plugins can be sideloaded into your Developer Hub instance without the need to
    recompile your code or rebuild the container. To install or update a static plugin
    you must update your RHDH application source code and rebuild the application
    and container image. To install or update a dynamic plugin, you must restart your
    RHDH application source code after installing the plugin. You can also import
    your own custom-built or custom plugins or create new features using dynamic plugins.
    Dynamic plugins boost modularity and scalability by enabling more flexible and
    efficient functionality loading, significantly enhancing the developer experience
    and customization of your RHDH instance. ## Dynamic plugins in Red Hat Developer
    Hub You can use RHDH dynamic plugins in environments where flexibility, scalability,
    and customization are key. Using dynamic plugins in RHDH provides: Modularity
    and extensibility:: You can add or modify features without altering the core RHDH
    application. This modular approach makes it easier to extend functionality as
    needs evolve. Customization:: You can tailor RHDH to fit specific workflows and
    use cases, enhancing the overall user experience. Reduced maintenance and update
    overhead:: You can deploy the updates or new features independently of the main
    RHDH codebase, reducing the risks and efforts associated with maintaining and
    updating the platform. Faster iteration:: You can create and test new features
    more rapidly as plugins, encouraging experimentation and enabling you to quickly
    iterate based on feedback. Improved collaboration:: You can share plugins across
    teams or even externally. This sharing can foster collaboration and reduce duplication
    of effort, as well as help establish best practices across an organization. Scalability::
    As organizations grow, their needs become complex. Dynamic plugins enable RHDH
    to scale alongside such complex needs, accommodating an increasing number of users
    and services. Ecosystem growth:: Fostering the development of plugins can create
    a dynamic ecosystem around RHDH. This community can contribute to plugins that
    cater to different needs, thereby enhancing the platform. Security and compliance::
    You can develop plugins with specific security and compliance requirements in
    mind, ensuring that RHDH installations meet the necessary standards without compromising
    the core application. Overall, the use of dynamic plugins in RHDH promotes a flexible,
    adaptable, and sustainable approach to managing and scaling development infrastructure.
    ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:41:38.700791'
    uuid: 4b21eb0c-d0c3-4b95-8e09-0a3dcbc492f7
  response: In the Red Hat Developer Hub (RHDH) application, plugins are modular extensions
    that extend functionality, streamline development workflows, and improve the developer
    experience. They allow users to access any kind of development infrastructure
    or software development tool. Each plugin is a self-contained application that
    utilizes a shared set of platform APIs and reusable UI components, and can retrieve
    data from external sources through APIs or external modules.
  user_input: What is the function of plugins within the RHDH application?
- context:
  - '# Introduction to plugins # Plugins in Red Hat Developer Hub The Red Hat Developer
    Hub (RHDH) application offers a unified platform with various plugins. Using the
    plugin ecosystem within the RHDH application, you can access any kind of development
    infrastructure or software development tool. Plugins are modular extensions for
    RHDH that extend functionality, streamline development workflows, and improve
    the developer experience. You can add and configure plugins in RHDH to access
    various software development tools. Each plugin is designed as a self-contained
    application and can incorporate any type of content. The plugins utilize a shared
    set of platform APIs and reusable UI components. Plugins can also retrieve data
    from external sources through APIs or by relying on external modules to perform
    the tasks. RHDH provides both static and dynamic plugins that enhance its functionality.
    Static plugins are integrated into the core of the RHDH application, while dynamic
    plugins can be sideloaded into your Developer Hub instance without the need to
    recompile your code or rebuild the container. To install or update a static plugin
    you must update your RHDH application source code and rebuild the application
    and container image. To install or update a dynamic plugin, you must restart your
    RHDH application source code after installing the plugin. You can also import
    your own custom-built or custom plugins or create new features using dynamic plugins.
    Dynamic plugins boost modularity and scalability by enabling more flexible and
    efficient functionality loading, significantly enhancing the developer experience
    and customization of your RHDH instance. ## Dynamic plugins in Red Hat Developer
    Hub You can use RHDH dynamic plugins in environments where flexibility, scalability,
    and customization are key. Using dynamic plugins in RHDH provides: Modularity
    and extensibility:: You can add or modify features without altering the core RHDH
    application. This modular approach makes it easier to extend functionality as
    needs evolve. Customization:: You can tailor RHDH to fit specific workflows and
    use cases, enhancing the overall user experience. Reduced maintenance and update
    overhead:: You can deploy the updates or new features independently of the main
    RHDH codebase, reducing the risks and efforts associated with maintaining and
    updating the platform. Faster iteration:: You can create and test new features
    more rapidly as plugins, encouraging experimentation and enabling you to quickly
    iterate based on feedback. Improved collaboration:: You can share plugins across
    teams or even externally. This sharing can foster collaboration and reduce duplication
    of effort, as well as help establish best practices across an organization. Scalability::
    As organizations grow, their needs become complex. Dynamic plugins enable RHDH
    to scale alongside such complex needs, accommodating an increasing number of users
    and services. Ecosystem growth:: Fostering the development of plugins can create
    a dynamic ecosystem around RHDH. This community can contribute to plugins that
    cater to different needs, thereby enhancing the platform. Security and compliance::
    You can develop plugins with specific security and compliance requirements in
    mind, ensuring that RHDH installations meet the necessary standards without compromising
    the core application. Overall, the use of dynamic plugins in RHDH promotes a flexible,
    adaptable, and sustainable approach to managing and scaling development infrastructure.
    ##'
  metadata:
    classification:
      category: plugins
      datetime: '2025-12-10T16:41:45.759998'
    uuid: bb5669ee-88ec-4ad6-a10a-7c7db64ec251
  response: The Red Hat Developer Hub (RHDH) application offers a unified platform
    with various plugins that can be used to access any kind of development infrastructure
    or software development tool. These plugins are modular extensions that extend
    functionality, streamline development workflows, and improve the developer experience.
  user_input: what do Red Hat Developer Hub do for us?
metadata:
  classification:
    dataset_size: 501
    model: gemini-2.5-pro
    provider: google
    temperature: 0.5
  generation:
    dataset_size: 501
    datetime: '2025-12-10T12:08:24.811133'
    embedding_model: sentence-transformers/all-mpnet-base-v2
    generation_type: synthetic_ragas
    max_tokens: null
    model: gemini-2.5-pro
    provider: google
    synthesizer_name: single_hop_specific_query_synthesizer
    temperature: 0.5
  human_validated: false
